title,place,company,posting_date,link,job_description,jd_html,seniority_level,job_function,employment_type,industries
Data Engineer,"Los Angeles, CA",Snap Inc.,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-snap-inc-2418271091?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=xTMvU60DcYjxASpqpMh10Q%3D%3D&position=1&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Enginee r to join Team Snap Inc! As a member of the People Tech team, you will lead and build the People Team Data infrastructure. Working from our Santa Monica, CA headquarters, you’ll collaborate with the HR Technology and IT Teams to build robust systems and processes to help drive our business forward!


What you’ll do:


Work closely with IT, HRIS, & People Analytics to influence the build the HR data infrastructure
Collaboration cross-functionally with other engineers and product managers to develop the best data practices in line with things we value.
Grow the technical expertise of the People Tech Team
Help cultivate agile methodologies and foster a culture of balanced tech health
Ensure accuracy and timeliness of data is maintained in the data layer
Actively participate in Data Governance efforts.
Knowledge, Skills & Abilities:


Experience cultivating a strong engineering culture in an agile environment
Proven engineering background with previous experience developing large scale systems for data engineering, including processing, storage, quality and management
In-depth knowledge of agile software processes, data-driven development, reliability, and responsible experimentation
Proven track record of collaborating with other teams on relevant topics such as data science, and software systems design
Minimum Qualifications:


BS/BA degree in Computer Science, Math, Physics, or related field, or equivalent experience in a relevant field
5+ years working as a Software Engineering or in relevant field
5+ years experience in SQL or similar languages.
5+ years development experience in at least one object-oriented language (Python, Perl, Java, etc.)
2+ years of technical people management experience
Preferred Qualifications:


Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture experience
Experience in ETL / Data application development
Experience working with a MapReduce or an MPP system

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com .
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.<br><br>We’re looking for a Data Enginee r to join Team Snap Inc! As a member of the People Tech team, you will lead and build the People Team Data infrastructure. Working from our Santa Monica, CA headquarters, you’ll collaborate with the HR Technology and IT Teams to build robust systems and processes to help drive our business forward!<br><br><ul><li><strong>What you’ll do:<br><br></strong><ul><li> Work closely with IT, HRIS, &amp; People Analytics to influence the build the HR data infrastructure </li><li> Collaboration cross-functionally with other engineers and product managers to develop the best data practices in line with things we value. </li><li> Grow the technical expertise of the People Tech Team </li><li> Help cultivate agile methodologies and foster a culture of balanced tech health </li><li> Ensure accuracy and timeliness of data is maintained in the data layer </li><li> Actively participate in Data Governance efforts. </li></ul></li><li><strong>Knowledge, Skills &amp; Abilities:<br><br></strong><ul><li> Experience cultivating a strong engineering culture in an agile environment </li><li> Proven engineering background with previous experience developing large scale systems for data engineering, including processing, storage, quality and management </li><li> In-depth knowledge of agile software processes, data-driven development, reliability, and responsible experimentation </li><li> Proven track record of collaborating with other teams on relevant topics such as data science, and software systems design </li></ul></li></ul><ul><li><strong>Minimum Qualifications: <br><br></strong><ul><li> BS/BA degree in Computer Science, Math, Physics, or related field, or equivalent experience in a relevant field </li><li> 5+ years working as a Software Engineering or in relevant field </li><li> 5+ years experience in SQL or similar languages. </li><li> 5+ years development experience in at least one object-oriented language (Python, Perl, Java, etc.) </li><li> 2+ years of technical people management experience </li></ul></li></ul><ul><li><strong>Preferred Qualifications:<br><br></strong><ul><li> Hands on experience with Google BigQuery </li><li> Experience in version control systems such as Git </li><li> Data architecture experience </li><li> Experience in ETL / Data application development </li><li> Experience working with a MapReduce or an MPP system <br></li></ul></li></ul>At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at <u>accommodations-ext@snap.com</u> .</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"New York, NY",DigitalOcean,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-digitalocean-2417229955?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=v9sC13052lftGDHDuiQGPw%3D%3D&position=2&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Enginee r to join Team Snap Inc! As a member of the People Tech team, you will lead and build the People Team Data infrastructure. Working from our Santa Monica, CA headquarters, you’ll collaborate with the HR Technology and IT Teams to build robust systems and processes to help drive our business forward!


What you’ll do:


Work closely with IT, HRIS, & People Analytics to influence the build the HR data infrastructure
Collaboration cross-functionally with other engineers and product managers to develop the best data practices in line with things we value.
Grow the technical expertise of the People Tech Team
Help cultivate agile methodologies and foster a culture of balanced tech health
Ensure accuracy and timeliness of data is maintained in the data layer
Actively participate in Data Governance efforts.
Knowledge, Skills & Abilities:


Experience cultivating a strong engineering culture in an agile environment
Proven engineering background with previous experience developing large scale systems for data engineering, including processing, storage, quality and management
In-depth knowledge of agile software processes, data-driven development, reliability, and responsible experimentation
Proven track record of collaborating with other teams on relevant topics such as data science, and software systems design
Minimum Qualifications:


BS/BA degree in Computer Science, Math, Physics, or related field, or equivalent experience in a relevant field
5+ years working as a Software Engineering or in relevant field
5+ years experience in SQL or similar languages.
5+ years development experience in at least one object-oriented language (Python, Perl, Java, etc.)
2+ years of technical people management experience
Preferred Qualifications:


Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture experience
Experience in ETL / Data application development
Experience working with a MapReduce or an MPP system

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com .
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.<br><br>We’re looking for a Data Enginee r to join Team Snap Inc! As a member of the People Tech team, you will lead and build the People Team Data infrastructure. Working from our Santa Monica, CA headquarters, you’ll collaborate with the HR Technology and IT Teams to build robust systems and processes to help drive our business forward!<br><br><ul><li><strong>What you’ll do:<br><br></strong><ul><li> Work closely with IT, HRIS, &amp; People Analytics to influence the build the HR data infrastructure </li><li> Collaboration cross-functionally with other engineers and product managers to develop the best data practices in line with things we value. </li><li> Grow the technical expertise of the People Tech Team </li><li> Help cultivate agile methodologies and foster a culture of balanced tech health </li><li> Ensure accuracy and timeliness of data is maintained in the data layer </li><li> Actively participate in Data Governance efforts. </li></ul></li><li><strong>Knowledge, Skills &amp; Abilities:<br><br></strong><ul><li> Experience cultivating a strong engineering culture in an agile environment </li><li> Proven engineering background with previous experience developing large scale systems for data engineering, including processing, storage, quality and management </li><li> In-depth knowledge of agile software processes, data-driven development, reliability, and responsible experimentation </li><li> Proven track record of collaborating with other teams on relevant topics such as data science, and software systems design </li></ul></li></ul><ul><li><strong>Minimum Qualifications: <br><br></strong><ul><li> BS/BA degree in Computer Science, Math, Physics, or related field, or equivalent experience in a relevant field </li><li> 5+ years working as a Software Engineering or in relevant field </li><li> 5+ years experience in SQL or similar languages. </li><li> 5+ years development experience in at least one object-oriented language (Python, Perl, Java, etc.) </li><li> 2+ years of technical people management experience </li></ul></li></ul><ul><li><strong>Preferred Qualifications:<br><br></strong><ul><li> Hands on experience with Google BigQuery </li><li> Experience in version control systems such as Git </li><li> Data architecture experience </li><li> Experience in ETL / Data application development </li><li> Experience working with a MapReduce or an MPP system <br></li></ul></li></ul>At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at <u>accommodations-ext@snap.com</u> .</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"Remote, OR",Roofstock,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-roofstock-2418220340?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=CsAL0WvsnvUcJdKwWGPLIQ%3D%3D&position=3&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Have you ever wondered what happens inside the cloud?

Based in New York, DigitalOcean is a dynamic, high-growth technology company that serves a robust and passionate community of developers, teams, and businesses around the world. We believe that today’s entrepreneurs are changing the world through software. Our mission is to empower these entrepreneurs by bringing modern app development within reach for any developer, anywhere in the world.

We want people who are passionate about creating experiences that our customers will love.

As a Data Engineer, you will join a growing Data Engineering team within our Engineering Services organization that collaborates with decision-makers across the organization to catalyze business growth by providing insightful and actionable analysis, insights and data products. The Data Engineering team is hands-on with a wide variety of datasets, including user data, product behavior data, financial/payment data, upper-funnel marketing data, trust and safety data, and operational/infrastructure data, and is responsible for leveraging that data into usable analytical products by stakeholders across the company.

What You'll Be Doing

Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale
Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status
Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services
Pioneer initiatives around data quality, integrity, security and governance
Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science



What We'll Expect From You

Bachelor’s degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience.
Experience in custom ETL design, implementation and maintenance
Track record of developing in complex data environments and intelligence platforms for business users
Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts
History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale
Extensive hands-on experience with schema design and dimensional data modeling
Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies
Experience with analytics databases like Snowflake, Redshift, or BigQuery.
Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling
Experience scripting in Go or Python or a similar scripting language.
Effective communication and interpersonal skills
Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus
Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.
Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus
Experience with ephemeral/streaming metrics services (Prometheus, DataDog, etc) and with SLO/SLI driven analytics a big plus.



Why You’ll Like Working For DigitalOcean

We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.
We care about your physical, financial and mental well-being. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match.
We support our remote employee experience. While we have great office spaces in NYC, Cambridge and Palo Alto, we’re very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office.
We value diversity and inclusivity. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.



Department: Engineering

Want to learn more about our Engineering team? Click here!

Want an inside look into life at DO? Click here to hear from our employees!


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Have you ever wondered what happens inside the cloud?<br><br></strong>Based in New York, DigitalOcean is a dynamic, high-growth technology company that serves a robust and passionate community of developers, teams, and businesses around the world. We believe that today’s entrepreneurs are changing the world through software. Our mission is to empower these entrepreneurs by bringing modern app development within reach for any developer, anywhere in the world.<br><br><strong>We want people who are passionate about creating experiences that our customers will love.<br><br></strong>As a Data Engineer, you will join a growing Data Engineering team within our Engineering Services organization that collaborates with decision-makers across the organization to catalyze business growth by providing insightful and actionable analysis, insights and data products. The Data Engineering team is hands-on with a wide variety of datasets, including user data, product behavior data, financial/payment data, upper-funnel marketing data, trust and safety data, and operational/infrastructure data, and is responsible for leveraging that data into usable analytical products by stakeholders across the company.<br><br><strong><u>What You'll Be Doing<br></u></strong><ul> <li>Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale</li> <li>Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status</li> <li>Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services</li> <li>Pioneer initiatives around data quality, integrity, security and governance</li> <li>Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science</li> <br><br></ul><strong><u>What We'll Expect From You<br></u></strong><ul> <li>Bachelor’s degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience. </li> <li>Experience in custom ETL design, implementation and maintenance</li> <li>Track record of developing in complex data environments and intelligence platforms for business users</li> <li>Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts</li> <li>History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale</li> <li>Extensive hands-on experience with schema design and dimensional data modeling</li> <li>Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies</li> <li>Experience with analytics databases like Snowflake, Redshift, or BigQuery. </li> <li>Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling</li> <li>Experience scripting in Go or Python or a similar scripting language.</li> <li>Effective communication and interpersonal skills</li> <li>Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus</li> <li>Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.</li> <li>Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus</li> <li>Experience with ephemeral/streaming metrics services (Prometheus, DataDog, etc) and with SLO/SLI driven analytics a big plus.</li> <br><br></ul><strong><u>Why You’ll Like Working For DigitalOcean<br></u></strong><ul> <li><strong>We value development</strong>. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.</li> <li><strong>We care about your physical, financial and mental well-being</strong>. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match. </li> <li><strong>We support our remote employee experience</strong>. While we have great office spaces in NYC, Cambridge and Palo Alto, we’re very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office.</li> <li><strong>We value diversity and inclusivity</strong>. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</li> <br><br></ul>Department: Engineering<br><br>Want to learn more about our Engineering team? Click here!<br><br>Want an inside look into life at DO? Click here to hear from our employees!<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Engineering",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Fremont, CA",Tesla,2021-01-29,https://www.linkedin.com/jobs/view/data-engineer-at-tesla-2386743105?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=MPutScKBeUNngyoGS1ed7g%3D%3D&position=4&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Roofstock is the leading marketplace for investing in single-family rental homes. Our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace Great Place to Work® and have been recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $135M to date, is based in Oakland, CA and Dallas,TX with approximately 180 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We've built an amazing culture where everyone has a voice. We're nice. We get things done. We have fun. We believe in work-life balance (yes, you can really take a vacation). And our values are pretty B.A.D.A.S.S.

Be customer obsessed.

Act like an owner, because you are one.

Don't be afraid to break things in the pursuit of better.

All of us are empowered to do the right thing.

Stay curious and create what's next. Fast.

Seriously. No jerks.

Analytics at Roofstock is a two way street: sure you use data to answer questions posed by others, but you also formulate and test your own hypothesis, and use you data sense to inform and influence the process. A key outcome of your analysis are the datasets you assemble, focusing on foresight, quality and maintainability are paramount to enable future re-use. You will generate insights from data and build reports/dashboards/visualizations to communicate your results and to encourage future self-serve by our partners.

This is an excellent opportunity to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data analysts, and data scientists, in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

We care you about your career growth so you’ll have opportunities to develop along at least three paths in addition to maturing as an analyst and data architect: data engineering (more data processing and computational systems), data science (more modeling, ML and algorithms) or product (more business). If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, this is the place for you.

What You Will Do

Build code to gather, refine, and transform large diverse datasets into simplified, meaningful, and actionable aggregations

Analyze data, to provide information that supports decision making across the company

Develop reporting workbooks and dashboards in Tableau (and others)

Write robust SQL and sometimes Python code, operating on a modern cloud stack (Snowflake, AWS, Azure)

Some analyses will require basic statistical tests, and prototypes may occasionally involve building basic statistical and machine learning models (regression, random forests, etc.)

Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions

Be responsible for data accuracy and integrity, implement data quality processes, create data dictionaries and data governance policies.

What You Bring With You

BS or MS in computer science, analytics, statistics, economics, engineering, operations research or computational field

3+ years of industry experience writing advanced SQL, developing complicated analysis and creating advanced dashboards in Tableau or other BI/viz tools

Familiar with Python

Bonus skill sets: intermediate/advanced data modeling, R

Structured approach to problem-solving, ability to take a broad challenge and break it down into solvable components, accounting for confounding variables and statistical challenges

Demonstrated ability to work independently, prototype rapidly, iterate quickly and meet deadlines in a fast-paced environment

Strong communication and collaboration skills to effectively explain, influence, and advise with interdisciplinary partners

Experience in data warehousing, dimensional data modeling and tools like Airflow and DBT is a plus

What We Offer

Competitive compensation
Medical, Vision and Dental for you (95%) and your dependents (65%)
401k
Flexible time off and sick days
Supplemental bonus to support ""work from home"" office needs
Equity incentives to give you a stake in the Company’s future
As a remote team we are an upbeat and collaborative work culture
Virtual company-sponsored outings

Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Roofstock is the leading marketplace for investing in single-family rental homes. Our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.<br><br>Roofstock has been recognized as a great workplace Great Place to Work® and have been recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $135M to date, is based in Oakland, CA and Dallas,TX with approximately 180 people and is growing rapidly. Check out our reviews and see why our employees love working here!<br><br>We've built an amazing culture where everyone has a voice. We're nice. We get things done. We have fun. We believe in work-life balance (yes, you can really take a vacation). And our values are pretty B.A.D.A.S.S.<br><br><strong>B</strong>e customer obsessed.<br><br><strong>A</strong>ct like an owner, because you are one.<br><br><strong>D</strong>on't be afraid to break things in the pursuit of better.<br><br><strong>A</strong>ll of us are empowered to do the right thing.<br><br><strong>S</strong>tay curious and create what's next. Fast.<br><br><strong>S</strong>eriously. No jerks.<br><br>Analytics at Roofstock is a two way street: sure you use data to answer questions posed by others, but you also formulate and test your own hypothesis, and use you data sense to inform and influence the process. A key outcome of your analysis are the datasets you assemble, focusing on foresight, quality and maintainability are paramount to enable future re-use. You will generate insights from data and build reports/dashboards/visualizations to communicate your results and to encourage future self-serve by our partners.<br><br>This is an excellent opportunity to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data analysts, and data scientists, in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.<br><br>We care you about your career growth so you’ll have opportunities to develop along at least three paths in addition to maturing as an analyst and data architect: data engineering (more data processing and computational systems), data science (more modeling, ML and algorithms) or product (more business). If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, this is the place for you.<br><br><strong><u>What You Will Do<br><br></u></strong>Build code to gather, refine, and transform large diverse datasets into simplified, meaningful, and actionable aggregations<br><br>Analyze data, to provide information that supports decision making across the company<br><br>Develop reporting workbooks and dashboards in Tableau (and others)<br><br>Write robust SQL and sometimes Python code, operating on a modern cloud stack (Snowflake, AWS, Azure)<br><br>Some analyses will require basic statistical tests, and prototypes may occasionally involve building basic statistical and machine learning models (regression, random forests, etc.)<br><br>Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions<br><br>Be responsible for data accuracy and integrity, implement data quality processes, create data dictionaries and data governance policies.<br><br><strong><u>What You Bring With You<br><br></u></strong>BS or MS in computer science, analytics, statistics, economics, engineering, operations research or computational field<br><br>3+ years of industry experience writing advanced SQL, developing complicated analysis and creating advanced dashboards in Tableau or other BI/viz tools<br><br>Familiar with Python<br><br>Bonus skill sets: intermediate/advanced data modeling, R<br><br>Structured approach to problem-solving, ability to take a broad challenge and break it down into solvable components, accounting for confounding variables and statistical challenges<br><br>Demonstrated ability to work independently, prototype rapidly, iterate quickly and meet deadlines in a fast-paced environment<br><br>Strong communication and collaboration skills to effectively explain, influence, and advise with interdisciplinary partners<br><br>Experience in data warehousing, dimensional data modeling and tools like Airflow and DBT is a plus<br><br><strong><u>What We Offer<br></u></strong><ul><li> Competitive compensation</li><li> Medical, Vision and Dental for you (95%) and your dependents (65%)</li><li> 401k</li><li> Flexible time off and sick days</li><li> Supplemental bonus to support ""work from home"" office needs</li><li> Equity incentives to give you a stake in the Company’s future</li><li> As a remote team we are an upbeat and collaborative work culture</li><li> Virtual company-sponsored outings<br></li></ul><em>Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Internet, Financial Services, Real Estate"
Data Developer/Engineer - Python,"Plano, TX",Capital One,2021-02-13,https://www.linkedin.com/jobs/view/data-developer-engineer-python-at-capital-one-2358591144?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=kMiP3RCQ0E3QtAtdwyQQDw%3D%3D&position=5&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics ! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies.

Technology We Use

Python
Informatica
SQL Server and MySQL
Vertica
Kafka


Your Role

Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result
Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services
Plan effective data storage, security, sharing and publishing within the organization
Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks
Ensures data quality and implements tools and frameworks for automating the identification of data quality issues
Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings
Mentor and lead data engineers providing technical guidance and oversight
Provides ongoing support, monitoring, and maintenance of deployed products


Experience

Qualifications

5 – 8 years of development experience at an Enterprise level in the following tools and languages: Informatica , Python
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Strong background with data modeling, data access, and data storage techniques
Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment
Working experience with Kafka Streaming layer
Experience in Spark Framework on both batch and real-time data processing is a plus
Experience in Big Data Integration & Analytics is a plus
Experience in Supply Chain and Logistics data is a plus
Bachelor’s degree in Computer Science or related field or equivalent combination of industry related professional experience and education
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics ! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies.<br><br><strong><u>Technology We Use<br></u></strong><ul><li>Python</li><li>Informatica</li><li>SQL Server and MySQL</li><li>Vertica</li><li>Kafka<br><br></li></ul><strong><u>Your Role<br></u></strong><ul><li>Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result</li><li>Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services</li><li>Plan effective data storage, security, sharing and publishing within the organization</li><li>Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks</li><li>Ensures data quality and implements tools and frameworks for automating the identification of data quality issues</li><li>Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings</li><li>Mentor and lead data engineers providing technical guidance and oversight</li><li>Provides ongoing support, monitoring, and maintenance of deployed products<br><br></li></ul><strong><u>Experience<br><br></u></strong><strong>Qualifications<br></strong><ul><li>5 – 8 years of development experience at an Enterprise level in the following tools and languages: Informatica , Python</li><li>Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus</li><li>Strong background with data modeling, data access, and data storage techniques</li><li>Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment</li><li>Working experience with Kafka Streaming layer</li><li>Experience in Spark Framework on both batch and real-time data processing is a plus</li><li>Experience in Big Data Integration &amp; Analytics is a plus</li><li>Experience in Supply Chain and Logistics data is a plus</li><li>Bachelor’s degree in Computer Science or related field or equivalent combination of industry related professional experience and education</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Automotive, Renewables & Environment, Utilities"
Data Engineer,"Rochester, NY",Pluralsight,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-pluralsight-2415636114?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=F3ur2%2BxRXi5ud0zHwGS7gw%3D%3D&position=6&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Locations: TX - Plano, United States of America, Plano, Texas

Data Developer/Engineer - Python

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.

We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance


Basic Qualifications

Bachelor’s Degree
At least 2 years of experience in application development
At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)


Preferred Qualifications

Master's Degree
3+ years of experience in application development
1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink
1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service
1+ years of experience with Ansible / Terraform
2+ years of experience with Agile engineering practices
2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of experience developing Java based software solutions
2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
2+ years of experience developing software solutions to solve complex business problems
2+ years of experience with UNIX/Linux including basic commands and shell scripting


At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

Job Category - Information Technology, Engineering, Technology Explorers, Technology Explorers
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Locations: TX - Plano, United States of America, Plano, Texas<br><br>Data Developer/Engineer - Python<br><br>Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,<u>inclusive,</u> and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.<br><br>We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As a<u>Capital One Data Engineer</u>, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about<u>#lifeatcapitalone</u> and our commitment to<u>diversity &amp; inclusion</u> by jumping to<u> slides 76-91</u> on our Corporate Social Responsibility Report.<br><br><strong><u>What You’ll Do<br></u></strong><ul><li>Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies</li><li>Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems</li><li>Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake</li><li>Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal &amp; external technology communities, and mentoring other members of the engineering community</li><li>Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment</li><li>Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance<br><br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li>Bachelor’s Degree </li><li>At least 2 years of experience in application development</li><li>At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)<br><br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Master's Degree </li><li>3+ years of experience in application development</li><li>1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink</li><li>1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service</li><li>1+ years of experience with Ansible / Terraform</li><li>2+ years of experience with Agile engineering practices </li><li>2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase) </li><li>2+ years of experience with NoSQL implementation (Mongo, Cassandra) </li><li>2+ years of experience developing Java based software solutions </li><li>2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell) </li><li>2+ years of experience developing software solutions to solve complex business problems</li><li>2+ years of experience with UNIX/Linux including basic commands and shell scripting<br><br></li></ul>At this time, Capital One will not sponsor a new applicant for employment authorization for this position.<br><br>Job Category - Information Technology, Engineering, Technology Explorers, Technology Explorers</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Engineering",Full-time,"Banking, Financial Services, Investment Banking"
Big Data Engineer (Python),"Chicago, IL",Tiger Analytics,2021-02-17,https://www.linkedin.com/jobs/view/big-data-engineer-python-at-tiger-analytics-2416413640?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=7V0lynrdD7swK%2Fk6DXixyw%3D%3D&position=7&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"This position is available for remote employment in these areas:Draper UT, Remote - California (Bay Area), Remote - Illinois (Chicago), Remote - New Jersey (NYC Metro Area), Remote - New York, Remote - New York (New York City), Remote - Washington (Seattle)Job Description:
Our Data Engineering & Operations team is a force multiplier for data practitioners at Pluralsight. We provide tooling and data sets to make Pluralsight a data-driven organization. Our work includes: building pipelines which curate and land data, deploying data science models, and maintaining data infrastructure. You’ll have the opportunity to work with data tools, like Python and Spark, as well as web analytics and streaming data from our data platform.

Who You’re Committed To Being

You utilize a multidisciplinary approach to providing solutions for the business, combining technical, analytical, and domain knowledge.
You have strong development skills, experience transforming and profiling data
You understand the benefits and risks of a variety of data technology solutions, which guide your implementation decisions.
You love interfacing with data scientists and analysts to understand their needs.
You have an eagerness to dive in to data sources to understand availability, utility, and integrity of our data


What You’ll Own

Building and maintaining production data pipelines for data science and analytics
Developing tooling and solutions for data practitioners using a deep understanding of their objectives and pain points
Modeling and curating product data sets, such as web analytics and kafka topics
Improving observability in our data environment, including uptime, usage, data quality, and data freshness
Building production applications from data science research and exploratory analytical work


Experience You’ll Need

5+ years of taking a multidisciplinary approach to data development: we emphasize picking the right tool for the job
Deep experience with a number of data tools: e.g. SQL, Spark, Hadoop, Python
Managed systems with complex dependency management and orchestration requirements
Strong capability to manipulate and analyze complex, high-volume data from a variety of sources
Effective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward language
Ability to problem solve independently and prioritize work based on the anticipated business value


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><strong>This position is available for remote employment in these areas:</strong></strong>Draper UT, Remote - California (Bay Area), Remote - Illinois (Chicago), Remote - New Jersey (NYC Metro Area), Remote - New York, Remote - New York (New York City), Remote - Washington (Seattle)<strong><u><strong>Job Description:<br></strong></u></strong><em>Our Data Engineering &amp; Operations team is a force multiplier for data practitioners at Pluralsight. We provide tooling and data sets to make Pluralsight a data-driven organization. </em><em>Our work includes: building pipelines which curate and land data, deploying data science models, and maintaining data infrastructure. You’ll have the opportunity to work with data tools, like Python and Spark, as well as web analytics and streaming data from our data platform.<br><br></em><strong><u>Who You’re Committed To Being<br></u></strong><ul><li><em>You utilize a multidisciplinary approach to providing solutions for the business, combining technical, analytical, and domain knowledge.</em></li><li><em>You have strong development skills, experience transforming and profiling data</em></li><li><em>You understand the benefits and risks of a variety of data technology solutions, which guide your implementation decisions.</em></li><li><em>You love interfacing with data scientists and analysts to understand their needs.</em></li><li><em>You have an eagerness to dive in to data sources to understand availability, utility, and integrity of our data <br><br></em></li></ul><strong><u>What You’ll Own<br></u></strong><ul><li><em>Building and maintaining production data pipelines for data science and analytics</em></li><li><em>Developing tooling and solutions for data practitioners using a deep understanding of their objectives and pain points</em></li><li><em>Modeling and curating product data sets, such as web analytics and kafka topics</em></li><li><em>Improving observability in our data environment, including uptime, usage, data quality, and data freshness</em></li><li><em>Building production applications from data science research and exploratory analytical work<br><br></em></li></ul><strong><u>Experience You’ll Need<br></u></strong><ul><li><em>5+ years of taking a multidisciplinary approach to data development: we emphasize picking the right tool for the job</em></li><li><em>Deep experience with a number of data tools: e.g. SQL, Spark, Hadoop, Python</em></li><li><em>Managed systems with complex dependency management and orchestration requirements</em></li><li><em>Strong capability to manipulate and analyze complex, high-volume data from a variety of sources</em></li><li><em>Effective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward language</em></li><li><em>Ability to problem solve independently and prioritize work based on the anticipated business value<br><br></em></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,United States,Nextuple Inc,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-nextuple-inc-2415630388?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=iA0abFI67DEsvUm%2BfDrV8w%3D%3D&position=8&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Description

Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

An Engineer with 5+ years of experience and will ensure data quality, creation of new data pipelines, optimization and management of existing data pipelines, ingestion and curation of data sources for analytical purposes, and transformations of structured and unstructured data into formats suitable for machine learning and advanced analytics. The Engineer will work on deployment and making sure products are production-ready and function smoothly.

Requirements

Strong Python engineering skills and SQL skills
Ability to Clean, easy to maintain, modify and support code
Proficient in Python best practices, logging and strong debugging skills
Understanding of Python environments, package management
Strong basic SQL knowledge, able to read and understand SQL handed off
Able to do standard SQL joins, filtering, etc
Experience in Distributed computing frameworks such as Spark and Dask
Able to work independently and ask for guidance when needed
Strong communication skills and delivery focused
Familiar with git source control
Understanding the pre-processing analytical methods is a plus
Bachelor’s degree in Computer Science or closely related field



Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.<br><br>An Engineer with 5+ years of experience and will ensure data quality, creation of new data pipelines, optimization and management of existing data pipelines, ingestion and curation of data sources for analytical purposes, and transformations of structured and unstructured data into formats suitable for machine learning and advanced analytics. The Engineer will work on deployment and making sure products are production-ready and function smoothly.<br><br><strong><u>Requirements<br></u></strong><ul> <li>Strong Python engineering skills and SQL skills</li> <li>Ability to Clean, easy to maintain, modify and support code </li> <li>Proficient in Python best practices, logging and strong debugging skills</li> <li>Understanding of Python environments, package management</li> <li>Strong basic SQL knowledge, able to read and understand SQL handed off</li> <li>Able to do standard SQL joins, filtering, etc</li> <li>Experience in Distributed computing frameworks such as Spark and Dask</li> <li>Able to work independently and ask for guidance when needed</li> <li>Strong communication skills and delivery focused</li> <li>Familiar with git source control</li> <li>Understanding the pre-processing analytical methods is a plus</li> <li>Bachelor’s degree in Computer Science or closely related field</li> <br><br></ul><strong><u>Benefits<br><br></u></strong>Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Management Consulting"
Data Engineer,"San Jose, CA",Slalom,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-slalom-2418261953?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=VXydlrib2spcBF4rW7X3rQ%3D%3D&position=9&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Nextuple is helping retailers deliver perfect post purchase experiences to customers using AI/ML tools that are integrated with our products. We are looking for a Data-ML Engineer who can help us with building data ingestion pipelines, constructing  ML infrastructure, building research models and developing A/B testing procedures for ML models. This role is a full time opportunity based in the US or Canada. 




Responsibilities

Data mining using state-of-the-art methods
Work with multiple stakeholders to facilitate preprocessing, analysis of data.
Apply state of the art research techniques to derive insights and spot trends
Using machine learning techniques to correlate customer behavior to historical data
Developing testing strategies
Ad-hoc analysis and presenting results




Skills and Qualifications

Experience in large scale data processing, preferably with Spark
Knowledge of multi processing and cluster programming techniques.
Excellent understanding of common data science toolkits
Experience with data visualisation tools
Experience with SQL and NoSQL databases, such as MongoDB, Cassandra, HBase.
Excellent applied statistics skills, such as distributions, statistical testing, regression, etc.




Job Requirements

At least 2-4 years relevant working experience
Masters or PhD degree in computer science, operations research, statistics, mathematics, or equivalent fields
Solid theoretical foundations and industry experience in large scale data analysis/platforms, machine learning, sales forecasting.
Experience in machine learning libraries such as Tensorflow, Keras, PyTorch and Scikit-learn
Solid programming skills in SQL, Java, Python and Scala
Ability to consume research papers and convert them into quick proof of concepts 
Passionate about technology, demonstrates ability to generate new ideas and innovations; excellent in self-learning, problem analysis and solving; works independently and is proactive
Good interpersonal and communication skills, including the ability to describe the logic and complex models to stakeholders.

If you possess the skills and are passionate about joining a growing team with phenomenal potential, we would love to chat with you.  Please send us your resume via careers@nextuple.com

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Nextuple is helping retailers deliver perfect post purchase experiences to customers using AI/ML tools that are integrated with our products. We are looking for a Data-ML Engineer who can help us with building data ingestion pipelines, constructing&nbsp; ML infrastructure, building research models and developing A/B testing procedures for ML models. This role is a full time opportunity based in the US or Canada.&nbsp;</p><p><br></p><p><strong>Responsibilities</strong></p><ul><li>Data mining using state-of-the-art methods</li><li>Work with multiple stakeholders to facilitate preprocessing, analysis of data.</li><li>Apply state of the art research techniques to derive insights and spot trends</li><li>Using machine learning techniques to correlate customer behavior to historical data</li><li>Developing testing strategies</li><li>Ad-hoc analysis and presenting results</li></ul><p><br></p><p><strong>Skills and Qualifications</strong></p><ul><li>Experience in large scale data processing, preferably with Spark</li><li>Knowledge of multi processing and cluster programming techniques.</li><li>Excellent understanding of common data science toolkits</li><li>Experience with data visualisation tools</li><li>Experience with SQL and NoSQL databases, such as MongoDB, Cassandra, HBase.</li><li>Excellent applied statistics skills, such as distributions, statistical testing, regression, etc.</li></ul><p><br></p><p><strong>Job Requirements</strong></p><ul><li>At least 2-4 years relevant working experience</li><li>Masters or PhD degree in computer science, operations research, statistics, mathematics, or equivalent fields</li><li>Solid theoretical foundations and industry experience in large scale data analysis/platforms, machine learning, sales forecasting.</li><li>Experience in machine learning libraries such as Tensorflow, Keras, PyTorch and Scikit-learn</li><li>Solid programming skills in SQL, Java, Python and Scala</li><li>Ability to consume research papers and convert them into quick proof of concepts&nbsp;</li><li>Passionate about technology, demonstrates ability to generate new ideas and innovations; excellent in self-learning, problem analysis and solving; works independently and is proactive</li><li>Good interpersonal and communication skills, including the ability to describe the logic and complex models to stakeholders.</li></ul><p>If you possess the skills and are passionate about joining a growing team with phenomenal potential, we would love to chat with you.&nbsp;&nbsp;Please send us your resume via careers@nextuple.com</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Technology and Services
Data Engineer,"Denver, CO",Olive,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-olive-2427178007?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=Q19VPNRHNd8zddy2gEfGLA%3D%3D&position=10&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Slalom is a purpose-driven consulting firm that helps companies solve business problems and build for the future, with solutions spanning business advisory, customer experience, technology, and analytics. We partner with companies to push the boundaries of what’s possible—together.

Founded in 2001 and headquartered in Seattle, WA, Slalom has organically grown to over 8,500 employees. We were named one of Fortune’s 100 Best Companies to Work For five consecutive years from 2016 - 2020 and are regularly recognized by our employees as a best place to work. You can find us in 35 cities across the U.S., U.K., Australia, and Canada.

The Data & Analytics teams across Slalom Northern California are all hiring! Come make an impact with our East Bay, Sacramento, San Francisco, or Silicon Valley markets.

Data Engineer

As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver data pipelines and data models for our clients. You will design and build highly scalable and reliable modern data platforms including data lakes and data warehouse using Amazon Web Services, Azure, Google Cloud. Your work will include a variety of core data warehousing platforms like Hadoop, Snowflake, Redshift, etc. and core pipelining languages like Python, Spark, etc. and use modern orchestration engines like Airflow, Luigi, Jenkins, etc. In addition to building the next generation of data platforms, you'll be working with some of the most forward-thinking organizations in data and analytics.

Who are you?

You have passion for data!
You’re a smart, collaborative person who is excited about technology and driven to get things done.
You’re not afraid to be bring your authentic self to work.
You embrace a continuous learner mentality.

Who are we?

We are engineers, makers, planners, architects, and designers.
We choose to imagine things made better, and then set out on a journey to realize what’s possible.
We’ll never trade the upside of wonder for the comfort of the familiar or the safety of convention.

What technologies will you be using?

Every element of a modern data & analytics stack. It’s about using the right technologies to tackle problems and playing with new technologies to determine how to apply them intelligently. We work with technologies across the board.

Why do we work here?

Each of us came to Slalom because we wanted something different. We wanted to make a difference, we wanted autonomy to own and drive our future while partnering with the best companies in Silicon Valley using the coolest technologies. At Slalom, we found our people.

Qualifications

Deep programming skills in one of modern object-oriented data pipelining languages like Python or Java
Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins)
Experience with workflow orchestration platforms such as Airflow, Glue and Dataflow
Understanding of different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.)
Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality
Familiarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)
Understanding of agile project approaches and methodologies
Understanding of basic testing types
Experience working with SQL on relational databases
Strong aptitude for learning new technologies and analytics techniques
Strong analytical problem-solving ability
Self-starter with the ability to work independently or as part of a project team
Capability to conduct performance analysis, troubleshooting and remediation

Slalom Is An Equal Opportunity Employer And All Qualified Applicants Will Receive Consideration For Employment Without Regard To Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected By Law.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Slalom is a purpose-driven consulting firm that helps companies solve business problems and build for the future, with solutions spanning business advisory, customer experience, technology, and analytics. We partner with companies to push the boundaries of what’s possible—together.<br><br>Founded in 2001 and headquartered in Seattle, WA, Slalom has organically grown to over 8,500 employees. We were named one of Fortune’s 100 Best Companies to Work For five consecutive years from 2016 - 2020 and are regularly recognized by our employees as a best place to work. You can find us in 35 cities across the U.S., U.K., Australia, and Canada.<br><br>The Data &amp; Analytics teams across Slalom Northern California are all hiring! Come make an impact with our East Bay, Sacramento, San Francisco, or Silicon Valley markets.<br><br><strong>Data Engineer<br><br></strong>As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver data pipelines and data models for our clients. You will design and build highly scalable and reliable modern data platforms including data lakes and data warehouse using Amazon Web Services, Azure, Google Cloud. Your work will include a variety of core data warehousing platforms like Hadoop, Snowflake, Redshift, etc. and core pipelining languages like Python, Spark, etc. and use modern orchestration engines like Airflow, Luigi, Jenkins, etc. In addition to building the next generation of data platforms, you'll be working with some of the most forward-thinking organizations in data and analytics.<br><br><strong>Who are you?<br></strong><ul><li> You have passion for data! </li><li> You’re a smart, collaborative person who is excited about technology and driven to get things done. </li><li> You’re not afraid to be bring your authentic self to work. </li><li> You embrace a continuous learner mentality. <br></li></ul><strong>Who are we?<br></strong><ul><li> We are engineers, makers, planners, architects, and designers. </li><li> We choose to imagine things made better, and then set out on a journey to realize what’s possible. </li><li> We’ll never trade the upside of wonder for the comfort of the familiar or the safety of convention. <br></li></ul><strong>What technologies will you be using?<br><br></strong>Every element of a modern data &amp; analytics stack. It’s about using the right technologies to tackle problems and playing with new technologies to determine how to apply them intelligently. We work with technologies across the board.<br><br><strong>Why do we work here?<br><br></strong>Each of us came to Slalom because we wanted something different. We wanted to make a difference, we wanted autonomy to own and drive our future while partnering with the best companies in Silicon Valley using the coolest technologies. At Slalom, we found our people.<br><br><strong><u>Qualifications<br></u></strong><ul><li> Deep programming skills in one of modern object-oriented data pipelining languages like Python or Java </li><li> Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins) </li><li> Experience with workflow orchestration platforms such as Airflow, Glue and Dataflow </li><li> Understanding of different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.) </li><li> Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality </li><li> Familiarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression) </li><li> Understanding of agile project approaches and methodologies </li><li> Understanding of basic testing types </li><li> Experience working with SQL on relational databases </li><li> Strong aptitude for learning new technologies and analytics techniques </li><li> Strong analytical problem-solving ability </li><li> Self-starter with the ability to work independently or as part of a project team </li><li> Capability to conduct performance analysis, troubleshooting and remediation <br></li></ul>Slalom Is An Equal Opportunity Employer And All Qualified Applicants Will Receive Consideration For Employment Without Regard To Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected By Law.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"South Jordan, UT",Cricut,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-cricut-2429427544?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=Qr7qoNFvJ%2FByeptvOeahSg%3D%3D&position=11&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Description

Olive’s AI workforce is built to fix our broken healthcare system by addressing healthcare’s most burdensome issues -- delivering hospitals and health systems increased revenue, reduced costs, and increased capacity. People feel lost in the system today and healthcare employees are essentially working in the dark due to outdated technology that creates a lack of shared knowledge and siloed data. Olive is designed to drive connections, shining a new light on the broken healthcare processes that stand between providers and patient care. She uses AI to reveal life-changing insights that make healthcare more efficient, affordable and effective. Olive’s vision is to unleash a trillion dollars of hidden potential within healthcare by connecting its disconnected systems. Olive is improving healthcare operations today, so everyone can benefit from a healthier industry tomorrow.

Olive is made possible by a technology platform which allows her to understand the data emanating from the work that she does and to use that data to get smarter over time. Data Engineers work with the Olive Product Management team to deliver features that allow Olive to store and process large amounts of data. They also work on developing new tools that allow our teams to gain insight into the work Olive is doing and deliver ever increasing value back to our customers. Our team gives Data Engineers the ability to help develop an internal data streaming service that delivers high impact insights to the organization. As part of our mission our team creates visualizations and models to identify anomalies. A successful Data Engineer will possess strong analytical as well as technical skills, and have the ability to communicate the logic behind technical decisions to non-technical stakeholders.

Responsibilities (to Include But Not Limited To)

Collaborate with Engineers, Analysts, and Product Managers to design and implement features
Ability to meet deadlines and satisfy requirements from stakeholders
Peer review and code review participation to provide valuable feedback during every step of the development process
Quickly produce well-organized, optimized, and documented code
Communicate effectively and efficiently across all divisions including with the business, technical teams, and leaders
Take technical ownership of tasks and successfully work independently
Demonstrate the ability to become a domain expert in projects
Mentor and lead junior engineers on multiple tasks or projects



Requirements

Bachelor’s in Computer Science, Computer Engineering, or relevant equivalent experience
5+ years of relevant programming experience
4+ years of SQL experience
1-2+ years of Streaming Data and Analytics experience
Experience with data visualization through tools such as Tableau
Some experience with data modeling
Experience with the Telegraf, Grafana, InfluxDB, and Flink or other time series analysis stack
AWS experience preferred (Kinesis, S3, IAM)
History of designing and delivering software solutions to real world problems across a variety of technology stacks and programming languages with deep experience in several modern programming languages (e.g. JavaScript, Python, Go, JVM based languages)
Strong communication, critical thinking, and problem solving skills
Demonstrated understanding of fundamentals engineering concepts
Knowledge of software and application design and architecture
Experience writing and reviewing detailed Technical Design Documents (TDDs) is a plus
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>Olive’s AI workforce is built to fix our broken healthcare system by addressing healthcare’s most burdensome issues -- delivering hospitals and health systems increased revenue, reduced costs, and increased capacity. People feel lost in the system today and healthcare employees are essentially working in the dark due to outdated technology that creates a lack of shared knowledge and siloed data. Olive is designed to drive connections, shining a new light on the broken healthcare processes that stand between providers and patient care. She uses AI to reveal life-changing insights that make healthcare more efficient, affordable and effective. Olive’s vision is to unleash a trillion dollars of hidden potential within healthcare by connecting its disconnected systems. Olive is improving healthcare operations today, so everyone can benefit from a healthier industry tomorrow.<br><br>Olive is made possible by a technology platform which allows her to understand the data emanating from the work that she does and to use that data to get smarter over time. Data Engineers work with the Olive Product Management team to deliver features that allow Olive to store and process large amounts of data. They also work on developing new tools that allow our teams to gain insight into the work Olive is doing and deliver ever increasing value back to our customers. Our team gives Data Engineers the ability to help develop an internal data streaming service that delivers high impact insights to the organization. As part of our mission our team creates visualizations and models to identify anomalies. A successful Data Engineer will possess strong analytical as well as technical skills, and have the ability to communicate the logic behind technical decisions to non-technical stakeholders.<br><br><strong><u>Responsibilities (to Include But Not Limited To)<br></u></strong><ul> <li>Collaborate with Engineers, Analysts, and Product Managers to design and implement features</li> <li>Ability to meet deadlines and satisfy requirements from stakeholders</li> <li>Peer review and code review participation to provide valuable feedback during every step of the development process</li> <li>Quickly produce well-organized, optimized, and documented code</li> <li>Communicate effectively and efficiently across all divisions including with the business, technical teams, and leaders</li> <li>Take technical ownership of tasks and successfully work independently</li> <li>Demonstrate the ability to become a domain expert in projects</li> <li>Mentor and lead junior engineers on multiple tasks or projects</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Bachelor’s in Computer Science, Computer Engineering, or relevant equivalent experience</li> <li>5+ years of relevant programming experience</li> <li>4+ years of SQL experience</li> <li>1-2+ years of Streaming Data and Analytics experience</li> <li>Experience with data visualization through tools such as Tableau</li> <li>Some experience with data modeling</li> <li>Experience with the Telegraf, Grafana, InfluxDB, and Flink or other time series analysis stack</li> <li>AWS experience preferred (Kinesis, S3, IAM)</li> <li>History of designing and delivering software solutions to real world problems across a variety of technology stacks and programming languages with deep experience in several modern programming languages (e.g. JavaScript, Python, Go, JVM based languages)</li> <li>Strong communication, critical thinking, and problem solving skills </li> <li>Demonstrated understanding of fundamentals engineering concepts</li> <li>Knowledge of software and application design and architecture</li> </ul>Experience writing and reviewing detailed Technical Design Documents (TDDs) is a plus</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Python Data Engineer,"New York, NY","Take-Two Interactive Software, Inc.",2021-01-26,https://www.linkedin.com/jobs/view/python-data-engineer-at-take-two-interactive-software-inc-2215706321?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=SiSeF%2BTEy6Wp7gqMoDesZA%3D%3D&position=12&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Cricut® is looking for a Data Engineer to join our Data Platform team supporting the future of AI/ML. The ideal candidate will design, build, and integrate data from various resources, and manage big data pipelines that are easily accessible with optimized performance of Cricut®'s big data ecosystem.

The ideal candidate is an experienced data wrangler who will support our software developers, database architects and data analysts on business initiatives. You must be self-directed and comfortable supporting the data needs of cross-functional teams, systems and technical solutions.

Qualifications

CS or CE degree or commensurate experience required
MS SQL Server, MySQL (Aurora), MSSQL, REST API, etc.
Strong understanding of scalability, performance, and reliability
Experience with OOP frameworks, languages, design patterns, concepts and data sources such as C#/.NET, Java, Python, Kafka, Spark
Ability to work on multiple areas including data pipeline ETL, data modeling & design, writing complex SQL queries, etc.


Preferred Skills

Hands-on expertise in one or more Amazon Web Services (AWS) technologies, such as Kinesis, S3, Redshift, Athena, Lambda
Experience in Kanban methodologies
Experience in Test Driven Development and CI/CD.
Demonstrated ability to develop and support large-sized international-scale software systems
Experience in expanding and optimizing data pipeline architecture
Optimize data flow and data collection for cross functional teams


Additional Information

Equal Opportunity: Cricut is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees and members. Applicants will be considered based on their qualifications and without regards to age, race, ethnicity, gender identity or expression, national origin, religion, physical or mental disability, protected veteran states, sex (including pregnancy), sexual orientation or any other protected characteristic protected by applicable laws, regulations or ordinances.
ADA: If you require reasonable accommodation during the application or selection process please do not hesitate to reach out to Cricut HR or your assigned recruiter.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Cricut® is looking for a Data Engineer to join our Data Platform team supporting the future of AI/ML. The ideal candidate will design, build, and integrate data from various resources, and manage big data pipelines that are easily accessible with optimized performance of Cricut®'s big data ecosystem.<br><br>The ideal candidate is an experienced data wrangler who will support our software developers, database architects and data analysts on business initiatives. You must be self-directed and comfortable supporting the data needs of cross-functional teams, systems and technical solutions.<br><br><strong><u>Qualifications<br></u></strong><ul><li>CS or CE degree or commensurate experience required</li><li>MS SQL Server, MySQL (Aurora), MSSQL, REST API, etc.</li><li>Strong understanding of scalability, performance, and reliability</li><li>Experience with OOP frameworks, languages, design patterns, concepts and data sources such as C#/.NET, Java, Python, Kafka, Spark</li><li>Ability to work on multiple areas including data pipeline ETL, data modeling &amp; design, writing complex SQL queries, etc.<br><br></li></ul><strong><u>Preferred Skills<br></u></strong><ul><li>Hands-on expertise in one or more Amazon Web Services (AWS) technologies, such as Kinesis, S3, Redshift, Athena, Lambda</li><li>Experience in Kanban methodologies</li><li>Experience in Test Driven Development and CI/CD.</li><li>Demonstrated ability to develop and support large-sized international-scale software systems</li><li>Experience in expanding and optimizing data pipeline architecture</li><li>Optimize data flow and data collection for cross functional teams<br><br></li></ul>Additional Information<br><ul><li>Equal Opportunity: Cricut is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees and members. Applicants will be considered based on their qualifications and without regards to age, race, ethnicity, gender identity or expression, national origin, religion, physical or mental disability, protected veteran states, sex (including pregnancy), sexual orientation or any other protected characteristic protected by applicable laws, regulations or ordinances. </li><li>ADA: If you require reasonable accommodation during the application or selection process please do not hesitate to reach out to Cricut HR or your assigned recruiter.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer/Python/SQL/AWS,"United, PA",Motion Recruitment,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-python-sql-aws-at-motion-recruitment-2415349919?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=h2aumMNXGKogHrjKuvr8%2Fw%3D%3D&position=13&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Location: New York/London

Who We Are

Take-Two Interactive Software, Inc. is a leading developer, publisher, and marketer of interactive entertainment for consumers around the globe. For more than 25 years, our development teams have built some of the most critically acclaimed and commercially successful entertainment experiences, captivating and engaging audiences around the world. We are exceptionally proud of our ability to deliver consistently the highest-quality titles, as well as our colleagues who help to foster an open culture and work environment that is inclusive, diverse, and dynamic.

While our offices are casual and inviting, we are deeply committed to creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a phenomenal place to come to work every single day to pursue your passions.

Are you comfortable with writing code and helping business teams understand data? Are you comfortable with ambiguity, able to think big (while paying careful attention to detail) and enjoy working in a fast-paced environment?

The Challenge

A dynamic Python Data Engineer to join a team building a cloud-based data and analytics platform. The Data Engineer will craft, build, and maintain reliable and scalable data pipelines.

Develop data quality framework to provide transparency into data quality across systems (timeliness, accuracy, completeness, etc.) and ensure delivery of high-quality data to business teams.
Provide thought leadership and collaborate with other team members to continue to scale our architecture to evolve for the needs of tomorrow.
Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization.
Develop and support continuous integrations build and deployment processes using Jenkins, Docker, Git, etc.
Define and implement monitoring and alerting policies for data solutions.



What You Bring

2+ years of hands-on experience in Python.
3+ years of hands-on experience in using sophisticated SQL queries and writing/optimizing highly efficient SQL queries.
Experience integrating with 3rd party APIs.
Comfortable working with business customers to collect requirements and gain a deep understanding of varied business domains.
Experienced in testing and monitoring data for anomalies and rectifying them.
Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.



Preferred Qualifications

Python (required)
SQL (required)
Git (required)
Developing solutions using Docker (required)
Data modeling for data warehousing (nice to have)
Developing microservices (nice to have)



What We Offer You

Great Company Culture. Ranked as one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success.
Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, inquisitive, collaborative and to grow within and around the company.
Work Hard, Enjoy Life. Our employees bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, company parties, game release events, monthly socials, and team challenges.
Benefits. Medical (HSA & FSA), dental, vision, 401(k) with company match, employee stock purchase plan, commuter benefits, in-house wellness program, broad learning & development opportunities, a charitable giving platform and more!
Perks. Fitness allowance, employee discount programs, free games & events, stocked pantries and the ability to earn up to $500+ per year for taking care of yourself and more!


Take-Two Interactive Software, Inc. (“T2”) is proud to be an equal opportunity employer, which means we are committed to crafting and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual’s race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Location: <strong>New York/London<br><br></strong><strong><u>Who We Are<br><br></u></strong>Take-Two Interactive Software, Inc. is a leading developer, publisher, and marketer of interactive entertainment for consumers around the globe. For more than 25 years, our development teams have built some of the most critically acclaimed and commercially successful entertainment experiences, captivating and engaging audiences around the world. We are exceptionally proud of our ability to deliver consistently the highest-quality titles, as well as our colleagues who help to foster an open culture and work environment that is inclusive, diverse, and dynamic.<br><br>While our offices are casual and inviting, we are deeply committed to creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a phenomenal place to come to work every single day to pursue your passions.<br><br>Are you comfortable with writing code and helping business teams understand data? Are you comfortable with ambiguity, able to think big (while paying careful attention to detail) and enjoy working in a fast-paced environment?<br><br><strong><u>The Challenge<br><br></u></strong>A dynamic Python Data Engineer to join a team building a cloud-based data and analytics platform. The Data Engineer will craft, build, and maintain reliable and scalable data pipelines.<br><ul> <li>Develop data quality framework to provide transparency into data quality across systems (timeliness, accuracy, completeness, etc.) and ensure delivery of high-quality data to business teams.</li> <li>Provide thought leadership and collaborate with other team members to continue to scale our architecture to evolve for the needs of tomorrow.</li> <li>Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization.</li> <li>Develop and support continuous integrations build and deployment processes using Jenkins, Docker, Git, etc.</li> <li>Define and implement monitoring and alerting policies for data solutions.</li> <br><br></ul><strong><u>What You Bring<br></u></strong><ul> <li>2+ years of hands-on experience in Python.</li> <li>3+ years of hands-on experience in using sophisticated SQL queries and writing/optimizing highly efficient SQL queries.</li> <li>Experience integrating with 3rd party APIs.</li> <li>Comfortable working with business customers to collect requirements and gain a deep understanding of varied business domains.</li> <li>Experienced in testing and monitoring data for anomalies and rectifying them.</li> <li>Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Python (required)</li> <li>SQL (required)</li> <li>Git (required)</li> <li>Developing solutions using Docker (required)</li> <li>Data modeling for data warehousing (nice to have)</li> <li>Developing microservices (nice to have)</li> <br><br></ul><strong><u>What We Offer You<br></u></strong><ul> <li><strong>Great Company Culture</strong>. Ranked as one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success.</li> <li><strong>Growth</strong>: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, inquisitive, collaborative and to grow within and around the company.</li> <li><strong>Work Hard, Enjoy Life.</strong> Our employees bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, company parties, game release events, monthly socials, and team challenges.</li> <li><strong>Benefits</strong>. Medical (HSA &amp; FSA), dental, vision, 401(k) with company match, employee stock purchase plan, commuter benefits, in-house wellness program, broad learning &amp; development opportunities, a charitable giving platform and more!</li> <li><strong>Perks</strong>. Fitness allowance, employee discount programs, free games &amp; events, stocked pantries and the ability to earn up to $500+ per year for taking care of yourself and more!</li> <br></ul>Take-Two Interactive Software, Inc. (“T2”) is proud to be an equal opportunity employer, which means we are committed to crafting and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual’s race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Bedford, MA",iRobot,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-irobot-2418247469?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=qzL2cnxzEFxkGHyEZlwVtA%3D%3D&position=14&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Top brands in North America rely on this software product company for data services, and their Carlsbad team is looking to add a senior and an intermediate data engineer ASAP! This team is looking for individuals with a strong background working with python and SQL, working within and AWS environment to better understand and leverage data warehouses and data lakes. Major pluses for anyone with a background in greenfield projects, and mentorship experience.
This company provides cutting edge solutions in the AdTech/Marketing/Advertising space, deals with big data environments and has a growing tech-first culture.

Required Skills & Experience

3+ years' of professional experience with Python ETL
5+ years' with complex SQL databases - queries, tables, scripting
1+ years' of production experience with AWS: Redshift or Snowflake.

S3, EC2 and lambdas are a big plus as well.
Any other AWS based services are a big plus as well for R&D projects
Experience analyzing data to better understand business needs using Pandas, Numpy
B Sc in Computer Science or comparable is a must have


What You Will Be Doing

Tech Breakdown

40% SQL databases
60% Python and AWS


Daily Responsibilities

70% Hands On
10% Research
20% Team Collaboration


The Offer

Competitive Salary: Up to $150,000.00/year, DOE



You Will Receive The Following Benefits

Medical Insurance & Health Savings Account (HSA)
401(k)
Paid Sick Time Leave
Pre-tax Commuter Benefit
Remote flex for indefinite future



Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Top brands in North America rely on this software product company for data services, and their Carlsbad team is looking to add a senior and an intermediate data engineer ASAP! This team is looking for individuals with a strong background working with python and SQL, working within and AWS environment to better understand and leverage data warehouses and data lakes. Major pluses for anyone with a background in greenfield projects, and mentorship experience.<br>This company provides cutting edge solutions in the AdTech/Marketing/Advertising space, deals with big data environments and has a growing tech-first culture.<br><br><strong><u>Required Skills &amp; Experience<br></u></strong><ul> <li>3+ years' of professional experience with Python ETL</li> <li>5+ years' with complex SQL databases - queries, tables, scripting</li> <li>1+ years' of production experience with AWS: Redshift or Snowflake.<br><ul> <li>S3, EC2 and lambdas are a big plus as well.</li> <li>Any other AWS based services are a big plus as well for R&amp;D projects</li> </ul> </li> <li>Experience analyzing data to better understand business needs using Pandas, Numpy</li> <li>B Sc in Computer Science or comparable is a must have</li> <br></ul>What You Will Be Doing<br><br>Tech Breakdown<br><ul> <li>40% SQL databases</li> <li>60% Python and AWS</li> <br></ul>Daily Responsibilities<br><ul> <li>70% Hands On</li> <li>10% Research</li> <li>20% Team Collaboration</li> <br></ul>The Offer<br><ul> <li>Competitive Salary: Up to $150,000.00/year, DOE</li> <br><br></ul><strong><u>You Will Receive The Following Benefits<br></u></strong><ul> <li>Medical Insurance &amp; Health Savings Account (HSA)</li> <li>401(k)</li> <li>Paid Sick Time Leave</li> <li>Pre-tax Commuter Benefit</li> <li>Remote flex for indefinite future</li> <br><br></ul><u><strong>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br><br></strong></u></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Dearborn, MI",Ford Motor Company,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-ford-motor-company-2420468625?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=EasTIYbPtmkYxIszNgO9gA%3D%3D&position=15&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Introduction

Introduction

The data science team at iRobot builds models, runs experiments, and conducts analyses to understand our fleet of millions of consumer robots. Our expertise in machine learning and focus on the customer help us to produce data-driven digital features for robots and users around the world. Join our team as a data scientist with a focus on marketing applications!

What You Will Do

Perform analyses and data mining to better understand our customers and our business, joining data points across multiple sources.
Develop metrics to track company performance, contribute to data definitions, and write documentation.
Build models to forecast revenue, understand attribution or LTV, and predict conversion or churn rates.
Test hypotheses about company performance using appropriate statistical methods.
Uphold scientific best practices in experimental design and testing.


To Be Successful You Will Have

A strong candidate does not necessarily have to possess all of the following, and we’re open to the possibility that you may bring other skills to the table aside from those listed here. If you fit that description, do not hesitate to apply!

4-year degree in a STEM field or coding bootcamp
At least 1-2 years of relevant job, internship, or co-op experience. M.S. in statistics, mathematics, physics, chemistry, biology, or social sciences is a plus.
Proficient in Python (pandas, numpy, sklearn, scipy), SQL, and data visualization (matplotlib, seaborn, or plotly).
Possess fundamental understanding of machine learning algorithms (e.g. regression, decision trees, time-series analysis, clustering, etc.)
Savvy in statistical methods and able to select the right test for the situation.
Can balance business considerations with the need for scientific rigor.
Customer-focused, with demonstrated experience in the marketing domain.
Self-motivated and comfortable working in a fast-paced, delivery-focused environment.
Skilled communicator who can collaborate effectively across multiple teams.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Introduction<br><br></strong><strong><u>Introduction<br><br></u></strong>The data science team at iRobot builds models, runs experiments, and conducts analyses to understand our fleet of millions of consumer robots. Our expertise in machine learning and focus on the customer help us to produce data-driven digital features for robots and users around the world. Join our team as a data scientist with a focus on marketing applications!<br><br><strong><u>What You Will Do<br></u></strong><ul><li>Perform analyses and data mining to better understand our customers and our business, joining data points across multiple sources.</li><li>Develop metrics to track company performance, contribute to data definitions, and write documentation.</li><li>Build models to forecast revenue, understand attribution or LTV, and predict conversion or churn rates.</li><li>Test hypotheses about company performance using appropriate statistical methods.</li><li>Uphold scientific best practices in experimental design and testing.<br><br></li></ul><strong><u>To Be Successful You Will Have<br><br></u></strong>A strong candidate does not necessarily have to possess all of the following, and we’re open to the possibility that you may bring other skills to the table aside from those listed here. If you fit that description, do not hesitate to apply!<br><ul><li>4-year degree in a STEM field or coding bootcamp</li><li>At least 1-2 years of relevant job, internship, or co-op experience. M.S. in statistics, mathematics, physics, chemistry, biology, or social sciences is a plus.</li><li>Proficient in Python (pandas, numpy, sklearn, scipy), SQL, and data visualization (matplotlib, seaborn, or plotly).</li></ul><ul><li>Possess fundamental understanding of machine learning algorithms (e.g. regression, decision trees, time-series analysis, clustering, etc.)</li><li>Savvy in statistical methods and able to select the right test for the situation.</li><li>Can balance business considerations with the need for scientific rigor.</li><li>Customer-focused, with demonstrated experience in the marketing domain.</li><li>Self-motivated and comfortable working in a fast-paced, delivery-focused environment.</li><li>Skilled communicator who can collaborate effectively across multiple teams.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Electrical/Electronic Manufacturing, Information Technology and Services, Computer Software"
Data Engineer,"Nashville, TN",Core10,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-core10-2429421984?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=p%2F%2Fs13E%2BKevOumX9TITfmw%3D%3D&position=16&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Data Engineer

At Ford Motor Company, we believe freedom of movement drives human progress. We also believe in providing you with the freedom to define and realize your dreams. With our incredible plans for the future of mobility, we have a wide variety of opportunities for you to accelerate your career potential as you help us define tomorrow's transportation.

Creating the future of smart mobility requires the highly intelligent use of data, metrics and analytics. That's where you can make an impact as part of our Global Data Insight & Analytics team. We are the trusted advisers that enable Ford to clearly see business conditions, customer needs and the competitive landscape. With our support, key decision makers can act in meaningful, positive ways. Join us and use your data expertise and analytical skills to drive evidence-based, timely decision making.

What You'll Be Able To Do

The Third-Party Data team is seeking a Data Engineer to land, curate, and manage data products purchased from external sources. In addition to supporting new data landing efforts, the Data Engineer will work to identify opportunities to optimize existing landing code and leverage automation techniques where possible. Lastly, the Data Engineer will work to create data products derived from one or multiple sources for use by internal Ford customers. To support the activities previously listed, the Data Engineer will:

Work with internal and external stakeholders to define requirements for landing data. The Data Engineer will translate customer requirements into technical specifications and develop automated landing procedures to create data products aligned with end customer goals and GDI&A Data Factory data management best practices.
Identify flexible solutions supporting data egress from vendor platforms to the GDI&A Data Factory. The data managed by the Third-Party team varies in scale and complexity, and the Data Engineer is expected to be comfortable with multiple technologies supporting data ingestion, transformation and curation.
Support GDI&A Data Factory curation best practices, ensuring that landed data meets data quality and enrichment standards.
Work with GDI&A Data Factory team members to establish monitoring solutions for landed and created data solutions.
Collaborate with GDI&A team members and internal customers to identify and develop derivative, value-add data products. Examples of derived data products include complex transforms of source data to support downstream analytics and visualization tools supporting exploratory data analysis.


The Minimum Requirements We Seek

Bachelor's degree
5+ years ETL and related tools/applications experience including:
Data retrieval from SFTP, Azure Blob, Amazon S3 and other file hosting solutions using Shell scripting, Sqoop, Kafka and other comparable tools
Hadoop Data Management, Querying, Scheduling & Analysis tools: Hadoop v2, MapReduce, HDFS, Cloudera/MapR; Ambari, Hive, Pig; HQL, Spark; Oozie, Zookeeper; Java, Scala, Python
Data blending and visualization tools: Alteryx, Qlik, Tableau


Preferred Requirements

Our preferred requirements

Master's degree
Experience with Informatica and DataStage preferred
Experience with enterprise project management tools (Rally, JIRA) preferred; previous direct project management or PMP certification a plus
Experience with agile software development practices (Scrum/Scrumban) preferred
Strong communication skills required;
previous customer-facing experience preferred


What You'll Receive In Return

As part of the Ford family, you'll enjoy excellent compensation and a comprehensive benefits package that includes generous PTO, retirement, savings and stock investment plans, incentive compensation and much more. You'll also experience exciting opportunities for professional and personal growth and recognition.

If you have what it takes to help us redefine the future of mobility, we'd love to have you join us.

Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.

Visa sponsorship is not available for this position.

By choice, we are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status.

For information on Ford's benefits and compensation, click here: https://clicktime.symantec.com/34jag92XUFJYHaNge9RMLCD7Vc?u=https%3A%2F%2Fcorporate.ford.com%2Fcontent%2Fdam%2Fcorporate%2Fus%2Fen-us%2Fdocuments%2Fcareers%2F2021-benefits-and-comp-GSR-sal-plan-1.pdf

About Us

Ford Motor Company is about more than making world-class vehicles – at Ford we Go Further to make people’s lives better.

We do this in every corner of the globe. Ford is both an automotive and mobility company. Across six continents, our employees produce innovative products in our engineering and design centers, research labs and high-tech assembly plants.

And in order to do that, we are looking to attract the top talent like you.

Ford is a place where development is valued for all, and employees are encouraged to learn, build skills and continuously improve year-after-year. When you work at Ford, you and your team will Go Further each day to deliver great products, build a strong business and contribute to a better world.

The distance between you and an amazing career has never been shorter!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Data Engineer<br><br></u></strong>At Ford Motor Company, we believe freedom of movement drives human progress. We also believe in providing you with the freedom to define and realize your dreams. With our incredible plans for the future of mobility, we have a wide variety of opportunities for you to accelerate your career potential as you help us define tomorrow's transportation.<br><br>Creating the future of smart mobility requires the highly intelligent use of data, metrics and analytics. That's where you can make an impact as part of our Global Data Insight &amp; Analytics team. We are the trusted advisers that enable Ford to clearly see business conditions, customer needs and the competitive landscape. With our support, key decision makers can act in meaningful, positive ways. Join us and use your data expertise and analytical skills to drive evidence-based, timely decision making.<br><br><strong><u>What You'll Be Able To Do<br><br></u></strong>The Third-Party Data team is seeking a Data Engineer to land, curate, and manage data products purchased from external sources. In addition to supporting new data landing efforts, the Data Engineer will work to identify opportunities to optimize existing landing code and leverage automation techniques where possible. Lastly, the Data Engineer will work to create data products derived from one or multiple sources for use by internal Ford customers. To support the activities previously listed, the Data Engineer will:<br><ul><li>Work with internal and external stakeholders to define requirements for landing data. The Data Engineer will translate customer requirements into technical specifications and develop automated landing procedures to create data products aligned with end customer goals and GDI&amp;A Data Factory data management best practices.</li><li>Identify flexible solutions supporting data egress from vendor platforms to the GDI&amp;A Data Factory. The data managed by the Third-Party team varies in scale and complexity, and the Data Engineer is expected to be comfortable with multiple technologies supporting data ingestion, transformation and curation.</li><li>Support GDI&amp;A Data Factory curation best practices, ensuring that landed data meets data quality and enrichment standards.</li><li>Work with GDI&amp;A Data Factory team members to establish monitoring solutions for landed and created data solutions.</li><li>Collaborate with GDI&amp;A team members and internal customers to identify and develop derivative, value-add data products. Examples of derived data products include complex transforms of source data to support downstream analytics and visualization tools supporting exploratory data analysis. <br><br></li></ul><strong><u>The Minimum Requirements We Seek<br></u></strong><ul><li>Bachelor's degree </li><li>5+ years ETL and related tools/applications experience including:</li></ul><ul><li>Data retrieval from SFTP, Azure Blob, Amazon S3 and other file hosting solutions using Shell scripting, Sqoop, Kafka and other comparable tools</li><li>Hadoop Data Management, Querying, Scheduling &amp; Analysis tools: Hadoop v2, MapReduce, HDFS, Cloudera/MapR; Ambari, Hive, Pig; HQL, Spark; Oozie, Zookeeper; Java, Scala, Python</li><li>Data blending and visualization tools: Alteryx, Qlik, Tableau<br><br></li></ul><strong><u>Preferred Requirements<br><br></u></strong>Our preferred requirements<br><ul><li>Master's degree</li><li>Experience with Informatica and DataStage preferred</li><li>Experience with enterprise project management tools (Rally, JIRA) preferred; previous direct project management or PMP certification a plus</li><li>Experience with agile software development practices (Scrum/Scrumban) preferred</li><li>Strong communication skills required;</li><li>previous customer-facing experience preferred<br><br></li></ul><strong><u>What You'll Receive In Return<br><br></u></strong>As part of the Ford family, you'll enjoy excellent compensation and a comprehensive benefits package that includes generous PTO, retirement, savings and stock investment plans, incentive compensation and much more. You'll also experience exciting opportunities for professional and personal growth and recognition.<br><br>If you have what it takes to help us redefine the future of mobility, we'd love to have you join us.<br><br>Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.<br><br>Visa sponsorship is not available for this position.<br><br>By choice, we are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status.<br><br>For information on Ford's benefits and compensation, click here: https://clicktime.symantec.com/34jag92XUFJYHaNge9RMLCD7Vc?u=https%3A%2F%2Fcorporate.ford.com%2Fcontent%2Fdam%2Fcorporate%2Fus%2Fen-us%2Fdocuments%2Fcareers%2F2021-benefits-and-comp-GSR-sal-plan-1.pdf<br><br><strong><u>About Us<br><br></u></strong>Ford Motor Company is about more than making world-class vehicles – at Ford we Go Further to make people’s lives better.<br><br>We do this in every corner of the globe. Ford is both an automotive and mobility company. Across six continents, our employees produce innovative products in our engineering and design centers, research labs and high-tech assembly plants.<br><br>And in order to do that, we are looking to attract the top talent like you.<br><br>Ford is a place where development is valued for all, and employees are encouraged to learn, build skills and continuously improve year-after-year. When you work at Ford, you and your team will Go Further each day to deliver great products, build a strong business and contribute to a better world.<br><br>The distance between you and an amazing career has never been shorter!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Automotive
Data Science Engineer,"New York, NY",Warner Music Group,2021-02-19,https://www.linkedin.com/jobs/view/data-science-engineer-at-warner-music-group-2415670767?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=4jVRlAG%2BoiGGBr6VRzJ9%2BQ%3D%3D&position=17&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"At Core10, we have a clear vision to be the place where a diverse group of talented people want to come, stay and do their best work in the places they choose to call home. We pride ourselves on bringing a cost-effective alternative to financial technology companies who currently outsource their development efforts overseas. We’re looking for an Associate Data Engineer to join our team. We build complex and compelling fintech solutions for clients across many industries. The role is a mix of client-facing consultative work and behind the scenes platform design, configuration, data analysis, and data manipulation. To best serve our clients, you’ll delve into new subject matter on a regular basis, and you’ll always be on the lookout for innovative ways to approach our software projects.

What You'll Do

Delivering great experiences via both technology and our communications to clients and partners.
Delivering the right solution at the right time with integrity.
Transforming client data
Ability to multitask by balancing the needs of several clients
Providing high quality, empathetic support to all clients and partners.
Continually building and iteratively improving our integrations codebase to be increasingly reusable and enable our customers and partners to do more.
Confronting and tackling odd, unique data problems on a weekly basis.
Communicating and collaborating with non-technical team members to troubleshoot and resolve when bugs are found



Requirements

Bachelor’s degree from accredited college or university
3+ years of Python experience
Organization, effective time management, and ability to multi-task
Passion for delivering high quality outcomes
Ability to work under tight deadlines
Experience working as part of a team
The ability to participate in client meetings
Strong analytical and creative problem-solving abilities
Strong working knowledge of Python or comparable programming language, SQL, and MS Excel
Strong sense of personal responsibility and ownership over your work
Willingness and love of learning new technology, new processes and procedures, and new business models



Benefits

Health Care Plan (Medical, Dental & Vision) for employee (a significant portion of employee only paid) and family (paid in part)
PTO
Retirement Plan (401k)
Work From Home (up to 5 days per week)
Training & Development


Core 10, Inc. does not discriminate in employment matters on the basis of race, color, religion, gender, national origin, age, military service eligibility, veteran status, sexual orientation, marital status, disability, or any other protected class. We support workplace diversity.

We are unable to sponsor or transfer H1B Visas at this time.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Core10, we have a clear vision to be the place where a diverse group of talented people want to come, stay and do their best work in the places they choose to call home. We pride ourselves on bringing a cost-effective alternative to financial technology companies who currently outsource their development efforts overseas. We’re looking for an Associate Data Engineer to join our team. We build complex and compelling fintech solutions for clients across many industries. The role is a mix of client-facing consultative work and behind the scenes platform design, configuration, data analysis, and data manipulation. To best serve our clients, you’ll delve into new subject matter on a regular basis, and you’ll always be on the lookout for innovative ways to approach our software projects.<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>Delivering great experiences via both technology and our communications to clients and partners. </li> <li>Delivering the right solution at the right time with integrity.</li> <li>Transforming client data </li> <li>Ability to multitask by balancing the needs of several clients </li> <li>Providing high quality, empathetic support to all clients and partners.</li> <li>Continually building and iteratively improving our integrations codebase to be increasingly reusable and enable our customers and partners to do more.</li> <li>Confronting and tackling odd, unique data problems on a weekly basis.</li> <li>Communicating and collaborating with non-technical team members to troubleshoot and resolve when bugs are found</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Bachelor’s degree from accredited college or university </li> <li>3+ years of Python experience</li> <li>Organization, effective time management, and ability to multi-task</li> <li>Passion for delivering high quality outcomes</li> <li>Ability to work under tight deadlines</li> <li>Experience working as part of a team</li> <li>The ability to participate in client meetings</li> <li>Strong analytical and creative problem-solving abilities</li> <li>Strong working knowledge of Python or comparable programming language, SQL, and MS Excel</li> <li>Strong sense of personal responsibility and ownership over your work</li> <li>Willingness and love of learning new technology, new processes and procedures, and new business models</li> <br><br></ul><u><strong>Benefits<br></strong></u><ul> <li>Health Care Plan (Medical, Dental &amp; Vision) for employee (a significant portion of employee only paid) and family (paid in part)</li> <li>PTO</li> <li>Retirement Plan (401k)</li> <li>Work From Home (up to 5 days per week)</li> <li>Training &amp; Development</li> <br></ul>Core 10, Inc. does not discriminate in employment matters on the basis of race, color, religion, gender, national origin, age, military service eligibility, veteran status, sexual orientation, marital status, disability, or any other protected class. We support workplace diversity.<br><br><strong>We are unable to sponsor or transfer H1B Visas at this time.</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"San Diego, CA",Tata Consultancy Services,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-tata-consultancy-services-2418249783?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=gdDV3Pq2%2Fh2YQucjEEnXLg%3D%3D&position=18&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

At Warner Music Group we’re all about our people. Our global company is made up of knowledgeable, passionate, and creative individuals. Our commitment to Diversity, Equity and Inclusion fosters a culture where you can truly belong, contribute, and grow. We believe in each individual’s value and encourage applications from people of any age, gender identity, sexual orientation, race, religion, ethnicity, disability, veteran status, and any other characteristic or identity.

It is the mission of every member of the WMG team around the world to create a nurturing environment for artists, songwriters, and the people behind the music – at every stage of their career. We strive to set WMG apart by embracing innovation – an integral part of our company's DNA.

Consider a career at WMG and be a part of one of the most influential forces in culture today.

Job Title: Data Science Engineer

A Little Bit About Our Team

The Research + Analysis department works to influence WMG’s strategy and optimize day-to-day operations through data and insights. This position sits within the NYC-based global Research + Analysis team, working closely with colleagues across Business Development WEA Distribution, and Label Partners to better understand what makes our global digital partners tick, and how we can use that information to the advantage of our artists and songwriters.

Why This Could Be Your Next Big Break

The Data Science Engineer will support the newly created Data Science organization within Research + Analysis on tasks at the intersection on Data Engineering, Machine Learning Engineering and Machine Learning Operations. The Data Science Engineer will also serve as a technical liaison with Data Engineers in different technology organizations across Warner Music Group. The position is not entry-level and requires prior experience performing these tasks. The position reports to the Director of Data Science.

Here You’ll Get To

Harden and optimize ETL scripts and data pipelines built by Data Scientists for data exploration, modeling and visualizations,
Deploy model pipelines and build task orchestration,
Ensure computation efficiency in deployed algorithms and data pipelines
Build and maintain tables and APIs (or other endpoints) where model outputs can be read by dashboards or visualization tools
Serve as a technical liaison with Data Engineers in various technology organizations across Warner Music Group
Execute tasks in time and with exceptional attention to detail

It would be music to our ears if you also had:

Graduate Degree (Masters encouraged) in Computer Science, Information Technology, Software Engineering, Data Engineering, Data Science, or related fields
2 years of experience in a business setting

performing Data Engineering, Machine Learning Engineering or Machine Learning Operations tasks
training, tuning, validating Machine Learning models
scaling and optimizing Machine Learning models for deployment
expertly using SQL and NoSQL databases
operating in cloud environments (e.g. AWS, Azure, GCP)
using tools for large-scale data processing (e.g. Spark, Hadoop) with high proficiency
using scripting languages (e.g. Python, Julia, Scala) at an expert level
Aptitude to learn new technologies, tools and methods as required

Desired Characteristics

Experience with Data Science tasks and knowledge of additional programming languages a plus
Experience using and deploying containers a bonus


About Us

With its broad and diverse roster of new stars and legendary artists, Warner Music Group is home to a collection of the best-known record labels in the music industry including Asylum, Atlantic, East West, Elektra, FFRR, Fueled by Ramen, Nonesuch, Parlophone, Rhino, Roadrunner, Sire, Warner Records, Warner Classics and Warner Chappell Music, one of the world's leading music publishers with a catalogue of more than one million copyrights worldwide.

For more than four decades, WMG has been an industry-leading force in providing a world-class array of services designed to help artists and labels grow their careers and their businesses. Artist & Label Services is the umbrella for WEA (Warner-Elektra-Atlantic) – the pioneering WEA distribution and marketing network – and Alternative Distribution Alliance (ADA) – the ground-breaking global distribution company for independent artists and labels

WMG is committed to inclusion and diversity in all aspects of our business. We are proud to be an equal opportunity workplace and will evaluate qualified applicants without regard to race, religious creed, color, age, sex, sexual orientation, gender, gender identity, gender expression, national origin, ancestry, marital status, medical condition as defined by state law (genetic characteristics or cancer), physical or mental disability, military service or veteran status, pregnancy, childbirth and related medical conditions, genetic information or any other characteristic protected by applicable federal, state or local law.

Copyright © 2021 Warner Music Inc.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong><strong> At Warner Music Group we’re all about our people. Our global company is made up of knowledgeable, passionate, and creative individuals. Our commitment to Diversity, Equity and Inclusion fosters a culture where you can truly belong, contribute, and grow. We believe in each individual’s value and encourage applications from people of any age, gender identity, sexual orientation, race, religion, ethnicity, disability, veteran status, and any other characteristic or identity. <br><br></strong><strong> It is the mission of every member of the WMG team around the world to create a nurturing environment for artists, songwriters, and the people behind the music – at every stage of their career. We strive to set WMG apart by embracing innovation – an integral part of our company's DNA. <br><br></strong><strong> Consider a career at WMG and be a part of one of the most influential forces in culture today. <br><br></strong><strong>Job Title: </strong>Data Science Engineer<br><br><strong><u>A Little Bit About Our Team<br><br></u></strong>The Research + Analysis department works to influence WMG’s strategy and optimize day-to-day operations through data and insights. This position sits within the NYC-based global Research + Analysis team, working closely with colleagues across Business Development WEA Distribution, and Label Partners to better understand what makes our global digital partners tick, and how we can use that information to the advantage of our artists and songwriters.<br><br><strong><u>Why This Could Be Your Next Big Break<br><br></u></strong>The <strong>Data Science Engineer </strong> will support the newly created Data Science organization within Research + Analysis on tasks at the intersection on Data Engineering, Machine Learning Engineering and Machine Learning Operations. The <strong>Data Science Engineer</strong> will also serve as a technical liaison with Data Engineers in different technology organizations across Warner Music Group. The position is not entry-level and requires prior experience performing these tasks. The position reports to the Director of Data Science.<br><br><strong><u>Here You’ll Get To<br></u></strong><ul><li>Harden and optimize ETL scripts and data pipelines built by Data Scientists for data exploration, modeling and visualizations,</li><li>Deploy model pipelines and build task orchestration,</li><li>Ensure computation efficiency in deployed algorithms and data pipelines</li><li>Build and maintain tables and APIs (or other endpoints) where model outputs can be read by dashboards or visualization tools</li><li>Serve as a technical liaison with Data Engineers in various technology organizations across Warner Music Group</li><li>Execute tasks in time and with exceptional attention to detail<br></li></ul><strong> It would be music to our ears if you also had: <br></strong><ul><li>Graduate Degree (Masters encouraged) in Computer Science, Information Technology, Software Engineering, Data Engineering, Data Science, or related fields</li><li>2 years of experience in a business setting<br><ul><li>performing Data Engineering, Machine Learning Engineering or Machine Learning Operations tasks </li><li>training, tuning, validating Machine Learning models</li><li>scaling and optimizing Machine Learning models for deployment</li><li>expertly using SQL and NoSQL databases</li><li>operating in cloud environments (e.g. AWS, Azure, GCP)</li><li>using tools for large-scale data processing (e.g. Spark, Hadoop) with high proficiency</li><li>using scripting languages (e.g. Python, Julia, Scala) at an expert level</li></ul></li><li>Aptitude to learn new technologies, tools and methods as required<br></li></ul><strong>Desired Characteristics<br></strong><ul><li>Experience with Data Science tasks and knowledge of additional programming languages a plus</li><li>Experience using and deploying containers a bonus<br><br></li></ul><strong><u>About Us<br><br></u></strong>With its broad and diverse roster of new stars and legendary artists, Warner Music Group is home to a collection of the best-known record labels in the music industry including Asylum, Atlantic, East West, Elektra, FFRR, Fueled by Ramen, Nonesuch, Parlophone, Rhino, Roadrunner, Sire, Warner Records, Warner Classics and Warner Chappell Music, one of the world's leading music publishers with a catalogue of more than one million copyrights worldwide.<br><br>For more than four decades, WMG has been an industry-leading force in providing a world-class array of services designed to help artists and labels grow their careers and their businesses. Artist &amp; Label Services is the umbrella for WEA (Warner-Elektra-Atlantic) – the pioneering WEA distribution and marketing network – and Alternative Distribution Alliance (ADA) – the ground-breaking global distribution company for independent artists and labels<br><br>WMG is committed to inclusion and diversity in all aspects of our business. We are proud to be an equal opportunity workplace and will evaluate qualified applicants without regard to race, religious creed, color, age, sex, sexual orientation, gender, gender identity, gender expression, national origin, ancestry, marital status, medical condition as defined by state law (genetic characteristics or cancer), physical or mental disability, military service or veteran status, pregnancy, childbirth and related medical conditions, genetic information or any other characteristic protected by applicable federal, state or local law.<br><br>Copyright © 2021 Warner Music Inc.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Entertainment, Music, Publishing"
Data Engineer,"Minneapolis, MN",General Mills,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-general-mills-2418216919?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=B3HeUHmhb%2FLLiY4KI9qw3w%3D%3D&position=19&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"What You Will Do

Perform system analysis – profiling data, understanding business rules, understanding data relations, and data models.
Create complex SQL queries to analyze data characteristics and quality and create meaningful reports of findings.
Analyze existing data repositories to identify and develop data mapping and business rules for data conversions and processing
Participate in development activities by creating tables, views, functions, and stored procedures for data conversions and processing.
Participate in designing and developing ETL processes and complex data manipulation through batch processes, APIs, data streaming services, etc.
Communicate and coordinate effectively with business and technical personnel.
Self-motivated – Estimate accurately and efficiently manage effort / competing priorities to complete tasks on schedule.

What You Need To Have

BS/BA and above in Computer Science, Engineering, Information Systems, and/or equivalent formal training or experience.
5+ years of experience in the development of complex projects involving significant processing, manipulation, and volume.
Experienced with batch-oriented, API, and/or streaming processes.
Complete analysis and communications skills.
Strong hands-on experience with Oracle – experience with MS SQL and/or Postgres, etc., are highly desirable.
Experience with scripting languages like Windows PowerShell, Python, etc., is a plus.
Background in a similar industry: Wealth Management, Broker-Dealer, Financial Services.



Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>What You Will Do<br></u></strong><ul><li>Perform system analysis – profiling data, understanding business rules, understanding data relations, and data models.</li><li>Create complex SQL queries to analyze data characteristics and quality and create meaningful reports of findings.</li><li>Analyze existing data repositories to identify and develop data mapping and business rules for data conversions and processing</li><li>Participate in development activities by creating tables, views, functions, and stored procedures for data conversions and processing.</li><li>Participate in designing and developing ETL processes and complex data manipulation through batch processes, APIs, data streaming services, etc.</li><li>Communicate and coordinate effectively with business and technical personnel.</li><li>Self-motivated – Estimate accurately and efficiently manage effort / competing priorities to complete tasks on schedule.<br></li></ul><strong><u>What You Need To Have<br></u></strong><ul><li>BS/BA and above in Computer Science, Engineering, Information Systems, and/or equivalent formal training or experience.</li><li>5+ years of experience in the development of complex projects involving significant processing, manipulation, and volume.</li><li>Experienced with batch-oriented, API, and/or streaming processes.</li><li>Complete analysis and communications skills.</li><li>Strong hands-on experience with Oracle – experience with MS SQL and/or Postgres, etc., are highly desirable.</li><li>Experience with scripting languages like Windows PowerShell, Python, etc., is a plus.</li><li>Background in a similar industry: Wealth Management, Broker-Dealer, Financial Services.<br><br><br></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Information Services"
Data Engineer (Jr-Level),"New York, NY",Averity,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-jr-level-at-averity-2416733165?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=kdy4hSKNW%2F2NBy5z%2BjVHsQ%3D%3D&position=20&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Overview

Technology at General Mills accelerates process transformation and business growth around the globe. To achieve business success, the Digital & Technology team uses leading edge technology, innovative thinking and agile processes. One of our General Mills’ key technology priorities is driving business action through connected data.

The General Mills Digital & Technology organization is currently in the process of building a cloud data platform to advance the data-driven decision making capabilities of our enterprise. Additionally, General Mills also leverages a big data platform based on Cloudera Hadoop. If you are an agile learner, have strong problem solving skills and are able to function as part of a highly technical, cross functional team, we would like to hear from you.

General Mills is seeking a Data Engineer to act as a key technical leader in our organization.

Key Responsibilities

Act as a key technical leader within General Mills
Design, create, code, and support a variety of ETL solutions (potentially including but not limited to: Talend Studio, Python, Scala, Kafka, SAP Data Services, or others)
Generate and implement your own ideas on how to improve the operational and strategic health of big data ecosystem
Participate in the evaluation, implementation and deployment of emerging tools & process in the big data space.
Partner with business analysts and solutions architects to deliver business initiatives.
Collaboratively troubleshoot technical and performance issues in the big data ecosystem


Minimum Qualifications

Bachelor’s Degree; Computer Science, MIS, or Engineering preferred
Minimum 2 years of IT experience, 3+ preferred
Cloud data experience
Strong understanding of Hadoop fundamentals
Database development experience using Oracle, SQL Server, SAP BW or SAP HANA
Job Scheduling experience
Process mindset with experience creating, documenting and implementing standard processes
Development experience using Hive and/or Spark
Effective verbal and written communication and influencing skills.
Effective analytical and technical skills.
Ability to work in a team environment
Ability to research, plan, organize, lead, and implement new processes or technology



Preferred Qualifications

Python, Scala or Java development experience
Familiarity with Kafka
Familiarity with the Linux operating system
Experience with agile techniques or methods


Company Overview

We exist to make food the world loves. But we do more than that. Our company is a place that prioritizes being a force for good, a place to expand learning, explore new perspectives and reimagine new possibilities, every day. We look for people who want to bring their best — bold thinkers with big hearts who challenge one other and grow together. Because becoming the undisputed leader in food means surrounding ourselves with people who are hungry for what’s next.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong>Technology at General Mills accelerates process transformation and business growth around the globe. To achieve business success, the Digital &amp; Technology team uses leading edge technology, innovative thinking and agile processes. One of our General Mills’ key technology priorities is driving business action through connected data.<br><br>The General Mills Digital &amp; Technology organization is currently in the process of building a cloud data platform to advance the data-driven decision making capabilities of our enterprise. Additionally, General Mills also leverages a big data platform based on Cloudera Hadoop. If you are an agile learner, have strong problem solving skills and are able to function as part of a highly technical, cross functional team, we would like to hear from you.<br><br>General Mills is seeking a Data Engineer to act as a key technical leader in our organization.<br><br><strong><u>Key Responsibilities<br></u></strong><ul><li>Act as a key technical leader within General Mills</li><li>Design, create, code, and support a variety of ETL solutions (potentially including but not limited to: Talend Studio, Python, Scala, Kafka, SAP Data Services, or others)</li><li>Generate and implement your own ideas on how to improve the operational and strategic health of big data ecosystem</li><li>Participate in the evaluation, implementation and deployment of emerging tools &amp; process in the big data space.</li><li>Partner with business analysts and solutions architects to deliver business initiatives.</li><li>Collaboratively troubleshoot technical and performance issues in the big data ecosystem<br><br></li></ul><strong><u>Minimum Qualifications<br></u></strong><ul><li>Bachelor’s Degree; Computer Science, MIS, or Engineering preferred</li><li>Minimum 2 years of IT experience, 3+ preferred<br>Cloud data experience</li><li>Strong understanding of Hadoop fundamentals</li><li>Database development experience using Oracle, SQL Server, SAP BW or SAP HANA</li><li>Job Scheduling experience</li><li>Process mindset with experience creating, documenting and implementing standard processes</li><li>Development experience using Hive and/or Spark</li><li>Effective verbal and written communication and influencing skills.</li><li>Effective analytical and technical skills.</li><li>Ability to work in a team environment</li><li>Ability to research, plan, organize, lead, and implement new processes or technology<br><br><br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Python, Scala or Java development experience</li><li>Familiarity with Kafka </li><li>Familiarity with the Linux operating system</li><li>Experience with agile techniques or methods<br><br></li></ul><strong><u>Company Overview<br><br></u></strong>We exist to make food the world loves. But we do more than that. Our company is a place that prioritizes being a force for good, a place to expand learning, explore new perspectives and reimagine new possibilities, every day. We look for people who want to bring their best — bold thinkers with big hearts who challenge one other and grow together. Because becoming the undisputed leader in food means surrounding ourselves with people who are hungry for what’s next.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Food & Beverages, Consumer Goods"
Data Engineer,"Houston, TX",Sysco,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-sysco-2429717539?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=cRW%2F5cHCP2ToBRnzsE4lNw%3D%3D&position=21&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Are you a Junior Level Data Engineer that loves building data, writing code, implementing and building platforms? Do you also have great communication skills and can handle pressure well for customer facing responsibilities? Can you quickly deliver on customer requests? If so, then you will love this role on the team helping overcome problems and finding the solutions.

 

What's The Job?

 

As a Data Engineer on our team you will be problem solving, troubleshooting and engaging regularly with Customer/Vendor teams and delivering on all technical requests. You will be working on creating ETL pipelines, ingest/export integrations, new product lines and orchestrating platform migrations. Also there is building different tools for automation and customer specific configurations.

 

Who Are We?

 

We are a Customer Data Platform seeking to transform the industry. We provide ways to extract specific customer behavior data for large and well-known brands. This allows our clients to increase their marketing efforts and profitability.

We are an established Startup backed by some serious Venture Capital and are growing quickly due to bringing on board more big name clients. We are national but our head office is located here in the Flatiron area in Manhattan.

 

What Skills Do You Need?

 

REQUIRED Experience in a technical & client-facing role 1+ years
Experience working with Python and SQL in production
Experience involving large data sets for ETL & Data Warehousing
Independent mindset always finding ways to improve processes
Good problem solver and effective communication skills

 

Compensation

 

$85,000 - $110,000 base salary (based on experience)
Generous vacation
Full Medical, Dental and Vision
401(K) Matching

 

We are big proponents of diversity, and encourage diverse applicants / candidates with diverse backgrounds to apply.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Are you a Junior Level Data Engineer that loves building data, writing code, implementing and building platforms? Do you also have great communication skills and can handle pressure well for customer facing responsibilities? Can you quickly deliver on customer requests? If so, then you will love this role on the team helping overcome problems and finding the solutions.</p><p>&nbsp;</p><p><strong>What's The Job?</strong></p><p>&nbsp;</p><p>As a Data Engineer on our team you will be problem solving, troubleshooting and engaging regularly with Customer/Vendor teams and delivering on all technical requests. You will be working on creating ETL pipelines, ingest/export integrations, new product lines and orchestrating platform migrations. Also there is building different tools for automation and customer specific configurations.</p><p>&nbsp;</p><p><strong>Who Are We?</strong></p><p>&nbsp;</p><p>We are a Customer Data Platform seeking to transform the industry. We provide ways to extract specific customer behavior data for large and well-known brands. This allows our clients to increase their marketing efforts and profitability.</p><p>We are an established Startup backed by some serious Venture Capital and are growing quickly due to bringing on board more big name clients. We are national but our head office is located here in the Flatiron area in Manhattan.</p><p>&nbsp;</p><p><strong>What Skills Do You Need?</strong></p><p>&nbsp;</p><ul><li>REQUIRED Experience in a technical &amp; client-facing role 1+ years</li><li>Experience working with Python and SQL in production</li><li>Experience involving large data sets for ETL &amp; Data Warehousing</li><li>Independent mindset always finding ways to improve processes</li><li>Good problem solver and effective communication skills</li></ul><p>&nbsp;</p><p><strong>Compensation</strong></p><p>&nbsp;</p><ul><li>$85,000 - $110,000 base salary (based on experience)</li><li>Generous vacation</li><li>Full Medical, Dental and Vision</li><li>401(K) Matching</li></ul><p>&nbsp;</p><p>We are big proponents of diversity, and encourage diverse applicants / candidates with diverse backgrounds to apply.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Engineer,"Mountain View, CA",Samsung Electronics America,2021-02-08,https://www.linkedin.com/jobs/view/data-engineer-at-samsung-electronics-america-2373053183?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=3ZEo5W%2Fl62mF5COXyy0Z6g%3D%3D&position=22&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Company

US6469 Sysco Payroll, Division of Sysco Resources Services, LLC

Zip Code

77077

Minimum Level Of Education

Bachelor’s Degree

Minimum Years Of Experience

5 Years

Employment Type

Full Time

Overview

Travel Percentage:

We offer our associates the opportunity to grow personally and professionally, to contribute to the success of a dynamic organization, and to serve others in a manner that exceeds their expectations. We’re looking for talented, hard-working individuals to join our team. Come grow with us and let us show you why Sysco is at the heart of food and service.

Job Summary

Drives effective delivery of product/platform needs through developing high quality software and technical solutions. Fluent across the full stack and coaches junior developers to promote a flexible mindset and develop technical competence

Responsibilities

Leverages strong understanding of business to develop high quality code to meet product/platform requirements
D rives and leads adoption of architecture standards and development practices like Test-Driven development, code reviews, static code analysis etc.
Writes effective technical user stories and ensures that non-functional requirements are met to ensure performance, scaling, resilience and maintainability of software/solutions
Actively resolves defects and manages technical debt
Develops unit tests to ensure good coverage and regression testing ability
Assists in the development of automated tests and environment management scripts
Practices DevOps methods like CI/CD, SDLC automation and proactive monitoring/telemetry
Participates in sprint planning, daily stand-ups, sprint reviews and retrospectives to enable progress, and surface and resolve impediments
Evaluates emerging technologies continually to identify opportunities, trends and best practices to strengthen Sysco’s development practices
May play a supervisory role toward junior technical resources as they commit to and deliver work


Mandatory Experience

Bachelor's degree in CS or 4-5 years of relevant developer experience
5-10 years of experience in developing high performance and highly scalable applications in an agile environment, depending on education
Extensive hands-on experience and expertise in modern programming languages (Java, JavaScript, C#, Python, Ruby, Groovy)
Strong understanding of Scrum, Lean, XP, Kanban and other agile development techniques
Strong experience building and deploying applications on a cloud platform such as AWS
Fluency in DevOps, including continuous integration, continuous deployment / delivery, configuration and containerization, infrastructure as a code, and monitoring


Competencies

Demonstrated “agile-development” mindset with strong customer-focus & results-orientation
Flexible mindset (not married to a single language) and demonstrated ability to grow skillset and work across the full technology stack
Ability to excel in a fast paced agile environment
Excellent communication skills to effectively manage key business stakeholder relationships
Highly proficient in teamwork and collaboration skills


Preferred Experience

5+ years of experience in data engineering
Excellent analytical capabilities, including experience collecting, analyzing and gathering insights from very large data sets
High proficiency with SQL, ETL, and data visualization skills
High proficiency with Microsoft Excel and other Microsoft Office Suite Applications
Prior experience working with AWS technologies like EC2, Lambda, RedShift, S3, Kineses, Firehose, and Glue

Applicants must be currently authorized to work in the United States.

We are proud to be an Equal Opportunity and Affirmative Action employer, and considers qualified applicants without regard to race, color, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, disability, veteran status or any other protected factor under federal, state or local law.

This opportunity is available through Sysco Corporation, its subsidiaries and affiliates.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company<br><br></u></strong>US6469 Sysco Payroll, Division of Sysco Resources Services, LLC<br><br><strong><u>Zip Code<br><br></u></strong>77077<br><br><strong><u>Minimum Level Of Education<br><br></u></strong>Bachelor’s Degree<br><br><strong><u>Minimum Years Of Experience<br><br></u></strong>5 Years<br><br><strong><u>Employment Type<br><br></u></strong>Full Time<br><br><strong><u>Overview<br><br></u></strong><strong>Travel Percentage:<br><br></strong>We offer our associates the opportunity to grow personally and professionally, to contribute to the success of a dynamic organization, and to serve others in a manner that exceeds their expectations. We’re looking for talented, hard-working individuals to join our team. Come grow with us and let us show you why Sysco is at the heart of food and service.<br><br><strong><u>Job Summary<br><br></u></strong>Drives effective delivery of product/platform needs through developing high quality software and technical solutions. Fluent across the full stack and coaches junior developers to promote a flexible mindset and develop technical competence<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Leverages strong understanding of business to develop high quality code to meet product/platform requirements </li><li>D rives and leads adoption of architecture standards and development practices like Test-Driven development, code reviews, static code analysis etc. </li><li> Writes effective technical user stories and ensures that non-functional requirements are met to ensure performance, scaling, resilience and maintainability of software/solutions </li><li> Actively resolves defects and manages technical debt </li><li> Develops unit tests to ensure good coverage and regression testing ability </li><li> Assists in the development of automated tests and environment management scripts </li><li> Practices DevOps methods like CI/CD, SDLC automation and proactive monitoring/telemetry </li><li> Participates in sprint planning, daily stand-ups, sprint reviews and retrospectives to enable progress, and surface and resolve impediments </li><li> Evaluates emerging technologies continually to identify opportunities, trends and best practices to strengthen Sysco’s development practices </li><li> May play a supervisory role toward junior technical resources as they commit to and deliver work <br><br></li></ul><strong><u>Mandatory Experience<br></u></strong><ul><li> Bachelor's degree in CS or 4-5 years of relevant developer experience </li><li> 5-10 years of experience in developing high performance and highly scalable applications in an agile environment, depending on education </li><li> Extensive hands-on experience and expertise in modern programming languages (Java, JavaScript, C#, Python, Ruby, Groovy) </li><li> Strong understanding of Scrum, Lean, XP, Kanban and other agile development techniques </li><li> Strong experience building and deploying applications on a cloud platform such as AWS </li><li> Fluency in DevOps, including continuous integration, continuous deployment / delivery, configuration and containerization, infrastructure as a code, and monitoring <br><br></li></ul><strong><u>Competencies<br></u></strong><ul><li> Demonstrated “agile-development” mindset with strong customer-focus &amp; results-orientation </li><li> Flexible mindset (not married to a single language) and demonstrated ability to grow skillset and work across the full technology stack </li><li> Ability to excel in a fast paced agile environment </li><li> Excellent communication skills to effectively manage key business stakeholder relationships </li><li> Highly proficient in teamwork and collaboration skills <br><br></li></ul><strong><u>Preferred Experience<br></u></strong><ul><li>5+ years of experience in data engineering</li><li>Excellent analytical capabilities, including experience collecting, analyzing and gathering insights from very large data sets</li><li>High proficiency with SQL, ETL, and data visualization skills</li><li>High proficiency with Microsoft Excel and other Microsoft Office Suite Applications</li><li>Prior experience working with AWS technologies like EC2, Lambda, RedShift, S3, Kineses, Firehose, and Glue<br></li></ul>Applicants must be currently authorized to work in the United States.<br><br>We are proud to be an Equal Opportunity and Affirmative Action employer, and considers qualified applicants without regard to race, color, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, disability, veteran status or any other protected factor under federal, state or local law.<br><br>This opportunity is available through Sysco Corporation, its subsidiaries and affiliates.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Food & Beverages, Transportation/Trucking/Railroad"
Data Engineer,"Denver, CO","Ibotta, Inc.",2021-02-07,https://www.linkedin.com/jobs/view/data-engineer-at-ibotta-inc-2368806343?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=oCtiLn%2FbLiVvMRDO3hTrVw%3D%3D&position=23&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Position Summary

General DescriptionTechnical professionals are defined by what they create. Samsung has the risk taking corporate culture, strategic R&D investments and global know-how to imagine, develop and market products that lead the industry. Samsung Ads group located in Mountain View, CA is currently recruiting world-class engineers who share our “Innovation through passion” philosophy and thrive in a well-paced, results-driven environment. Samsung Ads team is responsible for delivering market leading Advertising products and services delivering billions of ad impressions to hundreds of millions of devices. This role is primarily focused on the Audience Builder product of Samsung Ads. Audience Builder provides the ability to build audiences based on the engagement with a particular content on Smart TVs that can be used for targeting Ads

Role and Responsibilities



Responsibilities


Design and develop scalable data stores and frameworks with sub-second query latency on highly multi-dimensional data.
Engineering solutions to aggregate and automate large scale data flows from varying sources
Build real time streaming pipelines that deliver data with measurable quality under the SLA
Ability to effectively communicate ideas to peers and distributed teams
Delivering products with top notch quality in a fast-paced environment
Contributing towards building a system with a test-driven development / agile approach
Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release. 
Works on complex issues where analyzing situations or data requires an in-depth evaluation of variables. Exercises judgement in selecting methods, techniques and evaluation criteria to obtain results.
Champion best practices for high availability, scalability and reliability of data processing components


Skills and Qualifications



Requirements:


Bachelor's degree in Computer Science/Engineering with 8+ years of experience or Master’s degree with 6+ years directly related experience.
Experience with large-scale distributed systems as pertains to data storage and computing.
Extensive experience with Amazon AWS technologies S3, EMR or similar cloud offerings.
Strong development skills in Java, Scala and/or PySpark
Knowledge of various databases / database technologies - Oracle, Postgres, Cassandra (NoSQL), Vertica or other columnar databases.
Advanced disciplinary knowledge in data technologies like Airflow, Spark, Python, Sql, Java, AWS and strong CS Fundamentals
Experience with caching technologies using Redis, Memcached
Experience with Full Stack development and building services on the data stack
Demonstrated strength in data modeling, ETL development, and data warehousing
Highly proficient in Object Oriented Design and Development


Not-Required but Preferred:


Experience building micro services on Kubernetes a plus
Experience working in the Advertising domain a big plus






Samsung Electronics America, Inc. is committed to employing a diverse workforce, and provides Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.



* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here .



* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and  provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Position Summary<br><br></strong>General DescriptionTechnical professionals are defined by what they create. Samsung has the risk taking corporate culture, strategic R&amp;D investments and global know-how to imagine, develop and market products that lead the industry. Samsung Ads group located in Mountain View, CA is currently recruiting world-class engineers who share our “Innovation through passion” philosophy and thrive in a well-paced, results-driven environment. Samsung Ads team is responsible for delivering market leading Advertising products and services delivering billions of ad impressions to hundreds of millions of devices. This role is primarily focused on the Audience Builder product of Samsung Ads. Audience Builder provides the ability to build audiences based on the engagement with a particular content on Smart TVs that can be used for targeting Ads<br><br>           <strong> Role and Responsibilities </strong>           <br><br><br><br><strong>Responsibilities<br><br></strong><ul><li>Design and develop scalable data stores and frameworks with sub-second query latency on highly multi-dimensional data.</li><li>Engineering solutions to aggregate and automate large scale data flows from varying sources</li><li>Build real time streaming pipelines that deliver data with measurable quality under the SLA</li><li>Ability to effectively communicate ideas to peers and distributed teams</li><li>Delivering products with top notch quality in a fast-paced environment</li><li>Contributing towards building a system with a test-driven development / agile approach</li><li>Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release.&nbsp;</li><li> Works on complex issues where analyzing situations or data requires an in-depth evaluation of variables. Exercises judgement in selecting methods, techniques and evaluation criteria to obtain results.  </li><li> Champion best practices for high availability, scalability and reliability of data processing components <br><br></li></ul>                                    <strong> Skills and Qualifications </strong>                                    <br><br><br><br><strong>Requirements:<br><br></strong><ul><li>Bachelor's degree in Computer Science/Engineering with 8+ years of experience or Master’s degree with 6+ years directly related experience.</li><li>Experience with large-scale distributed systems as pertains to data storage and computing.</li><li>Extensive experience with Amazon AWS technologies S3, EMR or similar cloud offerings.</li><li>Strong development skills in Java, Scala and/or PySpark</li><li>Knowledge of various databases / database technologies - Oracle, Postgres, Cassandra (NoSQL), Vertica or other columnar databases.</li><li> Advanced disciplinary knowledge&nbsp;in data technologies like Airflow, Spark, Python, Sql, Java, AWS and strong CS Fundamentals </li><li>Experience with caching technologies using Redis, Memcached</li><li>Experience with Full Stack development and building services on the data stack</li><li>Demonstrated strength in data modeling, ETL development, and data warehousing</li><li>Highly proficient in Object Oriented Design and Development<br><br></li></ul><strong>Not-Required but Preferred:<br><br></strong><ul><li>Experience building micro services on Kubernetes a plus</li><li>Experience working in the Advertising domain a big plus<br><br><br><br><br><br></li></ul> Samsung Electronics America, Inc. is committed to employing a diverse workforce, and provides Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law. <br><br><br><br> * Please visit  Samsung membership  to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click   here .<br><br><br><br>* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and &nbsp;provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Consumer Goods, Retail"
Data Scientist,"Beaverton, OR",Nike,2021-01-28,https://www.linkedin.com/jobs/view/data-scientist-at-nike-2416450106?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=IIZAhMCLkyW0RK4K6ARewQ%3D%3D&position=24&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Ibotta is looking for a Data Engineer to build something great with us. As part of the Data Services team, you will work with both Engineering and Analytics to develop and own stable, scalable, and forward-thinking data-driven processes. We're looking for a self-motivated engineer who has a passion for working with an event-based architecture heavily leveraging AWS cloud tools. The data engineering team is core to driving and delivering the current and future data, analytics, and decisioning platforms across Ibotta.

What You Will Be Doing

Embrace and uphold Ibotta’s Core Values: Integrity, Boldness, Ownership, Teamwork, Transparency & Advocate for Savers
Work with engineering, analytics, and product management to implement and support event-driven processes
Be a key contributor in the engineering of distributed systems, frameworks, and design patterns of BI and Data Science/Machine Learning
Use Scala, Java, or Python to utilize Hadoop/Spark to collect and analyze large-scale datasets
Design, implement and maintain distributed messaging systems
Build, monitor, and maintain data ETL pipelines
Help manage Data Governance and Security
Administer and maintain our data infrastructure
Mentor junior data engineers in principles and best practices
Share relevant knowledge and evangelize Data Engineering with Platform and Analytics teams



What We Are Looking For

Bachelor’s degree in Computer Science, Engineering or a related field or equivalent work experience
2+ years of experience in software development, preferably with Scala, Java, or Python
1-2+ years of experience working in the Hadoop ecosystem, using tools such as Hive, Spark, or Pig
Proven expertise in taking data projects from ideation to implementation
Some experience with event-driven architecture design patterns and practices
Experience in database design and architecture principles, and strong SQL abilities
Experience with the following a strong plus:
AWS Cloud Services, like EC2, EMR, RDS, or Redshift
Experience with Python, Hadoop, Hive, and Spark (either PySpark or Scala)
Message Brokers such as Kafka or Kinesis
ETL tools and processes (Airflow or other similar tools)
Agile (Kanban or Scrum) development experience


About Us

Built in Denver, CO, Ibotta (""I bought a..."") is a free mobile shopping app that gives users cash back on groceries and more. Through our partnerships with brands and retailers like Procter & Gamble, Kraft Heinz, Kellogg, Amazon, Walmart, Target and Uber, we’ve delivered over $800 million in cumulative cash rewards to our Savers. Guided by our values and our mission to make every purchase rewarding, we come to work energized by the business problems we get to solve, the technology we get to build, and the people we get to innovate (and have fun) with. Ibotta made Inc.’s 2020 list of the 5000 fastest-growing private companies in the U.S. for the third consecutive year. In 2019, we became the first mobile consumer technology company in Colorado to achieve $1B in valuation.

To learn more about what our Tech teams are doing day to day, visit Building Ibotta on Medium.com

Additional Details

This position is located in Denver, CO and includes competitive pay, flexible time off, benefits package (including medical, dental, vision), Lifestyle Spending Account, 401k match, profit sharing and equity.
Base compensation range: $90,000 - $120,000
Ibotta is an Equal Opportunity Employer. Ibotta’s employment decisions are made without regard with race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected status
Applicants must be currently authorized to work in the United States on a full-time basis.
For the security of our employees and the business, all employees are responsible for the secure handling of data in accordance with our security policies, identifying and reporting phishing attempts, as well as reporting security incidents to the proper channels.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Ibotta is looking for a <strong>Data Engineer</strong> to build something great with us. As part of the Data Services team, you will work with both Engineering and Analytics to develop and own stable, scalable, and forward-thinking data-driven processes. We're looking for a self-motivated engineer who has a passion for working with an event-based architecture heavily leveraging AWS cloud tools. The data engineering team is core to driving and delivering the current and future data, analytics, and decisioning platforms across Ibotta.<br><br><strong><u>What You Will Be Doing<br></u></strong><ul> <li>Embrace and uphold Ibotta’s Core Values: <em>Integrity, Boldness, Ownership, Teamwork, Transparency &amp; Advocate for Savers</em></li> <li>Work with engineering, analytics, and product management to implement and support event-driven processes</li> <li>Be a key contributor in the engineering of distributed systems, frameworks, and design patterns of BI and Data Science/Machine Learning</li> <li>Use Scala, Java, or Python to utilize Hadoop/Spark to collect and analyze large-scale datasets</li> <li>Design, implement and maintain distributed messaging systems</li> <li>Build, monitor, and maintain data ETL pipelines</li> <li>Help manage Data Governance and Security</li> <li>Administer and maintain our data infrastructure</li> <li>Mentor junior data engineers in principles and best practices</li> <li>Share relevant knowledge and evangelize Data Engineering with Platform and Analytics teams</li> <br><br></ul><strong><u>What We Are Looking For<br></u></strong><ul> <li>Bachelor’s degree in Computer Science, Engineering or a related field or equivalent work experience</li> <li>2+ years of experience in software development, preferably with Scala, Java, or Python</li> <li>1-2+ years of experience working in the Hadoop ecosystem, using tools such as Hive, Spark, or Pig</li> <li>Proven expertise in taking data projects from ideation to implementation</li> <li>Some experience with event-driven architecture design patterns and practices</li> <li>Experience in database design and architecture principles, and strong SQL abilities</li> <li>Experience with the following a strong plus:</li></ul><ul> <li>AWS Cloud Services, like EC2, EMR, RDS, or Redshift</li> <li>Experience with Python, Hadoop, Hive, and Spark (either PySpark or Scala)</li> <li>Message Brokers such as Kafka or Kinesis</li> <li>ETL tools and processes (Airflow or other similar tools)</li> </ul> <li>Agile (Kanban or Scrum) development experience</li> <br><br><strong><u>About Us<br><br></u></strong>Built in Denver, CO, Ibotta (""I bought a..."") is a free mobile shopping app that gives users cash back on groceries and more. Through our partnerships with brands and retailers like Procter &amp; Gamble, Kraft Heinz, Kellogg, Amazon, Walmart, Target and Uber, we’ve delivered over $800 million in cumulative cash rewards to our Savers. Guided by our values and our mission to make every purchase rewarding, we come to work energized by the business problems we get to solve, the technology we get to build, and the people we get to innovate (and have fun) with. Ibotta made Inc.’s 2020 list of the 5000 fastest-growing private companies in the U.S. for the third consecutive year. In 2019, we became the first mobile consumer technology company in Colorado to achieve $1B in valuation.<br><br>To learn more about what our Tech teams are doing day to day, visit Building Ibotta on Medium.com<br><br><strong><u>Additional Details<br></u></strong><ul> <li>This position is located in Denver, CO and includes competitive pay, flexible time off, benefits package (including medical, dental, vision), Lifestyle Spending Account, 401k match, profit sharing and equity.</li> <li>Base compensation range: $90,000 - $120,000</li> <li>Ibotta is an Equal Opportunity Employer. Ibotta’s employment decisions are made without regard with race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected status</li> <li>Applicants must be currently authorized to work in the United States on a full-time basis.</li> <li>For the security of our employees and the business, all employees are responsible for the secure handling of data in accordance with our security policies, identifying and reporting phishing attempts, as well as reporting security incidents to the proper channels.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"Seattle, WA",Seattle Children's,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-at-seattle-children-s-2396989960?refId=01fa7584-2802-4e04-a6d6-8144d61e68f3&trackingId=jiO0spHN5VbVOjuXMfUZGQ%3D%3D&position=25&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click,"Analytics is a competitive differentiator for Nike and is fundamentally changing how the company serves athletes and consumers around the world! Our Nike Commercial Analytics team builds analytic-based solutions to manage marketplace and optimize the supply chain. Using big data, advanced analytics and state-of-the-art technology, the team strives to ensure that Nike gets the right product to the right place at the right time for the consumers.

Who We Are Looking For

We are looking for a Data Scientist to join the Advanced Analytics team within Commercial Analytics. This role will be part of a multi-functional agile squad responsible for using predictive analytics to forecast consumer demand, enhance decision making and drive to action against our strategic priorities.

The candidate needs to be a dependable teammate with hands-on analytics experience, drive, and curiosity. While you are grounded in good working knowledge of data science methods, you know how to rise above the numbers and explain the essential insights to users at all levels. You ask good questions, are continually learning, and can effectively interact with and influence your colleagues and partners.

What You Will Work On

If this is you, you will be part of an Advanced Analytics squad. We deliver scalable models to power digital demand sensing and enable critical investment decisions at Nike. Specifically, you will:

Collaborate with other squad members to develop new sophisticated algorithms and improve existing approaches based on statistical/econometric methods, machine learning techniques and big data solutions to forecast consumer demand and determine optimal level of investment in various stages of the supply chain.
Assist in the design of analytics solutions and the identification of the best method for a problem based on business requirements and constraints.
Apply analytics methods to acquire, explore, cleanse, and fuse data from different sources.
Contribute to building, scoring, deploying, monitoring, updating and promoting Nike’s central forecasting platform.
Facilitate the planning, scheduling and value measurement of the work to meet timeline targets and success criteria.
Support the adoption of analytic products through effective storytelling and collaboration with key partners.
Participate in a continuous learning environment within the advanced analytics community through persistent development of new skills and sharing of knowledge through mentorships and contributions to the open source community.
WHO YOU WILL WORK WITH
You will work with the Director of Data Science while partner on daily basis with fellow data scientists, data analysts, engineers and product owner on your squad. You will collaborate across the broader organization with business teams in Demand and Supply Management as well as other data, analytics and technology functions at Nike.

What You Bring

Advanced quantitative degree (Statistics, Mathematics, Economics, Computer Science or related field) and at least 3 years of relevant industry experience or Bachelor’s degree and at least 5 years of relevant professional experience.
Demonstrated understanding of market demand and supply interactions, data structures, data science methods, and machine learning algorithms.
Solid skills in programming languages (particularly Python and SQL) and ability to apply them for data acquisition, preprocessing, modeling and monitoring.
Familiarity with common data science/analytics software tools (e.g. Jupyter Notebook, SQL consoles, Hadoop, Spark) and cloud computing platforms (e.g. Amazon Web Services).
Experience in building, training, scoring, tuning and maintaining predictive models in production at enterprise scale and familiarity with mainstream packages relevant to managing all stages of Data Science/Analytics lifecycle.
Familiarity with the Agile development process and Ability to work cross functionally and evaluate complex business information from multiple perspectives, including questioning assumptions and validity.
Excellent written and verbal communication skills, including ability to develop and deliver presentation.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Analytics is a competitive differentiator for Nike and is fundamentally changing how the company serves athletes and consumers around the world! Our Nike Commercial Analytics team builds analytic-based solutions to manage marketplace and optimize the supply chain. Using big data, advanced analytics and state-of-the-art technology, the team strives to ensure that Nike gets the right product to the right place at the right time for the consumers.<br><br><strong><u>Who We Are Looking For<br><br></u></strong>We are looking for a Data Scientist to join the Advanced Analytics team within Commercial Analytics. This role will be part of a multi-functional agile squad responsible for using predictive analytics to forecast consumer demand, enhance decision making and drive to action against our strategic priorities.<br><br>The candidate needs to be a dependable teammate with hands-on analytics experience, drive, and curiosity. While you are grounded in good working knowledge of data science methods, you know how to rise above the numbers and explain the essential insights to users at all levels. You ask good questions, are continually learning, and can effectively interact with and influence your colleagues and partners.<br><br><strong><u>What You Will Work On<br><br></u></strong>If this is you, you will be part of an Advanced Analytics squad. We deliver scalable models to power digital demand sensing and enable critical investment decisions at Nike. Specifically, you will:<br><ul> <li>Collaborate with other squad members to develop new sophisticated algorithms and improve existing approaches based on statistical/econometric methods, machine learning techniques and big data solutions to forecast consumer demand and determine optimal level of investment in various stages of the supply chain.</li> <li>Assist in the design of analytics solutions and the identification of the best method for a problem based on business requirements and constraints.</li> <li>Apply analytics methods to acquire, explore, cleanse, and fuse data from different sources.</li> <li>Contribute to building, scoring, deploying, monitoring, updating and promoting Nike’s central forecasting platform.</li> <li>Facilitate the planning, scheduling and value measurement of the work to meet timeline targets and success criteria.</li> <li>Support the adoption of analytic products through effective storytelling and collaboration with key partners.</li> <li>Participate in a continuous learning environment within the advanced analytics community through persistent development of new skills and sharing of knowledge through mentorships and contributions to the open source community.</li> </ul> WHO YOU WILL WORK WITH<br>You will work with the Director of Data Science while partner on daily basis with fellow data scientists, data analysts, engineers and product owner on your squad. You will collaborate across the broader organization with business teams in Demand and Supply Management as well as other data, analytics and technology functions at Nike.<br><br><strong><u>What You Bring<br></u></strong><ul> <li>Advanced quantitative degree (Statistics, Mathematics, Economics, Computer Science or related field) and at least 3 years of relevant industry experience or Bachelor’s degree and at least 5 years of relevant professional experience.</li> <li>Demonstrated understanding of market demand and supply interactions, data structures, data science methods, and machine learning algorithms.</li> <li>Solid skills in programming languages (particularly Python and SQL) and ability to apply them for data acquisition, preprocessing, modeling and monitoring.</li> <li>Familiarity with common data science/analytics software tools (e.g. Jupyter Notebook, SQL consoles, Hadoop, Spark) and cloud computing platforms (e.g. Amazon Web Services).</li> <li>Experience in building, training, scoring, tuning and maintaining predictive models in production at enterprise scale and familiarity with mainstream packages relevant to managing all stages of Data Science/Analytics lifecycle.</li> <li>Familiarity with the Agile development process and Ability to work cross functionally and evaluate complex business information from multiple perspectives, including questioning assumptions and validity.</li> <li>Excellent written and verbal communication skills, including ability to develop and deliver presentation.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Data Engineer (New Grad),"New York, New York, United States",Orchard,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-new-grad-at-orchard-2429708802?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=st5uh4dpTWwotZAfQj8GLg%3D%3D&position=1&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Overview

We are actively seeking a Data Engineer to build a data processing pipeline that collects, connects, centralizes, and curates data from various internal and external sources using a variety of languages and tools to marry systems together for the Enterprise Data Warehouse. This role is pivotal to the mission and vision of Seattle Children's Enterprise Analytics team to transform healthcare for children by providing patient safety, predictive analysis to cure diseases, and lowering cost of treatement.

Responsibilities

Develop highly scalable and reliable data engineering solutions for moving data efficiently across systems.
Design, implement, test, and deploy data processing infrastructure.
Break down, estimate, and provide just-in-time design for small increments of work.
Perform work in an Agile team setting.

Seattle Children's Employer Highlights

Leader in Pediatric Care: Because of our people, Seattle Children's is recognized as a leading teaching, research and specialty care center at the forefront of pediatric care.
Competitive Benefits: We support a healthy work-life balance. Our benefits include employee care, paid time off, health insurance and retirement savings.
Diversity/Inclusion: We strive to maintain an atmosphere that reflects our values of inclusion by providing effective and respectful care compatible with each patient and family's beliefs, values, and heritage.

Requirements

Required Education/Experience: - Bachelor's Degree in computer science or related field OR equivalent combination of education and experience/technical training that demonstrates analytical and technical competency. - Minimum of two (2) years of technology industry or related experience, including items such as: - Build highly scalable, scaled-out architectures on large scale database platforms. - Experience working in a complex data infrastructure environment. - Two (2) years of experience in a data engineering role. - Data pipeline development experience with industry standard data integration tools. - Advanced competency in SQL with ability to perform query optimization in large scale database platforms. - Experience in SDLC process with requirements gathering, analysis, architecture, design, implementation, testing, deployment and technical support. - Experience with any industry standard tool for Source Control and Project Management. - Experience writing test cases and test scripts for data quality assurance. - Experience creating stored procedures and functions. - Experience developing dimensional data model with any industry standard tool. Preferred: - Experience in Healthcare or related industry. - Experience utilizing Netezza, Datastage, BitBucket, JIRA, Confluence a plus. - Experience productizing/automating predictive models that use R, SAS, Python, SPSS, etc. - Continuous delivery and deployment automation for analytic solutions using tools like Bamboo. - Familiarity with test driven development methodology for analytic solutions. - AGILE. - API development. - Data visualization and/or dashboard development.

Our Commitment to Diversity

Our community welcomes diverse experiences, backgrounds, and thoughts as this is what drives our spirit of inquiry and allows us to better connect with our increasingly diverse patients and families. Our organization recruits, employs, trains, compensates, and promotes without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

The people who work at Seattle Children's are members of a community that seeks to respect and celebrate all the qualities that make each of us unique. Each of us is empowered to be ourselves within this community, which cultivates and promotes equity, diversity, and inclusion at all levels.

Seattle Children's is proud to be an Equal Opportunity Workplace and Affirmative Action Employer.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong>We are actively seeking a Data Engineer to build a data processing pipeline that collects, connects, centralizes, and curates data from various internal and external sources using a variety of languages and tools to marry systems together for the Enterprise Data Warehouse. This role is pivotal to the mission and vision of Seattle Children's Enterprise Analytics team to transform healthcare for children by providing patient safety, predictive analysis to cure diseases, and lowering cost of treatement.<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Develop highly scalable and reliable data engineering solutions for moving data efficiently across systems.</li><li> Design, implement, test, and deploy data processing infrastructure.</li><li> Break down, estimate, and provide just-in-time design for small increments of work.</li><li> Perform work in an Agile team setting.<br></li></ul><strong><u>Seattle Children's Employer Highlights<br></u></strong><ul><li> Leader in Pediatric Care: Because of our people, Seattle Children's is recognized as a leading teaching, research and specialty care center at the forefront of pediatric care.</li><li> Competitive Benefits: We support a healthy work-life balance. Our benefits include employee care, paid time off, health insurance and retirement savings.</li><li> Diversity/Inclusion: We strive to maintain an atmosphere that reflects our values of inclusion by providing effective and respectful care compatible with each patient and family's beliefs, values, and heritage.<br></li></ul><strong><u>Requirements<br><br></u></strong>Required Education/Experience: - Bachelor's Degree in computer science or related field OR equivalent combination of education and experience/technical training that demonstrates analytical and technical competency. - Minimum of two (2) years of technology industry or related experience, including items such as: - Build highly scalable, scaled-out architectures on large scale database platforms. - Experience working in a complex data infrastructure environment. - Two (2) years of experience in a data engineering role. - Data pipeline development experience with industry standard data integration tools. - Advanced competency in SQL with ability to perform query optimization in large scale database platforms. - Experience in SDLC process with requirements gathering, analysis, architecture, design, implementation, testing, deployment and technical support. - Experience with any industry standard tool for Source Control and Project Management. - Experience writing test cases and test scripts for data quality assurance. - Experience creating stored procedures and functions. - Experience developing dimensional data model with any industry standard tool. Preferred: - Experience in Healthcare or related industry. - Experience utilizing Netezza, Datastage, BitBucket, JIRA, Confluence a plus. - Experience productizing/automating predictive models that use R, SAS, Python, SPSS, etc. - Continuous delivery and deployment automation for analytic solutions using tools like Bamboo. - Familiarity with test driven development methodology for analytic solutions. - AGILE. - API development. - Data visualization and/or dashboard development.<br><br>Our Commitment to Diversity<br><br>Our community welcomes diverse experiences, backgrounds, and thoughts as this is what drives our spirit of inquiry and allows us to better connect with our increasingly diverse patients and families. Our organization recruits, employs, trains, compensates, and promotes without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.<br><br>The people who work at Seattle Children's are members of a community that seeks to respect and celebrate all the qualities that make each of us unique. Each of us is empowered to be ourselves within this community, which cultivates and promotes equity, diversity, and inclusion at all levels.<br><br>Seattle Children's is proud to be an Equal Opportunity Workplace and Affirmative Action Employer.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Legal,Full-time,"Nonprofit Organization Management, Health, Wellness and Fitness, Hospital & Health Care"
Associate Data Scientist Engineer,"San Francisco, California, United States",Gap Inc.,2021-02-18,https://www.linkedin.com/jobs/view/associate-data-scientist-engineer-at-gap-inc-2417251512?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=Vm97Rz8NjImmlkuSJyuaBg%3D%3D&position=2&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"The Company




Orchard is transforming the way people buy and sell their homes, simplifying it to be fair and true to market, straightforward & easy. The U.S. has $1.5 trillion worth of home transactions each year, generating over $120 billion of fees in a process that has changed little in decades. For the average American, the home purchase and sale process takes months, creates anxiety and is filled with uncertainty and hassle.




Orchard offers a modern alternative, making one of life's biggest decisions -- the sale and purchase of a home –stress free, fair and simple.




We are headquartered in New York City, have 200+ employees and have grown 10x year over year. In addition to this incredible growth, we’re proud to have been recognized by Inc. Magazine as a Best Workplace of 2020 while hold a 4.9 Glassdoor rating!




Team and Responsibilities




This is an exciting opportunity to join a high-growth team at the ground floor, and play an instrumental role in making the home buying and selling experience frictionless for our customers.




Orchard’s engineering culture is centered around product empathy and autonomous teams with high feature ownership. Engineers take ownership of feature development end to end. This means we partner with Product Managers and Designers to solve ambiguous business problems and have a high degree of collaborative input before writing code. We strive to keep common infrastructure and dependencies simple (or only as complex as necessary), to keep the coordination costs of infrastructure deployments low, and support lean & nimble product engineering teams. 




As part of the larger engineering organization, Orchard’s Data Team performs a function that is at the core of our business: we are responsible for building and maintaining the technical infrastructure to ingest the data sources, and deploy the models that drive our decision-making and software. Part of this role will be working directly with the Data Science team in order to make their models production-ready.

The team values engineers who prioritize results and testing, and we’re looking for engineers who are excited to explore our data and come up with novel ways to use it.

We are interested in all qualified candidates who are eligible to work in the United States. However, we are not able to sponsor visas at this time.




In this role you will be




Integrating with third-party data sources (MLS and county tax data are primary sources, among others) to support our home transaction platform and Data Science initiatives
Building and maintaining ETL pipelines to support business intelligence
Building and maintaining model training and validation pipelines for our automated valuation model (AVM)
Deploying machine learning models (our AVM) to production so that analysts can use them to value the homes we make offers on
Work with the following technologies: Python3, PostgreSQL, Docker, AWS, Airflow




Professional Qualifications




Proficiency in SQL and Python is required. Familiarity with Postgres or Airflow is a plus.
Prior internship experience working with a team to plan, prioritize, build, and deploy code
Currently have, or are in the process of attaining, BS or MS in Computer Science or related field




Personal Qualifications




Results-oriented with attention to detail: we expect engineers to own projects from planning to production deployment (and production operations!)
Low ego with appetite for feedback: we value humility and sharing + receiving feedback for growth and continuous improvement
Business empathy & clear communication: we work with product, design & business stakeholders collaboratively from early in the design process. We look for engineers to frame technical problems in the context of business value and be able to communicate with cross-functional teams
Prioritization & value orientation: we operate with agile principles and balance long-term planning with re-evaluating priorities based on new data and assumptions
Problem solving & ownership: we look for a willingness to take on problems in a growing organization where there's not yet a defined solution
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>The Company</strong></p><p><br></p><p>Orchard is transforming the way people buy and sell their homes, simplifying it to be fair and true to market, straightforward &amp; easy. The U.S. has $1.5 trillion worth of home transactions each year, generating over $120 billion of fees in a process that has changed little in decades. For the average American, the home purchase and sale process takes months, creates anxiety and is filled with uncertainty and hassle.</p><p><br></p><p>Orchard offers a modern alternative, making one of life's biggest decisions -- the sale and purchase of a home –stress free, fair and simple.</p><p><br></p><p>We are headquartered in New York City, have 200+ employees and have grown 10x year over year. In addition to this incredible growth, we’re proud to have been recognized by Inc. Magazine as a Best Workplace of 2020 while hold a 4.9 Glassdoor rating!</p><p><br></p><p><strong>Team and Responsibilities</strong></p><p><br></p><p>This is an exciting opportunity to join a high-growth team at the ground floor, and play an instrumental role in making the home buying and selling experience frictionless for our customers.</p><p><br></p><p>Orchard’s engineering culture is centered around product empathy and autonomous teams with high feature ownership. Engineers take ownership of feature development end to end. This means we partner with Product Managers and Designers to solve ambiguous business problems and have a high degree of collaborative input before writing code. We strive to keep common infrastructure and dependencies simple (or only as complex as necessary), to keep the coordination costs of infrastructure deployments low, and support lean &amp; nimble product engineering teams.&nbsp;</p><p><br></p><p>As part of the larger engineering organization, Orchard’s Data Team performs a function that is at the core of our business: we are responsible for building and maintaining the technical infrastructure to ingest the data sources, and deploy the models that drive our decision-making and software. Part of this role will be working directly with the Data Science team in order to make their models production-ready.</p><p>The team values engineers who prioritize results and testing, and we’re looking for engineers who are excited to explore our data and come up with novel ways to use it.</p><p>We are interested in all qualified candidates who are eligible to work in the United States. However, we are not able to sponsor visas at this time.</p><p><br></p><p><strong>In this role you will be</strong></p><p><br></p><ul><li>Integrating with third-party data sources (MLS and county tax data are primary sources, among others) to support our home transaction platform and Data Science initiatives</li><li>Building and maintaining ETL pipelines to support business intelligence</li><li>Building and maintaining model training and validation pipelines for our automated valuation model (AVM)</li><li>Deploying machine learning models (our AVM) to production so that analysts can use them to value the homes we make offers on</li><li>Work with the following technologies: Python3, PostgreSQL, Docker, AWS, Airflow</li></ul><p><br></p><p><strong>Professional Qualifications</strong></p><p><br></p><ul><li>Proficiency in SQL and Python is required. Familiarity with Postgres or Airflow is a plus.</li><li>Prior internship experience working with a team to plan, prioritize, build, and deploy code</li><li>Currently have, or are in the process of attaining, BS or MS in Computer Science or related field</li></ul><p><br></p><p><strong>Personal Qualifications</strong></p><p><br></p><ul><li>Results-oriented with attention to detail: we expect engineers to own projects from planning to production deployment (and production operations!)</li><li>Low ego with appetite for feedback: we value humility and sharing + receiving feedback for growth and continuous improvement</li><li>Business empathy &amp; clear communication: we work with product, design &amp; business stakeholders collaboratively from early in the design process. We look for engineers to frame technical problems in the context of business value and be able to communicate with cross-functional teams</li><li>Prioritization &amp; value orientation: we operate with agile principles and balance long-term planning with re-evaluating priorities based on new data and assumptions</li><li>Problem solving &amp; ownership: we look for a willingness to take on problems in a growing organization where there's not yet a defined solution</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Real Estate
Python Software Engineer,"Houston, Texas, United States",JPMorgan Chase & Co.,2021-01-25,https://www.linkedin.com/jobs/view/python-software-engineer-at-jpmorgan-chase-co-2418267150?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=J%2BtQEfnmYgusVZ%2FRh88M%2BA%3D%3D&position=3&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"About Gap Inc.

Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials.    

This simple idea—that we all deserve to belong, and on our own terms—is core to who we are as a company and how we make decisions. Our team is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to  learn fast, create with audacity and lead boldly? Join our team.

About The Role

This position will be part of the Data Science Engineering team at Gap Inc, whose primary goals include building data products and infrastructure that support analytics and data-science at scale. With business users all across the company, the team works cross-functionally to ensure reports, analytics, and models are supported by a stable, efficient, and accurate back-end.

What you'll do

Partner with internal customers to understand business needs and build strong relationships with key stakeholders.
Develop, deploy, and support analytic data products, such as data marts, ETL’s (extract/transform/load), functions (in Python/SQL/Spark/R), and visualizations.
Navigate various data sources and efficiently locate data in a complex data ecosystem.
Work closely with our data scientists to ensure production models are built using a scalable back-end.
Maintain and support deployed solutions and data products.

Who you are

BA/BS in a technical or engineering field (Master’s preferred).
1-3 years of experience in a data engineering or full-stack data scientist role.
Strong understanding of relational databases and SQL.
Solid programming foundations and proficiency with data related languages such as Python/Spark/R.
Excellent communication skills. Ability to effectively communicate with both technical and non-technical audiences.

Notice to applicants in San Francisco: Gap Inc. and its related brands will consider for employment, qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. The Fair Chance Ordinance is provided here: English Spanish Chinese Tagalog

Benefits at Gap Inc.

Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees.
One of the most competitive Paid Time Off plans in the industry.*
Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*
Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*
Employee stock purchase plan.*
Medical, dental, vision and life insurance.*
See more of the benefits we offer.


For eligible employees

Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. This year, we’ve been named as one of the Best Places to Work by the Humans Rights Campaign for the fourteenth consecutive year and have been included in the 2019 Bloomberg Gender-Equality Index for the second year in a row.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Gap Inc.<br><br></u></strong>Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials.    <br><br>This simple idea—that we all deserve to belong, and on our own terms—is core to who we are as a company and how we make decisions. Our team is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to  learn fast, create with audacity and lead boldly? Join our team.<br><br><strong><u>About The Role<br><br></u></strong>This position will be part of the Data Science Engineering team at Gap Inc, whose primary goals include building data products and infrastructure that support analytics and data-science at scale. With business users all across the company, the team works cross-functionally to ensure reports, analytics, and models are supported by a stable, efficient, and accurate back-end.<br><br>What you'll do<br><ul> <li>Partner with internal customers to understand business needs and build strong relationships with key stakeholders.</li> <li>Develop, deploy, and support analytic data products, such as data marts, ETL’s (extract/transform/load), functions (in Python/SQL/Spark/R), and visualizations.</li> <li>Navigate various data sources and efficiently locate data in a complex data ecosystem.</li> <li>Work closely with our data scientists to ensure production models are built using a scalable back-end.</li> <li>Maintain and support deployed solutions and data products.<br></li></ul>Who you are<br><ul> <li>BA/BS in a technical or engineering field (Master’s preferred).</li> <li>1-3 years of experience in a data engineering or full-stack data scientist role.</li> <li>Strong understanding of relational databases and SQL.</li> <li>Solid programming foundations and proficiency with data related languages such as Python/Spark/R.</li> <li>Excellent communication skills. Ability to effectively communicate with both technical and non-technical audiences.<br></li></ul><strong>Notice to applicants in San Francisco:</strong> Gap Inc. and its related brands will consider for employment, qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. The Fair Chance Ordinance is provided here: English Spanish Chinese Tagalog<br><br>Benefits at Gap Inc.<br><ul> <li>Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees.</li> <li>One of the most competitive Paid Time Off plans in the industry.*</li> <li>Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*</li> <li>Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*</li> <li>Employee stock purchase plan.*</li> <li>Medical, dental, vision and life insurance.*</li> <li>See more of the benefits we offer.</li> <br></ul><em><li>For eligible employees<br><br>Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. This year, we’ve been named as one of the Best Places to Work by the Humans Rights Campaign for the fourteenth consecutive year and have been included in the 2019 Bloomberg Gender-Equality Index for the second year in a row.</li></em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Retail, Financial Services"
Data Scientist,"Lehi, Utah, United States",Vivint,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-vivint-2418245962?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=FW25hG8ua5Mh23%2FcMzKQ6w%3D%3D&position=4&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

﻿

Athena (platform)

Athena is a cross-asset platform transforming technology at JP Morgan. It delivers innovative and efficient applications to a wide range of the firm's business, including sales, trading, operations, risk and research. Athena combines the best of open source technologies with innovative components developed internally, which gives you the ability to contribute to wide range of exciting projects. Our developers enjoy working with front office, quants and other technology teams.

The people who thrive in Athena are hands-on developers, who enjoy solving challenging technical problems. You’re someone who has strong computer science foundations and is comfortable working across different platforms and languages. You’re inspired by working in a collaborative, fast-changing environment with a high degree of code sharing and reuse. If this sounds like you, then Athena could be the perfect place to grow your career.

As a member of our Software Engineering Group you will dive head-first into creating innovative solutions that advance businesses and careers. You’ll join an inspiring and curious team of technologists dedicated to improving the design, analytics, development, coding, testing and application programming that goes into creating high quality software and new products. You’ll be tasked with keeping the team and other key stakeholders up to speed on the progress of what’s being developed. Coming in with an understanding of the importance of end-to-end software development-such as Agile frameworks-is key. And best of all, you’ll be working with and sharing ideas, information and innovation with our global team of technologists from all over the world.

Role

The Software Engineer will contribute to design and implementation of a proprietary risk management and trading platform. Responsibilities will include both resolving known challenges of the platform and introduction of designs for new generations of the platform. The position involves development of highly reliable and highly performant software.

The Engineer will contribute to the implementation of Athena and provide guidance to the developers who use this platform for development of applications.

Requirements

BS/BA degree or equivalent experience
Strong system design and algorithm optimization skills.
Commercial development in imperative programming languages.
Willingness to become proficient and develop in Python if not already a primary language
Experience with debuggers and profilers and revision control tools.
Strong system troubleshooting skills, solid understanding of Computer Science fundamentals.
Good communication skills and ability to collaborate with and influence other technology teams to deliver end to end solutions to the business in a constantly changing environment
Creative, quick-thinking, pragmatic, with an aptitude for solving problems with technology and an ability to quickly translate requirements into a sound technical design and implementation.



About Us

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.

Equal Opportunity Employer/Disability/Veterans

Organization

Our Corporate & Investment Bank relies on innovators like you to build and maintain the technology that helps us safely service the world’s important corporations, governments and institutions. You'll develop solutions that help the bank provide strategic advice, raise capital, manage risk, and extend liquidity in markets spanning over 100 countries around the world.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>﻿<br><br>Athena (platform)<br><br>Athena is a cross-asset platform transforming technology at JP Morgan. It delivers innovative and efficient applications to a wide range of the firm's business, including sales, trading, operations, risk and research. Athena combines the best of open source technologies with innovative components developed internally, which gives you the ability to contribute to wide range of exciting projects. Our developers enjoy working with front office, quants and other technology teams.<br><br>The people who thrive in Athena are hands-on developers, who enjoy solving challenging technical problems. You’re someone who has strong computer science foundations and is comfortable working across different platforms and languages. You’re inspired by working in a collaborative, fast-changing environment with a high degree of code sharing and reuse. If this sounds like you, then Athena could be the perfect place to grow your career.<br><br>As a member of our Software Engineering Group you will dive head-first into creating innovative solutions that advance businesses and careers. You’ll join an inspiring and curious team of technologists dedicated to improving the design, analytics, development, coding, testing and application programming that goes into creating high quality software and new products. You’ll be tasked with keeping the team and other key stakeholders up to speed on the progress of what’s being developed. Coming in with an understanding of the importance of end-to-end software development-such as Agile frameworks-is key. And best of all, you’ll be working with and sharing ideas, information and innovation with our global team of technologists from all over the world.<br><br>Role<br><br>The Software Engineer will contribute to design and implementation of a proprietary risk management and trading platform. Responsibilities will include both resolving known challenges of the platform and introduction of designs for new generations of the platform. The position involves development of highly reliable and highly performant software.<br><br>The Engineer will contribute to the implementation of Athena and provide guidance to the developers who use this platform for development of applications.<br><br><strong><u>Requirements<br></u></strong><ul> <li>BS/BA degree or equivalent experience</li> <li>Strong system design and algorithm optimization skills.</li> <li>Commercial development in imperative programming languages.</li> <li>Willingness to become proficient and develop in Python if not already a primary language</li> <li>Experience with debuggers and profilers and revision control tools. </li> <li>Strong system troubleshooting skills, solid understanding of Computer Science fundamentals.</li> <li>Good communication skills and ability to collaborate with and influence other technology teams to deliver end to end solutions to the business in a constantly changing environment</li> <li>Creative, quick-thinking, pragmatic, with an aptitude for solving problems with technology and an ability to quickly translate requirements into a sound technical design and implementation.</li> <br><br></ul><strong><u>About Us<br><br></u></strong>JPMorgan Chase &amp; Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.<br><br>We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.<br><br>Equal Opportunity Employer/Disability/Veterans<br><br><strong>Organization<br><br></strong>Our Corporate &amp; Investment Bank relies on innovators like you to build and maintain the technology that helps us safely service the world’s important corporations, governments and institutions. You'll develop solutions that help the bank provide strategic advice, raise capital, manage risk, and extend liquidity in markets spanning over 100 countries around the world.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Banking, Financial Services"
Data Engineer,"Nashville, Tennessee, United States",AllianceBernstein,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-at-alliancebernstein-2206908470?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=p%2BiVEuBHfp1BefrbC%2BJ7vg%3D%3D&position=5&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Our mission is to redefine the home experience through intelligently designed products and services delivered to every home by people who care.

Who Are We

Vivint Smart Home is a leading smart home company in North America. Vivint delivers an integrated smart home system with in-home consultation, professional installation and support delivered by its Smart Home Pros, as well as 24/7 customer care and monitoring. Dedicated to redefining the home experience with intelligent products and services, Vivint serves more than 1.7 million customers.

Vivint was named to the Forbes list of “America’s Best Employers for Diversity” in 2020 and 2019, and to the Forbes list of “America’s Best Employers” in 2018. The company has a strong commitment to philanthropy and received a 2020 Gold Halo Award from Engage for Good for group volunteerism. Vivint is the largest tech employer in Utah and has received multiple awards for innovation, including being named among Fast Company’s “World’s 50 Most Innovative Companies.”

Job Summary

As a Data Scientist on our Data Engineering team, you will be responsible for all production data science models used by various groups in the organization. You will be responsible for building and providing oversight and guidance to other citizen data scientists embedded in business units. You will be the expert on both the models as well as the data science platform used for developing and deploying all models. Working closely with our Data Ops and Business Analytics teams, you will work to build out use cases that can drive growth within the organization and cost savings efficiencies.

Who You Will Work With

As a member of the data engineering team you will report to the Sr. Manager of Data Engineering. You will be a member of a high performing team with cross functional support and responsibilities. The data engineering team works to support the data warehouse and analytics teams throughout the company.

What We’re Looking For

Bachelors Degree in Statistics, Computer Science, or other data-related field with 4 + years industry experience in machine learning and statistical modeling
OR
Masters Degree or in Statistics, Computer Science, or other data-related field with 2+ years industry experience in machine learning and statistical modeling
Knowledge and demonstrated application of a variety of statistical and data science approaches
Proven track record of completing multiple data science projects end-to-end; from idea generation, objectives formulation, to implementation and deliverables
Strong proficiency in Python, SQL and R
Experience building deep learning models using tools like TensorFlow, Scikit and Pytorch
Strong written and verbal communication skills
Ability to lead and teach other Jr level data scientists and analysts


Bonus Skills

Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)
Experience with Tableau or similar data visualization tool
Experience with machine learning technologies and platforms (SparkML, AzureML, Datarobot, Dataiku, etc.)


Why Vivint

Paid holidays and flexible paid time away
Your choice between Mac or PC
Employee pricing on smart home products
Casual dress code
Onsite health clinic
Medical/dental/vision/life coverage


What We Stand For

Honesty and Integrity Come First

Do the right thing

Customer Obsession is Our Advantage

A relentless passion to serve the customer

Innovation is Essential

Today’s innovation is tomorrow’s lifeblood

We Win Together

Individuals win games: teams win championships

Exceptional is Expected

Talk is cheap: create value, not just motion

We Give Back

Helping people is core to our DNA

Find out more about what it's like to work here:

http://archive.sltrib.com/article.php?id=5360131&itype=CMSID

https://www.fastcompany.com/3067476/why-vivint-smart-home-is-one-of-the-most-innovative-companies-of-2

https://www.vivint.com/company/careers/culture

Working Conditions

This job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines.

Safety

Vivint enforces a safety culture whereby all employees have the responsibility for continuously developing and maintaining a safe working environment. Each new employee is responsible for completing all training requirements. Additionally, the employee must accept they have responsibility for maintaining the safety of themselves, their co-workers, and the public. Employee must adhere to all written and verbal instructions, promptly report and correct all hazards or unsafe conditions, question non-standard operations or unmitigated hazards, and provide feedback to management on all safety issues.
If you are an active Vivint employee, please apply through Workday by searching ""Find Jobs"".
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Our mission is to redefine the home experience through intelligently designed products and services delivered to every home by people who care.<br><br><strong><u>Who Are We<br><br></u></strong>Vivint Smart Home is a leading smart home company in North America. Vivint delivers an integrated smart home system with in-home consultation, professional installation and support delivered by its Smart Home Pros, as well as 24/7 customer care and monitoring. Dedicated to redefining the home experience with intelligent products and services, Vivint serves more than 1.7 million customers.<br><br>Vivint was named to the Forbes list of “America’s Best Employers for Diversity” in 2020 and 2019, and to the Forbes list of “America’s Best Employers” in 2018. The company has a strong commitment to philanthropy and received a 2020 Gold Halo Award from Engage for Good for group volunteerism. Vivint is the largest tech employer in Utah and has received multiple awards for innovation, including being named among Fast Company’s “World’s 50 Most Innovative Companies.”<br><br><strong><u>Job Summary<br><br></u></strong>As a Data Scientist on our Data Engineering team, you will be responsible for all production data science models used by various groups in the organization. You will be responsible for building and providing oversight and guidance to other citizen data scientists embedded in business units. You will be the expert on both the models as well as the data science platform used for developing and deploying all models. Working closely with our Data Ops and Business Analytics teams, you will work to build out use cases that can drive growth within the organization and cost savings efficiencies.<br><br><strong><u>Who You Will Work With<br><br></u></strong>As a member of the data engineering team you will report to the Sr. Manager of Data Engineering. You will be a member of a high performing team with cross functional support and responsibilities. The data engineering team works to support the data warehouse and analytics teams throughout the company.<br><br><strong><u>What We’re Looking For<br></u></strong><ul><li>Bachelors Degree in Statistics, Computer Science, or other data-related field with 4 + years industry experience in machine learning and statistical modeling</li><li>OR</li><li>Masters Degree or in Statistics, Computer Science, or other data-related field with 2+ years industry experience in machine learning and statistical modeling</li><li>Knowledge and demonstrated application of a variety of statistical and data science approaches</li><li>Proven track record of completing multiple data science projects end-to-end; from idea generation, objectives formulation, to implementation and deliverables</li><li>Strong proficiency in Python, SQL and R</li><li>Experience building deep learning models using tools like TensorFlow, Scikit and Pytorch</li><li>Strong written and verbal communication skills</li><li>Ability to lead and teach other Jr level data scientists and analysts<br><br></li></ul><strong><u>Bonus Skills<br></u></strong><ul><li>Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)</li><li>Experience with Tableau or similar data visualization tool</li><li>Experience with machine learning technologies and platforms (SparkML, AzureML, Datarobot, Dataiku, etc.)<br><br></li></ul><strong><u>Why Vivint<br></u></strong><ul><li>Paid holidays and flexible paid time away</li><li>Your choice between Mac or PC</li><li>Employee pricing on smart home products</li><li>Casual dress code</li><li>Onsite health clinic</li><li> Medical/dental/vision/life coverage <br><br></li></ul><strong><u>What We Stand For<br><br></u></strong>Honesty and Integrity Come First<br><br>Do the right thing<br><br>Customer Obsession is Our Advantage<br><br>A relentless passion to serve the customer<br><br>Innovation is Essential<br><br>Today’s innovation is tomorrow’s lifeblood<br><br>We Win Together<br><br>Individuals win games: teams win championships<br><br>Exceptional is Expected<br><br>Talk is cheap: create value, not just motion<br><br>We Give Back<br><br>Helping people is core to our DNA<br><br><strong> Find out more about what it's like to work here: <br><br></strong><strong> http://archive.sltrib.com/article.php?id=5360131&amp;itype=CMSID <br><br></strong><strong> https://www.fastcompany.com/3067476/why-vivint-smart-home-is-one-of-the-most-innovative-companies-of-2 <br><br></strong><strong> https://www.vivint.com/company/careers/culture <br><br></strong><strong><u>Working Conditions<br><br></u></strong>This job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines.<br><br><strong><u>Safety<br><br></u></strong>Vivint enforces a safety culture whereby all employees have the responsibility for continuously developing and maintaining a safe working environment. Each new employee is responsible for completing all training requirements. Additionally, the employee must accept they have responsibility for maintaining the safety of themselves, their co-workers, and the public. Employee must adhere to all written and verbal instructions, promptly report and correct all hazards or unsafe conditions, question non-standard operations or unmitigated hazards, and provide feedback to management on all safety issues.<br><strong><strong>If you are an active Vivint employee, please apply through Workday by searching ""Find Jobs"".</strong></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Consumer Electronics, Information Technology and Services"
Data Engineer,"Wichita, Kansas, United States",Koch Industries,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-koch-industries-2412137911?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=bZIoSeA3QbridVNv6mvjGw%3D%3D&position=6&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"IT Group Description

The Equity Investment Management Technology (“EIMT”) team creates software to support the research, portfolio management, and trading activities for our institutional and private client equity products. This role is within the EIMT – Research team which is focused on delivering solutions for our buy side equity quantitative and research analysts. The solutions built include tools for quantitative analysis, business intelligence, and data ingestion.

Job Description

We are seeking a Nashville based Data Engineer to join our Equity Investment Management Technology Research team.

Describe The Role

This is a Data Engineering position focused on enhancing the equity data architecture to provide rapid data onboarding, quality control, and accessibility. This role will focus on building out infrastructure and frameworks using cloud-based distributed compute and storage technologies, continuous integration and deployment tools, data pipeline orchestration, non-SQL and traditional data warehousing (RDMS) technology.

The key job responsibilities include, but are not limited to:

Automation of data ingestion supporting various sources and formats both external and internal.
Implementing a quality control framework for ensuring data consistency.
Cataloging new data sets to facilitate data discovery, lineage, and self-service.
Building business intelligence dashboards to provide data insights.
Assist with ad-hoc data and research requests from the investment team.
Provide support for overnight jobs.

What makes this role unique or interesting?

This role provides the opportunity to experience the full lifecycle of building investment decisions from onboarding data to evaluating factor performance while applying modern processing concepts using cloud based solutions

What is the professional development value of this role?

This Role Provides Opportunity In The Following Areas

Learning the equity investment business and engaging directly with end users.
Automating complex data loads and pipelines.
Onboard alternative datasets including learning how to web scrape.
Best practices managing large data sets.
Building technical skills including SQL, Python, and PowerBI.
Applying cloud based technologies including data lakes and data pipelines.


Qualifications, Experience, Education

BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major
2-3 years programing in SQL with experience in relational schema designs and optimizing query performance
1-2 years using Python or another object oriented language (C#, Java)
ETL experience is a strong plus
Working with NoSQL is a strong plus
Building visualizations using Tableau, Qlik, or PowerBI is a strong plus


Skills

Solid analytical and technical skills
Candidate must be willing to take ownership of projects and show strong client commitment
Must demonstrate good communication skills and be comfortable working closely with business users
Self starter as well as a good team player
A strong desire to document and share work done to aid in long term support


Special Knowledge (nice To Have, But Not Required)

Experience working in the financial industry or knowledge of basic financial statement concepts
Azure experience building data pipelines
Experience using Airflow

People of color, women, and those who identify as LGBTQ people are encouraged to apply. AB does not discriminate against any employee or applicant for employment on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability, marital status, citizenship status, sexual orientation, gender identity, military or veteran status or any other basis that is prohibited by applicable law. AB’s policies, as well as practices, seek to ensure that employment opportunities are available to all employees and applicants, based solely on job-related criteria.
Nashville, Tennessee
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>IT Group Description<br><br></u></strong>The Equity Investment Management Technology (“EIMT”) team creates software to support the research, portfolio management, and trading activities for our institutional and private client equity products. This role is within the EIMT – Research team which is focused on delivering solutions for our buy side equity quantitative and research analysts. The solutions built include tools for quantitative analysis, business intelligence, and data ingestion.<br><br><strong><u>Job Description<br><br></u></strong>We are seeking a Nashville based Data Engineer to join our Equity Investment Management Technology Research team.<br><br><strong><u>Describe The Role<br><br></u></strong>This is a Data Engineering position focused on enhancing the equity data architecture to provide rapid data onboarding, quality control, and accessibility. This role will focus on building out infrastructure and frameworks using cloud-based distributed compute and storage technologies, continuous integration and deployment tools, data pipeline orchestration, non-SQL and traditional data warehousing (RDMS) technology.<br><br><strong> The key job responsibilities include, but are not limited to: <br></strong><ul><li> Automation of data ingestion supporting various sources and formats both external and internal. </li><li> Implementing a quality control framework for ensuring data consistency. </li><li> Cataloging new data sets to facilitate data discovery, lineage, and self-service. </li><li> Building business intelligence dashboards to provide data insights. </li><li> Assist with ad-hoc data and research requests from the investment team. </li><li> Provide support for overnight jobs. <br></li></ul><strong> What makes this role unique or interesting? <br><br></strong>This role provides the opportunity to experience the full lifecycle of building investment decisions from onboarding data to evaluating factor performance while applying modern processing concepts using cloud based solutions<br><br><strong> What is the professional development value of this role? <br><br></strong><strong><u>This Role Provides Opportunity In The Following Areas<br></u></strong><ul><li> Learning the equity investment business and engaging directly with end users. </li><li> Automating complex data loads and pipelines. </li><li> Onboard alternative datasets including learning how to web scrape. </li><li> Best practices managing large data sets. </li><li> Building technical skills including SQL, Python, and PowerBI. </li><li> Applying cloud based technologies including data lakes and data pipelines. <br><br></li></ul><strong><u>Qualifications, Experience, Education<br></u></strong><ul><li> BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major </li><li> 2-3 years programing in SQL with experience in relational schema designs and optimizing query performance </li><li> 1-2 years using Python or another object oriented language (C#, Java) </li><li> ETL experience is a strong plus </li><li> Working with NoSQL is a strong plus </li><li> Building visualizations using Tableau, Qlik, or PowerBI is a strong plus <br><br></li></ul><strong><u>Skills<br></u></strong><ul><li> Solid analytical and technical skills </li><li> Candidate must be willing to take ownership of projects and show strong client commitment </li><li> Must demonstrate good communication skills and be comfortable working closely with business users </li><li> Self starter as well as a good team player </li><li> A strong desire to document and share work done to aid in long term support <br><br></li></ul><strong><u>Special Knowledge (nice To Have, But Not Required)<br></u></strong><ul><li> Experience working in the financial industry or knowledge of basic financial statement concepts </li><li> Azure experience building data pipelines </li><li> Experience using Airflow <br></li></ul><em>People of color, women, and those who identify as LGBTQ people are encouraged to apply. AB does not discriminate against any employee or applicant for employment on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability, marital status, citizenship status, sexual orientation, gender identity, military or veteran status or any other basis that is prohibited by applicable law. AB’s policies, as well as practices, seek to ensure that employment opportunities are available to all employees and applicants, based solely on job-related criteria. <br></em>Nashville, Tennessee</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Remote, Oregon, United States",7N,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-7n-2430486009?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=y4aq6DyewYdAbOrXBqjHkw%3D%3D&position=7&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Description

Koch Engineered Solutions (KES) is currently looking for a Data Engineer to work with our Information Technology (IT) Team at our Wichita, KS headquarters. The IT team is a vital component in KES’ strategy to improve business performance through the application of technology and profitably transform our business. Working as an integrated group with the Engineering, Operations, Commercial and Financial teams that design and maintain facilities. Our team functions as a startup entity within our enterprise to develop innovative solutions and build a market for their solutions through transforming KES work processes.

As a member of the Information Technology team, you will need to thrive in a fast pace and innovative environment. You will collaborate to develop solutions and prove their value through experimentation and scalable deployment in our business. Collaboration, creativity, and focus on attaining positive business results will be necessary skills. Like an employee of a startup, you will need to be resourceful and capable of partnering with market solution providers that can accelerate progress of our business objectives.

What You Will Do In Your Role

Design, develop, and maintain a Big Data framework and ETL (Extract, Transform, and Load) processes for the collection, organization, analysis, and visualization of an ever-increasing array of data sets
Integrate the Big Data platform with the broader architectures and enterprise software ecosystem across the company and industry
Support domain data scientists in writing complex queries and developing machine learning models, AI applications, and visual story telling
Own successful implementation and design of KES architect data solutions, contribute to strategy for code management and product development for reusable assets that accelerate time-to-value
Assist the data and analytics team with validation and verification of end-to-end analytics system performance
Grow, through influence, a data enablement mindset across the organization and mentor others on how to think about data needs
Effectively capture business requirements, map processes, and develop functional specifications in support of business data priorities
Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings
Maintains the support structure for self-service BI tools


The Experience You Will Bring

The ability to adapt to new problems and successfully operate within an experimentation environment
Strong collaboration and communication skills and ability to work within cross functional teams
Strong economic thinking skills
Self-motivation and the persistence to create value through work process transformation
A positive attitude and the innovative thinking skills to turn the impossible into capability


Requirements

2+ years of experience in data visualization tools with a strong grasp of effective data visualization practices
2+ years of experience leveraging cloud platforms such as Amazon Web Services (AWS), Google Cloud Platform (GCP) or Microsoft Azure
2+ years of experience with conventional open source and commercial RDBMS (e.g. MySQL, MS SQL Server)
2+ years of experience with query languages, data modeling, data ownership, and data platforms
Experience rapidly developing proof of concepts and testing new ideas, as well as scale these ideas into production ready models
Experience with ETL & analytics tools (AWS, Denodo, Matillion, AtScale, etc.)


What Will Put You Ahead

Experience with multiple languages and syntax (Python, SQL, Apache Spark, etc.)
Experience with Scrum/Agile delivery processes and DevOps concepts (i.e. CI/CD)
Experience with user enablement ETL tools, such as Alteryx
Bachelor’s Degree in Computer Science, Engineering or Mathematics preferred
Statistics and machine learning background
Experience working or leading Agile Teams
Experience with Infor platform


Salary And Benefits Commensurate With Experience.

Equal Opportunity Employer.
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>Koch Engineered Solutions (KES) is currently looking for a Data Engineer to work with our Information Technology (IT) Team at our Wichita, KS headquarters. The IT team is a vital component in KES’ strategy to improve business performance through the application of technology and profitably transform our business. Working as an integrated group with the Engineering, Operations, Commercial and Financial teams that design and maintain facilities. Our team functions as a startup entity within our enterprise to develop innovative solutions and build a market for their solutions through transforming KES work processes.<br><br>As a member of the Information Technology team, you will need to thrive in a fast pace and innovative environment. You will collaborate to develop solutions and prove their value through experimentation and scalable deployment in our business. Collaboration, creativity, and focus on attaining positive business results will be necessary skills. Like an employee of a startup, you will need to be resourceful and capable of partnering with market solution providers that can accelerate progress of our business objectives.<br><br>What You Will Do In Your Role<br><ul><li>Design, develop, and maintain a Big Data framework and ETL (Extract, Transform, and Load) processes for the collection, organization, analysis, and visualization of an ever-increasing array of data sets</li><li>Integrate the Big Data platform with the broader architectures and enterprise software ecosystem across the company and industry</li><li>Support domain data scientists in writing complex queries and developing machine learning models, AI applications, and visual story telling</li><li>Own successful implementation and design of KES architect data solutions, contribute to strategy for code management and product development for reusable assets that accelerate time-to-value</li><li>Assist the data and analytics team with validation and verification of end-to-end analytics system performance</li><li>Grow, through influence, a data enablement mindset across the organization and mentor others on how to think about data needs</li><li>Effectively capture business requirements, map processes, and develop functional specifications in support of business data priorities</li><li>Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings</li><li>Maintains the support structure for self-service BI tools<br><br></li></ul>The Experience You Will Bring<br><ul><li>The ability to adapt to new problems and successfully operate within an experimentation environment</li><li>Strong collaboration and communication skills and ability to work within cross functional teams</li><li>Strong economic thinking skills</li><li>Self-motivation and the persistence to create value through work process transformation</li><li>A positive attitude and the innovative thinking skills to turn the impossible into capability<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>2+ years of experience in data visualization tools with a strong grasp of effective data visualization practices</li><li>2+ years of experience leveraging cloud platforms such as Amazon Web Services (AWS), Google Cloud Platform (GCP) or Microsoft Azure</li><li>2+ years of experience with conventional open source and commercial RDBMS (e.g. MySQL, MS SQL Server)</li><li>2+ years of experience with query languages, data modeling, data ownership, and data platforms</li><li>Experience rapidly developing proof of concepts and testing new ideas, as well as scale these ideas into production ready models</li><li>Experience with ETL &amp; analytics tools (AWS, Denodo, Matillion, AtScale, etc.)<br><br></li></ul>What Will Put You Ahead<br><ul><li>Experience with multiple languages and syntax (Python, SQL, Apache Spark, etc.)</li><li>Experience with Scrum/Agile delivery processes and DevOps concepts (i.e. CI/CD)</li><li>Experience with user enablement ETL tools, such as Alteryx</li><li>Bachelor’s Degree in Computer Science, Engineering or Mathematics preferred</li><li>Statistics and machine learning background</li><li>Experience working or leading Agile Teams</li><li>Experience with Infor platform<br><br></li></ul><strong><u>Salary And Benefits Commensurate With Experience.<br><br></u></strong>Equal Opportunity Employer.<br>Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.<br><br>This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Engineering",Full-time,"Electrical/Electronic Manufacturing, Information Technology and Services, Computer Software"
Data Engineer,"Lake Mary, Florida, United States",Team Cymru,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-team-cymru-2430612177?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=qCnOtYgyfPB2vhYQ6jP0VA%3D%3D&position=8&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"15 120 - 19 320 pln net / month (B2B)
Remote possible: 100%

Skills

Python - Excellent
ETL - Excellent
SQL - Excellent
Cloud - Excellent

Who we're looking for?

Requirements

3+ years of experience working with SQL

3+ years of working in Python or R

3+ years of experience working on GCP, AWS or other cloud platform

1+ years of experience with different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.)

2+ years of experience in working in data architecture concepts (in any of following areas data modeling, metadata mng., workflow management, ETL/ELT, real-time streaming, data quality, distributed systems)

Exposure to open source and proprietary cloud data pipeline tools such as Airflow, Glue and Dataflow

Very good knowledge of relational databases

Very good knowledge of code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins)

Project description
7N is an agent for high-end IT professionals. For over 30 years of operation we have proven that a clear and transparent financial model, collaboration exclusively with experts in their respective fields, and taking good care of them, comprise the best possible IT consulting model. We act as an individual agent for our consultants and promote their competences to our clients by offering them a wide range of projects in which they may participate. We add wage transparency, career development support and professional stability. Our main goal is a long-term collaboration; therefore the majority of our staff have been with us for many years.
We're looking for an ambitious Data Engineer who wants to join a project from the pharmaceutical industry with a multi-technology application stack. The person will take a leading role in implementing new tools and analyses in the project, using the Python programming language.

Fully remote work
We offer

Transparent wage model; disclosed margin for 7N. The aforementioned wages are target wages paid to the consultant for the subcontracted work

Stable and long-term collaboration with various client projects

Professional freedom; We are one of the few IT companies who do not use non-compete clauses or retention agreements

Career development support, training and technical certification subsidies, conference participation, etc.

Private healthcare and the Benefit Multisport card

Collaboration with experts

Large client and project portfolio of over 40 companies, prioritizing project continuity and ongoing personal agent support

Full integration into the client company structure (e.g. participation in all company events, 7N Kick Off 2019: https://www.youtube.com/watch?v=i5KjJpFBNpI)
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">15 120 - 19 320 pln net / month (B2B)<br>Remote possible: 100%<br><br><strong><u>Skills<br><br></u></strong>Python - Excellent<br>ETL - Excellent<br>SQL - Excellent<br>Cloud - Excellent<br><br>Who we're looking for?<br><br><strong><u>Requirements<br><br></u></strong>3+ years of experience working with SQL<br><br>3+ years of working in Python or R<br><br>3+ years of experience working on GCP, AWS or other cloud platform<br><br>1+ years of experience with different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.)<br><br>2+ years of experience in working in data architecture concepts (in any of following areas data modeling, metadata mng., workflow management, ETL/ELT, real-time streaming, data quality, distributed systems)<br><br>Exposure to open source and proprietary cloud data pipeline tools such as Airflow, Glue and Dataflow<br><br>Very good knowledge of relational databases<br><br>Very good knowledge of code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins)<br><br>Project description<br>7N is an agent for high-end IT professionals. For over 30 years of operation we have proven that a clear and transparent financial model, collaboration exclusively with experts in their respective fields, and taking good care of them, comprise the best possible IT consulting model. We act as an individual agent for our consultants and promote their competences to our clients by offering them a wide range of projects in which they may participate. We add wage transparency, career development support and professional stability. Our main goal is a long-term collaboration; therefore the majority of our staff have been with us for many years.<br>We're looking for an ambitious Data Engineer who wants to join a project from the pharmaceutical industry with a multi-technology application stack. The person will take a leading role in implementing new tools and analyses in the project, using the Python programming language.<br><br>Fully remote work<br>We offer<br><br>Transparent wage model; disclosed margin for 7N. The aforementioned wages are target wages paid to the consultant for the subcontracted work<br><br>Stable and long-term collaboration with various client projects<br><br>Professional freedom; We are one of the few IT companies who do not use non-compete clauses or retention agreements<br><br>Career development support, training and technical certification subsidies, conference participation, etc.<br><br>Private healthcare and the Benefit Multisport card<br><br>Collaboration with experts<br><br>Large client and project portfolio of over 40 companies, prioritizing project continuity and ongoing personal agent support<br><br>Full integration into the client company structure (e.g. participation in all company events, 7N Kick Off 2019: https://www.youtube.com/watch?v=i5KjJpFBNpI)</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Management Consulting"
"Data Engineer (Python, Java)","Chicago, Illinois, United States",Huxley,2021-01-29,https://www.linkedin.com/jobs/view/data-engineer-python-java-at-huxley-2400701768?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=eHQrzH6UBDbBwVOMMCNhKQ%3D%3D&position=9&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Job Summary

The Data Engineer utilizes a wide range of technologies to design, develop, and deploy innovative programming and technical solutions to data analytics and data processing. The Data Engineer is expected to demonstrate increased proficiency in newly acquired industry-related skills. This person can work independently and produce work according to clear-cut and complete specifications.

Supervisory Responsibilities

None.



Duties/Responsibilities

Proficiency in designing and developing innovative data analytics software and methods.
Contributes across whole project lifecycle, utilizing peers for guidance where necessary.
Operate independently and seeks assistance or guidance when required.
Ability to recognize trends and patterns in the data that can be exploited into a repeatable analysis process
Performs triage of product support requests, problem determination and assists with escalation when appropriate
Demonstrates a complete understanding of a core-product or service offering's features, construction and operating characteristics
Incorporates effective test procedures, logging and monitoring in software with minimal oversight
Participates in regular review of individual output to ensure it conforms to department and company standards
Contributes to efforts in maintaining and improving product quality
identification and submission of product improvement when appropriate
Creates quality product and support documentation
Identifies risks to projects, communicates and formulates mitigation plans
Actively contributes to cross-functional team efforts
Conducts self-assessments by comparing required skills with existing knowledge to develop, present and execute plans for improvement
Consistently delivers to deadlines at the required quality standards



Required Skills/Abilities

Embodies and demonstrates maturity, professionalism, and ethics
Articulate in oral and written communication
Working-level knowledge of algorithms
Demonstrates sound coding techniques
Able to break-down complex requirements into workflows and identify key performance indicators.
Proficient in the use of databases: query and data definition
Proficiency in one or more core languages: Golang, Python, SQL, Bash, Perl
Proficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)
Competent with Linux
Solid oral and written communications skills
Consistently adheres to commitments with respect to delivery and timeframe
Working knowledge of networking protocols



Additional Desired Skills/Abilities

Familiarity with design patterns and industry best practices
Experience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, Spark
Experience with Cloud technologies like: AWS, Google Cloud, Azure
Ability to effectively create and utilize REST APIs
Proactively creates automated analytics solutions to push team's capabilities and increased situational awareness
Knowledge of MVC frameworks
Ability to execute complex queries and design relational databases in PostgreSQL using referential integrity, views, stored procedures and proper indices
Ability to create visualizations from resultant analytic results
Experience creating and distributing Jupyter Notebooks for repeatable data analysis



Education And Experience

High school diploma or equivalent required
Typically has two to four years combined industry / education experience
Some specialized training or education beyond high school is preferred



Physical Requirements

Prolonged periods of sitting at a desk and working on a computer.
Must be able to travel up to 5% of the time.



Location:

Virtual

PI129799278
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Summary<br><br></u></strong>The <strong>Data Engineer</strong> utilizes a wide range of technologies to design, develop, and deploy innovative programming and technical solutions to data analytics and data processing. The Data Engineer is expected to demonstrate increased proficiency in newly acquired industry-related skills. This person can work independently and produce work according to clear-cut and complete specifications.<br><br><strong><u>Supervisory Responsibilities<br></u></strong><ul> <li>None.</li> <br><br></ul><strong><u>Duties/Responsibilities<br></u></strong><ul> <li>Proficiency in designing and developing innovative data analytics software and methods.</li> <li>Contributes across whole project lifecycle, utilizing peers for guidance where necessary.</li> <li>Operate independently and seeks assistance or guidance when required.</li> <li>Ability to recognize trends and patterns in the data that can be exploited into a repeatable analysis process</li> <li>Performs triage of product support requests, problem determination and assists with escalation when appropriate</li> <li>Demonstrates a complete understanding of a core-product or service offering's features, construction and operating characteristics</li> <li>Incorporates effective test procedures, logging and monitoring in software with minimal oversight</li> <li>Participates in regular review of individual output to ensure it conforms to department and company standards</li> <li>Contributes to efforts in maintaining and improving product quality</li> <li>identification and submission of product improvement when appropriate</li> <li>Creates quality product and support documentation</li> <li>Identifies risks to projects, communicates and formulates mitigation plans</li> <li>Actively contributes to cross-functional team efforts</li> <li>Conducts self-assessments by comparing required skills with existing knowledge to develop, present and execute plans for improvement</li> <li>Consistently delivers to deadlines at the required quality standards</li> <br><br></ul><strong><u>Required Skills/Abilities<br></u></strong><ul> <li>Embodies and demonstrates maturity, professionalism, and ethics</li> <li>Articulate in oral and written communication</li> <li>Working-level knowledge of algorithms</li> <li>Demonstrates sound coding techniques</li> <li>Able to break-down complex requirements into workflows and identify key performance indicators.</li> <li>Proficient in the use of databases: query and data definition</li> <li>Proficiency in one or more core languages: Golang, Python, SQL, Bash, Perl</li> </ul><ul> <li>Proficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)</li> </ul><ul> <li>Competent with Linux</li> <li>Solid oral and written communications skills</li> <li>Consistently adheres to commitments with respect to delivery and timeframe</li> <li>Working knowledge of networking protocols</li> <br><br></ul><strong><u>Additional Desired Skills/Abilities<br></u></strong><ul> <li>Familiarity with design patterns and industry best practices</li> <li>Experience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, Spark</li> <li>Experience with Cloud technologies like: AWS, Google Cloud, Azure</li> <li>Ability to effectively create and utilize REST APIs</li> <li>Proactively creates automated analytics solutions to push team's capabilities and increased situational awareness</li> <li>Knowledge of MVC frameworks</li> <li>Ability to execute complex queries and design relational databases in PostgreSQL using referential integrity, views, stored procedures and proper indices</li> <li>Ability to create visualizations from resultant analytic results</li> <li>Experience creating and distributing Jupyter Notebooks for repeatable data analysis</li> <br><br></ul><strong><u>Education And Experience<br></u></strong><ul> <li>High school diploma or equivalent required</li> <li>Typically has two to four years combined industry / education experience</li> <li>Some specialized training or education beyond high school is preferred</li> <br><br></ul><strong><u>Physical Requirements<br></u></strong><ul> <li>Prolonged periods of sitting at a desk and working on a computer.</li> <li>Must be able to travel up to 5% of the time.</li> <br><br></ul><strong>Location:<br><br></strong><em>Virtual<br><br></em>PI129799278</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Computer & Network Security"
Python Developer,"Home, Kansas, United States",Rose International,2021-02-19,https://www.linkedin.com/jobs/view/python-developer-at-rose-international-2430648631?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=wtPZ3QjEC8FPjLpnOFERyA%3D%3D&position=10&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"This company is a fast-growing innovative trading firm looking for Data Engineers to grow out their Data Infrastructure team. In this role, you will use new technologies, and implement new ideas to help identify new ways to improve and expand the firm's data capabilities.



Responsibilities include:



Building and deploying data pipelines to collect and convert Big Data set
Working closely with stakeholders throughout the firm, understanding how the data is consumed
Be apart of a team, designing and expanding the data platform within a wide variety of data sources
Helping support an array of streaming. operational, and research work flows

Skills needed:



BS/MS/PhD in Computer Science, Engineering or related field
At least 5+ or more years of software/data engineering experience
Message que experience using Kafka or similar
Experience with Java, Scala, Or Kotlin
Have worked with SQL and NoSQL databases
Experience building out large-scale ETL pipelines

What's in it for you?!



Competitive Compensation and bonus structure
Generous PTO and Paid Volunteer Time
Take ownership of project and initiatives right away
Ability to collaborate with leadership and make an impact immediately


Sthree US is acting as an Employment Agency in relation to this vacancy.



Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>This company is a fast-growing innovative trading firm looking for Data Engineers to grow out their Data Infrastructure team. In this role, you will use new technologies, and implement new ideas to help identify new ways to improve and expand the firm's data capabilities. <br><br></p><p><strong>Responsibilities include:<br><br></strong></p><ul><li>Building and deploying data pipelines to collect and convert Big Data set</li><li>Working closely with stakeholders throughout the firm, understanding how the data is consumed</li><li>Be apart of a team, designing and expanding the data platform within a wide variety of data sources</li><li>Helping support an array of streaming. operational, and research work flows</li></ul><p><strong>Skills needed:<br><br></strong></p><ul><li>BS/MS/PhD in Computer Science, Engineering or related field</li><li>At least 5+ or more years of software/data engineering experience</li><li>Message que experience using Kafka or similar</li><li>Experience with Java, Scala, Or Kotlin</li><li>Have worked with SQL and NoSQL databases</li><li>Experience building out large-scale ETL pipelines</li></ul><p><strong>What's in it for you?!<br><br></strong></p><ul><li>Competitive Compensation and bonus structure</li><li>Generous PTO and Paid Volunteer Time</li><li>Take ownership of project and initiatives right away</li><li>Ability to collaborate with leadership and make an impact immediately<br></li></ul><p>Sthree US is acting as an Employment Agency in relation to this vacancy.<br><br></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Finance, Information Technology",Full-time,"Capital Markets, Computer Software, Design"
Data Engineer,"Allentown, Pennsylvania, United States","OpenArc, LLC.",2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-openarc-llc-2430455005?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=wiBtbXCQcfzsAm3gKIwkCQ%3D%3D&position=11&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Position Description

**Only U.S. Citizens and those authorized to work in the U.S. can be considered as W2 candidates.**
Location: REMOTE
Duration: 6 months

Python Developer - Intermediate

The Climate Corporation is looking for an intermediate Python Developer to join the Modeling team within our Science organization. This team directly works with world-class data scientists, scientific software engineers, statisticians and domain scientists. The team focuses on creating and improving state-of-the art agronomic models that drive our commercial agricultural decision-support tools.

We are looking for a software engineer who can create and deploy conda packages written in Python. The packages will be used by researchers to validate, compare and deploy models to a production environment, and to conduct sensitivity analyses; therefore the successful candidate will have an understanding of methods and metrics for validating predictions from models. In addition, this developer will help to socialize the new Python packages by creating and leading tutorials, writing how-to help pages, conducting code reviews, and assisting researchers using the packages.

What You Will Do

Implement existing algorithms for model validation and sensitivity analyses in a scalable and generalized fashion
Write clean, robust, well-documented code, including comprehensive tests
Engage with data scientists to understand their models and tooling needs
Support various aspects of data science research through software tooling
Create and lead tutorials to help socialize new Python functionality
Provide technical consultancy and code reviews for Python code developed by researchers and data analysts

Basic Qualifications

A bachelor''s degree in computer science, agronomy, crop science, soil science or a related field.
Deep understanding of scientific Python (e.g., leveraging classes and objects, writing packages, test frameworks, Pandas, numpy), as demonstrated through previous experience in commercial or open-source environments.
Proficient in software engineering best practices (agile, test development, PEP-8, git, continuous integration/ continuous deployment)
Familiarity with basic statistics and machine learning concepts
Strong organizational and communication skills

Preferred Qualifications

Strong understanding of statistics and machine learning
Experience building machine learning training pipelines or deploying research models in a production setting
Experience with at least one of the following: Spark, TensorFlow, PyTorch, XGBoost, or scikit-learn
Demonstrated oral and written communication skills (e.g., through past presentations, examples of technical writing, consulting projects, tutorials, etc.)
Experience with AWS ecosystem (S3, EC2)

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Position Description<br><br></u></strong>**Only U.S. Citizens and those authorized to work in the U.S. can be considered as W2 candidates.**<br>Location: REMOTE<br>Duration: 6 months<br><br>Python Developer - Intermediate<br><br>The Climate Corporation is looking for an intermediate Python Developer to join the Modeling team within our Science organization. This team directly works with world-class data scientists, scientific software engineers, statisticians and domain scientists. The team focuses on creating and improving state-of-the art agronomic models that drive our commercial agricultural decision-support tools.<br><br>We are looking for a software engineer who can create and deploy conda packages written in Python. The packages will be used by researchers to validate, compare and deploy models to a production environment, and to conduct sensitivity analyses; therefore the successful candidate will have an understanding of methods and metrics for validating predictions from models. In addition, this developer will help to socialize the new Python packages by creating and leading tutorials, writing how-to help pages, conducting code reviews, and assisting researchers using the packages.<br><br><strong><u>What You Will Do<br></u></strong><ul><li> Implement existing algorithms for model validation and sensitivity analyses in a scalable and generalized fashion</li><li> Write clean, robust, well-documented code, including comprehensive tests</li><li> Engage with data scientists to understand their models and tooling needs</li><li> Support various aspects of data science research through software tooling</li><li> Create and lead tutorials to help socialize new Python functionality</li><li> Provide technical consultancy and code reviews for Python code developed by researchers and data analysts<br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li> A bachelor''s degree in computer science, agronomy, crop science, soil science or a related field.</li><li> Deep understanding of scientific Python (e.g., leveraging classes and objects, writing packages, test frameworks, Pandas, numpy), as demonstrated through previous experience in commercial or open-source environments.</li><li> Proficient in software engineering best practices (agile, test development, PEP-8, git, continuous integration/ continuous deployment)</li><li> Familiarity with basic statistics and machine learning concepts</li><li> Strong organizational and communication skills<br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> Strong understanding of statistics and machine learning</li><li> Experience building machine learning training pipelines or deploying research models in a production setting</li><li> Experience with at least one of the following: Spark, TensorFlow, PyTorch, XGBoost, or scikit-learn</li><li> Demonstrated oral and written communication skills (e.g., through past presentations, examples of technical writing, consulting projects, tutorials, etc.)</li><li> Experience with AWS ecosystem (S3, EC2)<br></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"New York, New York, United States",Stash,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-at-stash-2397588249?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=gxahVsBcywq2oSv4DhQt5w%3D%3D&position=12&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"As a Data Engineer, you will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling advance data-driven decision-making capabilities of our enterprise. This role requires a deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows.

Responsibilities

Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics


Requirements

Bachelor’s degree required; Computer Science, or related field
Proven experience working in data engineering or architecture role
Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)
Experience developing and maintaining data warehouses in big data solutions
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space
Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies
Worked with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka
Familiarity with the Linux operating system
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passionate about Agile software processes, data-driven development, reliability, and experimentation
Demonstrated strong number sense, intellectually curious and willing to adjust position based on additional information


The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.

OpenArc is a technology consulting firm providing industry-leading technical talent placement, software development, and technology strategy services to clients nationwide. Through a unique blending of people and software, OpenArc has a business practice that delivers amazing enterprise, mobile and consumer-facing apps and the best talent for contract, contract-to-hire and direct placements for clients and partners alike.

Staffed with the most-trusted recruiting experts, elite software developers, UI/UX designers and market experts, our team provides clients with the best resources, the right techniques and world-class support resulting in powerful measurable success.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">As a Data Engineer, you will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling advance data-driven decision-making capabilities of our enterprise. This role requires a deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals</li><li>Solve complex data problems to deliver insights that helps our business to achieve their goals</li><li>Create data products for analytics and data scientist team members to improve their productivity</li><li>Advise, consult, mentor and coach other data and analytic professionals on data standards and practices</li><li>Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions</li><li>Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team</li><li>Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes</li><li>Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives</li><li>Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>Bachelor’s degree required; Computer Science, or related field</li><li>Proven experience working in data engineering or architecture role</li><li>Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)</li><li>Experience developing and maintaining data warehouses in big data solutions</li><li>Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space</li><li>Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies</li><li>Worked with BI tools such as Tableau, Power BI, Looker, Shiny</li><li>Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data</li><li>Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka</li><li>Familiarity with the Linux operating system</li><li>Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics</li><li>Passionate about Agile software processes, data-driven development, reliability, and experimentation</li><li>Demonstrated strong number sense, intellectually curious and willing to adjust position based on additional information<br><br></li></ul>The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.<br><br>OpenArc is a technology consulting firm providing industry-leading technical talent placement, software development, and technology strategy services to clients nationwide. Through a unique blending of people and software, OpenArc has a business practice that delivers amazing enterprise, mobile and consumer-facing apps and the best talent for contract, contract-to-hire and direct placements for clients and partners alike.<br><br>Staffed with the most-trusted recruiting experts, elite software developers, UI/UX designers and market experts, our team provides clients with the best resources, the right techniques and world-class support resulting in powerful measurable success.<br><br>The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Houston, Texas, United States",Cognite,2021-02-15,https://www.linkedin.com/jobs/view/data-engineer-at-cognite-2424747379?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=mGnTbx5YilDhJxNDi%2BL43Q%3D%3D&position=13&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Stash is pioneering the future of personal finance with the first financial subscription that helps people create better lives. From budgeting to saving for retirement, Stash unites banking, investing, and advice all in one app that has helped more than 5M people reach their financial goals and make progress towards financial freedom

At Stash, data is at the core of how we make decisions and build great products for millions of users. As a Data Engineer you will be a part of our Data Platform Team which is leading the architectural design decisions and implementation of a modern data infrastructure at scale. You will build distributed services and large scale processing systems that will support various teams to work faster and smarter. You will partner with Data Science to help productionize machine learning models and algorithms into actual data driven products that will help make smarter products for our users.

Tools And Technologies In Our Tech Stack (evolving)

Hadoop, Yarn, Spark, MongoDB, Hive
AWS EMR/EC2/Lambda/kinesis/S3/Glue/DynamoDB/API Gateway, Redshift
ElasticSearch, Airflow, and Terraform.
Scala, Python



What You'll Do

Build core components of data platform which will serve various types of consumers including but not limited to data science, engineers, product, qa
Build various data ingestion and transformation job/s as and when they are needed
Productionize our machine learning models and algorithms into data-driven feature MVPs that scale
Leverage best practices in continuous integration and deployment to our cloud-based infrastructure
Build scalable data services to bridge the gap between analytics and application space
Optimize data access and consumption for our business and product colleagues
Develop an understanding of key product, user, and business questions



Who We’re Looking For

3+ years of professional experience working in data engineering
BS / MS in Computer Science, Engineering, Mathematics, or a related field
You have built large-scale data products and understand the tradeoffs made when building these features
You have a deep understanding of system design, data structures, and algorithms
Experience (or a strong interest in) working with Python or Scala
Experience with working with a cluster manager (YARN / Mesos / Kubernetes)
Experience with distributed computing and working with Spark, Hadoop, or MapReduce Framework
Experience working on a cloud platform such as AWS
Experience with ETL in general



Gold Stars

Experience working with Apache Airflow
Experience working with AWS Glue
Experience in Machine Learning and Information Retrieval


_________________________________________

We believe that diversity and inclusion are essential to living our values, promoting innovation, and building the best products out there. Our success is directly related to the employees that we hire, grow and retain and we believe that our team should reflect the diversity of the customers that we serve.

As an Equal Opportunity Employer, Stash is committed to building an inclusive environment for people of all backgrounds. We do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by law. Everyone is encouraged to apply.

Benefits & Perks

Equity in Stash
Flexible Vacation
Family-Friendly Medical, Dental, and Vision Insurance Plans
401k
Learning & Development Stipend
Commuter Benefits and Flexible Spending Account (FSA)
Employee referral bonuses
Stocked fridges & kitchens and catered lunch on Fridays
Thursday happy hours
Team outings that do not involve trust falls...



Awards & Recognition

Forbes Fintech 50 (2019)
LendIt Fintech Innovator of the Year (2019)
Built in NYC's Best Places to work (2019)
Built in NYC’s Startups to Watch (2018)
Wall Street Journal's ""Top 25 Tech Companies To Watch"" (2018)
MarCom Awards Double Gold & Platinum Winner (2018)
Webby Award Winner for Best Mobile Sites & Apps in the Financial Services and Banking category (2017)
W3 Awards Winner for Best User Experience (2017)


No recruiters, please.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Stash is pioneering the future of personal finance with the first financial subscription that helps people create better lives. From budgeting to saving for retirement, Stash unites banking, investing, and advice all in one app that has helped more than 5M people reach their financial goals and make progress towards financial freedom<br><br>At Stash, data is at the core of how we make decisions and build great products for millions of users. As a Data Engineer you will be a part of our Data Platform Team which is leading the architectural design decisions and implementation of a modern data infrastructure at scale. You will build distributed services and large scale processing systems that will support various teams to work faster and smarter. You will partner with Data Science to help productionize machine learning models and algorithms into actual data driven products that will help make smarter products for our users.<br><br><strong><u>Tools And Technologies In Our Tech Stack (evolving)<br></u></strong><ul> <li>Hadoop, Yarn, Spark, MongoDB, Hive</li> <li>AWS EMR/EC2/Lambda/kinesis/S3/Glue/DynamoDB/API Gateway, Redshift</li> <li>ElasticSearch, Airflow, and Terraform.</li> <li>Scala, Python</li> <br><br></ul><strong><u>What You'll Do<br></u></strong><ul> <li>Build core components of data platform which will serve various types of consumers including but not limited to data science, engineers, product, qa</li> <li>Build various data ingestion and transformation job/s as and when they are needed</li> <li>Productionize our machine learning models and algorithms into data-driven feature MVPs that scale</li> <li>Leverage best practices in continuous integration and deployment to our cloud-based infrastructure</li> <li>Build scalable data services to bridge the gap between analytics and application space</li> <li>Optimize data access and consumption for our business and product colleagues</li> <li>Develop an understanding of key product, user, and business questions</li> <br><br></ul><strong><u>Who We’re Looking For<br></u></strong><ul> <li>3+ years of professional experience working in data engineering</li> <li>BS / MS in Computer Science, Engineering, Mathematics, or a related field</li> <li>You have built large-scale data products and understand the tradeoffs made when building these features</li> <li>You have a deep understanding of system design, data structures, and algorithms</li> <li>Experience (or a strong interest in) working with Python or Scala</li> <li>Experience with working with a cluster manager (YARN / Mesos / Kubernetes)</li> <li>Experience with distributed computing and working with Spark, Hadoop, or MapReduce Framework</li> <li>Experience working on a cloud platform such as AWS</li> <li>Experience with ETL in general</li> <br><br></ul><strong><u>Gold Stars<br></u></strong><ul> <li>Experience working with Apache Airflow</li> <li>Experience working with AWS Glue</li> <li>Experience in Machine Learning and Information Retrieval</li> <br></ul><strong>_________________________________________<br><br></strong>We believe that diversity and inclusion are essential to living our values, promoting innovation, and building the best products out there. Our success is directly related to the employees that we hire, grow and retain and we believe that our team should reflect the diversity of the customers that we serve.<br><br>As an Equal Opportunity Employer, Stash is committed to building an inclusive environment for people of all backgrounds. We do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by law. Everyone is encouraged to apply.<br><br><strong><u>Benefits &amp; Perks<br></u></strong><ul> <li>Equity in Stash </li> <li>Flexible Vacation</li> <li>Family-Friendly Medical, Dental, and Vision Insurance Plans</li> <li>401k</li> <li>Learning &amp; Development Stipend</li> <li>Commuter Benefits and Flexible Spending Account (FSA)</li> <li>Employee referral bonuses</li> <li>Stocked fridges &amp; kitchens and catered lunch on Fridays</li> <li>Thursday happy hours </li> <li>Team outings that do not involve trust falls...</li> <br><br></ul><strong><u>Awards &amp; Recognition<br></u></strong><ul> <li>Forbes Fintech 50 (2019)</li> <li>LendIt Fintech Innovator of the Year (2019)</li> <li>Built in NYC's Best Places to work (2019)</li> <li>Built in NYC’s Startups to Watch (2018)</li> <li>Wall Street Journal's ""Top 25 Tech Companies To Watch"" (2018)</li> <li>MarCom Awards Double Gold &amp; Platinum Winner (2018)</li> <li>Webby Award Winner for Best Mobile Sites &amp; Apps in the Financial Services and Banking category (2017)</li> <li>W3 Awards Winner for Best User Experience (2017)</li> <br></ul><strong><li>No recruiters, please.</li></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Python Developer,"Dallas, Texas, United States",Infosys,2021-02-17,https://www.linkedin.com/jobs/view/python-developer-at-infosys-2415322640?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=1VcpiznS0hkx1wxJYs3GUw%3D%3D&position=14&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Description

Do you see how data can be used, modeled and visualized in new ways to improve decisions in industrial engineering, but you experience that the tools and data availability is insufficient to create impact? If you want to change that, and take part in forming what the future of the industry will look like you should join our Cognite and become a part of the team responsible for delivering Cognite’s cutting edge industry solutions to our customers!

As a Data Engineer, located in Houston, TX, you will design, develop and implement data infrastructure and best-in-class pipelines that collect, connect, centralize and curate data from various internal and external data sources. You will ensure that architectures support the needs of the business, and recommend ways to improve data reliability, efficiency. You are an experienced engineer with a passion for software development, hands-on in designing, implementing, and delivering features for flagship products.

What You’ll Do

Partner with Solution Architects to understand client requirements and define queries with subject matter experts
Develop custom extractors using backend technologies and languages i.e Python, Spark, Rest APIs
Customize existing extractors i.e. database extractor using SQL, event streaming using Kafka and deploy using Docker
Create custom data models for data discovery, mapping, and cleansing
Collaborate with product development to turn customer needs into potential product offerings
Prototype data visualization and dashboards


Who You Are

1-3+ years of experience (degree in computer science or information related)
Loves to code, passion for coding, and enjoys sharing that knowledge with others
Strong understanding of data analysis or data science
Experience working with data technologies, such as: ETL, SQL, Python
Ability to work on both internal and external client-facing projects and communicate with key stakeholders
Ability to travel onsite to meet with and engage with clients -- we don’t build solutions in isolation.
Role based in Houston, TX or (Austin, TX w/ travel to Houston)


What Makes Us Great

An opportunity to make an impact on the industrial future and be part of disruptive and groundbreaking global projects
High level of autonomy, ability to influence decisions and to learn from mistakes
Work along side a driven, engaging team with in-depth software expertise and industry experience
Opportunity to join Together@Cognite for social, community, and diversity initiatives
Focus on agility and speed, openness, togetherness, impact, and obligation to speak up
Join a team that truly lives their values and brings their whole selves to Cognite


Perks & Benefits

Competitive Compensation + 401(k) with employer matching
Health, Dental, Vision & Disability Coverages with premiums fully covered
Unlimited PTO + flexibility to enjoy it
Paid Parental Leave Program
Learning & Development Stipends
Global Mobility & Exchange Program
FriYay Catered Meal + Fully Stocked Fridges



About Cognite

Cognite is a global industrial Software-as-a-Service (SaaS) company enabling the full-scale digital transformation of heavy-asset industries. Our core software product, Cognite Data Fusion (CDF), powers companies with contextualized OT/IT data to develop and scale solutions that increase safety, sustainability, efficiency, and drive revenue.

Headquartered in Oslo, Norway, Cognite has garnered the attention and partnership of some of the world's top industrial and tech companies, and the company’s success has been profiled in publications like Boston Consulting Group, Bloomberg, Digital Energy Journal, and Houston Chronicle. Google awarded Cognite Google Cloud Technology Partner of the Year 2019 for Manufacturing and Austin Business Journal named Cognite 2020 Best Places to Work.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>Do you see how data can be used, modeled and visualized in new ways to improve decisions in industrial engineering, but you experience that the tools and data availability is insufficient to create impact? If you want to change that, and take part in forming what the future of the industry will look like you should join our Cognite and become a part of the team responsible for delivering Cognite’s cutting edge industry solutions to our customers!<br><br>As a <strong>Data Engineer</strong>, located in <strong>Houston, TX, </strong>you will design, develop and implement data infrastructure and best-in-class pipelines that collect, connect, centralize and curate data from various internal and external data sources. You will ensure that architectures support the needs of the business, and recommend ways to improve data reliability, efficiency. You are an experienced engineer with a passion for software development, hands-on in designing, implementing, and delivering features for flagship products.<br><br>What You’ll Do<br><ul> <li>Partner with Solution Architects to understand client requirements and define queries with subject matter experts</li> <li>Develop custom extractors using backend technologies and languages i.e Python, Spark, Rest APIs</li> <li>Customize existing extractors i.e. database extractor using SQL, event streaming using Kafka and deploy using Docker</li> <li>Create custom data models for data discovery, mapping, and cleansing</li> <li>Collaborate with product development to turn customer needs into potential product offerings</li> <li>Prototype data visualization and dashboards</li> <br></ul>Who You Are<br><ul> <li>1-3+ years of experience (degree in computer science or information related)</li> <li>Loves to code, passion for coding, and enjoys sharing that knowledge with others</li> <li>Strong understanding of data analysis or data science</li> <li>Experience working with data technologies, such as: ETL, SQL, Python</li> <li>Ability to work on both internal and external client-facing projects and communicate with key stakeholders</li> <li>Ability to travel onsite to meet with and engage with clients -- we don’t build solutions in isolation.</li> <li>Role based in Houston, TX or (Austin, TX w/ travel to Houston)</li> <br></ul>What Makes Us Great<br><ul> <li>An opportunity to make an impact on the industrial future and be part of disruptive and groundbreaking global projects</li> <li>High level of autonomy, ability to influence decisions and to learn from mistakes</li> <li>Work along side a driven, engaging team with in-depth software expertise and industry experience</li> <li>Opportunity to join Together@Cognite for social, community, and diversity initiatives</li> <li>Focus on agility and speed, openness, togetherness, impact, and obligation to speak up</li> <li>Join a team that truly lives their values and brings their whole selves to Cognite</li> <br></ul>Perks &amp; Benefits<br><ul> <li>Competitive Compensation + 401(k) with employer matching </li> <li>Health, Dental, Vision &amp; Disability Coverages with premiums fully covered</li> <li>Unlimited PTO + flexibility to enjoy it</li> <li>Paid Parental Leave Program</li> <li>Learning &amp; Development Stipends</li> <li>Global Mobility &amp; Exchange Program </li> <li>FriYay Catered Meal + Fully Stocked Fridges</li> <br><br></ul><strong><u>About Cognite<br><br></u></strong>Cognite is a global industrial Software-as-a-Service (SaaS) company enabling the full-scale digital transformation of heavy-asset industries. Our core software product, Cognite Data Fusion (CDF), powers companies with contextualized OT/IT data to develop and scale solutions that increase safety, sustainability, efficiency, and drive revenue.<br><br>Headquartered in Oslo, Norway, Cognite has garnered the attention and partnership of some of the world's top industrial and tech companies, and the company’s success has been profiled in publications like Boston Consulting Group, Bloomberg, Digital Energy Journal, and Houston Chronicle. Google awarded Cognite Google Cloud Technology Partner of the Year 2019 for Manufacturing and Austin Business Journal named Cognite 2020 Best Places to Work.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer / Python Developer,"Los Angeles, California, United States",TWO NIL,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-python-developer-at-two-nil-2417518712?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=UJVNIXL3DBUfVfbc9QKOGA%3D%3D&position=15&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

In the role of Big Data Engineer, you will interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. You will play an important role in creating the high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.

Required Qualifications

Candidate must be located within commuting distance of Richardson, TX or be willing to relocate to the location. This position may require travel within the US and Canada.
Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education
2+ years of experience in Information Technology.
Bachelor’s Degree or foreign equivalent, will consider work experience in lieu of a degree
1 years of experience in Hadoop ecosystem leveraging tools like HBase, Hive, Pig, Scala, SPARK, Sqoop, Flume, Kafka, Python
1+ years of experience in Python & Spark with Advanced Spark programming and Advanced python programming.
Strong knowledge in object oriented concepts, data structures and algorithms
Experience in end-to-end implementation of DW BI projects, especially in data warehouse and mart
U.S. Citizenship or Permanent Residency required, we are not able to sponsor at this time
Preferred Senior Hadoop/Spark Developer Qualifications:

3 years of hands on experience with Hadoop distributed frameworks while handling large amount of big data using Spark, Python, Hive, and Hadoop Ecosystems, preferably on cloud platform
1+ years of experience with Python required
1+ years of experience with SQL and Big Data experience
Experience of working on AWS EMR Managed services is preferred
Experience with Agile delivery methodologies - Scrum, SaFe, Extreme programming
Ability to work within deadlines and effectively prioritize and execute on tasks.
Strong communication skills (verbal and written) with ability to communicate across teams, internal and external at all levels.
Experience in Drive automations
DevOps Knowledge is an added advantage.
Proficient knowledge of SQL with any RDBMS.


About Us

Infosys is a global leader in next-generation digital services and consulting. We enable clients in 46 countries to navigate their digital transformation.

With over three decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.

To learn more about Infosys and see our ideas in action please visit us at www.Infosys.com .

EOE/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity/National Origin
Country
USA
State / Region / Province
Texas
Work Location
Dallas, TX
Interest Group
Infosys Limited
Domain
Manufacturing

Skillset

Technology|Analytics - Packages|Python - Big Data

Company

ITL USA
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>In the role of Big Data Engineer, you will interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. You will play an important role in creating the high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.<br><br><strong><u>Required Qualifications<br></u></strong><ul><li> Candidate must be located within commuting distance of Richardson, TX or be willing to relocate to the location. This position may require travel within the US and Canada. </li><li> Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education </li><li> 2+ years of experience in Information Technology. </li><li> Bachelor’s Degree or foreign equivalent, will consider work experience in lieu of a degree </li><li> 1 years of experience in Hadoop ecosystem leveraging tools like HBase, Hive, Pig, Scala, SPARK, Sqoop, Flume, Kafka, Python </li><li> 1+ years of experience in Python &amp; Spark with Advanced Spark programming and Advanced python programming. </li><li> Strong knowledge in object oriented concepts, data structures and algorithms </li><li> Experience in end-to-end implementation of DW BI projects, especially in data warehouse and mart </li><li> U.S. Citizenship or Permanent Residency required, we are not able to sponsor at this time </li></ul> <strong> Preferred Senior Hadoop/Spark Developer Qualifications: <br></strong><ul><li> 3 years of hands on experience with Hadoop distributed frameworks while handling large amount of big data using Spark, Python, Hive, and Hadoop Ecosystems, preferably on cloud platform </li><li> 1+ years of experience with Python required </li><li> 1+ years of experience with SQL and Big Data experience </li><li> Experience of working on AWS EMR Managed services is preferred </li><li>Experience with Agile delivery methodologies - Scrum, SaFe, Extreme programming</li><li> Ability to work within deadlines and effectively prioritize and execute on tasks. </li><li> Strong communication skills (verbal and written) with ability to communicate across teams, internal and external at all levels. </li><li> Experience in Drive automations </li><li> DevOps Knowledge is an added advantage. </li><li> Proficient knowledge of SQL with any RDBMS. <br><br></li></ul><strong><u>About Us<br><br></u></strong>Infosys is a global leader in next-generation digital services and consulting. We enable clients in 46 countries to navigate their digital transformation.<br><br>With over three decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.<br><br>To learn more about Infosys and see our ideas in action please visit us at www.Infosys.com .<br><br><strong> EOE/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity/National Origin <br></strong><strong>Country<br></strong>USA<br><strong>State / Region / Province<br></strong>Texas<br><strong>Work Location<br></strong>Dallas, TX<br><strong>Interest Group<br></strong>Infosys Limited<br><strong>Domain<br></strong>Manufacturing<br><br><strong><u>Skillset<br><br></u></strong>Technology|Analytics - Packages|Python - Big Data<br><br><strong><u>Company<br><br></u></strong>ITL USA</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Management Consulting"
Data Scientist,"Atlanta, Georgia, United States","Anthem, Inc.",2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-anthem-inc-2430526600?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=19%2BmMYpUQmZzRxTp%2FESqKw%3D%3D&position=16&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"TWO NIL is a growth consultancy that uses a holistic approach to create profitable go to market campaigns – at scale. We provide clients with vertically integrated, unbundled solutions across their acquisition marketing needs, from strategy & planning to execution and optimization & modeling/forecasting. Our clients represent best of breed brands across a diverse range of verticals and geographies.

As a Data Engineer / Python Developer, you will be part of a growing team, building our next generation data analytics and data ingestion platform. In this role, you are constantly striving to build well-designed and efficient data platforms to enable data science products and services.

Responsibilities:


Build ETL applications for data validation, data scrubbing, and transformations using Python
Automate Data Pipelines using AWS Services (DataLake, Athena, MySQL, DynamoDB)
Integrate third party API's such as Google Analytics, Facebook, AWS, etc.
Troubleshoot and quickly resolve issues with data pipelines and automation jobs
Build scalable, reusable, secure, and efficient code
Work directly with clients to define data schemas for data ingestion
Collaborate with data scientists, data analysts, QA, and DevOps


Qualifications:


2+ years strong experience using Python 3.x
2+ years working with databases such as MySQL, PostgreSQL, or MS SQL
Experience using AWS Services (DynamoDB, Athena, DataLake, S3)
Experience working in a DevOps environment (Git, GitHub, CI/CD, Jira)
Experience with BI Visualization platforms such as Tableau or QuickSight is a plus
Experience using Agile/Scrum development methodology is a plus
Bachelor's degree in computer science or related technical field preferred
LOCAL CANDIDATES ONLY (Los Angeles Area). Currently working remotely during COVID


As a TWO NIL employee you will enjoy:


Competitive compensation package
Unlimited paid time off policy
Flexible working hours
Benefits (Health, Dental, Vision, Life Insurance, 401k, Flexible Spending Account and more)
Fitness reimbursement
Catered lunches and stocked kitchen with fresh fruit, snacks, premium coffee & tea, and cold brew coffee
Ongoing learning and classes for employees
Team events and outings
Due to COVID-19, our team is working remotely, this is subject to change



About TWO NIL:

Founded in 2011, TWO NIL is a leading growth consultancy with strategy, analytics, and media activation at its core, serving the top direct-to-consumer brands. TWO NIL provides clients with unbundled solutions across their acquisition marketing needs, from growth strategy to execution, media activation, optimization and forecasting. Headquartered in Los Angeles, California, TWO NIL is a trusted guide to corporations across the nation, including 23andMe, Bombas, Dollar Shave Club, Experian, Glassdoor, Blue Apron, RxSense, and many others. To learn more, please visit https://www.twonil.com/.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">TWO NIL is a growth consultancy that uses a holistic approach to create profitable go to market campaigns – at scale. We provide clients with vertically integrated, unbundled solutions across their acquisition marketing needs, from strategy &amp; planning to execution and optimization &amp; modeling/forecasting. Our clients represent best of breed brands across a diverse range of verticals and geographies.<br><br>As a Data Engineer / Python Developer, you will be part of a growing team, building our next generation data analytics and data ingestion platform. In this role, you are constantly striving to build well-designed and efficient data platforms to enable data science products and services.<br><br><strong>Responsibilities:<br><br></strong><ul> <li>Build ETL applications for data validation, data scrubbing, and transformations using Python</li> <li>Automate Data Pipelines using AWS Services (DataLake, Athena, MySQL, DynamoDB)</li> <li>Integrate third party API's such as Google Analytics, Facebook, AWS, etc.</li> <li>Troubleshoot and quickly resolve issues with data pipelines and automation jobs</li> <li>Build scalable, reusable, secure, and efficient code</li> <li>Work directly with clients to define data schemas for data ingestion</li> <li>Collaborate with data scientists, data analysts, QA, and DevOps</li> <br></ul><strong>Qualifications:<br><br></strong><ul> <li>2+ years strong experience using Python 3.x</li> <li>2+ years working with databases such as MySQL, PostgreSQL, or MS SQL</li> <li>Experience using AWS Services (DynamoDB, Athena, DataLake, S3)</li> <li>Experience working in a DevOps environment (Git, GitHub, CI/CD, Jira)</li> <li>Experience with BI Visualization platforms such as Tableau or QuickSight is a plus</li> <li>Experience using Agile/Scrum development methodology is a plus</li> <li>Bachelor's degree in computer science or related technical field preferred</li> <li>LOCAL CANDIDATES ONLY (Los Angeles Area). Currently working remotely during COVID</li> <br></ul><strong>As a TWO NIL employee you will enjoy:<br><br></strong><ul> <li>Competitive compensation package</li> <li>Unlimited paid time off policy </li> <li>Flexible working hours</li> <li>Benefits <em>(Health, Dental, Vision, Life Insurance, 401k, Flexible Spending Account and more)</em></li> <li>Fitness reimbursement</li> <li>Catered lunches and stocked kitchen with fresh fruit, snacks, premium coffee &amp; tea, and cold brew coffee </li> <li>Ongoing learning and classes for employees</li> <li>Team events and outings</li> <li><em>Due to COVID-19, our team is working remotely, this is subject to change</em></li> <br><br></ul><strong>About TWO NIL:<br><br></strong>Founded in 2011, TWO NIL is a leading growth consultancy with strategy, analytics, and media activation at its core, serving the top direct-to-consumer brands. TWO NIL provides clients with unbundled solutions across their acquisition marketing needs, from growth strategy to execution, media activation, optimization and forecasting. Headquartered in Los Angeles, California, TWO NIL is a trusted guide to corporations across the nation, including 23andMe, Bombas, Dollar Shave Club, Experian, Glassdoor, Blue Apron, RxSense, and many others. To learn more, please visit https://www.twonil.com/.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Management Consulting"
Data Engineer,"New York, New York, United States",The New York Times,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-the-new-york-times-2407684984?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=HHDFaAPsP%2Fk1d5RZqPHB7Q%3D%3D&position=17&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Description

SHIFT: Day Job

SCHEDULE: Full-time

Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Data Scientist

Responsible for the development and implementation of machine learning algorithms and techniques to solve business problems and optimize member experiences.

Primary Duties May Include Are But Not Limited To

Design machine learning projects to address specific business problems determined by consultation with business partners.
Work with data-sets of varying degrees of size and complexity including both structured and unstructured data.
Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis.
Implements batch and real-time model scoring to drive actions.
Develops proprietary machine learning algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions.
Develop sophisticated visualization of analysis output for business users.
Publish results and address constraints/limitations with business partners.
Provides high-level controllership/evaluation of all output produced to ensure established targets are met.
Determines the continuous improvement opportunities of current predictive modeling algorithms.
Proactively collaborates with business partners to determine identified population segments and develop actionable plans to enable the identification of patterns related to quality, use, cost and other variables.



Qualifications

Requires a Bachelor’s degree in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines and 3 or more years experience in predictive analytics or equivalent. Must have advanced expertise with software such as Python, R, SAS, SAS Enterprise Miner or equivalent, or any combination of education and experience which would provide an equivalent background. PhD and experience in the healthcare sector preferred.

1+ years experience with Text Mining or Natural Language Processing is preferred.
At least 1 year experience implementing deep learning models using Tensorflow, H20.ai or other similar packages is strongly preferred.
2 + years experience working on EMR(Electronic Medical Records) preferred.



We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.

Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and has been named a 2019 Best Employers for Diversity by Forbes. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran. Anthem promotes the delivery of services in a culturally competent manner and considers cultural competency when evaluating applicants for all Anthem positions.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>SHIFT: Day Job<br><br>SCHEDULE: Full-time<br><br>Your Talent. Our Vision.<strong> At Anthem, Inc.,</strong> it’s a powerful combination, and the foundation upon which we’re creating greater care for our members, greater value for our customers, and greater health for our communities. Join us and <strong>together we will drive the future of health care.<br><br></strong>This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.<br><br><strong>Data Scientist<br><br></strong>Responsible for the development and implementation of machine learning algorithms and techniques to solve business problems and optimize member experiences.<br><br><strong><u>Primary Duties May Include Are But Not Limited To<br></u></strong><ul> <li>Design machine learning projects to address specific business problems determined by consultation with business partners.</li> <li>Work with data-sets of varying degrees of size and complexity including both structured and unstructured data.</li> <li>Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis.</li> <li>Implements batch and real-time model scoring to drive actions.</li> <li>Develops proprietary machine learning algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions.</li> <li>Develop sophisticated visualization of analysis output for business users.</li> <li>Publish results and address constraints/limitations with business partners.</li> <li>Provides high-level controllership/evaluation of all output produced to ensure established targets are met.</li> <li>Determines the continuous improvement opportunities of current predictive modeling algorithms.</li> <li>Proactively collaborates with business partners to determine identified population segments and develop actionable plans to enable the identification of patterns related to quality, use, cost and other variables.</li> <br><br></ul><strong><u>Qualifications<br><br></u></strong>Requires a Bachelor’s degree in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines and 3 or more years experience in predictive analytics or equivalent. Must have advanced expertise with software such as Python, R, SAS, SAS Enterprise Miner or equivalent, or any combination of education and experience which would provide an equivalent background. PhD and experience in the healthcare sector preferred.<br><ul> <li>1+ years experience with Text Mining or Natural Language Processing is preferred.</li> <li>At least 1 year experience implementing deep learning models using Tensorflow, H20.ai or other similar packages is strongly preferred.</li> <li>2 + years experience working on EMR(Electronic Medical Records) preferred.</li> <br><br></ul>We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.<br><br>Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and has been named a 2019 Best Employers for Diversity by Forbes. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran. Anthem promotes the delivery of services in a culturally competent manner and considers cultural competency when evaluating applicants for all Anthem positions.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Insurance, Financial Services, Hospital & Health Care"
Data Analytic Engineer,"Charlotte, North Carolina, United States",Allstate,2021-02-08,https://www.linkedin.com/jobs/view/data-analytic-engineer-at-allstate-2414897981?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=Ys4DAIH35rMnCmKZ4rIuQg%3D%3D&position=18&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

The New York Times is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company.

About Us

Our Data Engineering teams are at the intersection of business analytics, data warehousing, and software engineering. As Maxime Beauchemin wrote in “The Rise of Data Engineering”, ETL and data modeling have evolved, and the changes are about distributed systems, stream processing, and computation at scale. They’re about working with data using the same practices that guide software engineering at large. A strong data foundation is essential for The New York Times and we’re responsible for it. We use our data infrastructure to power analytics and data products and to deliver relevant experiences to our customers in real-time. We enable our company to validate strategic decisions, make smarter choices, and react to the fast changing world. We are part of a New York based technology organization with a remote-friendly workplace that includes engineers around the world. We value transparency and openness, learning, community, and continuous improvement. Check out the Times Open blog, which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we’re up to.

About The Job

We focus on the software engineering related to data replication, storage, centralized computation, and data API’s. We provide customers and partners with data tools, shared frameworks, and data services. These are the foundational core of our group which enables ourselves and others to work with data from a common underpinning. Our tools and services enable our group to scale and avoid blocking others. We reduce data redundancy by creating systems and datasets that serve as sources of record. We enable discovery and governance of our data. We support key business goals like growing our digital subscriber base, understanding how our customers use our products, and retaining our print subscribers.

As a Data Engineer, You Will

Run and support a production enterprise data platform
Design and develop data models
Work with languages like Java, Python, Go, Bash, and SQL
Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub
Develop processes for automating, testing, and deploying your work


About You

To thrive in this role, you are excited about data and motivated to learn new technologies. You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are own and shape your technical domain area and move the related business goals forward. You are eager to resolve upstream data issues at the source instead of applying workarounds. You analyze and test changes to our data architectures and processes, and determine what the possible downstream effects and potential impacts to data consumers will be.

Benefits And Perks

Make an impact by supporting our original, independent and deeply reported journalism.
We provide competitive health, dental, vision and life insurance for employees and their families
We support responsible retirement planning with a generous 401(k) company match.
We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.
We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.
We have frequent panel discussions and talks by a wide variety of news makers and industry leaders.
Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.

This role may require limited on-call hours. An on-call schedule will be determined when you join, taking into account team size and other variables. On-call hours are unpaid, unless informed otherwise by your manager.

The New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.

The New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The New York Times Company will consider qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local ""Fair Chance"" laws.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>The New York Times is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company.<br><br><strong><u>About Us<br><br></u></strong>Our Data Engineering teams are at the intersection of business analytics, data warehousing, and software engineering. As Maxime Beauchemin wrote in “The Rise of Data Engineering”, ETL and data modeling have evolved, and the changes are about distributed systems, stream processing, and computation at scale. They’re about working with data using the same practices that guide software engineering at large. A strong data foundation is essential for The New York Times and we’re responsible for it. We use our data infrastructure to power analytics and data products and to deliver relevant experiences to our customers in real-time. We enable our company to validate strategic decisions, make smarter choices, and react to the fast changing world. We are part of a New York based technology organization with a remote-friendly workplace that includes engineers around the world. We value transparency and openness, learning, community, and continuous improvement. Check out the Times Open blog, which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we’re up to.<br><br><strong><u>About The Job<br><br></u></strong>We focus on the software engineering related to data replication, storage, centralized computation, and data API’s. We provide customers and partners with data tools, shared frameworks, and data services. These are the foundational core of our group which enables ourselves and others to work with data from a common underpinning. Our tools and services enable our group to scale and avoid blocking others. We reduce data redundancy by creating systems and datasets that serve as sources of record. We enable discovery and governance of our data. We support key business goals like growing our digital subscriber base, understanding how our customers use our products, and retaining our print subscribers.<br><br><strong><u>As a Data Engineer, You Will<br></u></strong><ul><li> Run and support a production enterprise data platform </li><li> Design and develop data models </li><li> Work with languages like Java, Python, Go, Bash, and SQL </li><li> Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub </li><li> Develop processes for automating, testing, and deploying your work <br><br></li></ul><strong><u>About You<br><br></u></strong>To thrive in this role, you are excited about data and motivated to learn new technologies. You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are own and shape your technical domain area and move the related business goals forward. You are eager to resolve upstream data issues at the source instead of applying workarounds. You analyze and test changes to our data architectures and processes, and determine what the possible downstream effects and potential impacts to data consumers will be.<br><br><strong><u>Benefits And Perks<br></u></strong><ul><li> Make an impact by supporting our original, independent and deeply reported journalism. </li><li> We provide competitive health, dental, vision and life insurance for employees and their families </li><li> We support responsible retirement planning with a generous 401(k) company match. </li><li> We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid. </li><li> We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement. </li><li> We have frequent panel discussions and talks by a wide variety of news makers and industry leaders. </li><li> Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups. <br></li></ul><em>This role may require limited on-call hours. An on-call schedule will be determined when you join, taking into account team size and other variables. On-call hours are unpaid, unless informed otherwise by your manager. <br><br></em><strong> The New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply. <br><br></strong><strong>The New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The New York Times Company will consider qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local ""Fair Chance"" laws.<br><br></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Online Media, Publishing, Newspapers"
Data Engineer,"Mountain View, California, United States",SentinelOne,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-sentinelone-2428597873?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=s8tUYbJq9wdPjEyjEJO7%2FA%3D%3D&position=19&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.

You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.

Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.

Job Description

Data, Discovery, and Decision Science (D3) is the research and analytics organization at Allstate. We are solving some of today’s most complicated analytics problems, making the lives of our Allstate colleagues easier and more productive, and driving our mission to deliver perfect insurance solutions to our customers. We are avid about learning new ways to get the most value from our massive data resources. We are partnering to incorporate analytics into every aspect of the enterprise. Developing ourselves and others is key to our success.

As a Data Analytic Engineer in D3, you'll be responsible for driving the use and development of data infrastructure projects & proof of concept business solutions for users in analytics and Data Science. You will work directly with data scientists and analytic engineers on needs and tactical solutions. You will execute new data engineering work tracks for Data Science and analytics from inception and prototyping to fully developed solutions. You will also have the opportunity to begin to manage projects.

Key Responsibilities

Work with Data Scientists and business partners on cross functional teams; developing subject matter expertise in the business as well as advanced analytics.
Provide support on requirement development for analytic data sources, breaking down business problems into solvable components and assist with documenting requirements with minimal supervision.
Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints
Help develop and deliver the data infrastructure required to support needs of predictive modeling and analytics with minimal supervision.
Builds test scripts, executes testing, works with data scientists and business to ensure end user acceptance
Leverage “agile” data analysis with technology fluency in parallel processing/programming, software/programming languages and technologies (i.e. Oracle, MongoDB, SQL, Python, Spark, Kafka, Scala and Hadoop), paired with a high degree of analytic agility to be able to meet fluid and dynamic business needs in this space.
Participate in the development of enterprise data assets, information platforms or data spaces designed for exploring and understanding the data.
Participate in the development of new concepts, proof of concept designs, and prototypes for business or research data solutions so that business users or predictive modelers may visually understand and explore a new feature or functionality before implementation to expose design assumptions and drive ideation.
Mentor other team members in a business technical environment and promote an environment that supports innovation and process improvement.



Job Qualifications

2 or more years of related experience
Bachelor’s degree or equivalent experience
Database development knowledge and experience (i.e. SQL)
Programming skills (i.e. Python, R, Java)
Computer Proficiency in Oracle, UNIX/Linux
Intermediate Analytic, Data Sourcing, and Data Management skills
Ability to extract data from various data sources.
Solid experience in time and task management
Ability to learn new technologies
Strong attention to detail
Good written and verbal communication skills, including the ability to effectively collaborate with multi-disciplinary groups and all organizational levels


Minimum base salary $85K. Target bonus eligible. Offer will be commensurate with experience and could be significantly higher than the minimum.

The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.<br><br>You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.<br><br>Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.<br><br><strong><u>Job Description<br><br></u></strong>Data, Discovery, and Decision Science (D3) is the research and analytics organization at Allstate. We are solving some of today’s most complicated analytics problems, making the lives of our Allstate colleagues easier and more productive, and driving our mission to deliver perfect insurance solutions to our customers. We are avid about learning new ways to get the most value from our massive data resources. We are partnering to incorporate analytics into every aspect of the enterprise. Developing ourselves and others is key to our success.<br><br>As a Data Analytic Engineer in D3, you'll be responsible for driving the use and development of data infrastructure projects &amp; proof of concept business solutions for users in analytics and Data Science. You will work directly with data scientists and analytic engineers on needs and tactical solutions. You will execute new data engineering work tracks for Data Science and analytics from inception and prototyping to fully developed solutions. You will also have the opportunity to begin to manage projects.<br><br>Key Responsibilities<br><ul><li>Work with Data Scientists and business partners on cross functional teams; developing subject matter expertise in the business as well as advanced analytics. </li><li>Provide support on requirement development for analytic data sources, breaking down business problems into solvable components and assist with documenting requirements with minimal supervision.</li><li>Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints </li><li>Help develop and deliver the data infrastructure required to support needs of predictive modeling and analytics with minimal supervision. </li><li>Builds test scripts, executes testing, works with data scientists and business to ensure end user acceptance</li><li>Leverage “agile” data analysis with technology fluency in parallel processing/programming, software/programming languages and technologies (i.e. Oracle, MongoDB, SQL, Python, Spark, Kafka, Scala and Hadoop), paired with a high degree of analytic agility to be able to meet fluid and dynamic business needs in this space. </li><li>Participate in the development of enterprise data assets, information platforms or data spaces designed for exploring and understanding the data. </li><li>Participate in the development of new concepts, proof of concept designs, and prototypes for business or research data solutions so that business users or predictive modelers may visually understand and explore a new feature or functionality before implementation to expose design assumptions and drive ideation.</li><li>Mentor other team members in a business technical environment and promote an environment that supports innovation and process improvement.<br><br><br></li></ul><strong><u>Job Qualifications<br></u></strong><ul><li>2 or more years of related experience</li><li>Bachelor’s degree or equivalent experience</li><li>Database development knowledge and experience (i.e. SQL)</li><li>Programming skills (i.e. Python, R, Java)</li><li>Computer Proficiency in Oracle, UNIX/Linux</li><li>Intermediate Analytic, Data Sourcing, and Data Management skills </li><li>Ability to extract data from various data sources. </li><li>Solid experience in time and task management </li><li>Ability to learn new technologies </li><li>Strong attention to detail </li><li>Good written and verbal communication skills, including the ability to effectively collaborate with multi-disciplinary groups and all organizational levels <br><br></li></ul>Minimum base salary $85K. Target bonus eligible. Offer will be commensurate with experience and could be significantly higher than the minimum.<br><br>The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.<br><br><strong>Good Work. Good Life. Good Hands®. <br><br></strong>As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.<br><br>Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.<br><br><strong>Allstate generally does not sponsor individuals for employment-based visas for this position.<br><br></strong>Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.<br><br>For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.<br>For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.<br><br>To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs<br><br>To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.<br><br>It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Insurance, Financial Services"
Entry Level Data Engineer (AI Applications),"Littleton, Massachusetts, United States",IBM,2021-02-10,https://www.linkedin.com/jobs/view/entry-level-data-engineer-ai-applications-at-ibm-2398564407?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=1LV%2Bw1dqkuca2ZCoUGfXQw%3D%3D&position=20&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Who are we?

If you’re passionate about enabling success with data and creating business driving insights have a place with us. SentinelOne is growing its Customer Success team and looking for a data expert with technical orientation to assist in managing our Customer data and architecture for our rapidly growing base.

You should have an inclination to great successful business outcomes driven by data enablement and can create win/win environments for all parties that you work with. If this is you, and you want to be part of a next-gen growing technology in a company with a fantastic culture, we would love your help making our Customers successful!

What will you do?



Assist with designing and implementing our CS data architecture.
Drive key business objectives via data enablement.
Partner with RnD, Cloud Operations and other internal stakeholders to drive progress on data deliverables.
Own our CS data lake and drive incremental improvements.
Design and implement integration between our CS platform and data architecture.

What experience and skills you should bring?


Prior experience as a data analyst, engineer or similar role designing and implement cloud data architectures
Adept with SQL, Python and RESTful API
Experience with S3, GCP and other cloud storage technologies
Experience designing algorithms and enabling data for enterprises at scale.
Strong team player but still a self-starter.
Thrives in a multitasking environment and can adjust priorities on-the-fly.

Why us?

You will be joining a cutting-edge company, where you will tackle extraordinary challenges and work with the very best in the industry!


Medical, Vision, Dental, 401(k), Commuter, Health and Dependent FSA
Unlimited PTO
Paid Company Holidays
Paid Sick Time
Gym membership reimbursement
Cell phone reimbursement
Numerous company-sponsored events including regular happy hours and team building events
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Who are we?<br><br></strong>If you’re passionate about enabling success with data and creating business driving insights have a place with us. SentinelOne is growing its Customer Success team and looking for a data expert with technical orientation to assist in managing our Customer data and architecture for our rapidly growing base.<br><br>You should have an inclination to great successful business outcomes driven by data enablement and can create win/win environments for all parties that you work with. If this is you, and you want to be part of a next-gen growing technology in a company with a fantastic culture, we would love your help making our Customers successful!<br><br><strong>What will you do?<br><br><br></strong><ul><li>Assist with designing and implementing our CS data architecture.</li><li>Drive key business objectives via data enablement.</li><li>Partner with RnD, Cloud Operations and other internal stakeholders to drive progress on data deliverables.</li><li>Own our CS data lake and drive incremental improvements.</li><li>Design and implement integration between our CS platform and data architecture.<br></li></ul><strong>What experience and skills you should bring?<br><br></strong><ul><li>Prior experience as a data analyst, engineer or similar role designing and implement cloud data architectures</li><li>Adept with SQL, Python and RESTful API</li><li>Experience with S3, GCP and other cloud storage technologies</li><li>Experience designing algorithms and enabling data for enterprises at scale.</li><li>Strong team player but still a self-starter.</li><li>Thrives in a multitasking environment and can adjust priorities on-the-fly.<br></li></ul><strong>Why us?<br><br></strong>You will be joining a cutting-edge company, where you will tackle extraordinary challenges and work with the very best in the industry!<br><br><ul><li>Medical, Vision, Dental, 401(k), Commuter, Health and Dependent FSA</li><li>Unlimited PTO</li><li>Paid Company Holidays</li><li>Paid Sick Time</li><li>Gym membership reimbursement</li><li>Cell phone reimbursement</li><li>Numerous company-sponsored events including regular happy hours and team building events</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Computer & Network Security
Data Engineer,"Sunnyvale, California, United States",Blue River Technology,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-blue-river-technology-2419634482?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=7zPhIm5YALgVCcDYRhjmsA%3D%3D&position=21&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The AI Applications team is seeking an Entry Level Data Engineer. Climate science, weather forecasting and agricultural predictions are among the many leading Big Data, geospatially oriented problems that we work on. Problems that are extremely relevant to all of us in today's changing world. We are looking to add a results oriented individual to join us and help develop and maintain the information/data pipelines that fuel our geospatial analytics platform. A wide variety of data sources, such as satellites and IoT devices, contribute to the over 6 petabytes (and growing daily) of information that we curate for our clients.

As a Team Member You Will Be

Passionate about each client and their success
Building new data ingestion pipelines, and adapting existing ones to changing data sources and changing client data requirements
Working with others to design new ways of ingesting data that makes it faster and easier
Knowledgeable and skilled with one or more languages like Python, Java, Scala and Julia
Knowledgeable and/or willing to learn about different database technologies, Hadoop and Cloud development and delivery
Conscientious about deadlines and deliverables
Excited to continue to learn and develop new skills
Contributing to the governance and curation of the data, and tooling to support these activities


Required Technical and Professional Expertise

Basic knowledge in one or more of the following languages: Python, Java, Scala, Julia
Basic knowledge in database technologies
Basic knowledge in Hadoop


Preferred Technical And Professional Expertise

Previous internship or co-op experience as a Data Engineer


About Business Unit

IBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM

IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

IBM intends this job to be performed entirely outside of Colorado.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Introduction<br>At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.<br><br>Your Role and Responsibilities<br><br>The AI Applications team is seeking an Entry Level Data Engineer. Climate science, weather forecasting and agricultural predictions are among the many leading Big Data, geospatially oriented problems that we work on. Problems that are extremely relevant to all of us in today's changing world. We are looking to add a results oriented individual to join us and help develop and maintain the information/data pipelines that fuel our geospatial analytics platform. A wide variety of data sources, such as satellites and IoT devices, contribute to the over 6 petabytes (and growing daily) of information that we curate for our clients.<br><br><strong><u>As a Team Member You Will Be<br></u></strong><ul><li>Passionate about each client and their success</li><li>Building new data ingestion pipelines, and adapting existing ones to changing data sources and changing client data requirements</li><li>Working with others to design new ways of ingesting data that makes it faster and easier</li><li>Knowledgeable and skilled with one or more languages like Python, Java, Scala and Julia</li><li>Knowledgeable and/or willing to learn about different database technologies, Hadoop and Cloud development and delivery</li><li>Conscientious about deadlines and deliverables</li><li>Excited to continue to learn and develop new skills</li><li>Contributing to the governance and curation of the data, and tooling to support these activities<br><br></li></ul>Required Technical and Professional Expertise<br><ul><li>Basic knowledge in one or more of the following languages: Python, Java, Scala, Julia</li><li>Basic knowledge in database technologies</li><li>Basic knowledge in Hadoop<br><br></li></ul><strong><u>Preferred Technical And Professional Expertise<br></u></strong><ul><li>Previous internship or co-op experience as a Data Engineer<br><br></li></ul><strong><u>About Business Unit<br><br></u></strong>IBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.<br><br>Your Life @ IBM<br>What matters to you when you’re looking for your next career challenge?<br><br>Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.<br><br>Impact. Inclusion. Infinite Experiences. Do your best work ever.<br><br><strong><u>About IBM<br><br></u></strong>IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.<br><br>Location Statement<br>IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.<br><br>IBM intends this job to be performed entirely outside of Colorado.<br><br>Being You @ IBM<br>IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Information Technology and Services, Management Consulting"
Data Scientist,"Maryville, Tennessee, United States",DENSO,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-denso-2418271034?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=P6%2BWNOY60tsw0sDMn8sp8Q%3D%3D&position=22&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"Blue River Technology serves the agricultural industry by designing and building advanced farm machines that utilize technology like computer vision and machine learning to enable farmers to understand and manage every plant. These machines help farmers to improve profitability, protects the environment by reducing pesticide use, and captures valuable plant-by-plant data. Blue River is a pioneer in the agricultural robotics space and has developed the See & Spray precision sprayer, which applies pesticide only where needed, and can reduce pesticide use 90%.




John Deere & Company, with over 180 years of experience in designing, manufacturing, and distributing innovative products to farmers, acquired Blue River Technology in the fall of 2017 as an independently run subsidiary. In partnership with John Deere, Blue River has expanded rapidly and together both companies see many opportunities to apply advanced computer vision, machine learning, and robotics technologies to other areas in agriculture beyond spraying.




Blue River is based in Sunnyvale, CA and has 100+ team members with diverse experience including computer vision, machine learning, systems software, autonomous vehicles and precision agriculture. Our working environment is fast paced and highly collaborative, and employees are excited to use their talents to improve food production and protect the environment.




Position Description

We’re seeking a talented Data Engineer specializing in building and maintaining production machine learning software platforms to join our team. Our machine learning platform helps manage the various components of the ML application development life cycle, starting from data ingestion, annotation, exploration to model training, deployment and monitoring. All of these components are interdisciplinary, so you will be working closely with roboticists and ML researchers in both defining interfaces and optimizing implementations to meet the final product specifications.




Role Responsibilities:

Design and build updates to our data solutions supporting robotics and machine learning development cycle
Develop and architect enhanced systems to enable rapid retrieval of imagery and time series data
Promote standard methodologies in data modeling, storage, and processing
Assess, benchmark and select new technologies to be added to the digital product portfolio.
Help enable our users to find their data! Develop best practices for data access and queries.
Work with product, ML scientists, roboticists, and software engineers to build a data platform that supports development of Intelligent Machines




Required Professional Skills & Experience:

Expertise in data modeling for time series, spatial, and image data for analytic and operational use cases
Strong Python programmer
Experience with a diversity of datastores such as Redshift, Dynamo, Athena, Mongo, Postgres
Experience developing ETL in a microservice architecture
Data lifecycle management experience
Experience with infrastructure as code, such as Terraform
Self-motivated, ability to work both independently and in team environments
Excellent communicator
Bachelor’s Degree in Computer Science or related technical subject area




Preferred Skills & Experience:

Experience working with high dimensional data: images, videos, point clouds, etc.
Experience crafting data systems to support machine learning and robotics applications
Experienced in data mining and visualization of large data sets
Experience developing on Kubernetes based systems



Blue River offers competitive compensation and benefits, including a great 401(K) match. We believe in a work life balance and offer generous Paid Time Off and Sick Leave as well as Paid Parental Leave and an adoption benefit. Subsidized lunches (when we return to the office), flexible work hours, CalTrain passes (with mobile Wi-Fi!) and a collaborative and supportive environment also contribute to making Blue River a great place to work.




We are committed to building a diverse team and encourage applications from people of all backgrounds.

 

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Blue River Technology serves the agricultural industry by designing and building advanced farm machines that utilize technology like computer vision and machine learning to enable farmers to understand and manage every plant. These machines help farmers to improve profitability, protects the environment by reducing pesticide use, and captures valuable plant-by-plant data. Blue River is a pioneer in the agricultural robotics space and has developed the See &amp; Spray precision sprayer, which applies pesticide only where needed, and can reduce pesticide use 90%.</p><p><br></p><p>John Deere &amp; Company, with over 180 years of experience in designing, manufacturing, and distributing innovative products to farmers, acquired Blue River Technology in the fall of 2017 as an independently run subsidiary. In partnership with John Deere, Blue River has expanded rapidly and together both companies see many opportunities to apply advanced computer vision, machine learning, and robotics technologies to other areas in agriculture beyond spraying.</p><p><br></p><p>Blue River is based in Sunnyvale, CA and has 100+ team members with diverse experience including computer vision, machine learning, systems software, autonomous vehicles and precision agriculture. Our working environment is fast paced and highly collaborative, and employees are excited to use their talents to improve food production and protect the environment.</p><p><br></p><p><strong>Position Description</strong></p><p>We’re seeking a talented Data Engineer specializing in building and maintaining production machine learning software platforms to join our team. Our machine learning platform helps manage the various components of the ML application development life cycle, starting from data ingestion, annotation, exploration to model training, deployment and monitoring. All of these components are interdisciplinary, so you will be working closely with roboticists and ML researchers in both defining interfaces and optimizing implementations to meet the final product specifications.</p><p><br></p><p><strong>Role Responsibilities: </strong></p><ul><li>Design and build updates to our data solutions supporting robotics and machine learning development cycle</li><li>Develop and architect enhanced systems to enable rapid retrieval of imagery and time series data</li><li>Promote standard methodologies in data modeling, storage, and processing</li><li>Assess, benchmark and select new technologies to be added to the digital product portfolio.</li><li>Help enable our users to find their data! Develop best practices for data access and queries.</li><li>Work with product, ML scientists, roboticists, and software engineers to build a data platform that supports development of Intelligent Machines</li></ul><p><br></p><p><strong>Required Professional Skills &amp; Experience:</strong></p><ul><li>Expertise in data modeling for time series, spatial, and image data for analytic and operational use cases</li><li>Strong Python programmer</li><li>Experience with a diversity of datastores such as Redshift, Dynamo, Athena, Mongo, Postgres</li><li>Experience developing ETL in a microservice architecture</li><li>Data lifecycle management experience</li><li>Experience with infrastructure as code, such as Terraform</li><li>Self-motivated, ability to work both independently and in team environments</li><li>Excellent communicator</li><li>Bachelor’s Degree in Computer Science or related technical subject area</li></ul><p><br></p><p><strong>Preferred Skills &amp; Experience:</strong></p><ul><li>Experience working with high dimensional data: images, videos, point clouds, etc.</li><li>Experience crafting data systems to support machine learning and robotics applications</li><li>Experienced in data mining and visualization of large data sets</li><li>Experience developing on Kubernetes based systems</li><li><br></li></ul><p>Blue River offers competitive compensation and benefits, including a great 401(K) match. We believe in a work life balance and offer generous Paid Time Off and Sick Leave as well as Paid Parental Leave and an adoption benefit. Subsidized lunches (when we return to the office), flexible work hours, CalTrain passes (with mobile Wi-Fi!) and a collaborative and supportive environment also contribute to making Blue River a great place to work.</p><p><br></p><p><strong>We are committed to building a diverse team and encourage applications from people of all backgrounds.</strong></p><p>&nbsp;</p><p></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Production",Full-time,"Industrial Automation, Computer Software, Machinery"
Data Scientist,"Denver, Colorado, United States","RxRevu, Inc.",2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-rxrevu-inc-2430455321?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=DtAfzJrxqSnZqbi%2Bz2lrkA%3D%3D&position=23&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"About DENSO

DENSO is a global Fortune 500 company and an advanced mobility supplier and manufacturer. We develop technology and components for nearly every make and model on the road today.

At DENSO, we believe technology can help solve some of society's greatest challenges. Our broad product portfolio includes mobility, electrification, powertrain, and electronic systems. With manufacturing at our core, we have 170,000 employees across 221 facilities in 35 countries who engineer, design and manufacture advanced technologies that directly change how the world moves.

Globally headquartered in Kariya, Japan, we spend 9.9% of global consolidated sales on research & development in the fiscal year ending March 31, 2020. In North America, we're headquartered in Southfield, Michigan, and we employ 27,000+ in the United States, Canada and Mexico. In the United States alone, we employ 17,700 across 41 sites in 14 states, including the District of Columbia.

Plans and manages detailed project timelines; provides reporting on statios to key stakeholders.
Proactiveley raises data science concerns, risks and issues that may delay / impact the submission and presents risk mitigation strategy.
Applies knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries.
Applies Knowledge of relational databases, scripting languages, and statistical computing packages to facilitate generation and strorage of quality data.



Required Qualifications

Master's degree or higher in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields.
3 years of professional experience with data.
Proficient with one or more programming languages (Java, C , Python, R, etc.)
Demonstrated experience applying data science methods to real-world data problems.
Experience querying one or more SQL databases (MS SQL, Postgres, Oracle, etc.)
Experience utilizing one or more data visualization tool (Tableau, Sisense, etc.



Preferred Qualifications

Advanced analytical knowledge of data.
Data conditioning experience.
Experience tilizing SQL databaase queries.
Programming / Advanced Computing experience.
Experience eveloping and Deploying models and software, (CI/CD pipelines).
Experience executing predictive analytics.
Competency in instruction and presentation of material.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About DENSO<br><br></u></strong>DENSO is a global Fortune 500 company and an advanced mobility supplier and manufacturer. We develop technology and components for nearly every make and model on the road today.<br><br>At DENSO, we believe technology can help solve some of society's greatest challenges. Our broad product portfolio includes mobility, electrification, powertrain, and electronic systems. With manufacturing at our core, we have 170,000 employees across 221 facilities in 35 countries who engineer, design and manufacture advanced technologies that directly change how the world moves.<br><br>Globally headquartered in Kariya, Japan, we spend 9.9% of global consolidated sales on research &amp; development in the fiscal year ending March 31, 2020. In North America, we're headquartered in Southfield, Michigan, and we employ 27,000+ in the United States, Canada and Mexico. In the United States alone, we employ 17,700 across 41 sites in 14 states, including the District of Columbia.<br><ul> <li>Plans and manages detailed project timelines; provides reporting on statios to key stakeholders.</li> <li>Proactiveley raises data science concerns, risks and issues that may delay / impact the submission and presents risk mitigation strategy.</li> <li>Applies knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries.</li> <li>Applies Knowledge of relational databases, scripting languages, and statistical computing packages to facilitate generation and strorage of quality data.</li> <br><br></ul><strong><u>Required Qualifications<br></u></strong><ul> <li>Master's degree or higher in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields.</li> <li>3 years of professional experience with data.</li> <li>Proficient with one or more programming languages (Java, C , Python, R, etc.)</li> <li>Demonstrated experience applying data science methods to real-world data problems.</li> <li>Experience querying one or more SQL databases (MS SQL, Postgres, Oracle, etc.)</li> <li>Experience utilizing one or more data visualization tool (Tableau, Sisense, etc.</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Advanced analytical knowledge of data. </li> <li>Data conditioning experience. </li> <li>Experience tilizing SQL databaase queries. </li> <li>Programming / Advanced Computing experience.</li> <li>Experience eveloping and Deploying models and software, (CI/CD pipelines). </li> <li>Experience executing predictive analytics. </li> <li>Competency in instruction and presentation of material.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Electrical/Electronic Manufacturing, Automotive, Mechanical or Industrial Engineering"
Data Specialist,"Houston, Texas, United States",Murphy Oil Corporation,2021-02-18,https://www.linkedin.com/jobs/view/data-specialist-at-murphy-oil-corporation-2429682961?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=rxnXMrFGkRq99a62AuQLwA%3D%3D&position=24&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"RxRevu is hiring a Data Scientist who has demonstrated experience in developing data solutions. This person will help drive new data products from both an analytics and engineering perspective. This person will interface across teams to ensure solutions align for both data producers and consumers

Responsibilities Include The Following

Collaborate on roadmaps, best practices, and architecture to drive RxRevu’s data science vision.
Interpret and analyze data problems while guaranteeing data quality and integrity.
Make strategic decisions given our data quality and time constraints.
Create data solutions from prototype to production.
Work in both data engineering and analytics.
Quickly grasp our complex domain.
Communicate cross functionally.
Help the Data Science Lead promote a culture of openness and collaboration.


Qualifications

The successful candidate will have the following qualifications:

Degree(s) in Computer Science, Math, Physics, Economics, Operations Research, Statistics or related discipline
5+ years of experience in data science and data technologies
Experience with data warehousing, data modeling, ETL/ELT, and machine learning
Experience with DAG workflow management tools (ex. Airflow, DBT)
Strong SQL and relational database experience (we use Snowflake)
Expertise in Python for data pipelines
Experience with AWS services including Lambda, ECS, SQS, Cloudwatch


Desirable

Experience with infrastructure as code (we use Terraform)
Experience with Agile methodologies

At RxRevu, we recognize that people come with a wealth of experience and talent beyond just the requirements of a job. If your experience is close to what you see listed here, please still consider applying as we are often recruiting for many positions and can work together to identify the correct role. Diversity of experience and skills, combined with our passion for healthcare, is what continues to drive us to innovate. We encourage people from all backgrounds to apply to our positions.

This is a full-time position based in Denver, Colorado but remote options are available. The successful candidate must have authorization to work in the United States. At this time, RxRevu does not offer sponsorship. All candidate information will be held in confidence, and in accordance with EEOC guidelines.

Benefits

RxRevu benefits include the following:

Medical, Vision, Dental, HSA and Flexible Spending Accounts
401k
Stock options
Employer paid STD, LTD and Life Insurance Plans
Paid Maternity and Paternity Leaves
Unlimited Vacation Policy
Remote Options
Company-paid Parking, if applicable
Professional Development


About RxRevu

RxRevu believes in improving the value of healthcare through better prescribing decisions. Our integrated Real-Time Prescription Benefit solutions allow providers to choose the most effective medication at the lowest cost, removing friction for patients and providers.

The solution suite promotes cost transparency, improves patient safety and satisfaction, and promotes data-driven medication savings opportunities.

Our mission is to help doctors help patients receive better medications at a better price, right when they need it. RxRevu’s technology platform (SwiftRx®) fully integrates with electronic health records and uses real-time, patient-specific data to deliver patient-specific drug costs and lower-cost alternatives at the point of care.

RxRevu Benefits Include The Following


Medical, Vision, Dental, HSA and Flexible Spending Accounts
401k
Stock options
Employer paid STD, LTD and Life Insurance Plans
Paid Maternity and Paternity Leaves
Unlimited Vacation Policy
Remote Options
Company-paid Parking, if applicable
Professional Development
Fitness Reimbursement Policy
Home Office Reimbursement
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">RxRevu is hiring a Data Scientist who has demonstrated experience in developing data solutions. This person will help drive new data products from both an analytics and engineering perspective. This person will interface across teams to ensure solutions align for both data producers and consumers<br><br><strong><u>Responsibilities Include The Following<br></u></strong><ul><li>Collaborate on roadmaps, best practices, and architecture to drive RxRevu’s data science vision.</li><li>Interpret and analyze data problems while guaranteeing data quality and integrity.</li><li>Make strategic decisions given our data quality and time constraints.</li><li>Create data solutions from prototype to production.</li><li>Work in both data engineering and analytics.</li><li>Quickly grasp our complex domain.</li><li>Communicate cross functionally.</li><li>Help the Data Science Lead promote a culture of openness and collaboration.<br><br></li></ul><strong><u>Qualifications<br><br></u></strong>The successful candidate will have the following qualifications:<br><ul><li>Degree(s) in Computer Science, Math, Physics, Economics, Operations Research, Statistics or related discipline</li><li> 5+ years of experience in data science and data technologies</li><li>Experience with data warehousing, data modeling, ETL/ELT, and machine learning</li><li>Experience with DAG workflow management tools (ex. Airflow, DBT)</li><li>Strong SQL and relational database experience (we use Snowflake)</li><li>Expertise in Python for data pipelines</li><li>Experience with AWS services including Lambda, ECS, SQS, Cloudwatch<br><br></li></ul><strong><u>Desirable<br></u></strong><ul><li>Experience with infrastructure as code (we use Terraform)</li><li>Experience with Agile methodologies<br></li></ul>At RxRevu, we recognize that people come with a wealth of experience and talent beyond just the requirements of a job. If your experience is close to what you see listed here, please still consider applying as we are often recruiting for many positions and can work together to identify the correct role. Diversity of experience and skills, combined with our passion for healthcare, is what continues to drive us to innovate. We encourage people from all backgrounds to apply to our positions.<br><br>This is a full-time position based in Denver, Colorado but remote options are available. The successful candidate must have authorization to work in the United States. At this time, RxRevu does not offer sponsorship. All candidate information will be held in confidence, and in accordance with EEOC guidelines.<br><br><strong><u>Benefits<br><br></u></strong>RxRevu benefits include the following:<br><ul><li>Medical, Vision, Dental, HSA and Flexible Spending Accounts</li><li>401k</li><li>Stock options</li><li>Employer paid STD, LTD and Life Insurance Plans</li><li>Paid Maternity and Paternity Leaves</li><li>Unlimited Vacation Policy</li><li>Remote Options</li><li>Company-paid Parking, if applicable</li><li>Professional Development<br><br></li></ul><strong><u>About RxRevu<br><br></u></strong>RxRevu believes in improving the value of healthcare through better prescribing decisions. Our integrated Real-Time Prescription Benefit solutions allow providers to choose the most effective medication at the lowest cost, removing friction for patients and providers.<br><br>The solution suite promotes cost transparency, improves patient safety and satisfaction, and promotes data-driven medication savings opportunities.<br><br>Our mission is to help doctors help patients receive better medications at a better price, right when they need it. RxRevu’s technology platform (SwiftRx®) fully integrates with electronic health records and uses real-time, patient-specific data to deliver patient-specific drug costs and lower-cost alternatives at the point of care.<br><br><strong><u>RxRevu Benefits Include The Following<br><br></u></strong><li>Medical, Vision, Dental, HSA and Flexible Spending Accounts</li><li>401k</li><li>Stock options</li><li>Employer paid STD, LTD and Life Insurance Plans</li><li>Paid Maternity and Paternity Leaves</li><li>Unlimited Vacation Policy</li><li>Remote Options</li><li>Company-paid Parking, if applicable</li><li>Professional Development</li><li>Fitness Reimbursement Policy</li><li>Home Office Reimbursement</li></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Analytics Engineer,"Chicago, Illinois, United States",Clearcover,2021-01-29,https://www.linkedin.com/jobs/view/analytics-engineer-at-clearcover-2400249689?refId=d5565aa8-53fd-4738-92d2-ca28d95b6b22&trackingId=2kyl1FbDfqY4hR7ExcTqWQ%3D%3D&position=25&pageNum=1&trk=public_jobs_job-result-card_result-card_full-click,"At Murphy Oil Corporation, we believe the rich experiences and backgrounds of our employees strengthen our Company, create a productive workforce, and drive our success. We encourage you to apply for the positions for which you meet the qualifications.

Job Summary

Murphy IT is looking for a Data Specialist to support various IT and business teams build/secure/maintain inhouse and business databases. Work with the customer to understand data need and provide end to end solution which includes learning 3rd party data model, de-normalize data, join various data sets, build pipeline, model data and database to gain faster insights. The ideal candidate would be a problem solver who can analyze data, identify problems, develop, and improve workflows, automate processes, and lead various data management efforts. The right candidate would be passionate about all aspect of data administration and data solutions.

Responsibilities
Design and implement effective database solutions and models to store and retrieve company data.
Examine and identify database structural necessities by evaluating client operations, applications, and programming.
Design, implement and maintain database security.
Assess database implementation procedures to ensure they comply with internal and external regulations.
Install and organize information systems to guarantee company functionality.
Vendor management and usage reporting.
Engage with customers to provide End to end data solution that includes but not limited to
Understanding Data Challenge (New Data acquisition/vendor data Interpretation /Business need)
Creating Data Pipeline and reverse engineer pipeline
Develop and implement procedures for effective data management.
Create rules and procedures for data sharing
Assist in effective Data Analysis
Oversee the migration of data from legacy systems to new solutions
Monitor the system performance by performing regular tests, troubleshooting, and integrating new features.
Recommend solutions to improve new and existing database systems.
Educate staff members through training and individual support.
Offer support by responding to system problems in a timely manner.



Qualifications/Requirements

Bachelor’s Degree in Computer Science, Information science or similar fields
Minimum 6 years’ experience as Data Administrator or Data Architect
Proficiency in SQL writing, creating tables, procedures, views, functions using SQL Server, HANA or similar technologies
Strong understanding of Data modeling principles.
RDMSs (relational database management systems) or foundational database skills
Information management and data processing on multiple platforms
Data mining and modeling tools, especially Enterprise Architect, HANA studio and Visio
Experience in Database administration (SQL server, HANA, Hadoop).
Database management system software, especially Microsoft SQL Server
Backup/archival software
Programming languages, especially Python and Java
Operating systems, including LINUX, MS Windows



Desired/Preferred Qualifications

Master’s Degree in Computer Science, Information science or similar fields and minimum 4 years’ experience as a Data Administrator or Data Architect
Knowledge of Tibco tools like Spotfire, Database Virtualization is a plus.
Knowledge of Microsoft tools like power apps/power BI/power automate/SharePoint is a plus



PURPOSE

We believe in providing energy that empowers people.

MISSION

We challenge the norm, tap into our strong legacy and use our foresight and financial discipline to deliver inspired energy solutions.

VISION

We see a future where we are an industry leader who is positively impacting lives for the next 100 years and beyond.

VALUES & BEHAVIORS

Do Right Always

Respect people, safety, environment and the law
Follow through on commitments
Make it better


Think Beyond Possible

Offer solution
Step up and lead
Don’t settle for “good enough”
Embrace new opportunities


Stay With It

Show resilience
Lean into challenges
Support each other
Consider the implications


_________________________________________________________________________________________________

Murphy Oil Corporation participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program. Please read the E-Verify Notice-English / E-Verify Notice-Spanish and Right to Work Notice before proceeding with your job application.

For additional information, you may also visit the USCIS website.

Murphy Oil Corporation is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, genetic information, age, national origin, sexual orientation, disability, protected veteran status or any other category protected by federal, state or local law.
EEO is the Law Poster
EEO is the Law Supplement
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Murphy Oil Corporation, we believe the rich experiences and backgrounds of our employees strengthen our Company, create a productive workforce, and drive our success. We encourage you to apply for the positions for which you meet the qualifications.<br><br><strong><u>Job Summary<br><br></u></strong>Murphy IT is looking for a Data Specialist to support various IT and business teams build/secure/maintain inhouse and business databases. Work with the customer to understand data need and provide end to end solution which includes learning 3rd party data model, de-normalize data, join various data sets, build pipeline, model data and database to gain faster insights. The ideal candidate would be a problem solver who can analyze data, identify problems, develop, and improve workflows, automate processes, and lead various data management efforts. The right candidate would be passionate about all aspect of data administration and data solutions.<br><ul> <li><strong>Responsibilities</strong></li> <li>Design and implement effective database solutions and models to store and retrieve company data. </li> <li>Examine and identify database structural necessities by evaluating client operations, applications, and programming. </li> <li>Design, implement and maintain database security. </li> <li>Assess database implementation procedures to ensure they comply with internal and external regulations. </li> <li>Install and organize information systems to guarantee company functionality. </li> <li>Vendor management and usage reporting. </li> <li>Engage with customers to provide End to end data solution that includes but not limited to </li> <li>Understanding Data Challenge (New Data acquisition/vendor data Interpretation /Business need) </li> <li>Creating Data Pipeline and reverse engineer pipeline </li> <li>Develop and implement procedures for effective data management. </li> <li>Create rules and procedures for data sharing </li> <li>Assist in effective Data Analysis </li> <li>Oversee the migration of data from legacy systems to new solutions </li> <li>Monitor the system performance by performing regular tests, troubleshooting, and integrating new features. </li> <li>Recommend solutions to improve new and existing database systems. </li> <li>Educate staff members through training and individual support. </li> <li>Offer support by responding to system problems in a timely manner.</li> <br><br></ul><strong><u>Qualifications/Requirements<br></u></strong><ul> <li>Bachelor’s Degree in Computer Science, Information science or similar fields </li> <li>Minimum 6 years’ experience as Data Administrator or Data Architect</li> <li>Proficiency in SQL writing, creating tables, procedures, views, functions using SQL Server, HANA or similar technologies</li> <li>Strong understanding of Data modeling principles.</li> <li>RDMSs (relational database management systems) or foundational database skills</li> <li>Information management and data processing on multiple platforms</li> <li>Data mining and modeling tools, especially Enterprise Architect, HANA studio and Visio</li> <li>Experience in Database administration (SQL server, HANA, Hadoop). </li> <li>Database management system software, especially Microsoft SQL Server </li> <li>Backup/archival software</li> <li>Programming languages, especially Python and Java</li> <li>Operating systems, including LINUX, MS Windows</li> <br><br></ul><strong><u>Desired/Preferred Qualifications<br></u></strong><ul> <li>Master’s Degree in Computer Science, Information science or similar fields and minimum 4 years’ experience as a Data Administrator or Data Architect</li> <li>Knowledge of Tibco tools like Spotfire, Database Virtualization is a plus.</li> <li>Knowledge of Microsoft tools like power apps/power BI/power automate/SharePoint is a plus</li> <br><br></ul><strong>PURPOSE <br><br></strong>We believe in providing energy that empowers people.<br><br><strong>MISSION <br><br></strong>We challenge the norm, tap into our strong legacy and use our foresight and financial discipline to deliver inspired energy solutions.<br><br><strong>VISION <br><br></strong>We see a future where we are an industry leader who is positively impacting lives for the next 100 years and beyond.<br><br><strong>VALUES &amp; BEHAVIORS <br><br></strong>Do Right Always<br><ul> <li>Respect people, safety, environment and the law</li> <li>Follow through on commitments</li> <li>Make it better</li> <br></ul>Think Beyond Possible<br><ul> <li>Offer solution</li> <li>Step up and lead</li> <li>Don’t settle for “good enough”</li> <li>Embrace new opportunities</li> <br></ul>Stay With It<br><ul> <li>Show resilience</li> <li>Lean into challenges</li> <li>Support each other</li> <li>Consider the implications</li> <br></ul>_________________________________________________________________________________________________<br><br>Murphy Oil Corporation participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program. Please read the E-Verify Notice-English / E-Verify Notice-Spanish and Right to Work Notice before proceeding with your job application.<br><br>For additional information, you may also visit the USCIS website.<br><br>Murphy Oil Corporation is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, genetic information, age, national origin, sexual orientation, disability, protected veteran status or any other category protected by federal, state or local law.<br>EEO is the Law Poster<br>EEO is the Law Supplement</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Oil & Energy, Financial Services"
Data Scientist,"Benton Harbor, Michigan, United States",Whirlpool Corporation,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-whirlpool-corporation-2428116189?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=Ap%2BU2M0g38FAbGVONFKf7g%3D%3D&position=1&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Who's Clearcover?

Clearcover is the smarter car insurance company. We use powerful technology to offer everyday drivers better coverage for less money. We're proud to be one of the fastest-growing startups in Chicago, and we're currently looking to add a few more extraordinary people to our team.

Clearcover is seeking an Analytics Engineer to help supercharge our analytic efforts supporting our Claims management function at Clearcover! As a member of our Business Intelligence team, you'll…

What will you do?


Own and maintain all analytic data models sourced from our claims administration systems in our data warehouse
Design and optimize our cloud-based data warehouse architecture
Write production-quality ELT/ETL data transformation code with an eye towards performance, maintainability, and scalability
Design, build, and maintain data pipelines and dashboards to ensure reliable business reporting
Advocate for improvements to data quality and performance
Collaborate with data engineers on infrastructure projects for sourcing data
Responsible for delivering new, re-usable business intelligence solutions and demonstrating value proposition to business stakeholders
Work with the claims team to develop novel approaches to finding, collecting, and using data


What do you need?


Strong written and verbal communication skills including the ability to collaborate across teams
Significant experience developing and delivering data solutions as a member of a business intelligence or analytics team
Have a passion for solving problems using data and analytics
Must have a solid understanding of data warehouse architecture and best practices
Deep understanding of SQL, writing complex queries and/or stored procedures in current role
Have used Python, Ruby, or R when SQL failed you or was needed for a complex report or analysis
Experience with Snowflake or Redshift serving as the Data Warehouse production platform
Experience with Tableau or other data visualization tools (Looker, Periscope, PowerBI)


What's nice to have?


Experience with DBT (Data Build Tool)
Experience with version control tools (Github, Bitbucket)
Experience working with semi-structured data types such as JSON and XML
Experience in Claims and/or Property and Casualty insurance industry


What's in it for you?


Unlimited vacation, we hire adults
Equity for all employees, so you own a piece of the pie too
Dental and Vision, we've got you covered 100%
Medical, we cover the vast majority of your premiums to make the cost of you and your family's coverage affordable. Plus, we contribute to your HSA and HRA (cha-ching)
We invest in your future by contributing 3% of your salary to a 401(K), even if you don't
Come to work pre-taxed through our FSA commuter benefits
and yes, we have unlimited LaCroix, beer, snacks and the occasional ice cream social


Clearcover is an Equal Opportunity Employer (EOE) that welcomes and encourages all applicants to apply regardless of age, race, color, religion, sex, sexual orientation, gender identify and/or expression, national origin, disability, veteran status, marital or parental status, ancestry, citizenship status, pregnancy or other reasons prohibited by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Who's Clearcover?<br><br></strong>Clearcover is the smarter car insurance company. We use powerful technology to offer everyday drivers better coverage for less money. We're proud to be one of the fastest-growing startups in Chicago, and we're currently looking to add a few more extraordinary people to our team.<br><br>Clearcover is seeking an Analytics Engineer to help supercharge our analytic efforts supporting our Claims management function at Clearcover! As a member of our Business Intelligence team, you'll…<br><br><strong>What will you do?<br><br></strong><ul> <li>Own and maintain all analytic data models sourced from our claims administration systems in our data warehouse</li> <li>Design and optimize our cloud-based data warehouse architecture</li> <li>Write production-quality ELT/ETL data transformation code with an eye towards performance, maintainability, and scalability</li> <li>Design, build, and maintain data pipelines and dashboards to ensure reliable business reporting</li> <li>Advocate for improvements to data quality and performance</li> <li>Collaborate with data engineers on infrastructure projects for sourcing data</li> <li>Responsible for delivering new, re-usable business intelligence solutions and demonstrating value proposition to business stakeholders</li> <li>Work with the claims team to develop novel approaches to finding, collecting, and using data</li> <br></ul><strong>What do you need? <br><br></strong><ul> <li>Strong written and verbal communication skills including the ability to collaborate across teams</li> <li>Significant experience developing and delivering data solutions as a member of a business intelligence or analytics team </li> <li>Have a passion for solving problems using data and analytics</li> <li>Must have a solid understanding of data warehouse architecture and best practices</li> <li>Deep understanding of SQL, writing complex queries and/or stored procedures in current role</li> <li>Have used Python, Ruby, or R when SQL failed you or was needed for a complex report or analysis</li> <li>Experience with Snowflake or Redshift serving as the Data Warehouse production platform</li> <li>Experience with Tableau or other data visualization tools (Looker, Periscope, PowerBI)</li> <br></ul><strong>What's nice to have? <br><br></strong><ul> <li>Experience with DBT (Data Build Tool)</li> <li>Experience with version control tools (Github, Bitbucket)</li> <li>Experience working with semi-structured data types such as JSON and XML</li> <li>Experience in Claims and/or Property and Casualty insurance industry</li> <br></ul><strong>What's in it for you?<br><br></strong><ul> <li>Unlimited vacation, we hire adults</li> <li>Equity for all employees, so you own a piece of the pie too</li> <li>Dental and Vision, we've got you covered 100%</li> <li>Medical, we cover the vast majority of your premiums to make the cost of you and your family's coverage affordable. Plus, we contribute to your HSA and HRA (cha-ching)</li> <li>We invest in your future by contributing 3% of your salary to a 401(K), even if you don't</li> <li>Come to work pre-taxed through our FSA commuter benefits</li> <li>and yes, we have unlimited LaCroix, beer, snacks and the occasional ice cream social</li> <br></ul>Clearcover is an Equal Opportunity Employer (EOE) that welcomes and encourages all applicants to apply regardless of age, race, color, religion, sex, sexual orientation, gender identify and/or expression, national origin, disability, veteran status, marital or parental status, ancestry, citizenship status, pregnancy or other reasons prohibited by law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Insurance, Financial Services"
Analytics Engineer,"Los Angeles, California, United States",Albert,2021-02-19,https://www.linkedin.com/jobs/view/analytics-engineer-at-albert-2430707393?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=LF0P7twaAyPdTFLEUSauzw%3D%3D&position=2&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Requisition ID: 41643

Whirlpool Corporation is consistently recognized by Fortune Magazine as one of the World’s Most Admired Companies. Our values are the driving force behind everything we do. Respect, integrity, diversity and inclusion, teamwork and the spirit of winning propel our teams to excellence. Get to know us and see what it's like to be part of the world's leading major home appliance company.

Function Overview

As a member of Whirlpool’s Analytics Center of Excellence (ACoE) team, you will help internal clients leverage large amounts of disparate data to solve their toughest problems and arrive at data-driven answers with greater speed and accuracy. You will work with our clients to develop customized algorithms that are used to answer their most pressing business questions—providing insights that increase their Return on Investment (ROI). Clients include Internet of Things (IoT), Marketing, Sales, Merchandising, Category Management, Finance, Manufacturing, Service, and others. This is a remote postion with the ability to commute to the Riverview Michigan Office.

Job Responsibilities

Use advanced analytics techniques to solve complex problems, discover insights and uncover patterns
Lead and build predictive models to support business initiatives
Coordinate with data engineers to run models on appropriate environments, providing expectations and direction needed to execute data scientific work
Work closely with business to provide thought leadership, appropriate methodologies, direction, findings and manage expectations
Monitor model performances that are in place and recommend changes
Explain and visualize results to stakeholders
Analyze new data sources for availability and quality, and integrate with internal sources to support research and analysis
Work in multicultural environment and coordinate efforts with global teams



Minimum Requirements

Master’s degree in Statistics, Mathematics, Computer Science, Biostatistics or other STEM (Science, Technology, Engineering, Math) field of study
3+ years of experience in data a science driven role, utilizing data mining and predictive modeling techniques; regression, classification, clustering, or other Machine Learning (ML) techniques
3+ years’ experience with predictive modeling using Python
1+ years’ experience using SQL
1+ years’ experience in execution of all model development stages including; data creation, data cleaning, variable creation, model building and model diagnostics



Preferred Requirements

Experience and knowledge about big data platforms and data handling utilizing Spark and parallel processing
Experience working with disparate data sources and unstructured data, including text and image data
Experience with AWS
Experience with various BI tools, specifically Tableau


RSRWH

About Us

Whirlpool Corporation (NYSE: WHR) is the world’s leading kitchen and laundry appliance company, with approximately $20 billion in annual sales, 77,000 employees and 59 manufacturing and technology research centers in 2019. The company markets Whirlpool, KitchenAid, Maytag, Consul, Brastemp, Amana, Bauknecht, JennAir, Indesit and other major brand names in nearly every country throughout the world. Additional information about the company can be found at whirlpoolcorp.com

At Whirlpool Corporation, we believe that all people matter. Celebrating diversity and including thousands of perspectives empower us to create products that blend into every concept of home. Whirlpool Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Requisition ID: 41643 <br><br></strong>Whirlpool Corporation is consistently recognized by Fortune Magazine as one of the World’s Most Admired Companies. Our values are the driving force behind everything we do. Respect, integrity, diversity and inclusion, teamwork and the spirit of winning propel our teams to excellence. Get to know us and see what it's like to be part of the world's leading major home appliance company.<br><br><strong><u>Function Overview<br><br></u></strong>As a member of Whirlpool’s Analytics Center of Excellence (ACoE) team, you will help internal clients leverage large amounts of disparate data to solve their toughest problems and arrive at data-driven answers with greater speed and accuracy. You will work with our clients to develop customized algorithms that are used to answer their most pressing business questions—providing insights that increase their Return on Investment (ROI). Clients include Internet of Things (IoT), Marketing, Sales, Merchandising, Category Management, Finance, Manufacturing, Service, and others. This is a remote postion with the ability to commute to the Riverview Michigan Office.<br><br><strong><u>Job Responsibilities<br></u></strong><ul> <li> Use advanced analytics techniques to solve complex problems, discover insights and uncover patterns </li> <li> Lead and build predictive models to support business initiatives </li> <li> Coordinate with data engineers to run models on appropriate environments, providing expectations and direction needed to execute data scientific work </li> <li> Work closely with business to provide thought leadership, appropriate methodologies, direction, findings and manage expectations </li> <li> Monitor model performances that are in place and recommend changes </li> <li> Explain and visualize results to stakeholders </li> <li> Analyze new data sources for availability and quality, and integrate with internal sources to support research and analysis </li> <li> Work in multicultural environment and coordinate efforts with global teams </li> <br><br></ul><strong><u>Minimum Requirements<br></u></strong><ul> <li> Master’s degree in Statistics, Mathematics, Computer Science, Biostatistics or other STEM (Science, Technology, Engineering, Math) field of study </li> <li> 3+ years of experience in data a science driven role, utilizing data mining and predictive modeling techniques; regression, classification, clustering, or other Machine Learning (ML) techniques </li> <li> 3+ years’ experience with predictive modeling using Python </li> <li> 1+ years’ experience using SQL </li> <li> 1+ years’ experience in execution of all model development stages including; data creation, data cleaning, variable creation, model building and model diagnostics </li> <br><br></ul><strong><u>Preferred Requirements<br></u></strong><ul> <li> Experience and knowledge about big data platforms and data handling utilizing Spark and parallel processing </li> <li> Experience working with disparate data sources and unstructured data, including text and image data </li> <li> Experience with AWS </li> <li> Experience with various BI tools, specifically Tableau </li> <br></ul>RSRWH<br><br><strong><u>About Us<br><br></u></strong>Whirlpool Corporation (NYSE: WHR) is the world’s leading kitchen and laundry appliance company, with approximately $20 billion in annual sales, 77,000 employees and 59 manufacturing and technology research centers in 2019. The company markets Whirlpool, KitchenAid, Maytag, Consul, Brastemp, Amana, Bauknecht, JennAir, Indesit and other major brand names in nearly every country throughout the world. Additional information about the company can be found at whirlpoolcorp.com<br><br>At Whirlpool Corporation, we believe that all people matter. Celebrating diversity and including thousands of perspectives empower us to create products that blend into every concept of home. Whirlpool Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Consumer Goods, Retail"
Data Engineer,"Bellevue, Washington, United States",Discovery Inc,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-discovery-inc-2401691905?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=kqtfA6sEkm6ogp0dGb8PRQ%3D%3D&position=3&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Who we are

Albert is a new type of financial service that uses powerful technology to automate your finances, with a team of human experts to guide you. Albert saves and invests automatically for you, helps you avoid overdrafts, finds savings you’re missing, identifies bills you’re overpaying, and much more. Text Albert a financial question, and our geniuses won’t just offer guidance — they’ll help you take action.

We’re an LA-based startup with a proven business model, backed by top-tier institutional investors and with nearly 5 million users who have trusted Albert to help them achieve their financial goals. We're on a mission to democratize money management through our simple, beautifully designed product, and we're looking for thoughtful, talented people to join us on our journey.

About The Role

Your overall objective will be to turn granular data into actionable knowledge for stakeholders across all Albert domains. You’ll do this with an eye toward sustainable engineering practices and you’ll make the insights you produce as easily consumable as possible for our business partners.

Things you're good at

Understanding a business holistically
Translating granular — often event-level — data into knowledge the business needs to succeed
Responsibilities

Writing ETLs
Creating dashboards
Conducting bespoke analyses
Evaluating tests
Assisting your coworkers with analytical challenges related to hiring additional team members
Qualifications

A demonstrable track record of turning big data into valuable information within the analytics sphere
Comfort with ambiguity and an ability to prioritize competing requests
Expertise in SQL
An ability to read and write Python (fluency not required)
Advanced experience with Tableau, Looker, Domo, ChartIO, or a similar BI tool
Benefits

Competitive salary and meaningful equity
Health, vision, and dental insurance
401(k) match
Free lunch
Job Applicants California Privacy Notice

This California Privacy Notice applies to personal information of California job applicants that Albert collects and processes as it relates to the submission of a job application.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Who we are<br><br>Albert is a new type of financial service that uses powerful technology to automate your finances, with a team of human experts to guide you. Albert saves and invests automatically for you, helps you avoid overdrafts, finds savings you’re missing, identifies bills you’re overpaying, and much more. Text Albert a financial question, and our geniuses won’t just offer guidance — they’ll help you take action.<br><br>We’re an LA-based startup with a proven business model, backed by top-tier institutional investors and with nearly 5 million users who have trusted Albert to help them achieve their financial goals. We're on a mission to democratize money management through our simple, beautifully designed product, and we're looking for thoughtful, talented people to join us on our journey.<br><br><strong> About The Role <br><br></strong>Your overall objective will be to turn granular data into actionable knowledge for stakeholders across all Albert domains. You’ll do this with an eye toward sustainable engineering practices and you’ll make the insights you produce as easily consumable as possible for our business partners.<br><br>Things you're good at<br><ul><li>Understanding a business holistically</li><li>Translating granular — often event-level — data into knowledge the business needs to succeed</li></ul>Responsibilities<br><ul><li>Writing ETLs</li><li>Creating dashboards </li><li>Conducting bespoke analyses </li><li>Evaluating tests</li><li>Assisting your coworkers with analytical challenges related to hiring additional team members </li></ul>Qualifications<br><ul><li>A demonstrable track record of turning big data into valuable information within the analytics sphere</li><li>Comfort with ambiguity and an ability to prioritize competing requests</li><li>Expertise in SQL</li><li>An ability to read and write Python (fluency not required)</li><li>Advanced experience with Tableau, Looker, Domo, ChartIO, or a similar BI tool</li></ul>Benefits<br><ul><li>Competitive salary and meaningful equity </li><li>Health, vision, and dental insurance</li><li>401(k) match</li><li>Free lunch</li></ul>Job Applicants California Privacy Notice<br><br>This California Privacy Notice applies to personal information of California job applicants that Albert collects and processes as it relates to the submission of a job application.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Data Engineer,"Redwood City, California, United States",Zuora,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-zuora-2412176348?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=TApzocoK%2FFgh%2BTI2i%2FTitg%3D%3D&position=4&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Discovery hires the very best and brightest talent who are enthusiastic and passionate to fulfill the company’s mission of empowering people to explore their world and satisfy their curiosity.

In exchange for their talent and drive, employees are provided with an engaging, diverse workplace and the resources they need to learn, thrive and grow in their careers.

Position Summary

About Us:

Discovery's Digital group is a well-funded start-up within Discovery, Inc. We are fast, nimble, and have fun developing new, innovative, and immersive digital products and content for iconic brands. We are working at the crossroads of technology, entertainment, and every day utility. As content creators across the digital ecosystem, we continuously leverage our technology to create immersive viewing and interactive experiences. We tell engaging stories to millions of viewers across the Internet every day and bring new interactive experiences to life to not only entertain but improve the lives of our customers. Most recently, our group is behind the launch of discovery+, Discovery’s global streaming service, serving as the definitive destination for real life entertainment with the largest ever content offering at launch, debuting in the U.S. on January 4, 2021.

Job Summary

Are you excited by the challenges of building up big data infrastructure and results-oriented and providing data solutions to resolve complex data-related problems? We are looking for a talented Data Engineer to join the Data and Analytics team. You will design and own the DDSA data infrastructure and build up robust pipelines. You will have an opportunity to improve efficiency and data quality. You will interface with other technology teams to extract, transform, and load data from a wide variety of data sources using big data technology.

A successful candidate will have deep knowledge of business intelligence solutions, big data technology, and have the ability to work with various customers to drive and implement data solutions. They will have a passion for data, be a self-starter, comfortable with ambiguity, strong attention to detail. In this role, you will be able to apply your technical skills in developing Data recommendation infrastructure, large databases, recommendation tools, and systems to impact the business.

Responsibilities

Contribute to the architecture, design, and implementation of next-generation Data solutions – including streaming data applications

Manage AWS resources including Glue, EMR, Kinesis, Lambda etc.

Collaborate with data scientists, BIEs, and BAs to deliver high-quality data architecture and pipelines.

Interface with other technology teams to extract, transform and load data from a wide variety of data sources

Continually improve ongoing processes and pipelines, automating or simplifying self-service support for customers




Requirements

Bachelor's Degree or higher in Computer Sciences or similar

Minimum 2 years of Software Industry experience

2+ years of development experience with AWS services Must have EMR or Glue, Data Pipeline or Airflow, S3, Jenkins or other CI/CD

2+ years of extensive working knowledge in spark (pyspark or scala).

1+ years of development experience with SQL queries.

1+ years of development experience with realtime data streams Kafka/Kinesis

Proficiency working with structured, semi-structured, and unstructured data sets and real-time streaming data feeds

Fluency in SQL, Python, or a similar modeling language.

Experience with data warehousing databases Redshift, Oracle, and techniques is preferred

Expert level usage with Jenkins, GitHub is preferred

Experience in the media industry is a plus

Must have the legal right to work in the United States




Discovery Communications, Inc. is an equal opportunity employer. Discovery is committed to being an employer of choice, not just a good place to work, but a great and inclusive place to work. To that end, we strive to recruit and maintain a workforce that meaningfully represents the diverse and culturally rich communities that we serve. Qualified applicants will receive consideration for employment without regard to their race, color, religion, national origin, sex, sexual orientation, gender identity, protected veteran status or disabled status or, genetic information.

We will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including but not limited to all local Fair Chance Ordinances.

EEO is the Law
Pay Transparency Policy Statement
California Job Applicant Privacy Policy
If you are an individual with a disability and need an accommodation during the application process, please send an email request to HR@discovery.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Discovery hires the very best and brightest talent who are enthusiastic and passionate to fulfill the company’s mission of empowering people to explore their world and satisfy their curiosity.<br><br>In exchange for their talent and drive, employees are provided with an engaging, diverse workplace and the resources they need to learn, thrive and grow in their careers.<br><br><strong><u>Position Summary<br><br></u></strong><strong>About Us: <br><br></strong>Discovery's Digital group is a well-funded start-up within Discovery, Inc. We are fast, nimble, and have fun developing new, innovative, and immersive digital products and content for iconic brands. We are working at the crossroads of technology, entertainment, and every day utility. As content creators across the digital ecosystem, we continuously leverage our technology to create immersive viewing and interactive experiences. We tell engaging stories to millions of viewers across the Internet every day and bring new interactive experiences to life to not only entertain but improve the lives of our customers. Most recently, our group is behind the launch of discovery+, Discovery’s global streaming service, serving as the definitive destination for real life entertainment with the largest ever content offering at launch, debuting in the U.S. on January 4, 2021.<br><br><strong><u>Job Summary<br><br></u></strong>Are you excited by the challenges of building up big data infrastructure and results-oriented and providing data solutions to resolve complex data-related problems? We are looking for a talented Data Engineer to join the Data and Analytics team. You will design and own the DDSA data infrastructure and build up robust pipelines. You will have an opportunity to improve efficiency and data quality. You will interface with other technology teams to extract, transform, and load data from a wide variety of data sources using big data technology.<br><br>A successful candidate will have deep knowledge of business intelligence solutions, big data technology, and have the ability to work with various customers to drive and implement data solutions. They will have a passion for data, be a self-starter, comfortable with ambiguity, strong attention to detail. In this role, you will be able to apply your technical skills in developing Data recommendation infrastructure, large databases, recommendation tools, and systems to impact the business.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Contribute to the architecture, design, and implementation of next-generation Data solutions – including streaming data applications<br></li> <li>Manage AWS resources including Glue, EMR, Kinesis, Lambda etc.<br></li> <li>Collaborate with data scientists, BIEs, and BAs to deliver high-quality data architecture and pipelines.<br></li> <li>Interface with other technology teams to extract, transform and load data from a wide variety of data sources<br></li> <li>Continually improve ongoing processes and pipelines, automating or simplifying self-service support for customers<br></li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Bachelor's Degree or higher in Computer Sciences or similar<br></li> <li>Minimum 2 years of Software Industry experience<br></li> <li>2+ years of development experience with AWS services Must have EMR or Glue, Data Pipeline or Airflow, S3, Jenkins or other CI/CD<br></li> <li>2+ years of extensive working knowledge in spark (pyspark or scala).<br></li> <li>1+ years of development experience with SQL queries.<br></li> <li>1+ years of development experience with realtime data streams Kafka/Kinesis<br></li> <li>Proficiency working with structured, semi-structured, and unstructured data sets and real-time streaming data feeds<br></li> <li>Fluency in SQL, Python, or a similar modeling language.<br></li> <li>Experience with data warehousing databases Redshift, Oracle, and techniques is preferred<br></li> <li>Expert level usage with Jenkins, GitHub is preferred<br></li> <li>Experience in the media industry is a plus<br></li> <li>Must have the legal right to work in the United States<br></li> <br><br></ul>Discovery Communications, Inc. is an equal opportunity employer. Discovery is committed to being an employer of choice, not just a good place to work, but a great and inclusive place to work. To that end, we strive to recruit and maintain a workforce that meaningfully represents the diverse and culturally rich communities that we serve. Qualified applicants will receive consideration for employment without regard to their race, color, religion, national origin, sex, sexual orientation, gender identity, protected veteran status or disabled status or, genetic information.<br><br>We will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including but not limited to all local Fair Chance Ordinances.<br><br><strong>EEO is the Law<br>Pay Transparency Policy Statement<br>California Job Applicant Privacy Policy<br></strong>If you are an individual with a disability and need an accommodation during the application process, please send an email request to HR@discovery.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Information Technology and Services"
Analytics Engineer,"Remote, Oregon, United States",HubSpot,2021-01-30,https://www.linkedin.com/jobs/view/analytics-engineer-at-hubspot-2361493324?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=0Mb0UNGY6XgYgk25tkcFcg%3D%3D&position=5&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"At Zuora, data is a key strategic pillar for operating our business. All our teams rely on accurate, timely data to measure and improve outcomes, including building better products, improving the customer experience, optimizing the sales process, and ultimately increasing the overall value we deliver to our customers.

As An Engineer On The Zuora Corporate Data Team, You'll Have The Opportunity To Design And Build Robust End-to-end Solutions To Support Data-driven Decision Making Across The Entire Company, Including

Pipelines and tools for delivering a reliable flow of metrics from all our products to help understand customer usage
Orchestration for extracting and transforming data from all our business applications and systems
A centralized data warehouse that assembles key data and insights about customers, users and products into one central location
Integrations with BI tools and other applications to provide business and technical users with secure, flexible trustworthy access to the data they need, through interfaces that meet their specific needs



Specific technical skills that you'll have a chance to learn and refine include:

Building and monitoring data pipelines using open source tools and frameworks
Designing, implementing and operating robust API services
Provisioning and maintaining complete architectures on public cloud infrastructure (AWS)
Working with a variety of data stores and technologies
Data modeling and solving complex analytic transformations using SQL



Skills

Joining the Corporate Data Team will also give you the opportunity to develop the whole range of skills you need to scale your effectiveness as an organizational leader

As an engineer, advancing your career depends on much more than your ability to solve isolated technical problems.

Working directly with end users in a variety of different roles to understand business requirements and identify appropriate technical solutions
Working cross-functionally to support an effective corporate data governance program
Writing design and implementation documentation
Running a transparent, predictable software delivery lifecycle, including planning, testing and release management
Operating high-availability, mission-critical services



Successful candidates for this position should be able to demonstrate a solid foundation as software engineers, experience building and operating complex data pipelines, excellent communication skills, and a strong desire to learn.

Specific Desired Experience And Knowledge Includes

python for data integration and application development
complex SQL for data transformation, validation, and analytics
data pipeline orchestration (we currently use Airflow)
provisioning and monitoring public cloud infrastructure (AWS)
interactive data exploration and visualization
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Zuora, data is a key strategic pillar for operating our business. All our teams rely on accurate, timely data to measure and improve outcomes, including building better products, improving the customer experience, optimizing the sales process, and ultimately increasing the overall value we deliver to our customers.<br><br><strong><u>As An Engineer On The Zuora Corporate Data Team, You'll Have The Opportunity To Design And Build Robust End-to-end Solutions To Support Data-driven Decision Making Across The Entire Company, Including<br></u></strong><ul> <li>Pipelines and tools for delivering a reliable flow of metrics from all our products to help understand customer usage</li> <li>Orchestration for extracting and transforming data from all our business applications and systems</li> <li>A centralized data warehouse that assembles key data and insights about customers, users and products into one central location</li> <li>Integrations with BI tools and other applications to provide business and technical users with secure, flexible trustworthy access to the data they need, through interfaces that meet their specific needs</li> <br><br></ul>Specific technical skills that you'll have a chance to learn and refine include:<br><ul> <li>Building and monitoring data pipelines using open source tools and frameworks</li> <li>Designing, implementing and operating robust API services</li> <li>Provisioning and maintaining complete architectures on public cloud infrastructure (AWS)</li> <li>Working with a variety of data stores and technologies</li> <li>Data modeling and solving complex analytic transformations using SQL</li> <br><br></ul><strong><u>Skills<br><br></u></strong>Joining the Corporate Data Team will also give you the opportunity to develop the whole range of skills you need to scale your effectiveness as an organizational leader<br><br>As an engineer, advancing your career depends on much more than your ability to solve isolated technical problems.<br><ul> <li>Working directly with end users in a variety of different roles to understand business requirements and identify appropriate technical solutions</li> <li>Working cross-functionally to support an effective corporate data governance program</li> <li>Writing design and implementation documentation</li> <li>Running a transparent, predictable software delivery lifecycle, including planning, testing and release management</li> <li>Operating high-availability, mission-critical services</li> <br><br></ul>Successful candidates for this position should be able to demonstrate a solid foundation as software engineers, experience building and operating complex data pipelines, excellent communication skills, and a strong desire to learn.<br><br><strong><u>Specific Desired Experience And Knowledge Includes<br></u></strong><ul> <li>python for data integration and application development</li> <li>complex SQL for data transformation, validation, and analytics</li> <li>data pipeline orchestration (we currently use Airflow)</li> <li>provisioning and monitoring public cloud infrastructure (AWS)</li> <li>interactive data exploration and visualization</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Information Technology and Services"
Big Data Engineer,"New York, New York, United States",Dataminr,2021-02-19,https://www.linkedin.com/jobs/view/big-data-engineer-at-dataminr-2430719385?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=TV%2FMup2%2BSHBQujLLEOAzgA%3D%3D&position=6&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"We are seeking an Analytics Engineer to be responsible for the data processing architecture and data modeling that will power our stock plan administration process (how we administer our employee equity, and employee stock purchase plans). This person will design and build the data infrastructure necessary to run those programs. They will also partner with cross-functional teams to use data to drive strategic and operational innovation throughout our finance, legal, and HR departments.

In This Role, You'll Get To

Own the data solutions for stock plan administration at HubSpot. This includes all data modeling and helping to scale our data collection and reporting capabilities.
Work closely with other systems teams to drive automation from your single source of truth reporting.
Establish a data governance model and develop best practices for collecting, cleaning, and maintaining our stock plan data
Partner with cross-functional teams (Finance, Legal, HR, Employee Tech, all of HubSpot) to identify opportunities for improving systems, processes, and reporting.
Help make strategic programs more data-driven, including: Equity, Employee Stock, Purchase Plan, etc



We're Looking For People Who

Have advanced, technical, hands-on experience with data model development, data visualization, data warehouse development, data preparation, and analytics tools.
Experience translating project requirements into a set of technical sub-tasks that build towards a final deliverable
Experience with sensitive data, specifically equity or payroll data
Use custom SQL for developing data pipelines and derived tables
Develop scripts to support data and analytics automation
Have experience building reporting infrastructure at scale
Possess strong analytical skills to determine data integrity and ensure the right controls are in place.
Are comfortable operating in a constantly changing global environment and have an eye for how to scale systems/processes
Are highly proficient in SQL. Proficiency in Python or R is also valuable.
Have experience using various BI tools/ systems



We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates, so please don’t hesitate to apply — we’d love to hear from you.

About HubSpot

HubSpot (NYSE: HUBS) is a leading customer relationship management (CRM) platform that provides software and support to help businesses grow better. We build marketing, sales, service, and website management products that start free and scale to meet our customers’ needs at any stage of growth. We’re also building a company culture that empowers people to do their best work through. If that sounds like something you’d like to be part of, we’d love to hear from you.

You can find out more about our company culture in the HubSpot Culture Code, which has more than 5M views, and learn about our commitment to creating a diverse and inclusive workplace, too. Thanks to the work of every employee globally, HubSpot was named the #4 Best Place to Work on Glassdoor in 2021, and has been recognized for award-winning culture by Great Place to Work, Comparably, Fortune, Entrepreneur, Inc., and more.

Headquartered in Cambridge, Massachusetts, HubSpot was founded in 2006. Today, thousands of employees work across the globe in HubSpot offices and remotely. Visit our careers website to learn more about culture and opportunities at HubSpot.

By submitting your application, you agree that HubSpot may collect your personal data for recruiting, global organization planning, and related purposes. HubSpot's Privacy Notice explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over HubSpot’s use of your personal information.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are seeking an Analytics Engineer to be responsible for the data processing architecture and data modeling that will power our stock plan administration process (how we administer our employee equity, and employee stock purchase plans). This person will design and build the data infrastructure necessary to run those programs. They will also partner with cross-functional teams to use data to drive strategic and operational innovation throughout our finance, legal, and HR departments.<br><br><strong><u>In This Role, You'll Get To<br></u></strong><ul> <li>Own the data solutions for stock plan administration at HubSpot. This includes all data modeling and helping to scale our data collection and reporting capabilities. </li> <li>Work closely with other systems teams to drive automation from your single source of truth reporting. </li> <li>Establish a data governance model and develop best practices for collecting, cleaning, and maintaining our stock plan data</li> <li>Partner with cross-functional teams (Finance, Legal, HR, Employee Tech, all of HubSpot) to identify opportunities for improving systems, processes, and reporting. </li> <li>Help make strategic programs more data-driven, including: Equity, Employee Stock, Purchase Plan, etc</li> <br><br></ul><strong><u>We're Looking For People Who<br></u></strong><ul> <li>Have advanced, technical, hands-on experience with data model development, data visualization, data warehouse development, data preparation, and analytics tools. </li> <li>Experience translating project requirements into a set of technical sub-tasks that build towards a final deliverable</li> <li>Experience with sensitive data, specifically equity or payroll data</li> <li>Use custom SQL for developing data pipelines and derived tables</li> <li>Develop scripts to support data and analytics automation</li> <li>Have experience building reporting infrastructure at scale</li> <li>Possess strong analytical skills to determine data integrity and ensure the right controls are in place.</li> <li>Are comfortable operating in a constantly changing global environment and have an eye for how to scale systems/processes</li> <li>Are highly proficient in SQL. Proficiency in Python or R is also valuable. </li> <li>Have experience using various BI tools/ systems</li> <br><br></ul><em>We know the</em><em> confidence gap</em><em> and</em><em> imposter syndrome</em><em> can get in the way of meeting spectacular candidates, so please don’t hesitate to apply — we’d love to hear from you.<br><br></em><strong><u>About HubSpot<br><br></u></strong>HubSpot (NYSE: HUBS) is a leading customer relationship management (CRM) platform that provides software and support to help businesses grow better. We build marketing, sales, service, and website management products that start free and scale to meet our customers’ needs at any stage of growth. We’re also building a company culture that empowers people to do their best work through. If that sounds like something you’d like to be part of, we’d love to hear from you.<br><br>You can find out more about our company culture in the HubSpot Culture Code, which has more than 5M views, and learn about our commitment to creating a diverse and inclusive workplace, too. Thanks to the work of every employee globally, HubSpot was named the #4 Best Place to Work on Glassdoor in 2021, and has been recognized for award-winning culture by Great Place to Work, Comparably, Fortune, Entrepreneur, Inc., and more.<br><br>Headquartered in Cambridge, Massachusetts, HubSpot was founded in 2006. Today, thousands of employees work across the globe in HubSpot offices and remotely. Visit our careers website to learn more about culture and opportunities at HubSpot.<br><br><em>By submitting your application, you agree that HubSpot may collect your personal data for recruiting, global organization planning, and related purposes. HubSpot's </em><em>Privacy Notice</em><em> explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over HubSpot’s use of your personal information.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Remote, Oregon, United States",Cisco Meraki,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-cisco-meraki-2416450720?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=vNoHFasKldJLOUNJzrVjqA%3D%3D&position=7&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"COVID-19 Hiring Update--

Dataminr is still actively hiring.

As the health and safety of our candidates and our employees come first,

we're excited to provide virtual experiences for interviews and new hire on-boarding.

Who We Are

Dataminr puts real-time AI and public data to work for our clients, generating relevant and actionable alerts for global corporations, public sector agencies, newsrooms, and NGOs. Our leading AI platform detects the earliest signals of high-impact events and emerging risks from vast amounts of publicly available information. Our real-time alerts enable tens of thousands of users at hundreds of public and private sector organizations to learn first of breaking events around the world, develop effective risk mitigation strategies, and respond with confidence as crises unfold.

Dataminr is making its mark for growth and innovation, recently earning recognition on the Deloitte Technology Fast 500, Forbes AI 50 and Forbes Cloud 100 lists. We also earned accolades for ‘Most Innovative Use of AI’ from the 2020 AI & Machine Learning Awards.

Who You Are

You're an experienced Big Data Engineer interested in working on a collaborative, high growth team with best-in-class cloud-native technologies. Our tech stack includes Snowflake, Kafka & Kafka Connect, Spark, SCALA, Java, Python, and our business model is 24/7 streaming data so if you have ever wanted to focus on both streaming and batch architecture building innovative data infrastructure that delivers high impact results for teams across the company, this is the role for you. You have experience designing, building and maintaining data infrastructure and are proficient in cloud-native dev ops. You have experience writing and maintaining ELTs and their orchestration in order to produce meaningful and timely insights. You are passionate about Data Infrastructure as a Service, and you find meaning in enabling others to work faster by building better tooling. Ideally you excel at integrating data from different sources, using SQL for exploratory analyses and data validation, and are well-versed in the advantages and limitations of various big data architectures and technologies. You are intellectually curious and you understand the importance of mindful communication in engineering. You have a history of mentoring other engineers and you give your time and support to help others.

The Opportunity

You will lead greenfield big data engineering projects on a high growth team. You will be responsible for architecting and building highly-performant and maintainable data infrastructure, working with best-in-class technologies and processes and partnering with the teams that manage our AI platform. You’ll be responsible for designing new methods for ensuring the validity and quality of the company’s datasets, and you’ll help develop systems that accurately monitor and measure the impact of releases to our production systems. In the first month, you’ll

start off by learning the ropes, spending time with different parts of the company to understand how Dataminr works.
get up to speed on our data infrastructure and our roadmap with overview sessions and deep dives with your team.
contribute code to production systems.



Within 3 Months, You’ll

share responsibility for data infrastructure with members of your team.
help to plan new infrastructure features and improvements.
begin to take more of a role in helping others understand our data platform strategy.



Within 6 Months, You’ll

own an area of the data platform, depending on your interests
design and implement pipelines that impact multiple teams across the company.
be influential in helping plan the next iteration of our data platforms.
bring new ideas to our engineering and analytics processes to help us continuously improve.



Why You Should Work Here

We recognize and reward hard work with:
company paid benefits for employees and their dependents, including medical, dental, vision, disability and life insurance
401(k) savings plan with company matching
flexible spending account for out-of-pocket medical, transit, parking and dependent care expenses
We want you to be your best, authentic self by supporting you with:
a diverse, driven, and passionate team of coworkers who want you to succeed
individual learning and development fund and professional training
generous paid time off; including sick leave and 100% company paid parental leave
in-office perks such as a kitchen stocked with snacks and beverages, and catered meals
remote working friendly perks such as expanded telehealth options for mental and physical well being, virtual yoga, meditation and health and fitness app reimbursements

…and this is just to name a few!

Dataminr is an equal opportunity and affirmative action employer. Individuals seeking employment at Dataminr are considered without regards to race, sex, color, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><li>COVID-19 Hiring Update--<br><br><strong>Dataminr is still actively hiring.<br><br></strong><strong>As the health and safety of our candidates and our employees come first, <br><br></strong><strong>we're excited to provide virtual experiences for interviews and new hire on-boarding.<br><br></strong><strong><u>Who We Are<br><br></u></strong>Dataminr puts real-time AI and public data to work for our clients, generating relevant and actionable alerts for global corporations, public sector agencies, newsrooms, and NGOs. Our leading AI platform detects the earliest signals of high-impact events and emerging risks from vast amounts of publicly available information. Our real-time alerts enable tens of thousands of users at hundreds of public and private sector organizations to learn first of breaking events around the world, develop effective risk mitigation strategies, and respond with confidence as crises unfold.<br><br>Dataminr is making its mark for growth and innovation, recently earning recognition on the Deloitte Technology Fast 500, Forbes AI 50 and Forbes Cloud 100 lists. We also earned accolades for ‘Most Innovative Use of AI’ from the 2020 AI &amp; Machine Learning Awards.<br><br><strong><u>Who You Are<br><br></u></strong>You're an experienced Big Data Engineer interested in working on a collaborative, high growth team with best-in-class cloud-native technologies. Our tech stack includes Snowflake, Kafka &amp; Kafka Connect, Spark, SCALA, Java, Python, and our business model is 24/7 streaming data so if you have ever wanted to focus on both streaming and batch architecture building innovative data infrastructure that delivers high impact results for teams across the company, this is the role for you. You have experience designing, building and maintaining data infrastructure and are proficient in cloud-native dev ops. You have experience writing and maintaining ELTs and their orchestration in order to produce meaningful and timely insights. You are passionate about Data Infrastructure as a Service, and you find meaning in enabling others to work faster by building better tooling. Ideally you excel at integrating data from different sources, using SQL for exploratory analyses and data validation, and are well-versed in the advantages and limitations of various big data architectures and technologies. You are intellectually curious and you understand the importance of mindful communication in engineering. You have a history of mentoring other engineers and you give your time and support to help others.<br><br><strong><u>The Opportunity<br><br></u></strong>You will lead greenfield big data engineering projects on a high growth team. You will be responsible for architecting and building highly-performant and maintainable data infrastructure, working with best-in-class technologies and processes and partnering with the teams that manage our AI platform. You’ll be responsible for designing new methods for ensuring the validity and quality of the company’s datasets, and you’ll help develop systems that accurately monitor and measure the impact of releases to our production systems. In the first month, you’ll<br><ul> <li> start off by learning the ropes, spending time with different parts of the company to understand how Dataminr works. </li> <li> get up to speed on our data infrastructure and our roadmap with overview sessions and deep dives with your team. </li> <li> contribute code to production systems. </li> <br><br></ul><strong><u>Within 3 Months, You’ll<br></u></strong><ul> <li> share responsibility for data infrastructure with members of your team. </li> <li> help to plan new infrastructure features and improvements. </li> <li> begin to take more of a role in helping others understand our data platform strategy. </li> <br><br></ul><strong><u>Within 6 Months, You’ll<br></u></strong><ul> <li> own an area of the data platform, depending on your interests </li> <li> design and implement pipelines that impact multiple teams across the company. </li> <li> be influential in helping plan the next iteration of our data platforms. </li> <li> bring new ideas to our engineering and analytics processes to help us continuously improve. </li> <br><br></ul><strong><u>Why You Should Work Here<br></u></strong><ul> <li> We recognize and reward hard work with: </li></ul><ul> <li> company paid benefits for employees and their dependents, including medical, dental, vision, disability and life insurance </li> <li> 401(k) savings plan with company matching </li> <li> flexible spending account for out-of-pocket medical, transit, parking and dependent care expenses </li> </ul> </li><li> We want you to be your best, authentic self by supporting you with: </li><ul> <li> a diverse, driven, and passionate team of coworkers who want you to succeed </li> <li> individual learning and development fund and professional training </li> <li> generous paid time off; including sick leave and 100% company paid parental leave </li> <li> in-office perks such as a kitchen stocked with snacks and beverages, and catered meals </li> <li> remote working friendly perks such as expanded telehealth options for mental and physical well being, virtual yoga, meditation and health and fitness app reimbursements </li> </ul> <br>…and this is just to name a few!<br><br>Dataminr is an equal opportunity and affirmative action employer. Individuals seeking employment at Dataminr are considered without regards to race, sex, color, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.<br><br></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
"Engineer, Data","Bellevue, Washington, United States",T-Mobile,2021-01-26,https://www.linkedin.com/jobs/view/engineer-data-at-t-mobile-2418256854?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=X%2B4cCsOgoihlSdL97jeaPg%3D%3D&position=8&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Cisco Meraki is revolutionizing the way IT administrators manage their infrastructure by providing simple and secure cloud-managed solutions. With a large install base of customers and rich, multi-dimensional data sets, the potential for data analytics to improve business performance for both our customers and our own business is enormous.

We are looking for a full-stack Data Scientist to join our Strategy & Data Science department. The Strategy & Data Science department is a growing group that works closely with executives and leaders across the company to support the development of and alignment on our business strategy. As part of this group, you will develop cross-functional relationships and use rigorous data science methods on our business and product data to drive near- and longer-term impact. This would be an outstanding fit for someone who has a passion for both math and technology, ability to provide deep insights for priority Meraki leadership asks and joint Cisco/Meraki product and customer analysis.

What Will You Do

Lead key, cross-functional analytical projects, identifying and bringing together stakeholders, building project plans, developing joint analytical approaches, and executing against the project
Build predictive models to influence business decisions
Use data to identify opportunities to improve customer support needs
Define key metrics to help track our business performance and customer experience
Analyze user journey data and understand root causes of customer engagement with products and dashboard
Enable task automation using machine intelligence
Analyze trends in data to identify growth opportunities for our business



What Skills You Possess

Strong SQL skills
Strong coding skills in Python/R, Hadoop/Spark technologies
2-3+ years of prior knowledge in building data science pipelines
Good understanding of machine learning based model building flows
Hands-on experience using machine learning frameworks
BS/MS degree, such as economics, mathematics, statistics or engineering
3-5+ years of experience in an analytical role or equivalent combination of graduate degree and work experience in data science
Exceptional critical thinking and problem-solving ability
Good written and verbal communication skills
Strong attention to detail and accuracy
Self-starter and ability to work autonomously



Who You Are

You demonstrate business acumen in your work
You have a real passion for analytics and desire for continuous learning
You have strong organizational skills; able to keep track of multiple competing priorities without losing details
Ability to communicate the results of analysis
You are eager to take ownership of projects
You remain curious and hungry to understand all components of your work


Are you wondering what it is like to work at Cisco Meraki? Picture a breathtaking office, healthy catered meals, fully stocked kitchens, onsite gym and paid time off to volunteer. Meraki Cisco has crafted an amazing equal opportunity focused office where employees thrive. With that said, we are confident you will love it here. Check out more of our benefits on our job page, at https://meraki.cisco.com/jobs, and we look forward to talking with you soon.

Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis.

At Cisco Meraki, we’re challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release the full potential of our people. We’re building an employee experience that includes appreciation, belonging, growth, and purpose for everyone.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Cisco Meraki is revolutionizing the way IT administrators manage their infrastructure by providing simple and secure cloud-managed solutions. With a large install base of customers and rich, multi-dimensional data sets, the potential for data analytics to improve business performance for both our customers and our own business is enormous.<br><br>We are looking for a full-stack Data Scientist to join our Strategy &amp; Data Science department. The Strategy &amp; Data Science department is a growing group that works closely with executives and leaders across the company to support the development of and alignment on our business strategy. As part of this group, you will develop cross-functional relationships and use rigorous data science methods on our business and product data to drive near- and longer-term impact. This would be an outstanding fit for someone who has a passion for both math and technology, ability to provide deep insights for priority Meraki leadership asks and joint Cisco/Meraki product and customer analysis.<br><br><strong><u>What Will You Do<br></u></strong><ul> <li>Lead key, cross-functional analytical projects, identifying and bringing together stakeholders, building project plans, developing joint analytical approaches, and executing against the project</li> <li>Build predictive models to influence business decisions</li> <li>Use data to identify opportunities to improve customer support needs</li> <li>Define key metrics to help track our business performance and customer experience</li> <li>Analyze user journey data and understand root causes of customer engagement with products and dashboard</li> <li>Enable task automation using machine intelligence</li> <li>Analyze trends in data to identify growth opportunities for our business</li> <br><br></ul><strong><u>What Skills You Possess<br></u></strong><ul> <li>Strong SQL skills</li> <li>Strong coding skills in Python/R, Hadoop/Spark technologies</li> <li>2-3+ years of prior knowledge in building data science pipelines</li> <li>Good understanding of machine learning based model building flows</li> <li>Hands-on experience using machine learning frameworks</li> <li>BS/MS degree, such as economics, mathematics, statistics or engineering</li> <li>3-5+ years of experience in an analytical role or equivalent combination of graduate degree and work experience in data science</li> <li>Exceptional critical thinking and problem-solving ability</li> <li>Good written and verbal communication skills</li> <li>Strong attention to detail and accuracy</li> <li>Self-starter and ability to work autonomously</li> <br><br></ul><strong><u>Who You Are<br></u></strong><ul> <li>You demonstrate business acumen in your work</li> <li>You have a real passion for analytics and desire for continuous learning</li> <li>You have strong organizational skills; able to keep track of multiple competing priorities without losing details</li> <li>Ability to communicate the results of analysis</li> <li>You are eager to take ownership of projects</li> <li>You remain curious and hungry to understand all components of your work</li> <br></ul>Are you wondering what it is like to work at Cisco Meraki? Picture a breathtaking office, healthy catered meals, fully stocked kitchens, onsite gym and paid time off to volunteer. Meraki Cisco has crafted an amazing equal opportunity focused office where employees thrive. With that said, we are confident you will love it here. Check out more of our benefits on our job page, at https://meraki.cisco.com/jobs, and we look forward to talking with you soon.<br><br>Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis.<br><br>At Cisco Meraki, we’re challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release the full potential of our people. We’re building an employee experience that includes appreciation, belonging, growth, and purpose for everyone.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Networking
Data Scientist,"Irvine, California, United States",Blizzard Entertainment,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-blizzard-entertainment-2418247349?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=lPiQr5p8ivEdeDE9BNvaYA%3D%3D&position=9&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

The Data Engineer will create and maintain optimal data pipeline architecture, including assembling large, complex data sets that meet functional / non-functional business requirements. The professional will also identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.


Functional Group
Emerging Products

Location
WA108-WA-Bellevue Building 12 Office

Location Address
3076 160th Ave SE

City
Bellevue

State
Washington

Zip
98006

Travel Required?
No


Responsibilities


Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholder teams and team management to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product’s performance and effectiveness.
Work with data and analytics experts to strive for greater functionality in our data systems.


Qualifications


Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
5 years of experience in a Data Engineer role
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
3 years of experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
3 years of experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Experience in languages such as Python, Java, Scala, and/or Go
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Good ability to manage work across multiple projects and good organizational skills.


Minimum Qualifications


At least 18 years of age.
Legally authorized to work in the United States.
High School Diploma or GED.
Pre-employment background screen.


Company Profile

As America’s Un-carrier, T-Mobile USA, Inc. (NASDAQ: “TMUS”) is redefining the way consumers and businesses buy wireless services through leading product and service innovation. The company’s advanced nationwide 4G and 4G LTE network delivers outstanding wireless experiences for customers who are unwilling to compromise on quality and value. Based in Bellevue, Washington, T-Mobile USA. Inc. provides services through its subsidiaries and operates its flagship brands, T-Mobile and Metro by T-Mobile. For more information, please visit http://www.t-mobile.com

Applicant Privacy Policy

We are committed to maintaining your trust by respecting and protecting your privacy. For more information about how T-Mobile processes the personal data of job applicants, please visit Applicant Privacy Policy .

EOE Statement

Equal Employment Opportunity

We take equal opportunity seriously—by choice.

T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.

Positions Remaining
1

Brand
T-Mobile

Schedule
Full Time
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Job Description<br><br></strong>The Data Engineer will create and maintain optimal data pipeline architecture, including assembling large, complex data sets that meet functional / non-functional business requirements. The professional will also identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.<br><br><br><strong>Functional Group<br></strong>Emerging Products<br><br><strong>Location<br></strong>WA108-WA-Bellevue Building 12 Office<br><br><strong>Location Address<br></strong>3076 160th Ave SE<br><br><strong>City<br></strong>Bellevue<br><br><strong>State<br></strong>Washington<br><br><strong>Zip<br></strong>98006<br><br><strong>Travel Required?<br></strong>No<br><br><br><strong>Responsibilities<br><br></strong><ul><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.</li><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.</li><li> Work with stakeholder teams and team management to assist with data-related technical issues and support their data infrastructure needs.</li><li> Create data tools for analytics and data scientist team members that assist them in building and optimizing our product’s performance and effectiveness.</li><li> Work with data and analytics experts to strive for greater functionality in our data systems.<br><br></li></ul><strong>Qualifications<br><br></strong><ul><li> Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.</li><li> 5 years of experience in a Data Engineer role</li><li> Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li> 3 years of experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li><li> 3 years of experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li><li> Strong analytic skills related to working with unstructured datasets.</li><li> Experience in languages such as Python, Java, Scala, and/or Go</li><li> Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li><li> A successful history of manipulating, processing and extracting value from large disconnected datasets.</li><li> Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li><li> Good ability to manage work across multiple projects and good organizational skills.<br><br></li></ul><strong>Minimum Qualifications<br><br></strong><ul><li> At least 18 years of age.</li><li> Legally authorized to work in the United States.</li><li> High School Diploma or GED.</li><li> Pre-employment background screen.<br><br></li></ul><strong>Company Profile<br><br></strong>As America’s Un-carrier, T-Mobile USA, Inc. (NASDAQ: “TMUS”) is redefining the way consumers and businesses buy wireless services through leading product and service innovation. The company’s advanced nationwide 4G and 4G LTE network delivers outstanding wireless experiences for customers who are unwilling to compromise on quality and value. Based in Bellevue, Washington, T-Mobile USA. Inc. provides services through its subsidiaries and operates its flagship brands, T-Mobile and Metro by T-Mobile. For more information, please visit http://www.t-mobile.com<br><br>Applicant Privacy Policy<br><br>We are committed to maintaining your trust by respecting and protecting your privacy. For more information about how T-Mobile processes the personal data of job applicants, please visit Applicant Privacy Policy .<br><br><strong>EOE Statement<br><br></strong><strong>Equal Employment Opportunity<br><br></strong>We take equal opportunity seriously—by choice.<br><br>T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.<br><br><strong>Positions Remaining<br></strong>1<br><br><strong>Brand<br></strong>T-Mobile<br><br><strong>Schedule<br></strong>Full Time</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Telecommunications
Data Scientist,"San Francisco, California, United States",Notion,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-notion-2417201585?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=tu%2Bzfx%2Bb5u0P%2B9zxIElxTw%3D%3D&position=10&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Team Name

Service Technologies

Job Title

Data Scientist

Requisition ID

R005149

Job Description

Blizzard Entertainment has been rated by Fortune as one of the ""Best Places to Work"" for several years running (and our ranking continues to rise!). We are a diverse community of 4000 global employees who are passionate about not only gaming, but creating epic entertainment and the technology that drives our customers’ experience. Our goal is to delight our customers by never settling for anything but the highest quality and providing worlds filled with creativity and adventure around every corner.

Blizzard Entertainment is seeking an experienced Data Scientist to join the Service Technologies team. The Data Scientist champions the data science efforts on the Service Technologies team, concentrating on player behavior and interactions. The team partners closely with game teams, other technical teams, global security, and customer service to help build a safe and welcoming environment for all gamers.

You’ll join the established Player Interactions and Trust team within Service Tech which includes data science, software engineering, research, design, and key partners within our game teams. The ideal candidate is passionate about machine learning, artificial intelligence, statistics, and deep learning and has expertise in designing highly scalable machine learning algorithms.

Responsibilities

Assist with efforts in developing data science capabilities in Service Technologies.
Work with data science products and work closely with engineers to help improve the engineering platform in relation to data science work.
Work closely with data and software engineers to deploy, automate, and maintain models seamlessly on production systems.
Help build platform-level solutions for machine learning systems.
Communicate machine learning models and products to both technical and non-technical audiences.
Be a part of the wider machine learning community within Blizzard to share ideas and learnings.
Join the data science efforts as it relates to player interactions and research into player behaviors in first- and second party games.


Requirements

Masters or Ph.D. with a specialization in deep learning, machine learning, artificial intelligence, computer vision, statistics, applied math, algorithm design, or a related quantitative field.
Proficiency in statistics, machine learning, and model analytics.
A minimum of 2 years’ hands-on applied or research experience developing machine learning models on large scale data sets.
Able to translate academic research into application.
Intermediate knowledge in computer architecture/compilers/OOP/data structure and algorithms.
Basic understanding of natural language processing
Advanced knowledge of SQL analysis.
Knowledge of GIT/version control, SQL DB architecture, and Hadoop/Map Reduce/Spark
Proficiency in one or more of the higher-level programming languages like Python, Java, C++, Scala, R, etc.
Strong problem-solving, written and spoken communication skills.


Pluses

Strong understanding of natural language processing.
Experience with Blizzard Entertainment games.
A proven track record of original contributions to machine learning or statistics.
Experience with data visualization tools like Tableau.
Passion for video games


Blizzard Entertainment is a global company committed to growing our employees. We offer generous benefits and perks with an eye on providing true work / life balance. We’ve worked hard to champion an intensely collaborative and creative environment, a diverse and inclusive employee culture, and training and opportunity for professional growth. Our people are everything. Our core values are real, and our mission has never changed.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We are dedicated to creating the most epic entertainment experiences…ever. Join us!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Team Name<br><br></u></strong>Service Technologies<br><br><strong><u>Job Title<br><br></u></strong>Data Scientist<br><br><strong><u>Requisition ID<br><br></u></strong>R005149<br><br><strong><u>Job Description<br><br></u></strong>Blizzard Entertainment has been rated by Fortune as one of the ""Best Places to Work"" for several years running (and our ranking continues to rise!). We are a diverse community of 4000 global employees who are passionate about not only gaming, but creating epic entertainment and the technology that drives our customers’ experience. Our goal is to delight our customers by never settling for anything but the highest quality and providing worlds filled with creativity and adventure around every corner.<br><br>Blizzard Entertainment is seeking an experienced Data Scientist to join the Service Technologies team. The Data Scientist champions the data science efforts on the Service Technologies team, concentrating on player behavior and interactions. The team partners closely with game teams, other technical teams, global security, and customer service to help build a safe and welcoming environment for all gamers.<br><br>You’ll join the established Player Interactions and Trust team within Service Tech which includes data science, software engineering, research, design, and key partners within our game teams. The ideal candidate is passionate about machine learning, artificial intelligence, statistics, and deep learning and has expertise in designing highly scalable machine learning algorithms.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Assist with efforts in developing data science capabilities in Service Technologies.</li><li>Work with data science products and work closely with engineers to help improve the engineering platform in relation to data science work.</li><li>Work closely with data and software engineers to deploy, automate, and maintain models seamlessly on production systems.</li><li>Help build platform-level solutions for machine learning systems.</li><li>Communicate machine learning models and products to both technical and non-technical audiences.</li><li>Be a part of the wider machine learning community within Blizzard to share ideas and learnings.</li><li>Join the data science efforts as it relates to player interactions and research into player behaviors in first- and second party games.<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>Masters or Ph.D. with a specialization in deep learning, machine learning, artificial intelligence, computer vision, statistics, applied math, algorithm design, or a related quantitative field.</li><li>Proficiency in statistics, machine learning, and model analytics.</li><li>A minimum of 2 years’ hands-on applied or research experience developing machine learning models on large scale data sets.</li><li>Able to translate academic research into application.</li><li>Intermediate knowledge in computer architecture/compilers/OOP/data structure and algorithms.</li><li>Basic understanding of natural language processing</li><li>Advanced knowledge of SQL analysis.</li><li>Knowledge of GIT/version control, SQL DB architecture, and Hadoop/Map Reduce/Spark</li><li>Proficiency in one or more of the higher-level programming languages like Python, Java, C++, Scala, R, etc.</li><li>Strong problem-solving, written and spoken communication skills.<br><br></li></ul><strong>Pluses<br></strong><ul><li>Strong understanding of natural language processing.</li><li>Experience with Blizzard Entertainment games.</li><li>A proven track record of original contributions to machine learning or statistics.</li><li>Experience with data visualization tools like Tableau.</li><li>Passion for video games<br><br></li></ul>Blizzard Entertainment is a global company committed to growing our employees. We offer generous benefits and perks with an eye on providing true work / life balance. We’ve worked hard to champion an intensely collaborative and creative environment, a diverse and inclusive employee culture, and training and opportunity for professional growth. Our people are everything. Our core values are real, and our mission has never changed.<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We are dedicated to creating the most epic entertainment experiences…ever. Join us!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Software Engineer (Python),"New York, New York, United States",OpenSlate,2021-02-18,https://www.linkedin.com/jobs/view/software-engineer-python-at-openslate-2429525171?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=o%2FV5sHpkfwXOK3SSuRNPiw%3D%3D&position=11&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"About Us

We make software that anyone can mold and shape to take on every challenge — from taking personal notes to running large companies. We've been building together since 2016 and are trusted by customers including Nike, Airbnb, Slack, Samsung, and more. We're excited to be growing a team as diverse and creative as the millions of people we reach worldwide, and a company where everyone can thrive.

About The Role

Do you want to help define what data means at Notion? As one of our first Data Scientists, you'll be instrumental in setting what our data strategy looks like as we grow the business, and then doing the hands on work to execute against it. There will be significant variation from one day to the next, but whether you're exploring what a successful Notion account looks like, building out a core activity data set, or creating a model to deliver leads to the sales team, you'll absolutely be having impact on the direction of the business.

What You'll Do

You'll set the foundation for what data means at Notion, determining how we balance product intuition with analytical rigor.
You'll build data pipelines that transform messy raw data into tables that are reliable, broadly useful, and clear. (We currently use DBT, Snowflake, Mode Analytics, Fivetran, Census, Amplitude, Segment, and more).
You'll collaborate with team leads across the business to understand and support their data needs.
You'll design and enact the process for using statistical inference to evaluate the success of changes, from product launches to marketing campaigns.
You'll build models to understand and predict things like user growth, product engagement, conversion, churn, and more.
You'll build and maintain KPI dashboards that teams rely on for making key decisions.
You'll communicate your findings with the rest of the company, and drive and verify change in our product and business (Insights are useful. Impact is even better!)



What We're Looking For

You've spent meaningful time as a data scientist.
You are a SQL expert. You have no problem regularly leveraging window functions, UDFs, self-joins, and other complex SQL functions to accomplish your data analysis goals.
You have expertise in at least one scripting language (ideally Python or R).
You know how to use statistical inference to drive product and business recommendations.
You have experience building predictive models, and you know how to evaluate their effectiveness.
You have a bias for using the right tools to get a job done with maximum efficiency. You have experience making tradeoffs between speed and accuracy.
You have strong product sense and user intuition which inform the questions you ask of the data you are analyzing.



Bonus Points

You have led or managed a Data Science team.
You have led initiatives across multiple product areas and communicated findings with leadership and product teams.
You have worked at a fast-growing start-up.
You have experience building out data infrastructure that facilitates speed, reliability, and scalability.
You have prior experience with data-distributed tools (Scalding, Hadoop, Pig, etc) and statistical libraries.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Us<br><br></u></strong>We make software that anyone can mold and shape to take on every challenge — from taking personal notes to running large companies. We've been building together since 2016 and are trusted by customers including Nike, Airbnb, Slack, Samsung, and more. We're excited to be growing a team as diverse and creative as the millions of people we reach worldwide, and a company where everyone can thrive.<br><br><strong><u>About The Role<br><br></u></strong>Do you want to help define what data means at Notion? As one of our first Data Scientists, you'll be instrumental in setting what our data strategy looks like as we grow the business, and then doing the hands on work to execute against it. There will be significant variation from one day to the next, but whether you're exploring what a successful Notion account looks like, building out a core activity data set, or creating a model to deliver leads to the sales team, you'll absolutely be having impact on the direction of the business.<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>You'll set the foundation for what data means at Notion, determining how we balance product intuition with analytical rigor.</li> <li>You'll build data pipelines that transform messy raw data into tables that are reliable, broadly useful, and clear. (We currently use DBT, Snowflake, Mode Analytics, Fivetran, Census, Amplitude, Segment, and more).</li> <li>You'll collaborate with team leads across the business to understand and support their data needs.</li> <li>You'll design and enact the process for using statistical inference to evaluate the success of changes, from product launches to marketing campaigns.</li> <li>You'll build models to understand and predict things like user growth, product engagement, conversion, churn, and more.</li> <li>You'll build and maintain KPI dashboards that teams rely on for making key decisions.</li> <li>You'll communicate your findings with the rest of the company, and drive and verify change in our product and business (Insights are useful. Impact is even better!)</li> <br><br></ul><strong><u>What We're Looking For<br></u></strong><ul> <li>You've spent meaningful time as a data scientist.</li> <li>You are a SQL expert. You have no problem regularly leveraging window functions, UDFs, self-joins, and other complex SQL functions to accomplish your data analysis goals.</li> <li>You have expertise in at least one scripting language (ideally Python or R).</li> <li>You know how to use statistical inference to drive product and business recommendations.</li> <li>You have experience building predictive models, and you know how to evaluate their effectiveness.</li> <li>You have a bias for using the right tools to get a job done with maximum efficiency. You have experience making tradeoffs between speed and accuracy.</li> <li>You have strong product sense and user intuition which inform the questions you ask of the data you are analyzing.</li> <br><br></ul><strong><u>Bonus Points<br></u></strong><ul> <li>You have led or managed a Data Science team.</li> <li>You have led initiatives across multiple product areas and communicated findings with leadership and product teams.</li> <li>You have worked at a fast-growing start-up.</li> <li>You have experience building out data infrastructure that facilitates speed, reliability, and scalability.</li> <li>You have prior experience with data-distributed tools (Scalding, Hadoop, Pig, etc) and statistical libraries.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"New York, New York, United States",Peloton Interactive,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-at-peloton-interactive-2227966279?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=bjsoPqMiPmvU9e%2FzleZPrg%3D%3D&position=12&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"We’re looking for experienced Python engineers who would enjoy the challenge of designing and building applications to provide insights into a highly dynamic and expansive data set. Working with user-generated content at scale poses some unique problems so we highly value creative technical minds that can imagine solutions and bring them to reality.

Responsibilities

Designing and building scalable systems that can collect, store, retrieve and transform data coming from a variety of different sources including APIs, Postgres, Solr, S3 and Cassandra.
Designing and implementing maintainable API’s that support our end-user applications.
Selecting appropriate data storage and retrieval methods and technologies.
Designing data-structures and optimizing queries that deal with millions of rows of data.
Creating reusable and maintainable code, automated tests and clear documentation.
Optimizing your code to run in a high-performance real-time environment that generates billions of events a day.
Supporting the software and systems you write and deploy in our production environment.
Collaborating across engineering, product and data teams to solve technical and business issues.


About You

5+ years experience building non-trivial, data-centric python applications and API’s in a Linux environment
Experience designing and implementing scalable systems processing large amounts of data
2+ years building back-end services and APIs in Django or Flask
Thorough understanding of common internet networking technologies, including TCP, HTTP, DNS.
Expertise working with RDBMS, including schema design, writing SQL for complex multi-table queries and optimizing query performance
Expertise in using Git and Git branching models
You enjoy working as a part of a collaborative team and demonstrate an open mindset.
Strong communication skills: able to clearly articulate, defend and document design decisions and work with a cross-discipline team
A love of problem-solving and a sense of imagination
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We’re looking for experienced Python engineers who would enjoy the challenge of designing and building applications to provide insights into a highly dynamic and expansive data set. Working with user-generated content at scale poses some unique problems so we highly value creative technical minds that can imagine solutions and bring them to reality.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Designing and building scalable systems that can collect, store, retrieve and transform data coming from a variety of different sources including APIs, Postgres, Solr, S3 and Cassandra.</li><li>Designing and implementing maintainable API’s that support our end-user applications.</li><li>Selecting appropriate data storage and retrieval methods and technologies.</li><li>Designing data-structures and optimizing queries that deal with millions of rows of data.</li><li>Creating reusable and maintainable code, automated tests and clear documentation.</li><li>Optimizing your code to run in a high-performance real-time environment that generates billions of events a day.</li><li>Supporting the software and systems you write and deploy in our production environment.</li><li>Collaborating across engineering, product and data teams to solve technical and business issues. <br><br></li></ul><strong><u>About You<br></u></strong><ul><li>5+ years experience building non-trivial, data-centric python applications and API’s in a Linux environment</li><li>Experience designing and implementing scalable systems processing large amounts of data</li><li>2+ years building back-end services and APIs in Django or Flask</li><li>Thorough understanding of common internet networking technologies, including TCP, HTTP, DNS.</li><li>Expertise working with RDBMS, including schema design, writing SQL for complex multi-table queries and optimizing query performance</li><li>Expertise in using Git and Git branching models</li><li>You enjoy working as a part of a collaborative team and demonstrate an open mindset.</li><li>Strong communication skills: able to clearly articulate, defend and document design decisions and work with a cross-discipline team</li><li>A love of problem-solving and a sense of imagination</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Online Media, Internet"
Data Engineer,"Orange, California, United States",MeridianLink,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-meridianlink-2430702792?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=G3cvTe61M7eNeu1qcXIxEQ%3D%3D&position=13&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Peloton is looking for a Data Engineer to build our Data Warehouse and Data Pipelines. You will work with multiple teams of passionate and skilled data engineers, architects, and analysts responsible for building batch and streaming data pipelines that process terabytes of data daily and support all of the analytics, business intelligence, data science and reporting data needs across the organization.

Peloton is a cloud first engineering organization with all of our data infrastructure in AWS leveraging EMR, AWS Glue, Redshift, S3, Spark. You will be interacting with many business teams including marketing, sales, supply chain, logistics, finance and partner to scale Peloton’s data infrastructure for future strategic needs.

Responsibilities

Understand the data needs of different stakeholders across multiple business verticals including Finance, Marketing, Logistics, Product etc.
Develop the vision and map strategy to provide proactive solutions and enable stakeholders to extract insights and value from data.
Understand end to end data interactions and dependencies across complex data pipelines and data transformation and how they impact business decisions.
Design best practices for big data processing, data modeling and warehouse development throughout the company.



Requirements

Familiar with at least one of the programming languages: Python, Java.
Comfortable with Linux operating system and command line tools such as Bash.
Familiar with REST for accessing cloud based services.
Excellent knowledge about databases, such as PostgreSQL and Redshift.
Has experiences with GIT, Github, JIRA and SCRUM.
2+ years in building a data warehouse and data pipelines. Or, 3+ years in data intensive engineering roles.
Experience with big data architectures and data modeling to efficiently process large volumes of data.
Background in ETL and data processing, know how to transform data to meet business goals.
Experience developing large data processing pipelines on Apache Spark.
Experience with Python or Java programming languages.
Strong understanding of SQL and working knowledge of using SQL(prefer PostgreSQL and Redshift) for various reporting and transformation needs.
Excellent communication, adaptability and collaboration skills.
Experience running Agile methodology and applying Agile to data engineering.
Experience with Java, JDBC, AWS, SDK


Nice to have

Familiar with AWS ecosystem, including RDS, Glue, Athena, etc.
Has experiences with Apache Hadoop, Hive, Spark and PySpark.



About Peloton

Peloton is the largest interactive fitness platform in the world with a loyal community of more than 2.6 million Members. The company pioneered connected, technology-enabled fitness, and the streaming of immersive, instructor-led boutique classes for its Members anytime, anywhere. Peloton makes fitness entertaining, approachable, effective, and convenient, while fostering social connections that encourage its Members to be the best versions of themselves. An innovator at the nexus of fitness, technology, and media, Peloton has reinvented the fitness industry by developing a first-of-its-kind subscription platform that seamlessly combines the best equipment, proprietary networked software, and world-class streaming digital fitness and wellness content, creating a product that its Members love. The brand's immersive content is accessible through the Peloton Bike, Peloton Tread, and Peloton App, which allows access to a full slate of fitness classes across disciplines, on any iOS or Android device, Fire TV, Roku, Chromecast and Android TV. Founded in 2012 and headquartered in New York City, Peloton has a growing number of retail showrooms across the US, UK, Canada and Germany. For more information, visit www.onepeloton.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Peloton is looking for a Data Engineer to build our Data Warehouse and Data Pipelines. You will work with multiple teams of passionate and skilled data engineers, architects, and analysts responsible for building batch and streaming data pipelines that process terabytes of data daily and support all of the analytics, business intelligence, data science and reporting data needs across the organization.<br><br>Peloton is a cloud first engineering organization with all of our data infrastructure in AWS leveraging EMR, AWS Glue, Redshift, S3, Spark. You will be interacting with many business teams including marketing, sales, supply chain, logistics, finance and partner to scale Peloton’s data infrastructure for future strategic needs.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Understand the data needs of different stakeholders across multiple business verticals including Finance, Marketing, Logistics, Product etc. </li> <li>Develop the vision and map strategy to provide proactive solutions and enable stakeholders to extract insights and value from data.</li> <li>Understand end to end data interactions and dependencies across complex data pipelines and data transformation and how they impact business decisions.</li> <li>Design best practices for big data processing, data modeling and warehouse development throughout the company. </li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Familiar with at least one of the programming languages: Python, Java.</li> <li>Comfortable with Linux operating system and command line tools such as Bash.</li> <li>Familiar with REST for accessing cloud based services.</li> <li>Excellent knowledge about databases, such as PostgreSQL and Redshift.</li> <li>Has experiences with GIT, Github, JIRA and SCRUM.</li> <li>2+ years in building a data warehouse and data pipelines. Or, 3+ years in data intensive engineering roles.</li> <li>Experience with big data architectures and data modeling to efficiently process large volumes of data.</li> <li>Background in ETL and data processing, know how to transform data to meet business goals.</li> <li>Experience developing large data processing pipelines on Apache Spark.</li> <li>Experience with Python or Java programming languages.</li> <li>Strong understanding of SQL and working knowledge of using SQL(prefer PostgreSQL and Redshift) for various reporting and transformation needs.</li> <li>Excellent communication, adaptability and collaboration skills.</li> <li>Experience running Agile methodology and applying Agile to data engineering.</li> <li>Experience with Java, JDBC, AWS, SDK</li> <br></ul><strong>Nice to have<br></strong><ul> <li>Familiar with AWS ecosystem, including RDS, Glue, Athena, etc.</li> <li>Has experiences with Apache Hadoop, Hive, Spark and PySpark.</li> <br><br></ul><strong><u>About Peloton<br><br></u></strong>Peloton is the largest interactive fitness platform in the world with a loyal community of more than 2.6 million Members. The company pioneered connected, technology-enabled fitness, and the streaming of immersive, instructor-led boutique classes for its Members anytime, anywhere. Peloton makes fitness entertaining, approachable, effective, and convenient, while fostering social connections that encourage its Members to be the best versions of themselves. An innovator at the nexus of fitness, technology, and media, Peloton has reinvented the fitness industry by developing a first-of-its-kind subscription platform that seamlessly combines the best equipment, proprietary networked software, and world-class streaming digital fitness and wellness content, creating a product that its Members love. The brand's immersive content is accessible through the Peloton Bike, Peloton Tread, and Peloton App, which allows access to a full slate of fitness classes across disciplines, on any iOS or Android device, Fire TV, Roku, Chromecast and Android TV. Founded in 2012 and headquartered in New York City, Peloton has a growing number of retail showrooms across the US, UK, Canada and Germany. For more information, visit www.onepeloton.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Health, Wellness and Fitness"
Data Engineer,"Chicago, Illinois, United States",Addepar,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-addepar-2405738450?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=cA9EiCkcXURHrt%2B%2ByIYqtw%3D%3D&position=14&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Description

MeridianLink is looking for a savvy Data Engineer to join our growing team of Data experts. This role will contribute to the expansion and optimization of our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

As a contributing member of the Data Engineering team, your efforts will focus on deploying best practice around EDM, and cloud based data pipeline implementation in support of internal/external data and information requirements. You will partner with Architects, Analysts, Scientists, Product Leaders, and a cross functional group of Engineers to ensure that the MeridianLink data platform serves as an asset to the organization and its customers.

Scope

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Maintain and develop data processes in support of relational and non-relational schemas across the Azure data platform and product line



Qualifications

Working Knowledge or familiarity with the following: Kafka, Kubernetes, Azure, ETL, etc.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing and extracting value from large, disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with big data tools: Hadoop, Spark, Kafka, Azure, etc.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: GO, Python, Java, C++, Scala, etc.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>MeridianLink is looking for a savvy Data Engineer to join our growing team of Data experts. This role will contribute to the expansion and optimization of our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.<br><br>As a contributing member of the Data Engineering team, your efforts will focus on deploying best practice around EDM, and cloud based data pipeline implementation in support of internal/external data and information requirements. You will partner with Architects, Analysts, Scientists, Product Leaders, and a cross functional group of Engineers to ensure that the MeridianLink data platform serves as an asset to the organization and its customers.<br><br><strong> Scope <br></strong><ul> <li>Create and maintain optimal data pipeline architecture,</li> <li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li> <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li> <li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li> <li>Work with data and analytics experts to strive for greater functionality in our data systems.</li> <li>Maintain and develop data processes in support of relational and non-relational schemas across the Azure data platform and product line</li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li> Working Knowledge or familiarity with the following: Kafka, Kubernetes, Azure, ETL, etc. </li> <li> Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets. </li> <li> Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. </li> <li> Strong analytic skills related to working with unstructured datasets. </li> <li> Build processes supporting data transformation, data structures, metadata, dependency, and workload management. </li> <li> A successful history of manipulating, processing and extracting value from large, disconnected datasets. </li> <li> Experience supporting and working with cross-functional teams in a dynamic environment. </li> <li> Experience with big data tools: Hadoop, Spark, Kafka, Azure, etc. </li> <li> Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. </li> <li> Experience with object-oriented/object function scripting languages: GO, Python, Java, C++, Scala, etc.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Boston, Massachusetts, United States","OM1, Inc.",2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-om1-inc-2428981530?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=v7VZnW4uFTpWfgqHQfz40w%3D%3D&position=15&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"At its core, Addepar is a data company. We’re building interoperability and transparency across hundreds of financial systems, and creating more powerful and robust financial applications on top of that platform.

As Data Engineer in Business Intelligence, you will own the tech stack that produces, collects, transforms, persists, and models the business-critical product and financial data upon which Addepar relies to drive business and product direction. You will gain a deep understanding of the data sources and data pipelines that populate Addepar’s data warehouse. In this role you will have the opportunity to interact with different functional areas within the business, dive deep into the business and product data, and influence decision-making in a fast-paced, high-growth FinTech company.

The ideal candidate will have a proven track record of providing data solutions that impact product and business decisions. You thrive in a fast-paced environment and are capable of self-direction. You can take broad organizational goals and turn them into concise, effective deliverables. You will help set the vision for how we use data at Addepar and empower others in contributing toward that vision.

Responsibilities

Build and maintain the data feeds that deliver raw data to the data warehouse.
Define and maintain data models across all business intelligence databases and tools.
Partner with BI analysts to define and implement data transformations to convert raw data into schemas consumed by downstream tools.
Implement solutions to capture and process streaming data from the backend infrastructure and click-level data from the application.
Become a power user of Snowflake, and take ownership in Addepar’s successful adoption by ensuring high standards of data quality, data discoverability, and query performance.
Develop subject matter expertise in the Addepar product and the business tools upon which Addepar relies (including Periscope, Looker, and NetSuite).
Partner with product, engineering, and business teams to help shape the future of data-driven decision-making at Addepar.



Requirements

BS/MS in Computer Science, Statistics, Mathematics, or other quantitative field.
5+ years of professional engineering experience in analytics, data warehousing, data operations, or related role.
Expertise in writing, debugging, and optimizing SQL queries.
Experience using python to build data feeds and/or analyze data.
Experience with databases, data modeling, and data warehousing architecture.
Experience with large-scale / streaming data processing tools including Kafka, Spark, and Flink.
Experience with analytical/BI tools supporting data analysis, reporting, and visualization.
Exceptional analytical and problem solving skills.
Exceptional communication skills.



Addepar is a wealth management platform that specializes in data aggregation, analytics, and reporting for even the most complex investment portfolios. The company’s platform aggregates portfolio, market, and client data all in one place. It provides asset owners and advisors a clearer financial picture at every level, allowing them to make more informed and timely investment decisions. Addepar works with hundreds of leading financial advisors, family offices, and large financial institutions that manage data for over $2 trillion of assets on the company’s platform. In 2020, Addepar was named as a Forbes Fintech 50 and in 2018 received Morgan Stanley’s Fintech Award for making a significant impact on the firm’s mission of continuous innovation. Addepar is headquartered in Silicon Valley and has offices in New York City and Salt Lake City.

Addepar is an equal opportunity employer. We’re committed to building together and to do that best, we rely on a range of backgrounds, experiences, and ideas.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At its core, Addepar is a data company. We’re building interoperability and transparency across hundreds of financial systems, and creating more powerful and robust financial applications on top of that platform.<br><br>As Data Engineer in Business Intelligence, you will own the tech stack that produces, collects, transforms, persists, and models the business-critical product and financial data upon which Addepar relies to drive business and product direction. You will gain a deep understanding of the data sources and data pipelines that populate Addepar’s data warehouse. In this role you will have the opportunity to interact with different functional areas within the business, dive deep into the business and product data, and influence decision-making in a fast-paced, high-growth FinTech company.<br><br>The ideal candidate will have a proven track record of providing data solutions that impact product and business decisions. You thrive in a fast-paced environment and are capable of self-direction. You can take broad organizational goals and turn them into concise, effective deliverables. You will help set the vision for how we use data at Addepar and empower others in contributing toward that vision.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Build and maintain the data feeds that deliver raw data to the data warehouse.</li> <li>Define and maintain data models across all business intelligence databases and tools.</li> <li>Partner with BI analysts to define and implement data transformations to convert raw data into schemas consumed by downstream tools.</li> <li>Implement solutions to capture and process streaming data from the backend infrastructure and click-level data from the application.</li> <li>Become a power user of Snowflake, and take ownership in Addepar’s successful adoption by ensuring high standards of data quality, data discoverability, and query performance.</li> <li>Develop subject matter expertise in the Addepar product and the business tools upon which Addepar relies (including Periscope, Looker, and NetSuite).</li> <li>Partner with product, engineering, and business teams to help shape the future of data-driven decision-making at Addepar.</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>BS/MS in Computer Science, Statistics, Mathematics, or other quantitative field.</li> <li>5+ years of professional engineering experience in analytics, data warehousing, data operations, or related role.</li> <li>Expertise in writing, debugging, and optimizing SQL queries.</li> <li>Experience using python to build data feeds and/or analyze data.</li> <li>Experience with databases, data modeling, and data warehousing architecture.</li> <li>Experience with large-scale / streaming data processing tools including Kafka, Spark, and Flink.</li> <li>Experience with analytical/BI tools supporting data analysis, reporting, and visualization.</li> <li>Exceptional analytical and problem solving skills.</li> <li>Exceptional communication skills.</li> <br><br></ul>Addepar is a wealth management platform that specializes in data aggregation, analytics, and reporting for even the most complex investment portfolios. The company’s platform aggregates portfolio, market, and client data all in one place. It provides asset owners and advisors a clearer financial picture at every level, allowing them to make more informed and timely investment decisions. Addepar works with hundreds of leading financial advisors, family offices, and large financial institutions that manage data for over $2 trillion of assets on the company’s platform. In 2020, Addepar was named as a Forbes Fintech 50 and in 2018 received Morgan Stanley’s Fintech Award for making a significant impact on the firm’s mission of continuous innovation. Addepar is headquartered in Silicon Valley and has offices in New York City and Salt Lake City.<br><br>Addepar is an equal opportunity employer. We’re committed to building together and to do that best, we rely on a range of backgrounds, experiences, and ideas.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Junior Data Scientist,"Woodlawn, Maryland, United States",Mathematica,2021-02-19,https://www.linkedin.com/jobs/view/junior-data-scientist-at-mathematica-2419648148?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=gn2icsD3R9nQKAgsAsmHMA%3D%3D&position=16&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"OM1 is on a mission to improve health outcomes by unlocking the power of data. We are a healthcare data and technology company focused on improving real world clinical data and outcomes, accelerating medical research and personalizing healthcare. Our interdisciplinary team uses expertise in medicine, software, Big Data, machine learning, public health and mathematics to transform records from a diverse set of sources into enriched, research grade data. This data allows us to generate unique insights in a variety of disease areas.

As a Data Engineer, you'll build out and enhance big-data pipelines, code data-oriented product features, and analyze our complex data assets. The ideal candidate is a smart, creative, and curious analytical thinker who demonstrates strong software engineering skills and an excellent aptitude for data analysis. This is a key role within our Engineering team with responsibility for driving our high standards!

Responsibilities

Build, automate, and improve big-data pipelines
Code, test and deliver data-oriented product features
Integrate new data sources into our data asset
Model, enhance and enrich database schemas and underlying data
Craft scalable backend software and tools using modern software engineering practices
Analyze and interpret data flows, attributes, and quality



Requirements

Strong programming skills, preferably Python, Scala, Java, or similar
Excellent SQL skills
Solid understanding of software engineering principles
Comfort working in an Agile/Scrum environment with continuous delivery
A strong desire to advance healthcare and improve patient outcomes
Excellent attention to detail
NICE TO HAVE

Familiarity with cloud-based platforms such as AWS, Databricks, and/or Snowflake DB
Data processing experience with Python, Scala, Spark, and/or Airflow
Automated unit and integration testing experience
Experience with CI/CD tools such as Jenkins
Background in medical records and health insurance claims
Experience working on systems with strong security and privacy requirements
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">OM1 is on a mission to improve health outcomes by unlocking the power of data. We are a healthcare data and technology company focused on improving real world clinical data and outcomes, accelerating medical research and personalizing healthcare. Our interdisciplinary team uses expertise in medicine, software, Big Data, machine learning, public health and mathematics to transform records from a diverse set of sources into enriched, research grade data. This data allows us to generate unique insights in a variety of disease areas.<br><br>As a Data Engineer, you'll build out and enhance big-data pipelines, code data-oriented product features, and analyze our complex data assets. The ideal candidate is a smart, creative, and curious analytical thinker who demonstrates strong software engineering skills and an excellent aptitude for data analysis. This is a key role within our Engineering team with responsibility for driving our high standards!<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Build, automate, and improve big-data pipelines</li> <li>Code, test and deliver data-oriented product features</li> <li>Integrate new data sources into our data asset</li> <li>Model, enhance and enrich database schemas and underlying data</li> <li>Craft scalable backend software and tools using modern software engineering practices</li> <li>Analyze and interpret data flows, attributes, and quality</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Strong programming skills, preferably Python, Scala, Java, or similar</li> <li>Excellent SQL skills</li> <li>Solid understanding of software engineering principles</li> <li>Comfort working in an Agile/Scrum environment with continuous delivery</li> <li>A strong desire to advance healthcare and improve patient outcomes</li> <li>Excellent attention to detail</li> </ul>NICE TO HAVE<br><ul> <li>Familiarity with cloud-based platforms such as AWS, Databricks, and/or Snowflake DB</li> <li>Data processing experience with Python, Scala, Spark, and/or Airflow</li> <li>Automated unit and integration testing experience</li> <li>Experience with CI/CD tools such as Jenkins</li> <li>Background in medical records and health insurance claims</li> <li>Experience working on systems with strong security and privacy requirements</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Pharmaceuticals
Data and Analytics Engineer,"Hartford, Connecticut, United States",Travelers,2021-02-15,https://www.linkedin.com/jobs/view/data-and-analytics-engineer-at-travelers-2425078213?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=BSm7NmW%2FE0izfUZVIALVuQ%3D%3D&position=17&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Position Description

Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company’s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance.

We are looking for junior data scientists to lead and support data processing and analysis tasks, such as building data pipelines, monitoring data quality, developing documentation, applying statistical and data science methods, and creating data visualizations. Our junior data scientists underpin our company's core offerings in program improvement and data science, which yield crucial evidence and information for policy and decision makers. Junior data scientists are on the data scientist career track at Mathematica.

This position focuses on health policy, which includes projects such as:

Monitoring the impacts of an alternative payment model for primary care in terms of care quality, cost, and health outcomes for diverse beneficiaries, using claims from thousands of primary care practices across the country and predicting future hospital costs and behavior
Developing and testing how claims and survey data from federal and state-level programs could be used to measure patients’ experience of care, quality of life, care coordination, and long-term outcomes for beneficiaries enrolled in both Medicare and Medicaid
Creating an interactive data visualization tool to help local policy and decision makers understand how social determinants of health are related to health outcomes in their county, using open source data from public agencies and non-profits

Specifically, our junior data scientists contribute to team-based projects by:

Co-developing analysis plans with a data scientist
Leading and managing small teams and tasks with oversight from a data scientist
Writing and maintaining programming systems in languages such as Python and R to obtain, combine, and transform datasets on cloud, internal, and client servers
Developing and maintaining documentation
Implementing quality assurance practices, such as version control and testing
Conducting analysis and communicating results, both to internal teams and clients, such as descriptive statistics, data visualizations, and model diagnostics


Position Requirements

Master's degree, or bootcamp, with an excellent academic record, including courses in subjects such as statistics, data science, data analytics, mathematics, operations research, computer science, and/or social science
Demonstrated interest and/or experience using programming and data science and/or statistics to contribute to projects with a policy/social impact in academic and/or professional settings
At least three years of experience performing data cleaning and analysis using programming languages such as R or Python in the academic, extra-curricular, or professional environment
Experience executing data science and statistics techniques including machine learning algorithms, network analysis, or natural language processing
Ability and desire to work independently as part of an interdisciplinary team that may be geographically dispersed. This includes being able to learn resources such as self-guided tutorials, package documentation, and academic articles and willingness to constantly learn and contribute to knowledge sharing with team members.
Experience with reproducible research principles, version control, interactive visualizations, tidyverse, R Shiny, R Markdown, pandas, and/or scikit-learn
Desired but not required: experience with healthcare datasets (for example, Medicare or Medicaid claims and enrollment data), Bayesian statistics experience (especially with Stan), production-quality machine learning applications, cloud computing environments, and algorithmic fairness and ethics


To Apply, Please Submit

A cover letter
A resume
Salary expectations
A programming sample in one of the following languages: Python, R, Julia (Can be provided in the form of file attachment or GitHub repository link)

Various federal agencies with whom we contract require that staff successfully undergo a background investigation or security clearance as a condition of working on the project. If you are assigned to such a project, you will be required to obtain the requisite security clearance.

This position offers an anticipated annual base salary range of $60,000 - $121,000. This position may be eligible for a discretionary bonus based on company and individual performance.

Available locations: Washington, DC; Princeton, NJ; Cambridge, MA; Ann Arbor, MI; Woodlawn, MD; Oakland, CA.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Position Description<br><br></u></strong>Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company’s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance.<br><br>We are looking for junior data scientists to lead and support data processing and analysis tasks, such as building data pipelines, monitoring data quality, developing documentation, applying statistical and data science methods, and creating data visualizations. Our junior data scientists underpin our company's core offerings in program improvement and data science, which yield crucial evidence and information for policy and decision makers. Junior data scientists are on the data scientist career track at Mathematica.<br><br>This position focuses on health policy, which includes projects such as:<br><ul><li>Monitoring the impacts of an alternative payment model for primary care in terms of care quality, cost, and health outcomes for diverse beneficiaries, using claims from thousands of primary care practices across the country and predicting future hospital costs and behavior</li><li>Developing and testing how claims and survey data from federal and state-level programs could be used to measure patients’ experience of care, quality of life, care coordination, and long-term outcomes for beneficiaries enrolled in both Medicare and Medicaid</li><li>Creating an interactive data visualization tool to help local policy and decision makers understand how social determinants of health are related to health outcomes in their county, using open source data from public agencies and non-profits<br></li></ul>Specifically, our junior data scientists contribute to team-based projects by:<br><ul><li>Co-developing analysis plans with a data scientist</li><li>Leading and managing small teams and tasks with oversight from a data scientist</li><li>Writing and maintaining programming systems in languages such as Python and R to obtain, combine, and transform datasets on cloud, internal, and client servers</li><li>Developing and maintaining documentation</li><li>Implementing quality assurance practices, such as version control and testing</li><li>Conducting analysis and communicating results, both to internal teams and clients, such as descriptive statistics, data visualizations, and model diagnostics<br><br></li></ul><strong><u>Position Requirements<br></u></strong><ul><li>Master's degree, or bootcamp, with an excellent academic record, including courses in subjects such as statistics, data science, data analytics, mathematics, operations research, computer science, and/or social science</li><li>Demonstrated interest and/or experience using programming and data science and/or statistics to contribute to projects with a policy/social impact in academic and/or professional settings</li><li>At least three years of experience performing data cleaning and analysis using programming languages such as R or Python in the academic, extra-curricular, or professional environment</li><li>Experience executing data science and statistics techniques including machine learning algorithms, network analysis, or natural language processing</li><li>Ability and desire to work independently as part of an interdisciplinary team that may be geographically dispersed. This includes being able to learn resources such as self-guided tutorials, package documentation, and academic articles and willingness to constantly learn and contribute to knowledge sharing with team members.</li><li>Experience with reproducible research principles, version control, interactive visualizations, tidyverse, R Shiny, R Markdown, pandas, and/or scikit-learn</li><li>Desired but not required: experience with healthcare datasets (for example, Medicare or Medicaid claims and enrollment data), Bayesian statistics experience (especially with Stan), production-quality machine learning applications, cloud computing environments, and algorithmic fairness and ethics<br><br></li></ul><strong><u>To Apply, Please Submit<br></u></strong><ul><li>A cover letter</li><li>A resume</li><li>Salary expectations</li><li>A programming sample in one of the following languages: Python, R, Julia (Can be provided in the form of file attachment or GitHub repository link)<br></li></ul>Various federal agencies with whom we contract require that staff successfully undergo a background investigation or security clearance as a condition of working on the project. If you are assigned to such a project, you will be required to obtain the requisite security clearance.<br><br>This position offers an anticipated annual base salary range of $60,000 - $121,000. This position may be eligible for a discretionary bonus based on company and individual performance.<br><br>Available locations: Washington, DC; Princeton, NJ; Cambridge, MA; Ann Arbor, MI; Woodlawn, MD; Oakland, CA.<br><br>We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Nonprofit Organization Management, Financial Services, Hospital & Health Care"
Data Visualization Engineer,"Seattle, Washington, United States",98point6 Inc.,2021-02-17,https://www.linkedin.com/jobs/view/data-visualization-engineer-at-98point6-inc-2426699290?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=5rHKuysCJaTWI3NDPmgGCg%3D%3D&position=18&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Company Summary

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Target Openings
1

Job Description Summary

Are you seeking a dynamic, diverse and growth oriented environment in technology? Is passion for problem solving in your DNA? Are you seeking a company that offers comprehensive benefits including a pension and a matching 401K? Imagine the possibilities at Travelers!

We are seeking a Data and Analytics Engineer. Under limited supervision, performs expert programming, configuring, and/or analysis. Manages the effective use of team resources to implement ongoing projects, enhancements, and/or initiatives. Participates in the design/development process. Acts as subject matter expert for assigned applications, systems, and technologies. Leads investigation and resolution efforts for critical/high impact problems, defects and incidents. Provides technical guidance to team members. This job does not lead others.

Primary Job Duties & Responsibilities

Leads the effort to optimize the existing Cognos application portfolio and migrate them to Cloud compatible technology based applications, options could be Microstrategy or Qliksense. As part of the effort, there could be ETL work involved as well to optimize the data products for consumption.
Responsible for system programming and analysis tasks of advanced complexity within multiple systems.
Acts as subject matter expert for assigned applications, systems or technologies.
Responsible for transforming business specifications and requirements into organized technical activities.
Responsibilities include performing complex analysis, assessment, resolution, design, configuration and programming functions at an expert level.
Leads investigation and resolution efforts for critical/ high impact defects, problems, and incidents.
Collaborates with project team and other key stakeholders to identify, estimate, and prioritize project and/or enhancement activities.
Builds, maintains, and utilizes partnerships across the enterprise.
Provides team direction, mentorship, and feedback to technical resources.
Ensures work complies with Travelers standards, processes, and protocols.
Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.
Other duties as assigned.


Minimum Qualifications

A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience.


Education, Work Experience, & Knowledge

6 years of programming/development experience preferred.
Extensive hands-on experiences in Microstrategy and Qlikview/Qliksense
Overall strong knowledge and technical skills in ETL and Data warehouse
Experience with one or more Data platforms (e.g.: MongoDB, Teradata, Hadoop, Oracle, SQL Server, DB2)
Experience in ETL / Data Integration tools Talend, Python, Pyspark.
Exposure in Cloud Computing Technologies and related emerging technology (e.g. Amazon Web Services, Databricks, Qliksense)


Job Specific Technical Skills & Competencies

Technical Knowledge:

Able to expertly assess, design develop, and support applications, systems and solutions to achieve business and/or technical requirements.
Demonstrates technical expertise for multiple languages, applications, systems, technologies, and/or frameworks, and has the ability to influence technical direction or defect resolution.
Fully understands business applications and/or technical system environments in which the system operates.
Communication Skills:

Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.
Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.
Effectively contributes and communicates with the immediate team.
Able to present complex technical concepts to audiences of varying size and level.
Business Knowledge & Partnership:

Able to develop business partnerships and influence business priorities through solution identification aligned with business objectives and goals.
Able to communicate in business terms and describe IT capabilities and concepts in ways that the business can understand.
Problem Solving & Decision Making:

Able to proficiently diagnose root causes and solve complex problems.
Able to evaluate alternative solutions and assess risk before taking action.
Has the ability to reach sound decisions quickly and escalates appropriately.
Demonstrates ability to optimize the use of all available resources.
Team Orientation:

Able to maintain and enhance partnerships across the organization to achieve objectives.
Practices objectivity and openness to others' views.
Able to recognize and support team priorities.
Leadership:

Accountable to set technical goals and priorities for self and other team members.
Exhibits team leadership and collaborates with partners.
Planning and Project Management:
Demonstrates ability to identify critical project tasks and establish clear priorities while keeping the bigger picture in mind.
Able to effectively collaborate with Project Manager and utilize sound project management practices.
Able to manage time and competing priorities.
Financial Awareness: Able to assess the financial impact of recommended designs/solutions.
Environmental / Work Schedules / Other
Operates standard office equipment.
Requires extended periods of computer use.
Requires extended periods of sitting.


Employment Practices

Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

If you have questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company Summary<br><br></u></strong>Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.<br><br><strong>Target Openings<br></strong>1<br><br><strong><u>Job Description Summary<br><br></u></strong>Are you seeking a dynamic, diverse and growth oriented environment in technology? Is passion for problem solving in your DNA? Are you seeking a company that offers comprehensive benefits including a pension and a matching 401K? Imagine the possibilities at Travelers!<br><br>We are seeking a Data and Analytics Engineer. Under limited supervision, performs expert programming, configuring, and/or analysis. Manages the effective use of team resources to implement ongoing projects, enhancements, and/or initiatives. Participates in the design/development process. Acts as subject matter expert for assigned applications, systems, and technologies. Leads investigation and resolution efforts for critical/high impact problems, defects and incidents. Provides technical guidance to team members. This job does not lead others.<br><br><strong><u>Primary Job Duties &amp; Responsibilities<br></u></strong><ul><li>Leads the effort to optimize the existing Cognos application portfolio and migrate them to Cloud compatible technology based applications, options could be Microstrategy or Qliksense. As part of the effort, there could be ETL work involved as well to optimize the data products for consumption.</li><li>Responsible for system programming and analysis tasks of advanced complexity within multiple systems.</li><li>Acts as subject matter expert for assigned applications, systems or technologies.</li><li>Responsible for transforming business specifications and requirements into organized technical activities.</li><li>Responsibilities include performing complex analysis, assessment, resolution, design, configuration and programming functions at an expert level.</li><li>Leads investigation and resolution efforts for critical/ high impact defects, problems, and incidents.</li><li>Collaborates with project team and other key stakeholders to identify, estimate, and prioritize project and/or enhancement activities.</li><li>Builds, maintains, and utilizes partnerships across the enterprise.</li><li>Provides team direction, mentorship, and feedback to technical resources.</li><li>Ensures work complies with Travelers standards, processes, and protocols.</li><li>Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.</li><li>Other duties as assigned.<br><br></li></ul><strong><u>Minimum Qualifications<br></u></strong><ul><li>A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience.<br><br></li></ul><strong><u>Education, Work Experience, &amp; Knowledge<br></u></strong><ul><li>6 years of programming/development experience preferred.</li><li><strong>Extensive hands-on experiences in Microstrategy and Qlikview/Qliksense</strong></li><li><strong>Overall strong knowledge and technical skills in ETL and Data warehouse</strong></li><li>Experience with one or more Data platforms (e.g.: MongoDB, Teradata, Hadoop, Oracle, SQL Server, DB2)</li><li>Experience in ETL / Data Integration tools Talend, Python, Pyspark.</li><li>Exposure in Cloud Computing Technologies and related emerging technology (e.g. Amazon Web Services, Databricks, Qliksense)<br><br></li></ul><strong><u>Job Specific Technical Skills &amp; Competencies<br></u></strong><ul><li>Technical Knowledge:<br><ul><li>Able to expertly assess, design develop, and support applications, systems and solutions to achieve business and/or technical requirements.</li><li>Demonstrates technical expertise for multiple languages, applications, systems, technologies, and/or frameworks, and has the ability to influence technical direction or defect resolution.</li><li>Fully understands business applications and/or technical system environments in which the system operates.</li></ul></li><li>Communication Skills:<br><ul><li>Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.</li><li>Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.</li><li>Effectively contributes and communicates with the immediate team.</li><li>Able to present complex technical concepts to audiences of varying size and level.</li></ul></li><li>Business Knowledge &amp; Partnership:<br><ul><li>Able to develop business partnerships and influence business priorities through solution identification aligned with business objectives and goals.</li><li>Able to communicate in business terms and describe IT capabilities and concepts in ways that the business can understand.</li></ul></li><li>Problem Solving &amp; Decision Making:<br><ul><li>Able to proficiently diagnose root causes and solve complex problems.</li><li>Able to evaluate alternative solutions and assess risk before taking action.</li><li>Has the ability to reach sound decisions quickly and escalates appropriately.</li><li>Demonstrates ability to optimize the use of all available resources.</li></ul></li><li>Team Orientation:<br><ul><li>Able to maintain and enhance partnerships across the organization to achieve objectives.</li><li>Practices objectivity and openness to others' views.</li><li>Able to recognize and support team priorities.</li></ul></li><li>Leadership:<br><ul><li>Accountable to set technical goals and priorities for self and other team members.</li><li>Exhibits team leadership and collaborates with partners.</li><li>Planning and Project Management:</li><li>Demonstrates ability to identify critical project tasks and establish clear priorities while keeping the bigger picture in mind.</li><li>Able to effectively collaborate with Project Manager and utilize sound project management practices.</li><li>Able to manage time and competing priorities.</li></ul></li><li>Financial Awareness: Able to assess the financial impact of recommended designs/solutions.</li><li><strong>Environmental / Work Schedules / Other</strong></li><li>Operates standard office equipment.</li><li>Requires extended periods of computer use.</li><li>Requires extended periods of sitting.<br><br></li></ul><strong>Employment Practices<br><br></strong>Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.<br><br>If you have questions regarding the physical requirements of this role, please send us an email so we may assist you.<br><br>Travelers reserves the right to fill this position at a level above or below the level included in this posting.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Insurance, Financial Services"
Data Engineer,"Denver, Colorado, United States",DAT,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-dat-2428587537?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=tX3a8i9a8NlLTEWESBUksg%3D%3D&position=19&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Our mission is to deliver high-quality primary care that is accessible, convenient and affordable for all. Every single day you'll be working on challenging problems with an exceptional team to profoundly transform primary care and improve people's quality of life.

Your role and impact

As a Data Visualization Engineer, you will be part of a team dedicated to empowering business leaders to make data-driven decisions. You will collaborate with teams across the company to deliver thoughtful analyses and develop scalable data visualization solutions. You will also provide critical data and insights to our Product and Clinical Operations teams, enabling them to improve features and processes in ways that keep our service affordable while maintaining a high quality of care.

Strategic projects you will work on in your first year include:

Design and implement branded dashboards demonstrating how our customer populations utilize our service
Collaborate with product managers and designers in developing visualizations that enable deeper understanding of our virtual clinic performance
Build operational dashboards to drive organizational execution insights



Responsibilities

Design high-quality dashboards and visualizations that can be quickly and correctly interpreted by external and internal stakeholders
Identify insights that provide actionable recommendations to key stakeholders across the organization, specifically supporting sales, marketing, clinical operations and product
Serve as a catalyst for sharing knowledge, information and ideas throughout the company as it relates to the business intelligence function
Ensure existing dashboards are properly maintained and updated in an environment where data size and complexity is quickly growing as the business scales
Automate standard report creation and sharing using tools or scripts
Mentor and collaborate with a diverse group of business intelligence and data engineers at all levels



Qualifications

3+ years using Tableau, or similar data visualization tool, to generate complex dashboards and support internal business functions
2+ years using SQL to analyze data in a data warehouse
2+ years applying data modeling and fundamental core database concepts
1+ years coding with scripting languages (R, Python, Javascript) to do data manipulation, data analysis and reporting
Strong interest in extracting and transforming a high volume of data into actionable business insights
Ability to work cross-functionally, be detail-oriented and build and maintain trust with internal stakeholders in a fast and agile development environment
Experience communicating findings to stakeholders at various levels in the company, including leadership


98point6 provides equal employment opportunities to all without regard to race, color, religion, sex (including sexual orientation or gender identity), national origin, age, disability, genetic information or other protected status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Our mission is to deliver high-quality primary care that is accessible, convenient and affordable for all. Every single day you'll be working on challenging problems with an exceptional team to profoundly transform primary care and improve people's quality of life.<br><br><strong>Your role and impact<br><br></strong>As a Data Visualization Engineer, you will be part of a team dedicated to empowering business leaders to make data-driven decisions. You will collaborate with teams across the company to deliver thoughtful analyses and develop scalable data visualization solutions. You will also provide critical data and insights to our Product and Clinical Operations teams, enabling them to improve features and processes in ways that keep our service affordable while maintaining a high quality of care.<br><br><strong>Strategic projects you will work on in your first year include:<br></strong><ul> <li>Design and implement branded dashboards demonstrating how our customer populations utilize our service</li> <li>Collaborate with product managers and designers in developing visualizations that enable deeper understanding of our virtual clinic performance</li> <li>Build operational dashboards to drive organizational execution insights</li> <br><br></ul><strong><u>Responsibilities<br></u></strong><ul> <li>Design high-quality dashboards and visualizations that can be quickly and correctly interpreted by external and internal stakeholders</li> <li>Identify insights that provide actionable recommendations to key stakeholders across the organization, specifically supporting sales, marketing, clinical operations and product</li> <li>Serve as a catalyst for sharing knowledge, information and ideas throughout the company as it relates to the business intelligence function</li> <li>Ensure existing dashboards are properly maintained and updated in an environment where data size and complexity is quickly growing as the business scales</li> <li>Automate standard report creation and sharing using tools or scripts</li> <li>Mentor and collaborate with a diverse group of business intelligence and data engineers at all levels</li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li>3+ years using Tableau, or similar data visualization tool, to generate complex dashboards and support internal business functions</li> <li>2+ years using SQL to analyze data in a data warehouse</li> <li>2+ years applying data modeling and fundamental core database concepts</li> <li>1+ years coding with scripting languages (R, Python, Javascript) to do data manipulation, data analysis and reporting </li> <li>Strong interest in extracting and transforming a high volume of data into actionable business insights</li> <li>Ability to work cross-functionally, be detail-oriented and build and maintain trust with internal stakeholders in a fast and agile development environment</li> <li>Experience communicating findings to stakeholders at various levels in the company, including leadership</li> <br></ul><em>98point6 provides equal employment opportunities to all without regard to race, color, religion, sex (including sexual orientation or gender identity), national origin, age, disability, genetic information or other protected status.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Data Engineer,"Remote, Oregon, United States",Taos,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-taos-2415323455?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=J0%2BSqmz0pKeJOh1f8zhpCA%3D%3D&position=20&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"DAT Software & Analytics is seeking a Data Engineer to join our Data and Engineering team in Beaverton, Oregon.

DAT’s industry dominant network of carriers, brokers and shippers makes our data an immensely valuable asset to the industry.

The range of responsibilities of the Data Engineer are broad and range from traditional ETL & SQL solutions to building cloud infrastructure and serverless data processing solutions (e.g. AWS Lambdas) for sophisticated machine learning models. In this role you will be part of a supportive, collaborative, and diverse team responsible for exploring, making recommendations, and implementing enterprise data solutions primarily in our snowflake data warehouse.

What You’ll Do

Working closely with product teams and data scientists to determine how to capture, persist, and maintain data
Building distributed, scalable, and reliable data pipelines that ingest and process data at scale with ever diminishing time processing windows
Leverage AWS to deliver efficient, cloud-native solutions
Identifying opportunities in our data landscape where we need data enrichment
Identifying and make recommendations on data storage solutions using alternate technologies
Analyzing and recommending alternate persistence solutions
Serving as a resource for the Data Sciences team by partnering with them to make production quality and supportable solutions
Gathering requirements from analysts and the larger business community to optimize, unify, and simplify data according to business needs
Working either independently on projects or in collaborative teams depending upon the needs of the effort



The Skills You’ll Need

Exceptional ELT/ETL background with data transformation and operational experience
Strong SQL Proficiency with Snowflake including analytic queries and other complex use cases
Experience with SQL Query Tuning, data investigation, and optimization
Experience with Snowflake cloud data warehouse administration.
Experience modeling star schemas and other summary objects based on business requirements
Experience building large data stores, modern data warehouse, or advanced data processing solutions
Experience with AWS tools and infrastructure. Particularly in regards to s3 storage, data pipelines, and serverless AWS compute services (e.g. Lambdas)
Deployment pipeline and infrastructure as code and deployment pipeline experience on a cloud platform such as AWS



Bonus Skills

Understanding of Oracle, SQL Server, Mongo and other database systems
Scripting experience with Powershell and Python
Experience with WhereScape RED ELT Software
Understanding of modern data warehouse architectures such as data vault



About DAT

DAT Software and Analytics is a next-generation SaaS technology company that has been at the leading edge of innovation in transportation supply chain logistics for 43 years. We continue to transform the industry year over year, by deploying a suite of software solutions to millions of customers every day - customers who depend on DAT for the most relevant data and most accurate insights to help them make smarter business decisions and run their companies more profitably. We operate the largest marketplace of its kind in North America, with 226 million freight posts in 2020, and a database of $110 billion of annual global shipment market transaction data. DAT is based in Beaverton, OR, with offices in Colorado, Missouri, Texas, and Bangalore, India.

For Additional Information, See Www.DAT.com/company

DAT Software and Analytics embraces the value of a diverse workforce, and believes it is a core strength of our company that we encourage those values in every DAT employee, at every level of our organization, regardless of tenure or rank. We provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.

DAT Software and Analytics offers competitive compensation and an excellent benefit package that includes medical, dental, and vision coverage, flexible savings accounts, 401K, Life and AD&D insurance, a comprehensive Paid Leave program, and a Tuition Reimbursement program.

All referrals and résumés are managed exclusively through the Human Resources Department.

DAT Software and Analytics will not consider unsolicited résumés from vendors including search firms, fee-based referral services, and/or recruitment agencies.
Administration
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">DAT Software &amp; Analytics is seeking <strong>a Data Engineer</strong> to join our Data and Engineering team in Beaverton, Oregon.<br><br>DAT’s industry dominant network of carriers, brokers and shippers makes our data an immensely valuable asset to the industry.<br><br>The range of responsibilities of the Data Engineer are broad and range from traditional ETL &amp; SQL solutions to building cloud infrastructure and serverless data processing solutions (e.g. AWS Lambdas) for sophisticated machine learning models. In this role you will be part of a supportive, collaborative, and diverse team responsible for exploring, making recommendations, and implementing enterprise data solutions primarily in our snowflake data warehouse.<br><br><strong><u>What You’ll Do<br></u></strong><ul><li>Working closely with product teams and data scientists to determine how to capture, persist, and maintain data</li> <li>Building distributed, scalable, and reliable data pipelines that ingest and process data at scale with ever diminishing time processing windows</li> <li>Leverage AWS to deliver efficient, cloud-native solutions</li> <li>Identifying opportunities in our data landscape where we need data enrichment</li> <li>Identifying and make recommendations on data storage solutions using alternate technologies</li> <li>Analyzing and recommending alternate persistence solutions </li> <li>Serving as a resource for the Data Sciences team by partnering with them to make production quality and supportable solutions </li> <li>Gathering requirements from analysts and the larger business community to optimize, unify, and simplify data according to business needs</li> <li>Working either independently on projects or in collaborative teams depending upon the needs of the effort</li> <br><br></ul><strong><u>The Skills You’ll Need<br></u></strong><ul><li>Exceptional ELT/ETL background with data transformation and operational experience </li> <li>Strong SQL Proficiency with Snowflake including analytic queries and other complex use cases</li> <li>Experience with SQL Query Tuning, data investigation, and optimization</li> <li>Experience with Snowflake cloud data warehouse administration. </li> <li>Experience modeling star schemas and other summary objects based on business requirements</li> <li>Experience building large data stores, modern data warehouse, or advanced data processing solutions</li> <li>Experience with AWS tools and infrastructure. Particularly in regards to s3 storage, data pipelines, and serverless AWS compute services (e.g. Lambdas)</li> <li>Deployment pipeline and infrastructure as code and deployment pipeline experience on a cloud platform such as AWS</li> <br><br></ul><strong><u>Bonus Skills<br></u></strong><ul><li>Understanding of Oracle, SQL Server, Mongo and other database systems</li> <li>Scripting experience with Powershell and Python</li> <li>Experience with WhereScape RED ELT Software</li> <li>Understanding of modern data warehouse architectures such as data vault</li> <br><br></ul><strong><u>About DAT<br><br></u></strong>DAT Software and Analytics is a next-generation SaaS technology company that has been at the leading edge of innovation in transportation supply chain logistics for 43 years. We continue to transform the industry year over year, by deploying a suite of software solutions to millions of customers every day - customers who depend on DAT for the most relevant data and most accurate insights to help them make smarter business decisions and run their companies more profitably. We operate the largest marketplace of its kind in North America, with 226 million freight posts in 2020, and a database of $110 billion of annual global shipment market transaction data. DAT is based in Beaverton, OR, with offices in Colorado, Missouri, Texas, and Bangalore, India.<br><br><strong><u>For Additional Information, See Www.DAT.com/company<br><br></u></strong>DAT Software and Analytics embraces the value of a diverse workforce, and believes it is a core strength of our company that we encourage those values in every DAT employee, at every level of our organization, regardless of tenure or rank. We provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.<br><br>DAT Software and Analytics offers competitive compensation and an excellent benefit package that includes medical, dental, and vision coverage, flexible savings accounts, 401K, Life and AD&amp;D insurance, a comprehensive Paid Leave program, and a Tuition Reimbursement program.<br><br>All referrals and résumés are managed exclusively through the Human Resources Department.<br><br>DAT Software and Analytics will not consider unsolicited résumés from vendors including search firms, fee-based referral services, and/or recruitment agencies.<br>Administration</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Human Resources
Software Engineer - Data Platform Engineer,"Boston, Massachusetts, United States",Numerated,2021-02-19,https://www.linkedin.com/jobs/view/software-engineer-data-platform-engineer-at-numerated-2415641899?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=4s67hc63PdQsFUxd%2F2rOWA%3D%3D&position=21&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Taos is looking for a Sr Data Engineer to join our team for an exciting project. We are looking for an expert with data APIs, JSON, and unstructured data sources.

The Candidate Will Also Need The Following Skills

Experience using ETL tools to translate unstructured data into relational data for use in Data Warehousing, reporting, and BI

Experience building/designing Data Warehouses using best practices and cutting edge tools

The ability to build or at least design ETL processes using IPaaS’s

Experience with Mulesoft is critical

Who is Taos?

Taos helps today’s enterprises and rapidly growing businesses harness the power of the cloud and DevOps with digital transformation and optimization solutions. From Executive Leadership to our delivery teams, Taos listens, understands, and delivers best-in-class work. Our deep technical expertise and solutions-driven approach help address our client’s biggest business challenges and opportunities. As a Global Leader of Cloud and DevOps, Taos continues to solve What’s Next.

Talent at our Core®

Taos Consultants are adaptable problem-solvers, growth-minded doers, and lifelong learners.

Thanks to this mindset, we have helped thousands of clients achieve their goals and solve their challenges. From Cloud Architects to Security Analysts to DevOps Engineers, Taos is always seeking the best and brightest technical talent. Joining Taos gives you the opportunity to work with national enterprises and innovative Silicon Valley companies. Our model provides the support and benefits of full-time employment while giving you exposure to a variety of environments and technologies to sharpen your skills and deepen your technical expertise. These advantages combined with competitive benefits, continuous training and education, and a clear career progression path make Taos a great place to work.

Referrals

We love referrals so much that we pay for them! If you know someone that you would recommend, send an email to referrals@taos.com or Contact Us and we will do the rest! We'll make sure that you receive the $1000 referral bonus after they are employed with us.

Compensation

Our compensation package includes a competitive salary, medical and dental insurance, 401k, paid vacation, sick time and holiday pay, plus loads of free training (Puppet, Chef, Nagios, LAMP Stack, PMP, ITIL, Python, etc.)!

Equal Opportunity

Taos Mountain, LLC is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age, status as a protected veteran, or status as a qualified individual with disability.

Veterans are encouraged to apply!

E-Verify Participant

This employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employee’s Form I-9 to confirm work authorization. Please go to http://www.taos.com/join-our-team/ and review the E-Verify Participant and Right to Work links for more information.

#DICE
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Taos is looking for a Sr Data Engineer to join our team for an exciting project. We are looking for an expert with data APIs, JSON, and unstructured data sources.<br><br><strong><u>The Candidate Will Also Need The Following Skills<br><br></u></strong>Experience using ETL tools to translate unstructured data into relational data for use in Data Warehousing, reporting, and BI<br><br>Experience building/designing Data Warehouses using best practices and cutting edge tools<br><br>The ability to build or at least design ETL processes using IPaaS’s<br><br>Experience with Mulesoft is critical<br><br><strong>Who is Taos? <br><br></strong>Taos helps today’s enterprises and rapidly growing businesses harness the power of the cloud and DevOps with digital transformation and optimization solutions. From Executive Leadership to our delivery teams, Taos listens, understands, and delivers best-in-class work. Our deep technical expertise and solutions-driven approach help address our client’s biggest business challenges and opportunities. As a Global Leader of Cloud and DevOps, Taos continues to solve What’s Next.<br><br><strong>Talent at our Core®<br><br></strong>Taos Consultants are adaptable problem-solvers, growth-minded doers, and lifelong learners.<br><br>Thanks to this mindset, we have helped thousands of clients achieve their goals and solve their challenges. From Cloud Architects to Security Analysts to DevOps Engineers, Taos is always seeking the best and brightest technical talent. Joining Taos gives you the opportunity to work with national enterprises and innovative Silicon Valley companies. Our model provides the support and benefits of full-time employment while giving you exposure to a variety of environments and technologies to sharpen your skills and deepen your technical expertise. These advantages combined with competitive benefits, continuous training and education, and a clear career progression path make Taos a great place to work.<br><br><strong><u>Referrals<br><br></u></strong>We love referrals so much that we pay for them! If you know someone that you would recommend, send an email to referrals@taos.com or Contact Us and we will do the rest! We'll make sure that you receive the $1000 referral bonus after they are employed with us.<br><br><strong><u>Compensation<br><br></u></strong>Our compensation package includes a competitive salary, medical and dental insurance, 401k, paid vacation, sick time and holiday pay, plus loads of free training (Puppet, Chef, Nagios, LAMP Stack, PMP, ITIL, Python, etc.)!<br><br><strong><u>Equal Opportunity<br><br></u></strong>Taos Mountain, LLC is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age, status as a protected veteran, or status as a qualified individual with disability.<br><br>Veterans are encouraged to apply!<br><br><strong><u>E-Verify Participant<br><br></u></strong>This employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employee’s Form I-9 to confirm work authorization. Please go to http://www.taos.com/join-our-team/ and review the E-Verify Participant and Right to Work links for more information.<br><br>#DICE</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Networking, Computer Software, Information Technology and Services"
Data Engineer,"Remote, Oregon, United States",Airtime,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-airtime-2408959982?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=SRRa3Qyu%2FQROVUSnGTuSoA%3D%3D&position=22&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Overview /

We are seeking a Software Engineer to help build the next generation data platform for Numerated. As a key member of the data engineering team, you will help build a platform in AWS that supports both streaming and batch workloads, and can bring vital information to our banking clients. Our platform will evolve to adapt to constantly changing business requirements while enforcing strict data quality standards and preserving data integrity.

If you are interested in joining a collaborative team, working on pioneering technology, in an exciting phase of company growth -- we want to hear from you!

Essential Responsibilities /

Be a member of a scrum team to deliver shippable quality code every sprint
Deliver full-stack capabilities in our modern, developer-driven tech stack: Angular / Python / Postgres / Snowflake
Participate in code reviews and contribute to automated tests
Understand the importance of continuous integration and testing
Provide ongoing maintenance, support and enhancements to existing systems and platforms
Continue to grow your skill set and tool kit, continuously improving the quality of deliverables by authoring well-engineered solutions using test-first/test-driven mindset
Consistently apply best practices for design, coding standards, performance, security, delivery, and maintainability
Contribute to the continuous improvement of your team
Demonstrate ownership of developed components from development through production
Exemplify the principles behind Scrum and the Agile Manifesto in all interactions


Education Requirements /

Bachelor’s degree in computer science, information systems or related technical field required
Master’s degree in computer science, information systems or related technical field preferred


Work Experience Requirements /

Significant past experience with SQL, dimensional data modeling, relational and columnar databases
Experience with AWS desired, particularly Glue, EMR, Lambda, Kinesis or other data-related services. Working knowledge of Linux.
Experience in developing and working with data ingestion pipelines for analytics desired.
Experience with distributed computation platforms such as Apache Spark, Kafka, Presto.
Proficiency with Angular and Python, facility with other languages desirable: Java, NodeJS, Scala, OS scripting.
A professional attitude with strong interpersonal and communication skills at different levels - frequent video communication with remote teams required.
You're known as a creative, innovative and outside-the-box thinker, unafraid to express your ideas with other team members including those with more seniority.
You thrive in a fast-paced environment, and given context, you're capable of self-direction when solving difficult problems in creative ways and making a real impact to the business.
You have a passion for keeping up with the rapidly changing data technical landscape.
Demonstrated ability to work effectively in a fast-paced, team-oriented work environment.
Outstanding written and verbal communication skills.


About Numerated

Numerated is a fast-growing, venture-backed financial technology company powering digital transformation at banks. The platform makes originating bank products exceptionally easy by using data to remove work otherwise required from customers and lenders. Numerated works with over 100 banks and credit unions and has decisioned nearly $20 billion in lending. The Numerated platform was originally incubated inside one of the highest volume SBA banks in the country before spinning out of the bank in a high-profile round of venture capital financing. Investors include Patriot Financial Partners, FINTOP Capital, Hyperplane, and Venrock, one of the world’s leading venture capital firms with prior investments in Apple, DoubleClick, Endeca, and Intel. Numerated was recently recognized as one of the fastest growing fintechs in the world on CB Insights' ""2020 Fintech 250"" list, was named “2020’s Best Overall FinTech Software” by FinTech Breakthrough, and named “2020’s Most Innovative Industry Partner” by Barlow Research.

Our great people are at the heart of our company and key to our success. As a mostly remote workforce, we’re looking for more smart, driven, and down-to-earth Numerators to join our rapidly growing team. Our culture is open and flexible; our benefits range from 401(k) to care packages arriving at your house; and while we’re making a serious impact on banks, we always have time for witty puns and good laughs.

If you are interested in joining a collaborative team, working on pioneering technology, in an exciting phase of company growth – apply today!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Overview </strong><strong>/<br><br></strong>We are seeking a Software Engineer to help build the next generation data platform for Numerated. As a key member of the data engineering team, you will help build a platform in AWS that supports both streaming and batch workloads, and can bring vital information to our banking clients. Our platform will evolve to adapt to constantly changing business requirements while enforcing strict data quality standards and preserving data integrity.<br><br>If you are interested in joining a collaborative team, working on pioneering technology, in an exciting phase of company growth -- we want to hear from you!<br><br><strong><u>Essential Responsibilities /<br></u></strong><ul><li>Be a member of a scrum team to deliver shippable quality code every sprint</li><li>Deliver full-stack capabilities in our modern, developer-driven tech stack: Angular / Python / Postgres / Snowflake</li><li>Participate in code reviews and contribute to automated tests</li><li>Understand the importance of continuous integration and testing</li><li>Provide ongoing maintenance, support and enhancements to existing systems and platforms</li><li>Continue to grow your skill set and tool kit, continuously improving the quality of deliverables by authoring well-engineered solutions using test-first/test-driven mindset</li><li>Consistently apply best practices for design, coding standards, performance, security, delivery, and maintainability</li><li>Contribute to the continuous improvement of your team</li><li>Demonstrate ownership of developed components from development through production</li><li>Exemplify the principles behind Scrum and the Agile Manifesto in all interactions<br><br></li></ul><strong>Education Requirements </strong><strong>/<br></strong><ul><li>Bachelor’s degree in computer science, information systems or related technical field required </li><li>Master’s degree in computer science, information systems or related technical field preferred<br><br></li></ul><strong><u>Work Experience Requirements /<br></u></strong><ul><li>Significant past experience with SQL, dimensional data modeling, relational and columnar databases</li><li>Experience with AWS desired, particularly Glue, EMR, Lambda, Kinesis or other data-related services. Working knowledge of Linux. </li><li>Experience in developing and working with data ingestion pipelines for analytics desired.</li><li>Experience with distributed computation platforms such as Apache Spark, Kafka, Presto.</li><li>Proficiency with Angular and Python, facility with other languages desirable: Java, NodeJS, Scala, OS scripting.</li><li>A professional attitude with strong interpersonal and communication skills at different levels - frequent video communication with remote teams required.</li><li>You're known as a creative, innovative and outside-the-box thinker, unafraid to express your ideas with other team members including those with more seniority.</li><li>You thrive in a fast-paced environment, and given context, you're capable of self-direction when solving difficult problems in creative ways and making a real impact to the business.</li><li>You have a passion for keeping up with the rapidly changing data technical landscape.</li><li>Demonstrated ability to work effectively in a fast-paced, team-oriented work environment.</li><li>Outstanding written and verbal communication skills.<br><br></li></ul><strong><u>About Numerated<br><br></u></strong>Numerated is a fast-growing, venture-backed financial technology company powering digital transformation at banks. The platform makes originating bank products exceptionally easy by using data to remove work otherwise required from customers and lenders. Numerated works with over 100 banks and credit unions and has decisioned nearly $20 billion in lending. The Numerated platform was originally incubated inside one of the highest volume SBA banks in the country before spinning out of the bank in a high-profile round of venture capital financing. Investors include Patriot Financial Partners, FINTOP Capital, Hyperplane, and Venrock, one of the world’s leading venture capital firms with prior investments in Apple, DoubleClick, Endeca, and Intel. Numerated was recently recognized as one of the fastest growing fintechs in the world on CB Insights' ""2020 Fintech 250"" list, was named “2020’s Best Overall FinTech Software” by FinTech Breakthrough, and named “2020’s Most Innovative Industry Partner” by Barlow Research.<br><br>Our great people are at the heart of our company and key to our success. As a mostly remote workforce, we’re looking for more smart, driven, and down-to-earth Numerators to join our rapidly growing team. Our culture is open and flexible; our benefits range from 401(k) to care packages arriving at your house; and while we’re making a serious impact on banks, we always have time for witty puns and good laughs.<br><br>If you are interested in joining a collaborative team, working on pioneering technology, in an exciting phase of company growth – apply today!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"San Francisco, California, United States",Fast,2021-02-06,https://www.linkedin.com/jobs/view/data-engineer-at-fast-2411574704?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=25iwwkHUEbDaFb9horrkng%3D%3D&position=23&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Airtime’s Mission

Our mission is to empower people to create thriving online communities around shared interests, experiences, and passions. A goal like that doesn’t happen without an amazing team. With over 100 wonderful people in three offices across the country, we’re working hard to create the most welcoming online live social space out there, not only in our product but also in our organization.

In This Role

The Data Engineer will deliver data solutions, pertaining to strategic operations, that provide Airtime the ability to utilize data in unique ways not provided by Airtime’s current data architecture. This will allow the Analytics team to optimize: Data access, data creation, data measurement and data analysis of the Airtime application. In order to deliver this goal, the Data Engineer will partner with the Data Science Team to deliver data solutions that support the overall strategic goals of the company and ensure optimal data delivery throughout ongoing projects.

What You’ll Do

Create and maintain an optimal data pipeline architecture within the Airtime data infrastructure
Identify, design, and implement internal process improvements by automating manual processes; optimizing data storage, delivery, and visualization; etc.
Employ an array of technological languages and tools to connect data systems together
Build key working relationships with The Data Science Team and The Airtime IT Team to ensure alignment and support of all projects and systems
Test, debug, and audit custom scripts to ensure data accuracy
Ensure that all systems meet the business/company requirements as well as industry best practices
Create custom software components and analytic tools that utilize the data pipeline to provide actionable insights into key performance metrics to assist with growing and optimization of the Airtime application



What You’ll Bring To The Table

At least 3 years of experience working in data and analytics
Experience with Amazon REDSHIFT, MongoDB, Amazon Aurora, Looker etc.
Proficiency using object-oriented scripting languages: Python, PHP, Java, etc.
Familiarity with front-end technologies and data visualization: HTML5, JavaScript, d3.js, etc.
Experience designing and querying relational SQL databases: Postgres & MySQL
Proficient at web server administration (Apache, Node) with expertise with Ubuntu Linux and command line interfaces.
Experience with REST APIs
Proficient in code versioning tools: Git, etc.
In-depth understanding of the software development lifecycle
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Airtime’s Mission<br><br></u></strong>Our mission is to empower people to create thriving online communities around shared interests, experiences, and passions. A goal like that doesn’t happen without an amazing team. With over 100 wonderful people in three offices across the country, we’re working hard to create the most welcoming online live social space out there, not only in our product but also in our organization.<br><br><strong><u>In This Role<br><br></u></strong>The Data Engineer will deliver data solutions, pertaining to strategic operations, that provide Airtime the ability to utilize data in unique ways not provided by Airtime’s current data architecture. This will allow the Analytics team to optimize: Data access, data creation, data measurement and data analysis of the Airtime application. In order to deliver this goal, the Data Engineer will partner with the Data Science Team to deliver data solutions that support the overall strategic goals of the company and ensure optimal data delivery throughout ongoing projects.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Create and maintain an optimal data pipeline architecture within the Airtime data infrastructure</li> <li>Identify, design, and implement internal process improvements by automating manual processes; optimizing data storage, delivery, and visualization; etc.</li> <li>Employ an array of technological languages and tools to connect data systems together</li> <li>Build key working relationships with The Data Science Team and The Airtime IT Team to ensure alignment and support of all projects and systems</li> <li>Test, debug, and audit custom scripts to ensure data accuracy</li> <li>Ensure that all systems meet the business/company requirements as well as industry best practices</li> <li>Create custom software components and analytic tools that utilize the data pipeline to provide actionable insights into key performance metrics to assist with growing and optimization of the Airtime application</li> <br><br></ul><strong><u>What You’ll Bring To The Table<br></u></strong><ul> <li>At least 3 years of experience working in data and analytics</li> <li>Experience with Amazon REDSHIFT, MongoDB, Amazon Aurora, Looker etc.</li> <li>Proficiency using object-oriented scripting languages: Python, PHP, Java, etc.</li> <li>Familiarity with front-end technologies and data visualization: HTML5, JavaScript, d3.js, etc.</li> <li>Experience designing and querying relational SQL databases: Postgres &amp; MySQL</li> <li>Proficient at web server administration (Apache, Node) with expertise with Ubuntu Linux and command line interfaces.</li> <li>Experience with REST APIs</li> <li>Proficient in code versioning tools: Git, etc.</li> <li>In-depth understanding of the software development lifecycle</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Online Media, Internet"
Python Software Engineer,"Jacksonville, Florida, United States",Urban SDK,2021-02-17,https://www.linkedin.com/jobs/view/python-software-engineer-at-urban-sdk-2395120588?refId=61c4a7be-f8aa-4221-b0f0-4639c03a26ee&trackingId=OC1yk5HCgHGa9CT8FOsTYQ%3D%3D&position=24&pageNum=2&trk=public_jobs_job-result-card_result-card_full-click,"Build the world's fastest Identity and Checkout products

Company Mission

Our mission is to make buying online faster, safer and easier for everyone. Fast Login and Fast Checkout enable a one-click sign-in and purchasing experience that makes it easier for people to buy and merchants to sell. The company’s products work on any browser, device or platform to deliver a consistent, stress-free purchasing experience. Fast is entirely consumer-focused and invests heavily in its users’ privacy and data security. Headquartered in San Francisco but open to globally remote, we are a founders-led, privately held company funded by Stripe, Index Ventures, Susa Ventures and other world-class investors.

We are committed to diversity and inclusion, and demonstrate our values through equitable pay, fantastic benefits, and access to all reasonable accommodations.

Summary

As a Data Engineer at Fast, you will write data solutions, transform, and optimize large sets of raw and processed data, and implement data architectures used at Fast to support our product features. You would optimize data flow and representation to be consumed by distributed systems, reporting, analytics and machine learning, and will work closely with the engineering teams to architect solutions that enable robust and scalable data access and analysis.

Role

Interface with engineers, product managers and machine learning scientists/engineers to understand data needs and implement robust and scalable solutions
Work directly with DS scientists/engineers to implement robust and reusable data models
Build out automated solutions for ML feature testing, validation, and release
Implement and maintain a data version control system
Enable automated data preparation for model training
Ensure data quality and accessibility for all types of data used at Fast
Design, build, enhance, and launch ETL processes for new and existing data sources
Augment existing data with output from machine learning analysis/algorithms
Systematically identify and rectify data quality issues (missing data, mislabeled, old, poor schema/model, etc)
Produce basic statistical analyses and visualizations to help guide product and business decisions
Requirements

Bachelor’s degree in a technical field (computer science, engineering, mathematics, informatics); advanced degree preferred (or equivalent experience)
4+ years of industry data engineering experience, including experience in ETL design, implementation and maintenance
Proven experience in the data warehouse space, as well as schema design and dimensional data modeling
Profound knowledge of SQL and python
Practical application of basic statistical methods
Basic experience working on machine learning projects
Bonus

Prior working experience with FinTech, payments, identity, and wearable devices
Data visualization skills (R, python, Tableau)
Familiarity with tools for analysis of very large datasets
Benefits of life @ Fast


Fast Flex allows all of our employees to choose where they want to work: our office (when open), their home or any place else in the world.
Early stage well-funded company with innovative engineering and product culture
Inclusion and diversity as a company priority
Competitive compensation packages
Comprehensive benefits (including 99% of healthcare cost and 401k matching)
Home office reimbursements and snack deliveries (and awesome swag!)
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Build the world's fastest Identity and Checkout products<br><br>Company Mission<br><br>Our mission is to make buying online faster, safer and easier for everyone. Fast Login and Fast Checkout enable a one-click sign-in and purchasing experience that makes it easier for people to buy and merchants to sell. The company’s products work on any browser, device or platform to deliver a consistent, stress-free purchasing experience. Fast is entirely consumer-focused and invests heavily in its users’ privacy and data security. Headquartered in San Francisco but open to globally remote, we are a founders-led, privately held company funded by Stripe, Index Ventures, Susa Ventures and other world-class investors.<br><br>We are committed to diversity and inclusion, and demonstrate our values through equitable pay, fantastic benefits, and access to all reasonable accommodations.<br><br><strong> Summary <br><br></strong>As a Data Engineer at Fast, you will write data solutions, transform, and optimize large sets of raw and processed data, and implement data architectures used at Fast to support our product features. You would optimize data flow and representation to be consumed by distributed systems, reporting, analytics and machine learning, and will work closely with the engineering teams to architect solutions that enable robust and scalable data access and analysis.<br><br>Role<br><ul><li>Interface with engineers, product managers and machine learning scientists/engineers to understand data needs and implement robust and scalable solutions</li><li>Work directly with DS scientists/engineers to implement robust and reusable data models</li><li>Build out automated solutions for ML feature testing, validation, and release</li><li>Implement and maintain a data version control system</li><li>Enable automated data preparation for model training</li><li>Ensure data quality and accessibility for all types of data used at Fast</li><li>Design, build, enhance, and launch ETL processes for new and existing data sources</li><li>Augment existing data with output from machine learning analysis/algorithms</li><li>Systematically identify and rectify data quality issues (missing data, mislabeled, old, poor schema/model, etc)</li><li>Produce basic statistical analyses and visualizations to help guide product and business decisions</li></ul>Requirements<br><ul><li>Bachelor’s degree in a technical field (computer science, engineering, mathematics, informatics); advanced degree preferred (or equivalent experience)</li><li>4+ years of industry data engineering experience, including experience in ETL design, implementation and maintenance</li></ul><ul><li>Proven experience in the data warehouse space, as well as schema design and dimensional data modeling</li></ul><ul><li>Profound knowledge of SQL and python</li><li>Practical application of basic statistical methods</li><li>Basic experience working on machine learning projects</li></ul>Bonus<br><ul><li>Prior working experience with FinTech, payments, identity, and wearable devices</li><li>Data visualization skills (R, python, Tableau)</li><li>Familiarity with tools for analysis of very large datasets</li></ul>Benefits of life @ Fast<br><br><li>Fast Flex allows all of our employees to choose where they want to work: our office (when open), their home or any place else in the world.</li><li>Early stage well-funded company with innovative engineering and product culture</li><li>Inclusion and diversity as a company priority</li><li>Competitive compensation packages</li><li>Comprehensive benefits (including 99% of healthcare cost and 401k matching)</li><li>Home office reimbursements and snack deliveries (and awesome swag!)</li></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Data Engineer,"Fort Lauderdale, Florida, United States",CBS Interactive,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-cbs-interactive-2417164034?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=oKxpXC7OiJCQ0R0Xg%2BCmJw%3D%3D&position=1&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"We are hiring an experienced python software engineer to join our product team. Data engineers are responsible for developing API endpoints, Data Parsers, and Data Schema for our web and mobile applications.




The ideal candidate has 3+ years experience using Python to develop APIs, PostgreSQL/PostGIS to manage data and developing web or mobile applications in a product team.




Responsibilities

Designing, developing, and test restful API for web and mobile applications
Accurately translate user and business needs into functional restful APIs
Develiver assigned data engineering and data science related tasks in agile sprints
Working with data engineering and UI/UX team to deliver new features and enhancements
Constant concern over application performance and data accuracy




Qualifications

3+ years professional API development experience in Python
MS/BS in Computer Science or similar




Nice to Haves

Experience with GraphQL
Experience with Git
Experience with Docker\K8\AWS
Experience building restful API's in Python
Experience with geospatial data




As a data engineer you will work on an engineering team including UX, Data Science, QA, DevOps engineers and report directly to the Director of Engineering. Our team is organized by agile development methodology and your day to day will include reviewing requirements with product management, collaborating with UX to determine JSON requirements, developing API endpoints and data parsers.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>We are hiring an experienced python software engineer to join our product team.&nbsp;Data engineers are responsible for developing API endpoints, Data Parsers, and Data Schema for our web and mobile applications. </p><p><br></p><p>The ideal candidate has 3+ years experience using Python to develop APIs, PostgreSQL/PostGIS to manage data and developing web or mobile applications in a product team.</p><p><br></p><p><strong>Responsibilities</strong></p><ul><li>Designing, developing, and test restful API for web and mobile applications</li><li>Accurately translate user and business needs into functional restful APIs</li><li>Develiver assigned data engineering and data science related tasks in agile sprints</li><li>Working with data engineering and UI/UX&nbsp;team to deliver new features and enhancements</li><li>Constant concern over application performance and data accuracy</li></ul><p><br></p><p><strong>Qualifications </strong></p><ul><li>3+ years professional API development experience in Python</li><li>MS/BS&nbsp;in Computer Science or similar</li></ul><p><br></p><p><strong>Nice to Haves</strong></p><ul><li>Experience with GraphQL</li><li>Experience with Git</li><li>Experience with Docker\K8\AWS</li><li>Experience building restful API's in Python</li><li>Experience with geospatial data</li></ul><p><br></p><p>As a data engineer you will work on an engineering team including UX, Data Science, QA, DevOps engineers and report directly to the Director of Engineering.&nbsp;Our team is organized by agile development methodology and your day to day will include reviewing requirements with product management, collaborating with UX to determine JSON requirements, developing API endpoints and data parsers.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Engineer,"Chicago, Illinois, United States",Collective Health,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-collective-health-2417237096?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=7Ti1HGOWSNTmzcb1ho4YFA%3D%3D&position=2&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"REF#: 38059

CBS BUSINESS UNIT: CBS Interactive

JOB TYPE: Full-Time Staff

Job Schedule

JOB LOCATION: Fort Lauderdale, FL

About Us

CBS Interactive, a division of ViacomCBS, is the world’s largest publisher of premium digital content and a perennial top 10 Internet company. CBS Interactive’s brands span popular categories like technology, entertainment, sports, news and gaming.

Properties include the websites, apps and streaming services of the CBS Television Network such as the CBS All Access subscription service, CBS News Digital platforms including the 24/7 digital news network CBSN, and CBS Sports Digital brands including the 24-hour streaming sports news network CBS Sports HQ, as well as digital-first properties in key content verticals, including CNET, ZDNet, TVGuide.com, GameSpot, Last.fm, Metacritic and Chowhound.

Follow CBS Interactive on Twitter and Facebook.

Description

CDM Data/Data Products Overview:

We are a passionate group providing data needs for all CBS Digital Media properties. This includes CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data, Data Product and Ingestion Engineering. As a Data Engineer you will be responsible for driving the data strategy and best practices for data collection, Pipelines, usage and infrastructure.

Interested in joining the team? We have an ongoing hiring need for Data Engineers in various locations. All applicants will be reviewed and considered for a current or near-future opening.

Your Day-to-Day

Works with large volumes of traffic data and user behaviors to build pipelines that enhance raw data.
Able to break down and communicate highly complex data problems into simple, feasible solutions.
Extract patterns from large datasets and transform data into an informational advantage.
Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations.
Partnering with the internal product and business intelligence teams to determine the best approach around data ingestion, structure, and storage. Then, working with the team to ensure these are implemented correctly.
Contributing ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes.
Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams.
Early on collaboration with the team on internal initiatives to create strategies that improve company processes.



What You Bring To The Team

QUALIFICATIONS:

You have -

Bachelor's degree and 2-4 years work experience in Analytics/Measurement/Data Operations fields or consulting roles with focus on digital analytics implementations.
Experience with data management systems, both relational and NoSQL (e.g., HBase, Cassandra, MongoDB)
Proficient in Python.
Familiarity with SQL skills for MySQL, Postgres and BigQuery to perform common types of analysis
Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc.
Strong problem solving and creative-thinking skills.
Ability to break down and communicate highly complex data problems as simple, feasible solutions
Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams.
Experience developing solutions to business requirements via hands-on discovery and exploration of data.
Exceptional written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions
Experience with a Python web framework such as Django or Flask.
Experience building and deploying application on a cloud platform (Google Cloud Platform preferred)


You might also have -

Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus.
Experience with Apache Airflow is a plus.
Familiarity with Data Modeling.
Familiarity in Hadoop pipelines using Spark, Kafka.
Familiar with version control systems.
Can perform statistical analyses using tools such as R, Numpy/SciPy with Python
Experience with Adobe Analytics (Omniture) or Google Analytics.
Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising.
Familiarity with ELT/ETL concepts.


FUNCTION: Data and Research

EEO Statement

ViacomCBS is an equal opportunity employer (EOE) including disability/vet.

At ViacomCBS, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. ViacomCBS is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access www.viacbs.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com. Only messages left for this purpose will be returned.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>REF#:</strong> 38059<br><br><strong>CBS BUSINESS UNIT:</strong> CBS Interactive<br><br><strong>JOB TYPE:</strong> Full-Time Staff<br><br><strong><u>Job Schedule<br><br></u></strong><strong>JOB LOCATION:</strong> Fort Lauderdale, FL<br><br><strong><u>About Us<br><br></u></strong>CBS Interactive, a division of ViacomCBS, is the world’s largest publisher of premium digital content and a perennial top 10 Internet company. CBS Interactive’s brands span popular categories like technology, entertainment, sports, news and gaming.<br><br>Properties include the websites, apps and streaming services of the CBS Television Network such as the CBS All Access subscription service, CBS News Digital platforms including the 24/7 digital news network CBSN, and CBS Sports Digital brands including the 24-hour streaming sports news network CBS Sports HQ, as well as digital-first properties in key content verticals, including CNET, ZDNet, TVGuide.com, GameSpot, Last.fm, Metacritic and Chowhound.<br><br>Follow CBS Interactive on Twitter and Facebook.<br><br><strong><u>Description<br><br></u></strong>CDM Data/Data Products Overview:<br><br>We are a passionate group providing data needs for all CBS Digital Media properties. This includes CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data, Data Product and Ingestion Engineering. As a Data Engineer you will be responsible for driving the data strategy and best practices for data collection, Pipelines, usage and infrastructure.<br><br>Interested in joining the team? We have an ongoing hiring need for Data Engineers in various locations. All applicants will be reviewed and considered for a current or near-future opening.<br><br><strong><u>Your Day-to-Day<br></u></strong><ul> <li>Works with large volumes of traffic data and user behaviors to build pipelines that enhance raw data.</li> <li>Able to break down and communicate highly complex data problems into simple, feasible solutions.</li> <li>Extract patterns from large datasets and transform data into an informational advantage.</li> <li>Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations.</li> <li>Partnering with the internal product and business intelligence teams to determine the best approach around data ingestion, structure, and storage. Then, working with the team to ensure these are implemented correctly.</li> <li>Contributing ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes.</li> <li>Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams.</li> <li>Early on collaboration with the team on internal initiatives to create strategies that improve company processes.</li> <br><br></ul><strong><u>What You Bring To The Team<br><br></u></strong><strong>QUALIFICATIONS:<br><br></strong>You have -<br><ul> <li>Bachelor's degree and 2-4 years work experience in Analytics/Measurement/Data Operations fields or consulting roles with focus on digital analytics implementations.</li> <li>Experience with data management systems, both relational and NoSQL (e.g., HBase, Cassandra, MongoDB)</li> <li>Proficient in Python.</li> <li>Familiarity with SQL skills for MySQL, Postgres and BigQuery to perform common types of analysis</li> <li>Experience with exploratory data analysis using tools like iPython Notebook, Pandas &amp; matplotlib, etc.</li> <li>Strong problem solving and creative-thinking skills.</li> <li>Ability to break down and communicate highly complex data problems as simple, feasible solutions</li> <li>Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams.</li> <li>Experience developing solutions to business requirements via hands-on discovery and exploration of data.</li> <li>Exceptional written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions</li> <li>Experience with a Python web framework such as Django or Flask.</li> <li>Experience building and deploying application on a cloud platform (Google Cloud Platform preferred)</li> <br></ul>You might also have -<br><ul> <li>Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus.</li> <li>Experience with Apache Airflow is a plus.</li> <li>Familiarity with Data Modeling.</li> <li>Familiarity in Hadoop pipelines using Spark, Kafka.</li> <li>Familiar with version control systems.</li> <li>Can perform statistical analyses using tools such as R, Numpy/SciPy with Python</li> <li>Experience with Adobe Analytics (Omniture) or Google Analytics.</li> <li>Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising.</li> <li>Familiarity with ELT/ETL concepts.</li> <br></ul><strong>FUNCTION:</strong> Data and Research<br><br><strong><u>EEO Statement<br><br></u></strong>ViacomCBS is an equal opportunity employer (EOE) including disability/vet.<br><br>At ViacomCBS, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. ViacomCBS is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status<br><br>If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access www.viacbs.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com. Only messages left for this purpose will be returned.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Broadcast Media, Entertainment, Media Production"
Data Engineer - Analytics,"Chicago, Illinois, United States",VillageMD,2021-01-24,https://www.linkedin.com/jobs/view/data-engineer-analytics-at-villagemd-2007611085?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=DioJRhOdrMWRvs%2BcH4oAHg%3D%3D&position=3&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"We all depend on healthcare throughout our lifetimes, for ourselves, and our families and friends, but it is notoriously difficult to navigate and understand. As an industry that comprises 20% of the US economy we think healthcare should work better for all of us. At Collective Health we believe it’s time for a new day in healthcare where as members we are informed and empowered to make the right care choices when the decisions are urgent and critical.

We deliver a connected healthcare experience for over 200,000 members and 45+ companies across the nation who want the best for their employees. We've got a ton of interesting problems to solve around data pipeline design and implementation, data architecture and modeling, distributed systems, and more. If you're passionate about tackling hard problems while making a real difference in the world, we'd love to talk!

What You'll Do

Data Pipelines – Create new pipelines and improve/maintain existing pipelines using Spark (Scala, Pyspark, Spark SQL)
Data Modeling – Partner with analytic consumers to design logical and physical schemas, improve existing data models and build new ones
Cross-functional Collaboration – Interface with Product, Engineering, Data Science, Analytics/BI, and Operations to understand their data needs, providing both consultative and data engineering solutions for consumers
Build data expertise and own data quality across various business domains including healthcare claims and member experience



Your Skills And Qualifications Include

BS degree in Computer Science or related technical field, or equivalent practical experience
2+ years proven work experience as a data engineer, working with at least one programming language (e.g. Scala, Python/PySpark) plus SQL expertise
2+ years experience with schema design, dimensional data modeling, and large-scale data warehousing architecture
Expertise in building data pipelines through efficient ETL design, implementation and maintenance
Background working with distributed data systems such as Spark, Presto, Hive, and Redshift. Experience with schedulers/workflow management tools (e.g. Airflow) a plus
Excellent communication skills to collaborate with stakeholders in Engineering, Product, Data Science, Analytics/BI, and Operations


Collective Health is a technology company simplifying employer healthcare to make health insurance work for everyone. With more than 200,000 members and over 45 enterprise clients—including Pinterest, Red Bull, Restoration Hardware, Activision Blizzard, and more—our technical and customer experience teams are reinventing the healthcare experience for forward-thinking employers and their people across the U.S.

Collective Health is headquartered in San Francisco, CA, with additional offices in Chicago, IL, and Lehi, UT. Founded in 2013, Collective Health is backed by the SoftBank Vision Fund, DFJ Growth, PSP Investments, NEA, GV, G Squared, Founders Fund, Maverick Ventures, Mubadala Ventures, Sun Life, and other leading investors. For more information, visit us at https://www.collectivehealth.com

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We all depend on healthcare throughout our lifetimes, for ourselves, and our families and friends, but it is notoriously difficult to navigate and understand. As an industry that comprises 20% of the US economy we think healthcare should work better for all of us. At Collective Health we believe it’s time for a new day in healthcare where as members we are informed and empowered to make the right care choices when the decisions are urgent and critical.<br><br>We deliver a connected healthcare experience for over 200,000 members and 45+ companies across the nation who want the best for their employees. We've got a ton of interesting problems to solve around data pipeline design and implementation, data architecture and modeling, distributed systems, and more. If you're passionate about tackling hard problems while making a real difference in the world, we'd love to talk!<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>Data Pipelines – Create new pipelines and improve/maintain existing pipelines using Spark (Scala, Pyspark, Spark SQL)</li> <li>Data Modeling – Partner with analytic consumers to design logical and physical schemas, improve existing data models and build new ones</li> <li>Cross-functional Collaboration – Interface with Product, Engineering, Data Science, Analytics/BI, and Operations to understand their data needs, providing both consultative and data engineering solutions for consumers</li> <li>Build data expertise and own data quality across various business domains including healthcare claims and member experience</li> <br><br></ul><strong><u>Your Skills And Qualifications Include<br></u></strong><ul> <li>BS degree in Computer Science or related technical field, or equivalent practical experience</li> <li>2+ years proven work experience as a data engineer, working with at least one programming language (e.g. Scala, Python/PySpark) plus SQL expertise</li> <li>2+ years experience with schema design, dimensional data modeling, and large-scale data warehousing architecture</li> <li>Expertise in building data pipelines through efficient ETL design, implementation and maintenance </li> <li>Background working with distributed data systems such as Spark, Presto, Hive, and Redshift. Experience with schedulers/workflow management tools (e.g. Airflow) a plus</li> <li>Excellent communication skills to collaborate with stakeholders in Engineering, Product, Data Science, Analytics/BI, and Operations</li> <br></ul>Collective Health is a technology company simplifying employer healthcare to make health insurance work for everyone. With more than 200,000 members and over 45 enterprise clients—including Pinterest, Red Bull, Restoration Hardware, Activision Blizzard, and more—our technical and customer experience teams are reinventing the healthcare experience for forward-thinking employers and their people across the U.S.<br><br>Collective Health is headquartered in San Francisco, CA, with additional offices in Chicago, IL, and Lehi, UT. Founded in 2013, Collective Health is backed by the SoftBank Vision Fund, DFJ Growth, PSP Investments, NEA, GV, G Squared, Founders Fund, Maverick Ventures, Mubadala Ventures, Sun Life, and other leading investors. For more information, visit us at https://www.collectivehealth.com<br><br><strong>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.<br></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Emeryville, California, United States",Feasible Inc.,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-feasible-inc-2430277857?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=TyTYANab878JOkPdI7J%2FHw%3D%3D&position=4&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Why VillageMD?

VillageMD is changing the trajectory of healthcare by empowering primary care physicians to make informed decisions and engage patients in meaningful ways. We work with thousands of clinicians and healthcare disruptors across the country to build and contribute to our platform to improve patient health while driving down the cost to deliver it.

We are a mission-oriented organization and are thrilled about the work that we do every day. We’re transparent, collaborative, and relentless in pursuit of our mission, all while doing so with humility and a low ego. We believe that diverse backgrounds and experiences create the best opportunity for innovation and the community that we are creating is greater than any individual.

We’ve built our technology using the best of cloud and open-source technologies to create an open, data-first platform that is enriched with analytical models and modernly connected to internal and external apps. These apps drive clinical decision support, patient engagement, and other facilitators of innovative, information-enriched health experiences.

Data Engineers (Analytics) at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, data-driven decisions. We're in a unique position to impact everyone in primary care from independent, family-owned practices to world-class health systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary care for our doctors and patients.

What are examples of work that Data Engineers (Analytics) have done at VillageMD?

Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model
Created a summary data platform supporting our presentation layer that allows clinicians and operators in our practices to pinpoint interventions on-demand to patients most in need
Analyzed and designed the best ways to expand our data model to incorporate more data that’s mission critical



What will make you successful here?

Strong analytical and technical skills
A real passion for problem solving and learning new technology
Vision to balance speed and maintainability in solution design
The ability to handle multiple, concurrent projects
Crafting and implementing requirements, keeping projects on track, and engaging partners
Challenging the status quo to improve our processes and tools
Communicating complex technical details in meaningful business context
Attention to detail, mindful of building quality into every solution
A low ego and humility; an ability to gain trust by doing what you say you will do



What You Might Do In Your First Year

Own ten projects to design and implement best-in-class data processing enabling clean data flow directly to our data model and on to our presentation layer
Work with analytics, engineering and operations to design and implement a new analytics product that supports improving patient health
Design a new concept within our data model to meet a new operational or analytical need



The Following Experience Is Relevant To Us

2+ years of full-time experience designing and implementing data pipelines and/or data summarization processes using SQL
Ability to understand relational data structures required
Strong capabilities manipulating data using tools such as Matillion, FiveTran, Talend, etc. a plus
Health care data experience strongly preferred
Experience with Snowflake or an analytic implementation of SQL (e.g. Transact-SQL, PL/SQL) is a plus
Knowledge of, and/or willingness to learn, additional data structures and other technologies (e.g. S3, Airflow, JSON, Postgres)
Experience or willingness to learn building information pipelines utilizing Python a plus
BS/MS in computer science, math, engineering, or other related fields is required.
Track record of successfully executing projects with multiple partners
Experience with collaboration tools and processes (e.g. Confluence, Git/Bitbucket) a plus



What can we offer you?

Competitive salary, bonus, and health benefits
Paid gym membership
Fun, fast-paced, startup environment (with snacks)
Pre-tax savings on commute expenses
Remote flexibility
A highly-collaborative, conscientious, forward-thinking environment that welcomes the impact you can make from Day 1.
A clear link between our daily work on products and services and the improved quality of healthcare that this work facilitates for patients.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Why VillageMD?<br><br></strong>VillageMD is changing the trajectory of healthcare by empowering primary care physicians to make informed decisions and engage patients in meaningful ways. We work with thousands of clinicians and healthcare disruptors across the country to build and contribute to our platform to improve patient health while driving down the cost to deliver it.<br><br>We are a mission-oriented organization and are thrilled about the work that we do every day. We’re transparent, collaborative, and relentless in pursuit of our mission, all while doing so with humility and a low ego. We believe that diverse backgrounds and experiences create the best opportunity for innovation and the community that we are creating is greater than any individual.<br><br>We’ve built our technology using the best of cloud and open-source technologies to create an open, <em>data</em>-first platform that is enriched with analytical models and modernly connected to internal and external apps. These apps drive clinical decision support, patient engagement, and other facilitators of innovative, information-enriched <em>health</em> experiences.<br><br><em>Data</em> Engineers (Analytics) at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, <em>data</em>-driven decisions. We're in a unique position to impact everyone in primary <em>care</em> from independent, family-owned practices to world-class <em>health</em> systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary <em>care</em> for our doctors and patients.<br><br><strong>What</strong> <strong>are</strong> <strong>examples</strong> <strong>of</strong> <strong>work</strong> <strong>that <em>Data</em> Engineers (Analytics) have</strong> <strong>done</strong> <strong>at</strong> <strong>VillageMD?<br></strong><ul> <li>Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model</li> <li>Created a summary data platform supporting our presentation layer that allows clinicians and operators in our practices to pinpoint interventions on-demand to patients most in need</li> <li>Analyzed and designed the best ways to expand our data model to incorporate more data that’s mission critical</li> <br><br></ul><strong>What</strong> <strong>will</strong> <strong>make</strong> <strong>you</strong> <strong>successful</strong> <strong>here?<br></strong><ul> <li>Strong analytical and technical skills</li> <li>A real passion for problem solving and learning new technology</li> <li>Vision to balance speed and maintainability in solution design</li> <li>The ability to handle multiple, concurrent projects</li> <li>Crafting and implementing requirements, keeping projects on track, and engaging partners</li> <li>Challenging the status quo to improve our processes and tools</li> <li>Communicating complex technical details in meaningful business context</li> <li>Attention to detail, mindful of building quality into every solution</li> <li>A low ego and humility; an ability to gain trust by doing what you say you will do</li> <br><br></ul><strong><u>What You Might Do In Your First Year<br></u></strong><ul> <li>Own ten projects to design and implement best-in-class data processing enabling clean data flow directly to our data model and on to our presentation layer</li> <li>Work with analytics, engineering and operations to design and implement a new analytics product that supports improving patient health</li> <li>Design a new concept within our data model to meet a new operational or analytical need</li> <br><br></ul><strong><u>The Following Experience Is Relevant To Us<br></u></strong><ul> <li>2+ years of full-time experience designing and implementing data pipelines and/or data summarization processes using SQL</li> <li>Ability to understand relational data structures required</li> <li>Strong capabilities manipulating data using tools such as Matillion, FiveTran, Talend, etc. a plus</li> <li>Health care data experience strongly preferred</li> <li>Experience with Snowflake or an analytic implementation of SQL (e.g. Transact-SQL, PL/SQL) is a plus</li> <li>Knowledge of, and/or willingness to learn, additional data structures and other technologies (e.g. S3, Airflow, JSON, Postgres)</li> <li>Experience or willingness to learn building information pipelines utilizing Python a plus</li> <li>BS/MS in computer science, math, engineering, or other related fields is required.</li> <li>Track record of successfully executing projects with multiple partners</li> <li>Experience with collaboration tools and processes (e.g. Confluence, Git/Bitbucket) a plus</li> <br><br></ul><strong>What</strong> <strong>can we offer you? <br></strong><ul> <li>Competitive salary, bonus, and health benefits</li> <li>Paid gym membership</li> <li>Fun, fast-paced, startup environment (with snacks)</li> <li>Pre-tax savings on commute expenses</li> <li>Remote flexibility</li> <li>A highly-collaborative, conscientious, forward-thinking environment that welcomes the impact you can make from Day 1. </li> <li>A clear link between our daily work on products and services and the improved quality of healthcare that this work facilitates for patients.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Financial Services, Health, Wellness and Fitness, Hospital & Health Care"
Data Engineer - CIMD Technology,"Richardson, Texas, United States",Goldman Sachs,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-cimd-technology-at-goldman-sachs-2001311155?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=a8xwn%2F3L6QcbEhHlMxvCxg%3D%3D&position=5&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Battery Market Context

In 2019, global battery production could power ~5 million EVs, however the equivalent of ~1 in every 6 batteries were scrapped in production. That’s ~$4 Billion of waste in 2019, due largely to insufficient data and analytics in production. Batteries are fundamental to our clean energy transition, but unless we change the status quo, their cost will remain a major barrier.

About Feasible, Inc.

Our mission is to accelerate the clean energy transition by decreasing the cost of battery manufacturing. We are pioneers in advanced process inspection & intelligence solutions, enabling our customers to “See Batteries Differently.” Our EchoStat platform uses ultrasound and data analytics to deliver unique, valuable insights that create value in battery production by speeding up time-to-market for new batteries, accelerating yield ramp for new production processes, and improving steady-state productivity.

Founded in 2016, Feasible is headquartered in Emeryville, CA. Since inception, Feasible has received over $9M in grants and equity funding from Chrysalix Ventures, Incite Labs, NSF, DOE (ARPA-e), California Energy Commission, Elemental Excelerator, Activate (formerly Cyclotron Road), and others. We have active validation programs with leading battery manufacturers and automakers, and are deploying our first commercial systems this year.

Our Culture and Values

We are dedicated to building a world-class company that will improve the world.
We work closely on a foundation of mutual trust and data-driven decisions.
We value personal growth, continuous learning, safety, and inclusion.
We believe the most innovative teams seek out, welcome and celebrate all forms of diversity.



Role

As a data scientist at Feasible you will join a small, nimble team of engineers creating cutting-edge battery inspection equipment. You will be an integral part of analyzing the data produced with this equipment, developing a deeper understanding of the data's relationship to the battery's production history and performance, and creating tools and techniques to achieve those goals.

On a typical day, you may perform investigative analysis on experimental data; design and implement algorithms for distilling ultrasonic signals into meaningful features, and correlate those features with performance data; build analytics tools and visualizations to empower our engineers and customers; optimize, automate, and streamline our analytics pipeline, and integrate the pipeline with real-time data streams; or communicate your work to stakeholders with varied backgrounds.

You value careful listening, thoughtful questions, and data-driven discussions. You are comfortable with gathering and distilling information to drive the direction of open-ended projects.

The ideal candidate will approach this work with a mixture of intellectual curiosity, thoughtful creativity, and methodical rigor. The ideal candidate gets great satisfaction from seeing people do great things with their work, and above all is excited to solve hard problems that have a positive impact on the world’s clean energy future.

Responsibilities

Build predictive models blending acoustic and electrochemical data
Feature engineering
Build out data pipelines
Build out data visualization tools
Develop innovative analysis techniques
Analyze data from customers



Requirements

Practical experience working with and comparing large datasets acquired from experiments
Python (Numpy, Scipy, Pandas, Scikit-learn)
Experience with predictive modeling (Classification, Clustering, Dimensionality Reduction)
SQL Database proficiency (primarily through queries)
Statistics
Data visualization



Nice to haves (bonus skills)

Experience with frequency domain data
Experience with time-series analysis
Experience with battery data
Physical intuition about data, or experience w/ real world data



Benefits

Competitive compensation package.
Medical, dental, vision, and life insurance.
8 weeks of fully-paid parental leave.
401(k).
Paid week off July 4th and End of Year.
Flexible time-off policy.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Battery Market Context<br><br>In 2019, global battery production could power ~5 million EVs, however the equivalent of ~1 in every 6 batteries were scrapped in production. That’s ~$4 Billion of waste in 2019, due largely to insufficient data and analytics in production. Batteries are fundamental to our clean energy transition, but unless we change the status quo, their cost will remain a major barrier.<br><br><strong><u>About Feasible, Inc.<br><br></u></strong>Our mission is to accelerate the clean energy transition by decreasing the cost of battery manufacturing. We are pioneers in advanced process inspection &amp; intelligence solutions, enabling our customers to “See Batteries Differently.” Our EchoStat platform uses ultrasound and data analytics to deliver unique, valuable insights that create value in battery production by speeding up time-to-market for new batteries, accelerating yield ramp for new production processes, and improving steady-state productivity.<br><br>Founded in 2016, Feasible is headquartered in Emeryville, CA. Since inception, Feasible has received over $9M in grants and equity funding from Chrysalix Ventures, Incite Labs, NSF, DOE (ARPA-e), California Energy Commission, Elemental Excelerator, Activate (formerly Cyclotron Road), and others. We have active validation programs with leading battery manufacturers and automakers, and are deploying our first commercial systems this year.<br><br>Our Culture and Values<br><ul> <li>We are dedicated to building a world-class company that will improve the world.</li> <li>We work closely on a foundation of mutual trust and data-driven decisions.</li> <li>We value personal growth, continuous learning, safety, and inclusion.</li> <li>We believe the most innovative teams seek out, welcome and celebrate all forms of diversity.</li> <br><br></ul>Role<br><br>As a data scientist at Feasible you will join a small, nimble team of engineers creating cutting-edge battery inspection equipment. You will be an integral part of analyzing the data produced with this equipment, developing a deeper understanding of the data's relationship to the battery's production history and performance, and creating tools and techniques to achieve those goals.<br><br>On a typical day, you may perform investigative analysis on experimental data; design and implement algorithms for distilling ultrasonic signals into meaningful features, and correlate those features with performance data; build analytics tools and visualizations to empower our engineers and customers; optimize, automate, and streamline our analytics pipeline, and integrate the pipeline with real-time data streams; or communicate your work to stakeholders with varied backgrounds.<br><br>You value careful listening, thoughtful questions, and data-driven discussions. You are comfortable with gathering and distilling information to drive the direction of open-ended projects.<br><br>The ideal candidate will approach this work with a mixture of intellectual curiosity, thoughtful creativity, and methodical rigor. The ideal candidate gets great satisfaction from seeing people do great things with their work, and above all is excited to solve hard problems that have a positive impact on the world’s clean energy future.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Build predictive models blending acoustic and electrochemical data</li> <li>Feature engineering</li> <li>Build out data pipelines</li> <li>Build out data visualization tools</li> <li>Develop innovative analysis techniques</li> <li>Analyze data from customers</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Practical experience working with and comparing large datasets acquired from experiments</li> <li>Python (Numpy, Scipy, Pandas, Scikit-learn)</li> <li>Experience with predictive modeling (Classification, Clustering, Dimensionality Reduction)</li> <li>SQL Database proficiency (primarily through queries)</li> <li>Statistics</li> <li>Data visualization</li> <br><br></ul>Nice to haves (bonus skills)<br><ul> <li>Experience with frequency domain data</li> <li>Experience with time-series analysis</li> <li>Experience with battery data</li> <li>Physical intuition about data, or experience w/ real world data</li> <br><br></ul><u><strong>Benefits<br></strong></u><ul> <li>Competitive compensation package.</li> <li>Medical, dental, vision, and life insurance.</li> <li>8 weeks of fully-paid parental leave.</li> <li>401(k).</li> <li>Paid week off July 4th and End of Year.</li> <li>Flexible time-off policy.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Electrical/Electronic Manufacturing, Computer Software, Internet"
Python Engineer,"Waltham, Massachusetts, United States",Intralinks,2021-02-08,https://www.linkedin.com/jobs/view/python-engineer-at-intralinks-2396505710?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=W6pWA2DWPAwVNCzjjEH7Jw%3D%3D&position=6&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"CONSUMER (MARCUS BY GOLDMAN SACHS)
Marcus by Goldman Sachs is the firm’s consumer business, combining the entrepreneurial spirit of a startup with 150 years of experience. Today, Marcus has $50 billion in deposits, $5 billion in loan balances and 4 million customers across our lending and deposits businesses, as well as the personal financial management app, Clarity Money. Through the use of insights and intuitive design, we provide customers with powerful tools and products that are grounded in value, transparency and simplicity. We are backed by our unique team, comprised of individual contributors from leading agile technology companies, fintechs and consumer financial services companies, allowing us to disrupt the industry, while helping consumers take control of their financial lives

Responsibilities And Qualifications

We are seeking a hands-on Data engineer to design, develop and enhance the Marcus Consumer Banking Data Analytics Platform of Goldman Sachs. The person will be responsible for expanding and optimizing our data and data pipeline architecture on Big Data technologies. The ideal candidate is an experienced ETL developer who has not only worked on a traditional ETL tool but has also developed generic, reusable transformations in a programming language like python or java. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

How You Will Fulfill Your Potential

Design, develop and enhance the Marcus Data Platform
Develop data flows and pipelines in python and spark to support business needs
Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader
Work with data and analytics experts to strive for greater functionality in our data systems
Conduct POC to help define the components for the Big Data platform


Qualifications

3+ years academic or industry experience
Strong data warehousing concepts, especially in the ETL space
Experience with any one ETL tool
Strong in data structures and algorithms
Programming experience in either python or java.
Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets


About Goldman Sachs

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers .

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:// www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity

Division Engineering
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>CONSUMER (MARCUS BY GOLDMAN SACHS)<br></strong>Marcus by Goldman Sachs is the firm’s consumer business, combining the entrepreneurial spirit of a startup with 150 years of experience. Today, Marcus has $50 billion in deposits, $5 billion in loan balances and 4 million customers across our lending and deposits businesses, as well as the personal financial management app, Clarity Money. Through the use of insights and intuitive design, we provide customers with powerful tools and products that are grounded in value, transparency and simplicity. We are backed by our unique team, comprised of individual contributors from leading agile technology companies, fintechs and consumer financial services companies, allowing us to disrupt the industry, while helping consumers take control of their financial lives<br><br><strong><u>Responsibilities And Qualifications<br><br></u></strong>We are seeking a hands-on Data engineer to design, develop and enhance the Marcus Consumer Banking Data Analytics Platform of Goldman Sachs. The person will be responsible for expanding and optimizing our data and data pipeline architecture on Big Data technologies. The ideal candidate is an experienced ETL developer who has not only worked on a traditional ETL tool but has also developed generic, reusable transformations in a programming language like python or java. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.<br><br><strong><u>How You Will Fulfill Your Potential<br></u></strong><ul><li> Design, develop and enhance the Marcus Data Platform </li><li> Develop data flows and pipelines in python and spark to support business needs </li><li> Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader </li><li> Work with data and analytics experts to strive for greater functionality in our data systems </li><li> Conduct POC to help define the components for the Big Data platform <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> 3+ years academic or industry experience </li><li> Strong data warehousing concepts, especially in the ETL space </li><li> Experience with any one ETL tool </li><li> Strong in data structures and algorithms </li><li> Programming experience in either python or java. </li><li> Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases </li><li> Experience building and optimizing ‘big data’ data pipelines, architectures and data sets <br><br></li></ul><strong><u>About Goldman Sachs<br><br></u></strong><strong> ABOUT GOLDMAN SACHS <br><br></strong>At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.<br><br>We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at <u> GS.com/careers </u>.<br><br>We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: <u> https:// www.goldmansachs.com/careers/footer/disability-statement.html <br><br></u>© The Goldman Sachs Group, Inc., 2020. All rights reserved.<br>Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity<br><br>Division Engineering</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Salt Lake City, Utah, United States",Lucid,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-lucid-2416481022?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=miR41cmW04mD1QIBPATybg%3D%3D&position=7&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"About The Team

The team is chartered with developing mission critical products for our cloud offering using cutting edge technologies. The team is developing a robust data-warehouse infrastructure that drives a variety of business intelligence use cases for our customers.

This project involves the development of data solutions that provides intelligent insights to end users and other business stakeholders while honoring the security guidelines around data privacy and collaboration.

Overview

We are looking for a software engineer to work on a workflow engine at Intralinks. The project brings business value through execution of predictable and repeatable tasks at scale. This project has lot of visibility across the business with one-pointed focus on the customers to serve a wide range of compliance and regulatory data use cases.

You will join us to participate in developing, and maintaining step based and DAG workflows. You will develop Python code to extract, process compress and transfer data from/to S3. You will develop a RESTful service to for customers and operators to track, analyze and manage workflow tasks.

Required Qualifications And Experience

Bachelor’s degree (computer science or equivalent)
Python
2+ development years of experience in building data solutions using Python, SQL databases, security protocols
Experience with deployment automation and Infrastructure
Experience with RESTful api services, and data storage
Experience with public clouds like AWS or Google Cloud
Experience with git


Desired Skills

Experience with Kubernetes
Experience with workflow engines like Argo, Airflow
Testing and unit testing frameworks

#WhyJoinIN:

“Intralinks is the platform of choice for secure content distribution and collaboration. We continue to invest in new ideas to evolve our company and provide value to our clients. In this role you’ll have impact on the business, opportunities for personal and professional growth and create great products along the way.” #WhatLinksUs

SS&C Intralinks is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About The Team<br><br></u></strong>The team is chartered with developing mission critical products for our cloud offering using cutting edge technologies. The team is developing a robust data-warehouse infrastructure that drives a variety of business intelligence use cases for our customers.<br><br>This project involves the development of data solutions that provides intelligent insights to end users and other business stakeholders while honoring the security guidelines around data privacy and collaboration.<br><br><strong><u>Overview<br><br></u></strong>We are looking for a software engineer to work on a workflow engine at Intralinks. The project brings business value through execution of predictable and repeatable tasks at scale. This project has lot of visibility across the business with one-pointed focus on the customers to serve a wide range of compliance and regulatory data use cases.<br><br>You will join us to participate in developing, and maintaining step based and DAG workflows. You will develop Python code to extract, process compress and transfer data from/to S3. You will develop a RESTful service to for customers and operators to track, analyze and manage workflow tasks.<br><br><strong><u>Required Qualifications And Experience<br></u></strong><ul><li>Bachelor’s degree (computer science or equivalent)</li><li>Python</li><li>2+ development years of experience in building data solutions using Python, SQL databases, security protocols</li><li>Experience with deployment automation and Infrastructure</li><li>Experience with RESTful api services, and data storage</li><li>Experience with public clouds like AWS or Google Cloud</li><li>Experience with git<br><br></li></ul><strong><u>Desired Skills<br></u></strong><ul><li>Experience with Kubernetes</li><li>Experience with workflow engines like Argo, Airflow</li><li>Testing and unit testing frameworks<br></li></ul><strong><u> #WhyJoinIN: <br><br></u></strong><em> “Intralinks is the platform of choice for secure content distribution and collaboration. We continue to invest in new ideas to evolve our company and provide value to our clients. In this role you’ll have impact on the business, opportunities for personal and professional growth and create great products along the way.” #WhatLinksUs <br><br></em>SS&amp;C Intralinks is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Python Developer - Data Engineer,"Chicago, Illinois, United States","CPS, Inc.",2021-02-15,https://www.linkedin.com/jobs/view/python-developer-data-engineer-at-cps-inc-2382091467?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=SGhhBQHr4GXyDD3bq5oRhQ%3D%3D&position=8&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"We are a rapidly growing tech startup looking for a Data Scientist to join us at our headquarters in South Jordan, Utah. As a Data Scientist, you will be primarily responsible for developing predictive models and performing statistical analysis. Your role will involve data wrangling, training and tuning models, and productionizing these models in order to improve our business operations. In order to be a successful data scientist at Lucid you must have a high level of technical ability, an intense passion for problem solving, and excellent communication skills.

You will thrive as a Data Scientist at Lucid if:


You’re excited to take end-to-end responsibility for your projects, from idea generation to implementing and supporting automated predictive models.
You love exploring new tools and improving your technical skills as you identify the best possible solutions to complex, ambiguous problems.
You are comfortable being the primary subject matter expert on statistics and predictive modeling for business applications within the company.
You want to make a significant impact on our business with each and every project you complete.


To Help Illustrate The Types Of Projects You May Tackle, Some Examples Of Past Data Science Projects At Lucid Are Listed Below

The projects you will work on in this role will help internal stakeholders make decisions and improve operations (i.e., you will not be working on customer-facing features).


Predicting future revenue at the user, advertising keyword, and account level
Automatically labeling and routing support tickets based on ticket content
Building a system for analyzing A/B tests using Bayesian statistics
Building an anomaly detection system to proactively identify data issues
Quantifying the impact of product usage on revenue outcomes (e.g., trial conversion, subscription changes)


The core components of our tech stack include Snowflake, dbt, Databricks, Docker, Airflow, and Tableau. We’re always looking to improve our tech stack, and we are flexible in allowing people to use the tools that will enable them to be most effective.

Business Data Science is part of our Strategy and Analytics team, which also consists of data analysts and analytics engineers. Together, this team supports the data and analytics needs of all functions across the company. As a member of the Strategy and Analytics team, you will participate in activities and trainings together and collaborate on projects. You will also work from time to time with our Data Infrastructure team to deploy infrastructure or build custom applications for your projects.

Our mission is to help teams see and build the future. And we hold true to our core values of: (1) innovation in everything we do; (2) passion & excellence in every area; (3) providing individual empowerment, initiative and ownership; and (4) teamwork over ego.

Responsibilites

Work with appropriate stakeholders across a variety of business functions (e.g., Sales, Marketing, Finance, Biz Ops) to identify and scope promising applications of predictive modeling and statistical analysis (e.g. causal inference)
Advanced data wrangling, which involves collating, cleaning, and manipulating very large datasets
Develop models to help improve operations and drive business growth
Enable ongoing use of predictive models by implementing them in a production environment
Communicate your work and its results to different audiences, including non-technical stakeholders
Drive adoption of data science tools and best practices


Requirements

Master’s degree or PhD in a technical or quantitative field
Strong understanding of statistics
1-3 years of industry experience
Experience working with large data sets (100M+ rows)
Experience working with distributed systems (e.g., Apache Spark)
Excellent Python, R, or Scala skills
Able to think strategically and tackle problems independently from end to end
Comfortable working directly with a variety of business stakeholders
Detail-oriented, organized, and a good team player


Preferred Qualifications

Experience with A/B testing implementation and execution
Experience working with marketing, sales, and/or customer success teams
Can relate to Lucid Software's products and culture
Can easily thrive working in a fast-paced startup environment
Driven to meet Lucid Software’s Core Values of Innovation, Passion & Excellence, Empowerment & Initiative, and Teamwork over Ego


At Lucid Software our core values aren't just a pretty inspirational wall hanging. These principles work hard, just like we do. Lucidites use them, every day, whether they're discussing ideas for new projects, deciding on the best solution for a customer's problem, or interviewing candidates. It's just one of the many things that makes Lucid Software the best company to work for. Check out our Life at Lucid page and see how our core values align with yours.

We celebrate a diverse and an inclusive work environment, where we honor and support varying backgrounds, beliefs, and perspectives for the benefit of our business, including our employees and products. We are proud to be an equal opportunity workplace that has signed the Parity Pledge and strives to be a place where every Lucidite feels they belong. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please let us know.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are a rapidly growing tech startup looking for a Data Scientist to join us at our headquarters in South Jordan, Utah. As a Data Scientist, you will be primarily responsible for developing predictive models and performing statistical analysis. Your role will involve data wrangling, training and tuning models, and productionizing these models in order to improve our business operations. In order to be a successful data scientist at Lucid you must have a high level of technical ability, an intense passion for problem solving, and excellent communication skills.<br><br>You will thrive as a Data Scientist at Lucid if:<br><br><li> You’re excited to take end-to-end responsibility for your projects, from idea generation to implementing and supporting automated predictive models.</li><li> You love exploring new tools and improving your technical skills as you identify the best possible solutions to complex, ambiguous problems.</li><li> You are comfortable being the primary subject matter expert on statistics and predictive modeling for business applications within the company.</li><li> You want to make a significant impact on our business with each and every project you complete.<br><br></li><strong><u>To Help Illustrate The Types Of Projects You May Tackle, Some Examples Of Past Data Science Projects At Lucid Are Listed Below<br><br></u></strong>The projects you will work on in this role will help internal stakeholders make decisions and improve operations (i.e., you will not be working on customer-facing features).<br><br><li> Predicting future revenue at the user, advertising keyword, and account level</li><li> Automatically labeling and routing support tickets based on ticket content</li><li> Building a system for analyzing A/B tests using Bayesian statistics</li><li> Building an anomaly detection system to proactively identify data issues</li><li> Quantifying the impact of product usage on revenue outcomes (e.g., trial conversion, subscription changes)<br><br></li>The core components of our tech stack include Snowflake, dbt, Databricks, Docker, Airflow, and Tableau. We’re always looking to improve our tech stack, and we are flexible in allowing people to use the tools that will enable them to be most effective.<br><br>Business Data Science is part of our Strategy and Analytics team, which also consists of data analysts and analytics engineers. Together, this team supports the data and analytics needs of all functions across the company. As a member of the Strategy and Analytics team, you will participate in activities and trainings together and collaborate on projects. You will also work from time to time with our Data Infrastructure team to deploy infrastructure or build custom applications for your projects.<br><br>Our mission is to help teams see and build the future. And we hold true to our core values of: (1) innovation in everything we do; (2) passion &amp; excellence in every area; (3) providing individual empowerment, initiative and ownership; and (4) teamwork over ego.<br><br><strong><u>Responsibilites<br></u></strong><ul><ul><li>Work with appropriate stakeholders across a variety of business functions (e.g., Sales, Marketing, Finance, Biz Ops) to identify and scope promising applications of predictive modeling and statistical analysis (e.g. causal inference)</li><li>Advanced data wrangling, which involves collating, cleaning, and manipulating very large datasets</li><li>Develop models to help improve operations and drive business growth</li><li>Enable ongoing use of predictive models by implementing them in a production environment</li><li>Communicate your work and its results to different audiences, including non-technical stakeholders</li><li>Drive adoption of data science tools and best practices<br><br></li></ul></ul><strong><u>Requirements<br></u></strong><ul><ul><li>Master’s degree or PhD in a technical or quantitative field</li><li>Strong understanding of statistics</li><li>1-3 years of industry experience</li><li>Experience working with large data sets (100M+ rows)</li><li>Experience working with distributed systems (e.g., Apache Spark)</li><li>Excellent Python, R, or Scala skills</li><li>Able to think strategically and tackle problems independently from end to end</li><li>Comfortable working directly with a variety of business stakeholders</li><li>Detail-oriented, organized, and a good team player<br><br></li></ul></ul><strong><u>Preferred Qualifications<br></u></strong><ul><ul><li>Experience with A/B testing implementation and execution</li><li>Experience working with marketing, sales, and/or customer success teams</li><li>Can relate to Lucid Software's products and culture</li><li>Can easily thrive working in a fast-paced startup environment</li><li>Driven to meet Lucid Software’s Core Values of Innovation, Passion &amp; Excellence, Empowerment &amp; Initiative, and Teamwork over Ego<br><br></li></ul></ul>At Lucid Software our core values aren't just a pretty inspirational wall hanging. These principles work hard, just like we do. Lucidites use them, every day, whether they're discussing ideas for new projects, deciding on the best solution for a customer's problem, or interviewing candidates. It's just one of the many things that makes Lucid Software the best company to work for. Check out our Life at Lucid page and see how our core values align with yours.<br><br>We celebrate a diverse and an inclusive work environment, where we honor and support varying backgrounds, beliefs, and perspectives for the benefit of our business, including our employees and products. We are proud to be an equal opportunity workplace that has signed the Parity Pledge and strives to be a place where every Lucidite feels they belong. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please let us know.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"San Diego, California, United States",Omnitracs,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-omnitracs-2370263030?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=Fg4hBJLxJcO2PGAEkaHsOQ%3D%3D&position=9&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Our Data Intelligence team is seeking a Software/Data Engineer to help build out our platform that empowers our product and data engineering teams to deliver timely and accurate data. This data acquired is utilized by various business units allowing them to make the best decisions for our bottom line.

You will have hands-on Python development experience with an excellent technical background and/or Computer Science Degree.

#LI_RO1

For this role you should possess at least 1 year of Python Development

A Computer Science degree will prove beneficial as we look for those with strong core competencies in Data Structures, Rest API's, JSON, etc.


Experience with Python (at least 2 years)
Unix (Linux) and database experience (SQL, MySQL, PostgreSQL, redis)
Familiarity with object oriented development approach
AWS or similar public cloud experience
Docker and/or Kubernetes automating deployments


You should have an interest in the financial sector
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Our Data Intelligence team is seeking a Software/Data Engineer to help build out our platform that empowers our product and data engineering teams to deliver timely and accurate data. This data acquired is utilized by various business units allowing them to make the best decisions for our bottom line. <br><br></strong><strong>You will have hands-on Python development experience with an excellent technical background and/or Computer Science Degree. <br><br></strong><strong>#LI_RO1<br><br></strong><strong>For this role you should possess at least 1 year of Python Development<br><br></strong><strong>A Computer Science degree will prove beneficial as we look for those with strong core competencies in Data Structures, Rest API's, JSON, etc.<br><br></strong><ul> <li><strong>Experience with Python (at least 2 years)</strong></li> <li><strong>Unix (Linux) and database experience (SQL, MySQL, PostgreSQL, redis)</strong></li> <li><strong>Familiarity with object oriented development approach</strong></li> <li><strong>AWS or similar public cloud experience</strong></li> <li><strong>Docker and/or Kubernetes automating deployments</strong></li> <br></ul><strong>You should have an interest in the financial sector</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Staffing and Recruiting, Consumer Goods, Financial Services"
Python Back-End Software Engineer,"Boston, Massachusetts, United States",KAID Health,2021-02-19,https://www.linkedin.com/jobs/view/python-back-end-software-engineer-at-kaid-health-2430379749?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=tMSiy4uGIHwShwKxK%2BC22A%3D%3D&position=10&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Omnitracs - SmartDrive Systems gives fleets and drivers unprecedented driving performance insight and analysis, helping save fuel, expenses and lives. Its video analysis, predictive analytics and personalized performance program help fleets improve driving skills, lower operating costs, and deliver significant ROI. With an easy-to-use managed service, fleets and drivers can access and self-manage driving performance anytime, anywhere. The Company has compiled the world's largest storehouse of nearly 200 million analyzed risky-driving events, including video and comprehensive sensor data. SmartDrive Systems is based in San Diego, CA, Shenzhen, China, and Hyderabad, India, and employs over 600 people worldwide.

We are looking for an experienced data-focused engineers to join our team, leading the design, development, and delivery of our high-performance analytics engines for solving computer vision, machine learning, sensor fusion problems running in vehicle and in the cloud at high throughput and high accuracy vehicle event analysis engines (in vehicle and in the cloud), and robust and flexible coaching workflow, reporting, and alert management engines.

Our business is nearly doubling every year, and our people and our platforms are the foundation and enabler of that growth. We are significantly expanding our team, and are looking for technologists with a passion for high performance software development, and a drive to deliver software products that make a meaningful difference in the lives of others.

Omnitracs is an equal opportunity employer and federal contractor or subcontractor. Consequently, the Parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The Parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.

Responsibilities

Data Engineering to the core - analysis, modelling, transformation and visualization of datasets for online products and backend data platform.
Implement data engineering codebase using server-side languages Java/Scala or scripting using Python and Javascript
Design and develop apis for data pipelining frameworks on data collection, processing and storage across data stores.
Understand noSQL and stream programming apis for building data pipelines and micro-service based architecture across products
Design and development of data solutions for fast datastores, large scale data warehousing, machine learning and computer vision analytics.


Minimum Qualifications

Bachelor’s Degree in Computer Science or related discipline
5+ years of software development experience
2+ years of experience as a Data Engineer


Preferred Qualifications

Extensive knowledge of RDBMS (Microsoft SQL Server, Mysql, Postgres or similar)
Proven experience with NoSQL stores (one or more of Cassandra, MongoDB, InfluxDB, HBase/HDFS, ElasticSearch)
Experience in a distributed microservices and/or serverless (Lambda) cloud software architecture
In-Depth knowledge of ETL commercial software products (any of Informatica, Talend, Nifi or SSIS) with hands-on experience designing, implementing, and delivering solutions
Expertise with integration of complex and large data from multiple data sources, data and sensor fusion, and migration to newer methodologies
Prior experience as part of a large group working on massive data engineering pipelines and analytics for machine learning, computer vision
An aggressive problem solver who can provide creative solutions to complex situations and obtain buy-in from those affected
An independent worker who can take the initiative to define and prioritize specific goals and objectives, and to do the same for others
Strong people skills - able to communicate with colleagues while building credibility and rapport, modifying behavioral style to respond to the needs of others while maintaining objectives
An organized individual who is very detail oriented and can document and develop plans necessary for deliverables towards specific product or platform goals.
A team player that works hard, admits his/her strengths and weaknesses, and has the flexibility to improve by learning new things

Omnitracs LLC , is an Equal Opportunity Employer and does not unlawfully discriminate on the basis of any status or condition protected by applicable federal, state, or local municipal law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Omnitracs - SmartDrive Systems gives fleets and drivers unprecedented driving performance insight and analysis, helping save fuel, expenses and lives. Its video analysis, predictive analytics and personalized performance program help fleets improve driving skills, lower operating costs, and deliver significant ROI. With an easy-to-use managed service, fleets and drivers can access and self-manage driving performance anytime, anywhere. The Company has compiled the world's largest storehouse of nearly 200 million analyzed risky-driving events, including video and comprehensive sensor data. SmartDrive Systems is based in San Diego, CA, Shenzhen, China, and Hyderabad, India, and employs over 600 people worldwide.<br><br>We are looking for an <strong>experienced data-focused engineers to join our team</strong>, leading the design, development, and delivery of <strong>our high-performance analytics engines</strong> for solving computer vision, machine learning, sensor fusion problems running in vehicle and in the cloud at high throughput and high accuracy vehicle event analysis engines (in vehicle and in the cloud), and robust and flexible coaching workflow, reporting, and alert management engines.<br><br>Our business is nearly doubling every year, and our people and our platforms are the foundation and enabler of that growth. We are significantly expanding our team, and are looking for <strong>technologists with a passion for high performance software development, and a drive to deliver software products</strong> that make a meaningful difference in the lives of others.<br><br><strong>Omnitracs is an equal opportunity employer and federal contractor or subcontractor. Consequently, the Parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The Parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.<br><br></strong><strong><u>Responsibilities<br></u></strong><ul><li> Data Engineering to the core - <strong>analysis, modelling, transformation and visualization of datasets</strong> for online products and backend data platform. </li><li> Implement data engineering codebase <strong>using server-side languages Java/Scala or scripting using Python and Javascript</strong> </li><li><strong> Design and develop apis for data pipelining frameworks </strong> on data collection, processing and storage across data stores. </li><li><strong> Understand noSQL and stream programming apis for building data pipelines </strong> and micro-service based architecture across products </li><li> Design and development of <strong>data solutions for fast datastores, large scale data warehousing, machine learning and computer vision analytics</strong>. <br><br></li></ul><strong><u>Minimum Qualifications<br></u></strong><ul><li> Bachelor’s Degree in Computer Science or related discipline </li><li> 5+ years of software development experience </li><li><strong> 2+ years of experience as a Data Engineer <br><br></strong></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> Extensive knowledge of RDBMS (<strong>Microsoft SQL Server, Mysql, Postgres or similar)</strong> </li><li> Proven experience with <strong>NoSQL stores</strong> (one or more of <strong>Cassandra, MongoDB, InfluxDB, HBase/HDFS, ElasticSearch)</strong> </li><li> Experience in a <strong>distributed microservices and/or serverless (Lambda) cloud software architecture</strong> </li><li> In-Depth knowledge <strong>of ETL commercial software products (any of Informatica, Talend, Nifi or SSIS)</strong> with hands-on experience designing, implementing, and delivering solutions </li><li><strong> Expertise with integration of complex and large data from multiple data sources, data and sensor fusion, and migration to newer </strong> methodologies </li><li> Prior experience as part of a large group working on <strong>massive data engineering pipelines and analytics for machine learning, computer vision</strong> </li><li> An <strong>aggressive problem solver</strong> who can provide <strong>creative solutions to complex situations</strong> and obtain buy-in from those affected </li><li> An independent worker who can take the initiative to define and prioritize specific goals and objectives, and to do the same for others </li><li> Strong people skills - able to communicate with colleagues while building credibility and rapport, modifying behavioral style to respond to the needs of others while maintaining objectives </li><li> An organized individual who is very detail oriented and can document and develop plans necessary for deliverables towards specific product or platform goals. </li><li> A team player that works hard, admits his/her strengths and weaknesses, and has the flexibility to improve by learning new things <br></li></ul>Omnitracs LLC<strong> , is an Equal Opportunity Employer and does not unlawfully discriminate on the basis of any status or condition protected by applicable federal, state, or local municipal law.</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Mountain View, California, United States",Cognizant,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-cognizant-2426934212?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=oJcfTHIl03vta%2F4OUJnehw%3D%3D&position=11&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"We are looking for experienced Back-End Microservices Software Engineer who would be responsible for prototyping, designing and development of the back-end services for KAID Health’s product solution and assist with its deployment into AWS. The position requires the candidate to be individual contributor in a small agile distributed development team. The ideal candidate will be experienced in development of microservices, ideally in Python, and Elastic Container Service in Amazon Web Services cloud. This person will report directly to the Chief Technology Officer, and materially influence product and corporate strategy.

Essential Job Functions

The Python Back-End Software Engineer is responsible for:

Design and implement Python Flask microservices of the product API
Develop components supporting our streaming ETL
Implement and execute API unit tests
Troubleshoot and fix product API defects
Support continuous integration and continuous delivery of the API
Optimize responsiveness of the API through the use of caching and other techniques
Contributing to the successful and timely delivery of all software projects
Understand agile methodologies and processes


Education, Experience And Skills

Bachelor’s degree in Computer Science or a related discipline
Demonstrated professional experience in building Python-based microservices and APIs
Good understanding of AWS managed services and containers
Experience with at least two of the following services: Elastic Cache, ECS/Fargate, API Gateway, Cognito, and AWS Lambda
Expertise in Python, Flask, Flask-RESTplus development and the use of SQL and NoSQL databases
Knowledge of OAuth, OpenID Connect, SAML and other protocols
Familiarity with build tools such as CodePipeline, Jenkins, etc. and implementing automated unit tests.
Experience with Kafka, Kafka-Connect a big plus.
Working knowledge of Git and Gitflow Workflow
Excellent verbal and written communication skills


Location

The company is based out of the Metro-Boston area. Ideally, candidates are located here, but we are virtual through at least April of 2021. At minimum, candidate must be willing to travel periodically to Boston, MA, or a client location, once it is safe/practical to do so.

Compensation & Benefits

As a fully-funded startup, KAID offer competitive salary and bonus-based compensation, as well as participation in our equity incentive program. We offer health insurance, flexible time off, and select wellness benefits. Also, the position will entail direct exposure to the Company’s Board of Directors, which include CEOs of leading health systems and technology pioneers. Finally, KAID is welcoming, mission-driven, supportive, inclusive company, committed to continually learning and teaching one another.

KAID Health is a newly formed company on a unique mission— to make sure each patient’s healthcare experience is as coordinated as possible. We combine a team with decades of experience in building applications to improve healthcare with leading edge Artificial Intelligence technology. KAID’s principles have built several care management workflow and analytics products deployed all across the healthcare industry. We are mission-driven organization focused on helping patients and care givers, while building a culture that values continual innovation and individual growth.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are looking for experienced Back-End Microservices Software Engineer who would be responsible for prototyping, designing and development of the back-end services for KAID Health’s product solution and assist with its deployment into AWS. The position requires the candidate to be individual contributor in a small agile distributed development team. The ideal candidate will be experienced in development of microservices, ideally in Python, and Elastic Container Service in Amazon Web Services cloud. This person will report directly to the Chief Technology Officer, and materially influence product and corporate strategy.<br><br><strong><u>Essential Job Functions<br><br></u></strong>The Python Back-End Software Engineer is responsible for:<br><ul><li>Design and implement Python Flask microservices of the product API</li><li>Develop components supporting our streaming ETL</li><li>Implement and execute API unit tests</li><li>Troubleshoot and fix product API defects</li><li>Support continuous integration and continuous delivery of the API</li><li>Optimize responsiveness of the API through the use of caching and other techniques</li><li>Contributing to the successful and timely delivery of all software projects</li><li>Understand agile methodologies and processes<br><br></li></ul><strong><u>Education, Experience And Skills<br></u></strong><ul><li>Bachelor’s degree in Computer Science or a related discipline</li><li>Demonstrated professional experience in building Python-based microservices and APIs</li><li>Good understanding of AWS managed services and containers</li><li>Experience with at least two of the following services: Elastic Cache, ECS/Fargate, API Gateway, Cognito, and AWS Lambda</li><li>Expertise in Python, Flask, Flask-RESTplus development and the use of SQL and NoSQL databases</li><li>Knowledge of OAuth, OpenID Connect, SAML and other protocols</li><li>Familiarity with build tools such as CodePipeline, Jenkins, etc. and implementing automated unit tests.</li><li>Experience with Kafka, Kafka-Connect a big plus.</li><li>Working knowledge of Git and Gitflow Workflow</li><li>Excellent verbal and written communication skills<br><br></li></ul><strong>Location<br><br></strong>The company is based out of the Metro-Boston area. Ideally, candidates are located here, but we are virtual through at least April of 2021. At minimum, candidate must be willing to travel periodically to Boston, MA, or a client location, once it is safe/practical to do so.<br><br><strong><u>Compensation &amp; Benefits<br><br></u></strong>As a fully-funded startup, KAID offer competitive salary and bonus-based compensation, as well as participation in our equity incentive program. We offer health insurance, flexible time off, and select wellness benefits. Also, the position will entail direct exposure to the Company’s Board of Directors, which include CEOs of leading health systems and technology pioneers. Finally, KAID is welcoming, mission-driven, supportive, inclusive company, committed to continually learning and teaching one another.<br><br>KAID Health is a newly formed company on a unique mission— to make sure each patient’s healthcare experience is as coordinated as possible. We combine a team with decades of experience in building applications to improve healthcare with leading edge Artificial Intelligence technology. KAID’s principles have built several care management workflow and analytics products deployed all across the healthcare industry. We are mission-driven organization focused on helping patients and care givers, while building a culture that values continual innovation and individual growth.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Data Engineer,"San Jose, California, United States",Indus Valley Consultants,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-indus-valley-consultants-2430430002?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=560KR%2F6iLRw7wzFkVKh7MA%3D%3D&position=12&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Cognizant is looking for Data Scientist. As a trusted advisor, responsible for providing an approach for the overall project. As a domain specialist, you will drive technology discussions and analyze the existing gaps in addressing business needs. You are a thought leader-comfortable challenging the status quo to enhance our current services and technologies.

About AI & Analytics: Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.

By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.

Managing master data, including creation, updates, and deletion.
Experience in SQL & Python.
Provide quality assurance of imported data.
Commissioning and decommissioning of data sets.
Processing confidential data and information according to guidelines.
Helping develop reports and analysis.
Managing and designing the reporting environment, including data sources, security, and metadata.
Generating reports from single or multiple systems.
Troubleshooting the reporting database environment and reports.
Evaluating changes and updates to source production systems.
Training end users on new reports and dashboards.
Providing technical expertise on data storage structures, data mining, and data cleansing.



Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Feb 19 2021

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Cognizant is looking for Data Scientist. As a trusted advisor, responsible for providing an approach for the overall project. As a domain specialist, you will drive technology discussions and analyze the existing gaps in addressing business needs. You are a thought leader-comfortable challenging the status quo to enhance our current services and technologies.<br><br>About AI &amp; Analytics: Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI &amp; Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.<br><br>By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.<br><ul> <li>Managing master data, including creation, updates, and deletion.</li> <li>Experience in SQL &amp; Python.</li> <li>Provide quality assurance of imported data.</li> <li>Commissioning and decommissioning of data sets.</li> <li>Processing confidential data and information according to guidelines.</li> <li>Helping develop reports and analysis.</li> <li>Managing and designing the reporting environment, including data sources, security, and metadata.</li> <li>Generating reports from single or multiple systems.</li> <li>Troubleshooting the reporting database environment and reports.</li> <li>Evaluating changes and updates to source production systems.</li> <li>Training end users on new reports and dashboards.</li> <li>Providing technical expertise on data storage structures, data mining, and data cleansing.</li> <br><br></ul>Employee Status : Full Time Employee<br><br>Shift : Day Job<br><br>Travel : No<br><br>Job Posting : Feb 19 2021<br><br><strong><u>About Cognizant<br><br></u></strong>Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.<br><br>Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.<br><br>Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.<br><br>If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Management Consulting"
Data Engineer,"Broomfield, Colorado, United States",Crocs,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-crocs-2430711158?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=KuEDocp6w4JLvehKxHjfWw%3D%3D&position=13&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"What You'll Do

Designing, develop & tune data products, applications and integrations on large scale data platforms (SQL server, HANA, Hadoop, Kafka Streaming, etc) with an emphasis on performance, reliability and scalability and most of all quality.
Analyze the business needs, profile large data sets and build custom data models and applications to drive the Adobe business decision making and customers experience
Develop and extend design patterns, processes, standards, frameworks and reusable components for various data engineering functions/areas.
Collaborate with key stakeholders including business team, engineering leads, architects, BSA's & program managers.
Integrate data from MS-Dynamics 365 application and build reporting solution.


Working at Adobe you have the opportunity to extend your network and collaborate with engineers, architects and leaders across the Adobe data management space, Adobe product engineering and Business leadership teams.

The Ideal Candidate Will Have

MS in Computer Science / related technical field with 7 to 10 years of strong hands-on experience in enterprise data warehousing / big data implementations & complex data solutions and frameworks
Strong SQL, ETL, scripting and or programming skills with a preference towards Python, Java, Scala, shell scripting
Demonstrated ability to clearly form and communicate ideas to both technical and non-technical audiences.
Strong problem-solving skills with an ability to isolate, deconstruct and resolve complex data / engineering challenges
Results driven with attention to detail, strong sense of ownership, and a commitment to up-leveling the broader IDS engineering team through mentoring, innovation and thought leadership



Desired Skils

Demonstrated skill working with SQL and PL/SQL programming.
Demonstrated skill designing, developing and supporting database applications.
Performance Tuning of Database Schemas, Databases, SQL, ETL Jobs, and related scripts.
Demonstrated skills in HANA Modeling, SQL Stored Procedures.
SQL Server ETL Development experience using SSIS. Strong ETL, data warehouse, T-SQL skills.
Extensive experience in implementing large scale data warehouse and data mart architecture and implementation.
Dynamics 365 integration and reporting solution enablement experience is a plus.
Extensive experience on HANA & MSBI Stack SQL Server DBMS, SQL Server Analysis Services (SSAS) and SQL Server Integration Services (SSIS) is preferred.
Marketing, Sales, Bookings, and finance Domain expertise is a plus
Has agile scrum work experience for executing day to day activities and reporting to scrum team.
Good communication skills across distributed team environment
Must be self-motivated, responsive, professional and dedicated to customer success
Familiarity with streaming applications
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>What You'll Do<br></u></strong><ul> <li>Designing, develop &amp; tune data products, applications and integrations on large scale data platforms (SQL server, HANA, Hadoop, Kafka Streaming, etc) with an emphasis on performance, reliability and scalability and most of all quality. </li> <li>Analyze the business needs, profile large data sets and build custom data models and applications to drive the Adobe business decision making and customers experience </li> <li>Develop and extend design patterns, processes, standards, frameworks and reusable components for various data engineering functions/areas. </li> <li>Collaborate with key stakeholders including business team, engineering leads, architects, BSA's &amp; program managers. </li> <li>Integrate data from MS-Dynamics 365 application and build reporting solution. </li> <br></ul>Working at Adobe you have the opportunity to extend your network and collaborate with engineers, architects and leaders across the Adobe data management space, Adobe product engineering and Business leadership teams.<br><br><strong><u>The Ideal Candidate Will Have<br></u></strong><ul> <li>MS in Computer Science / related technical field with 7 to 10 years of strong hands-on experience in enterprise data warehousing / big data implementations &amp; complex data solutions and frameworks </li> <li>Strong SQL, ETL, scripting and or programming skills with a preference towards Python, Java, Scala, shell scripting </li> <li>Demonstrated ability to clearly form and communicate ideas to both technical and non-technical audiences. </li> <li>Strong problem-solving skills with an ability to isolate, deconstruct and resolve complex data / engineering challenges </li> <li>Results driven with attention to detail, strong sense of ownership, and a commitment to up-leveling the broader IDS engineering team through mentoring, innovation and thought leadership </li> <br><br></ul><strong><u>Desired Skils<br></u></strong><ul> <li>Demonstrated skill working with SQL and PL/SQL programming. </li> <li>Demonstrated skill designing, developing and supporting database applications. </li> <li>Performance Tuning of Database Schemas, Databases, <strong>SQL, ETL Jobs, and related scripts</strong>. </li> <li>Demonstrated skills in <strong>HANA Modeling, SQL Stored Procedures.</strong> </li> <li>SQL Server ETL Development experience using <strong>SSIS. Strong ETL, data warehouse, T-SQL skills</strong>. </li> <li>Extensive experience in implementing large scale data warehouse and data mart architecture and implementation. </li> <li><strong>Dynamics 365 integration and reporting solution enablement experience is a plus. </strong></li> <li><strong>Extensive experience </strong>on <strong>HANA &amp; MSBI Stack SQL Server DBMS, SQL Server Analysis Services (SSAS) and SQL Server Integration Services (SSIS) is preferred.</strong> </li> <li>Marketing, Sales, Bookings, and finance Domain expertise is a plus </li> <li>Has agile scrum work experience for executing day to day activities and reporting to scrum team. </li> <li>Good communication skills across distributed team environment </li> <li>Must be self-motivated, responsive, professional and dedicated to customer success </li> <li>Familiarity with streaming applications</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Technology and Services
Data Engineer-Product Specialist,"New York, New York, United States",ActionIQ,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-product-specialist-at-actioniq-2428105449?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=%2FMuX%2Bjz6shPhRN5X5UCIqw%3D%3D&position=14&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Crocs is seeking a Junior Data Engineer to develop, test, and maintain data pipelines and related architectures within the Azure platform. This position will help to enable the Crocs enterprise to make bigger, bolder decisions faster. The Junior Data Engineer will work independently and with the team to help facilitate the usage of more sophisticated analytics/data science throughout the organization

Job Duties

Data Modeling -Execute a framework to be used within our Enterprise Data Warehouse (EDW) by providing consistent predictable techniques and methodologies for data

ELT/ETL -Develop ETL/ELT processes and patterns to efficiently move data using batch processing

Engineering Best Practices- Adhere to engineering standard methodologies, including test-driven development, agile management, and continuous integration pipelines

Documentation -Create and maintain accurate and complete documentation of the pipelines developed

Aptitude for Learning - Stay ahead of on what is happening within the BI and analytics space and demonstrate interest and desire in the area of data science and machine learning

Job Requirements

Minimum Education

Bachelor’s degree in computer science, information technology, engineering, mathematics, or equivalent technical degree



Minimum Experience

2+ years in a similar role


Knowledge, Skills & Abilities

Strong proficiency in ANSI-SQL
Proficiency in Python, Pandas, and/or PySpark
Experience with Databricks or similar products
Experience with a business intelligence tool, such as Power BI
Experience in SAP ERP or other similar ERP systems is a plus
Experience in Snowflake Database or other similar columnar database
Prior experience working in a cloud platform
Experience working in Azure or a Microsoft-specific environment is a plus
Experience working with modern ETL/ELT tools, such as Data Factory, Databricks, or similar


Crocs is an Equal Opportunity Employer committed to a diverse and inclusive work environment.

Title: Data Engineer

Career Level: CL 4

Salary Range: $71,500-107,300

This position is eligible to participate in a company incentive program.

This position is eligible for company benefits including but not limited to medical, dental, and vision coverage, life and AD&D, short and long term disability coverage, paid time off, employee assistance, participation in a 401k program that includes company match, and many other additional voluntary benefits.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Crocs is seeking a <strong>Junior Data Engineer</strong> to develop, test, and maintain data pipelines and related architectures within the Azure platform. This position will help to enable the Crocs enterprise to make bigger, bolder decisions faster. The Junior Data Engineer will work independently and with the team to help facilitate the usage of more sophisticated analytics/data science throughout the organization<br><br><strong><u>Job Duties<br><br></u></strong>Data Modeling -Execute a framework to be used within our Enterprise Data Warehouse (EDW) by providing consistent predictable techniques and methodologies for data<br><br>ELT/ETL -Develop ETL/ELT processes and patterns to efficiently move data using batch processing<br><br>Engineering Best Practices- Adhere to engineering standard methodologies, including test-driven development, agile management, and continuous integration pipelines<br><br>Documentation -Create and maintain accurate and complete documentation of the pipelines developed<br><br>Aptitude for Learning - Stay ahead of on what is happening within the BI and analytics space and demonstrate interest and desire in the area of data science and machine learning<br><br><strong><u>Job Requirements<br><br></u></strong>Minimum Education<br><ul> <li>Bachelor’s degree in computer science, information technology, engineering, mathematics, or equivalent technical degree</li> <br><br></ul><strong><u>Minimum Experience<br></u></strong><ul> <li>2+ years in a similar role</li> <br></ul>Knowledge, Skills &amp; Abilities<br><ul> <li>Strong proficiency in ANSI-SQL</li> <li>Proficiency in Python, Pandas, and/or PySpark</li> <li>Experience with Databricks or similar products</li> <li>Experience with a business intelligence tool, such as Power BI</li> <li>Experience in SAP ERP or other similar ERP systems is a plus</li> <li>Experience in Snowflake Database or other similar columnar database</li> <li>Prior experience working in a cloud platform</li> <li>Experience working in Azure or a Microsoft-specific environment is a plus</li> <li>Experience working with modern ETL/ELT tools, such as Data Factory, Databricks, or similar</li> <br></ul>Crocs is an Equal Opportunity Employer committed to a diverse and inclusive work environment.<br><br>Title: Data Engineer<br><br>Career Level: CL 4<br><br>Salary Range: $71,500-107,300<br><br>This position is eligible to participate in a company incentive program.<br><br>This position is eligible for company benefits including but not limited to medical, dental, and vision coverage, life and AD&amp;D, short and long term disability coverage, paid time off, employee assistance, participation in a 401k program that includes company match, and many other additional voluntary benefits.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Consumer Goods, Retail"
Data Engineer,"Richmond, Virginia, United States",CapCenter,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-capcenter-2386753797?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=CeEryFVN6phBlvmshsHpuw%3D%3D&position=15&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Become part of the ActionIQ Forward Deployed Engineering Team.

ActionIQ is a Customer Data Platform (CDP) built to help modern marketers transform customer experiences by giving them access to 100% of their detailed customer behavior data. That access, combined with the ability to orchestrate cross-channel campaigns and measure incremental lift across all digital and offline channels, helps brands such as The New York Times, Michael Kors, Pandora Media and others drive innovation and profitability. We are backed by top investors Andreessen Horowitz, FirstMark, and Sequoia Capital.

This role is part of the Delivery team of Forward Deployed Engineering, and we’re seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value.

You are an engineer who loves data and wants to see technology and data used successfully. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer.

Above all, you want to make it work! You handle pressure well and you love being part of a team that wins. You know how to get the relevant people to help you achieve this goal, and you are prepared to roll up your sleeves and write code in whatever language makes sense to bypass obstacles and make things work.

Role & Responsibilities

Product Specialist Data Engineers are our experts on the AIQ data platform components, and can confidently and quickly deliver on existing customer requests and projects.

You will be working hands on with our technology stack, supporting our Customer Enablement Data Engineers (the customer facing technical owners of our existing customer relationships/ deliverables), and working closely with the Product Engineering team, the Engagement team, and our Customer/ Vendor technical teams, in order to deliver on all existing customer’s technical requests. This can include

Connecting disparate data sources and setting up ETL pipelines
Setting up ingest/ export integrations
Setting up/ enabling new product features
Conducting data and/ or platform migrations
Testing your solutions and validating data
Helping answer customer questions, and troubleshoot where necessary
Participating in the field on-call rotation


You will also be

Finding out sustainable ways of addressing repeatable issues, and building tools for automation
Contributing with documentation and building our product knowledge base
A source of feedback for our product team, full stack and backend engineering team



Requirements

BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar
Proficient in one programming language and working knowledge of SQL, and Unix command line tools
Project Management Skills

Ability to multitask, as well as manage and communicate competing priorities
Sense of ownership and ability to deliver
Excellent problem solving skills

Self sufficiency - giving it a try before reaching out for help
Attention to detail and testing mindset - making sure the end result meets the need
Strong Communication skills

Succinctly keeping the team apprised about status at every stage
Ability to communicate with customer/ vendor technical teams, for clarifying details and delivering technical solutions
Other skills

Improvement mindset, through processes, tools and/ or documentation
Works well in team settings
Strong professionalism & work ethic
Adaptable, self starter and fast learner
Dealing well with pressure


Nice to have

1+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc.
Python, Github, AWS/ GCP infrastructure
Industry & vendor knowledge



Benefits

Work with a fun, inclusive, and smart team of people as we build a NYC-based enterprise software company!
Competitive compensation package, including significant equity component
Back by top-tier VCs (Sequoia, Andreessen Horowitz, FirstMark Capital)
Top health insurance benefits
Currently remote with expectation to be back in office in 2021.
Work from Home stipend to optimize your set up.



ActionIQ is committed to building an inclusive, equitable, and diverse organization. We embrace equal opportunity for all applicants and seek to foster a culture of belonging for our employees. We recognize and appreciate that the more inclusive we are, the better we will function as a team. AIQ welcomes qualified applicants of any race, color, ancestry, religion, sex, national origin, gender identity, gender expression, age, marital or family status, disability, military veteran status, and any other status or background. Join us on our journey to build a product that will help our customers deliver memorable experiences that will drive loyalty and growth.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Become part of the ActionIQ Forward Deployed Engineering Team.<br><br>ActionIQ is a Customer Data Platform (CDP) built to help modern marketers transform customer experiences by giving them access to 100% of their detailed customer behavior data. That access, combined with the ability to orchestrate cross-channel campaigns and measure incremental lift across all digital and offline channels, helps brands such as The New York Times, Michael Kors, Pandora Media and others drive innovation and profitability. We are backed by top investors Andreessen Horowitz, FirstMark, and Sequoia Capital.<br><br>This role is part of the Delivery team of Forward Deployed Engineering, and we’re seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value.<br><br>You are an engineer who loves data and wants to see technology and data used successfully. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer.<br><br>Above all, you want to make it work! You handle pressure well and you love being part of a team that wins. You know how to get the relevant people to help you achieve this goal, and you are prepared to roll up your sleeves and write code in whatever language makes sense to bypass obstacles and make things work.<br><br>Role &amp; Responsibilities<br><br>Product Specialist Data Engineers are our experts on the AIQ data platform components, and can confidently and quickly deliver on existing customer requests and projects.<br><br>You will be working hands on with our technology stack, supporting our Customer Enablement Data Engineers (the customer facing technical owners of our existing customer relationships/ deliverables), and working closely with the Product Engineering team, the Engagement team, and our Customer/ Vendor technical teams, in order to deliver on all existing customer’s technical requests. This can include<br><ul> <li>Connecting disparate data sources and setting up ETL pipelines</li> <li>Setting up ingest/ export integrations</li> <li>Setting up/ enabling new product features</li> <li>Conducting data and/ or platform migrations</li> <li>Testing your solutions and validating data</li> <li>Helping answer customer questions, and troubleshoot where necessary</li> <li>Participating in the field on-call rotation</li> <br></ul>You will also be<br><ul> <li>Finding out sustainable ways of addressing repeatable issues, and building tools for automation</li> <li>Contributing with documentation and building our product knowledge base</li> <li>A source of feedback for our product team, full stack and backend engineering team</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar</li> <li>Proficient in one programming language and working knowledge of SQL, and Unix command line tools</li> <li>Project Management Skills<br><ul> <li>Ability to multitask, as well as manage and communicate competing priorities</li> <li>Sense of ownership and ability to deliver</li> </ul> </li> <li>Excellent problem solving skills<br><ul> <li>Self sufficiency - giving it a try before reaching out for help</li> <li>Attention to detail and testing mindset - making sure the end result meets the need</li> </ul> </li> <li>Strong Communication skills<br><ul> <li>Succinctly keeping the team apprised about status at every stage</li> <li>Ability to communicate with customer/ vendor technical teams, for clarifying details and delivering technical solutions</li> </ul> </li> <li>Other skills<br><ul> <li>Improvement mindset, through processes, tools and/ or documentation</li> <li>Works well in team settings</li> <li>Strong professionalism &amp; work ethic</li> <li>Adaptable, self starter and fast learner</li> <li>Dealing well with pressure</li> </ul> </li> <br></ul>Nice to have<br><ul> <li>1+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc.</li> <li>Python, Github, AWS/ GCP infrastructure</li> <li>Industry &amp; vendor knowledge</li> <br><br></ul><u><strong>Benefits<br></strong></u><ul> <li>Work with a fun, inclusive, and smart team of people as we build a NYC-based enterprise software company!</li> <li>Competitive compensation package, including significant equity component</li> <li>Back by top-tier VCs (Sequoia, Andreessen Horowitz, FirstMark Capital)</li> <li>Top health insurance benefits</li> <li>Currently remote with expectation to be back in office in 2021.</li> <li>Work from Home stipend to optimize your set up.</li> <br><br></ul><em>ActionIQ is committed to building an inclusive, equitable, and diverse organization. We embrace equal opportunity for all applicants and seek to foster a culture of belonging for our employees. We recognize and appreciate that the more inclusive we are, the better we will function as a team. AIQ welcomes qualified applicants of any race, color, ancestry, religion, sex, national origin, gender identity, gender expression, age, marital or family status, disability, military veteran status, and any other status or background. Join us on our journey to build a product that will help our customers deliver memorable experiences that will drive loyalty and growth.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Engineering,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer II,"New Philadelphia, Pennsylvania, United States",Grubhub,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-ii-at-grubhub-2409476117?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=LibNLmdsQwYICwN0A2Lysg%3D%3D&position=16&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Overview

CapCenter is looking for a Data Engineer with full-stack data experience to help align and centralize our data environments, processes and architecture across the firm. This role will play an integral part in accelerating innovation across CapCenter’s entire business. This is a career shaping opportunity.




This role will help maintain the ongoing evolution and application of data for CapCenter. The Data Engineer will need to understand the data space including systems, administration, governance, and transformation. A desire to expand your expertise into machine learning would be valuable.




What You’ll Do

Collaborate across the organization to support mission-critical business processes with data
Maintain and develop existing data infrastructure including overall design, ETL, and systems
Design and construct ETLs that communicate with APIs and internal systems
Over time, assume responsibility for furthering machine learning within the firm




Qualifications

Bachelor’s Degree
At least 1 year of API development experience
At least 1 year of ETL development experience
At least 1 year of SQL database experience
Organized, entrepreneurial, ambitious, and attentive to detail




Preferred Qualifications

Master’s Degree
At least 1 year of cloud service experience
At least 1 year of application development (Node, .NET, etc.) experience
At least 1 year of scripting language (Python, R, Perl, JavaScript, Shell, etc.) experience
At least 1 year of big data technology (Spark, Hadoop, Snowflake, etc.) experience
At least 1 year of NoSQL experience
At least 1 year of Agile engineering practices experience
At least 1 year of machine learning/predictive analytics experience

You’ll get  

A competitive salary & annual bonus 
401k w/ match, health, dental & vision benefits 
Exposure to the mortgage, real estate and insurance industries, front to back 
To participate in cross-functional collaboration and leadership  
The opportunity to lead transformative projects for an innovative and disruptive business

  

We offer a competitive compensation package to include base salary, medical, dental and life insurance benefits, 401K and paid vacation. We are an Equal Opportunity Employer M/V/F/D. 

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>Overview</strong></p><p>CapCenter is looking for a Data Engineer with full-stack data experience to help align and centralize our data environments, processes and architecture across the firm. This role will play an integral part in accelerating innovation across CapCenter’s entire business. This is a career shaping opportunity.</p><p><br></p><p>This role will help maintain the ongoing evolution and application of data for CapCenter. The Data Engineer will need to understand the data space including systems, administration, governance, and transformation. A desire to expand your expertise into machine learning would be valuable.</p><p><br></p><p><strong>What You’ll Do</strong></p><ul><li>Collaborate across the organization to support mission-critical business processes with data</li><li>Maintain and develop existing data infrastructure including overall design, ETL, and systems</li><li>Design and construct ETLs that communicate with APIs and internal systems</li><li>Over time, assume responsibility for furthering machine learning within the firm</li></ul><p><br></p><p><strong>Qualifications</strong></p><ul><li>Bachelor’s Degree</li><li>At least 1 year of API development experience</li><li>At least 1 year of ETL development experience</li><li>At least 1 year of SQL database experience</li><li>Organized, entrepreneurial, ambitious, and attentive to detail</li></ul><p><br></p><p><strong>Preferred Qualifications</strong></p><ul><li>Master’s Degree</li><li>At least 1 year of cloud service experience</li><li>At least 1 year of application development (Node, .NET, etc.) experience</li><li>At least 1 year of scripting language (Python, R, Perl, JavaScript, Shell, etc.) experience</li><li>At least 1 year of big data technology (Spark, Hadoop, Snowflake, etc.) experience</li><li>At least 1 year of NoSQL experience</li><li>At least 1 year of Agile engineering practices experience</li><li>At least 1 year of machine learning/predictive analytics experience</li></ul><p><strong>You’ll get&nbsp;&nbsp;</strong></p><ul><li>A competitive salary &amp; annual bonus&nbsp;</li><li>401k w/ match, health, dental &amp; vision benefits&nbsp;</li><li>Exposure to the mortgage, real estate and insurance industries, front to back&nbsp;</li><li>To participate in cross-functional collaboration and leadership&nbsp;&nbsp;</li><li>The opportunity to lead transformative projects for an innovative and disruptive business</li></ul><p>&nbsp;&nbsp;</p><p><em>We offer a competitive compensation package to include base salary, medical, dental and life insurance benefits, 401K and paid vacation. We are an Equal Opportunity Employer M/V/F/D.&nbsp;</em></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Real Estate
Data Scientist,"Burlington, Vermont, United States",Faraday,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-faraday-2416732270?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=DgURRJJvO9ajZB1rJ1HrlQ%3D%3D&position=17&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"About The Opportunity

Grubhub is dedicated to connecting hungry diners with our wide network of restaurants across the country. Our innovative technology, easy-to-use platforms and streamlined delivery capabilities make us an industry leader today, and in the future of online food ordering.

We strive to create a workplace that reflects the diversity of our customers and the communities we serve. When you join our team, you become part of a community that works together to innovate, solve problems, take risks, grow, work hard and have a ton of fun in the process!

Why Work For Us

We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what’s your favorite restaurant for food delivery!

More About The Role

Data Engineer will be responsible for building efficient data pipelines that transform raw data into a format usable by downstream applications that serve both analytical and operational use cases.

This Data Engineer will be working closely with business stakeholders, product managers and engineering teams to meet data requirements of various initiatives in Grubhub.

The Impact You Will Make

Working with high volumes of data to efficiently process and expose for analysis
Collaborating with other engineering teams on strategies for data
Work with cutting edge data processing technologies
Understand our stakeholder (Finance, Marketing, Product) requirements and write complex and efficient code to transform raw data into an easy to approach data marts.
Doing deep dives on business verticals where you become one of the foremost experts on that vertical in the company
Analyze data to measure impacts of data schemas and use it to iterate on improvements
Translate from technical to business, and vice versa. You need to be able to speak with the least technically-minded client (internal or external) and make technology make sense to them. Then turn around and do it the other way


What You Bring To The Table

Excellent knowledge on SQL, data modeling and patterns.
5-7 years experience with Python or another general purpose programming language
Background in writing ETL jobs within a Business Intelligence context
A bachelor's degree, preferably in a computer-related discipline.
Enthusiasm for the job. Are you excited about data? Do you love your users? Good, the same goes for us

Got These? Even Better:

Experience big data processing with Spark and other big data tools a plus
Excellent communication skills, including the ability to crystallize and broadly socialize insights
Problem analysis and problem-solving skills
Rigorous attention to detail and accuracy
Exposure to Amazon AWS or another cloud provider
Adaptability and collaborative skills


And Of Course, Perks!

Flexible PTO. Grubhub employees are provided a generous amount of time to recharge their batteries.
Health and Wellness. We provide programs that support your overall well-being such as generous medical benefits, employee network groups, company-wide fitness challenges, and a comfortable and casual workplace! We also support our parents by offering 8 weeks of paid parent bonding time, a 4-week returnship program, and 6-8 weeks paid medical leave.
Learning and Career Growth. Your personal and professional development is a priority at Grubhub. From day one, we empower you to lead and be an active participant in your career growth. We provide continuous learning opportunities, training, and coaching and mentorship programs.
MealPerks. Who’s ready for some lunch? We provide our employees with a weekly Grubhub credit to enjoy and support local restaurants. We also offer company-wide meals several times a year to bring our Grubhub family together.
Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives. Some of our popular past events include: Wing-eating contests, Grubtoberfest, 5k Runs, Bring Your Child to Work Day, regular happy hours, and more!
Social Impact. We believe in the importance of serving the communities that support our business. In addition, employees are given paid time off each year to support the causes that are important to them.


Grubhub is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. The EEO is the Law poster is available here: DOL Poster . If you are applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an e-mail to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.

CA Privacy Notice: If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.

Options

Apply for this job online Apply

Share

Email this job to a friend Refer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed

Connect With Us!

Not ready to apply? Connect with us for general consideration.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About The Opportunity<br><br></u></strong>Grubhub is dedicated to connecting hungry diners with our wide network of restaurants across the country. Our innovative technology, easy-to-use platforms and streamlined delivery capabilities make us an industry leader today, and in the future of online food ordering.<br><br>We strive to create a workplace that reflects the diversity of our customers and the communities we serve. When you join our team, you become part of a community that works together to innovate, solve problems, take risks, grow, work hard and have a ton of fun in the process!<br><br><strong> Why Work For Us <br><br></strong>We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what’s your favorite restaurant for food delivery!<br><br><strong><u>More About The Role<br><br></u></strong>Data Engineer will be responsible for building efficient data pipelines that transform raw data into a format usable by downstream applications that serve both analytical and operational use cases.<br><br>This Data Engineer will be working closely with business stakeholders, product managers and engineering teams to meet data requirements of various initiatives in Grubhub.<br><br><strong> The Impact You Will Make <br></strong><ul><li> Working with high volumes of data to efficiently process and expose for analysis </li><li> Collaborating with other engineering teams on strategies for data </li><li> Work with cutting edge data processing technologies </li><li> Understand our stakeholder (Finance, Marketing, Product) requirements and write complex and efficient code to transform raw data into an easy to approach data marts. </li><li> Doing deep dives on business verticals where you become one of the foremost experts on that vertical in the company </li><li> Analyze data to measure impacts of data schemas and use it to iterate on improvements </li><li> Translate from technical to business, and vice versa. You need to be able to speak with the least technically-minded client (internal or external) and make technology make sense to them. Then turn around and do it the other way <br><br></li></ul><strong><u>What You Bring To The Table<br></u></strong><ul><li> Excellent knowledge on SQL, data modeling and patterns. </li><li> 5-7 years experience with Python or another general purpose programming language </li><li> Background in writing ETL jobs within a Business Intelligence context </li><li> A bachelor's degree, preferably in a computer-related discipline. </li><li> Enthusiasm for the job. Are you excited about data? Do you love your users? Good, the same goes for us <br></li></ul><strong>Got These? Even Better: <br></strong><ul><li> Experience big data processing with Spark and other big data tools a plus </li><li> Excellent communication skills, including the ability to crystallize and broadly socialize insights </li><li> Problem analysis and problem-solving skills </li><li> Rigorous attention to detail and accuracy </li><li> Exposure to Amazon AWS or another cloud provider </li><li> Adaptability and collaborative skills <br><br></li></ul><strong> And Of Course, Perks! <br></strong><ul><li> <strong> Flexible PTO. </strong> Grubhub employees are provided a generous amount of time to recharge their batteries. </li><li> <strong> Health and Wellness. </strong> We provide programs that support your overall well-being such as generous medical benefits, employee network groups, company-wide fitness challenges, and a comfortable and casual workplace! We also support our parents by offering 8 weeks of paid parent bonding time, a 4-week returnship program, and 6-8 weeks paid medical leave. </li><li> <strong> Learning and Career Growth. </strong> Your personal and professional development is a priority at Grubhub. From day one, we empower you to lead and be an active participant in your career growth. We provide continuous learning opportunities, training, and coaching and mentorship programs. </li><li> <strong> MealPerks. </strong> Who’s ready for some lunch? We provide our employees with a weekly Grubhub credit to enjoy and support local restaurants. We also offer company-wide meals several times a year to bring our Grubhub family together. </li><li> <strong> Fun. </strong> Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives. Some of our popular past events include: Wing-eating contests, Grubtoberfest, 5k Runs, Bring Your Child to Work Day, regular happy hours, and more! </li><li> <strong> Social Impact. </strong> We believe in the importance of serving the communities that support our business. In addition, employees are given paid time off each year to support the causes that are important to them. <br><br></li></ul>Grubhub is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. The EEO is the Law poster is available here: DOL Poster . If you are applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an e-mail to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.<br><br>CA Privacy Notice: If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.<br><br><strong>Options<br><br></strong>Apply for this job online Apply<br><br>Share<br><br>Email this job to a friend Refer<br><br>Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.<br><br>Share on your newsfeed<br><br><strong> Connect With Us! <br><br></strong>Not ready to apply? Connect with us for general consideration.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"Bellevue, Washington, United States",BitTitan,2021-01-24,https://www.linkedin.com/jobs/view/data-engineer-at-bittitan-2378885421?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=ZyMcAXXvFYtzcKEdxlatKg%3D%3D&position=18&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"About Faraday

Faraday helps consumer brands find, convert, engage, and retain more customers using AI. Located in the historic Maltex Building in beautiful Burlington, Vermont, we're a fast-growing venture-backed startup founded in 2012.




Our values

We believe in privacy and are committed to ending the widespread proliferation of consumer data. We believe in science and the power of statistically significant conclusions. We believe in equality and reject all forms of algorithmic prejudice. We believe in health and fun and encourage a positive work/life balance.




Our dedication to diversity

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.




About our Data Science team

At the heart of the Faraday AI platform is a shared machine learning pipeline framework built from the ground up. Our data scientists work with clients and their Faraday account managers to carefully define one or more business goals for deployment on the platform. The pipeline uses these ""outcome"" definitions to perform ETL, training data formation, feature engineering, model building, validation, scoring, and deployment.




Your team is also responsible for curating the Faraday Identity Graph from upstream data sources, preparing interpretive analysis for clients, and nurturing Faraday’s quantitative culture.




About your role

We're looking for an expert, curious, relentless, trustworthy data scientist to join us at Faraday. You will pursue a variety of challenges, including:

Determining the best predictive approaches to meet clients’ business outcomes.
Driving research and development of new algorithms, tools, and methods
Communicating and providing context to clients.
Improving and maintaining Faraday data science products
Being curious—there’s so much we don’t know in the world of data science, and our only guaranteed driver of innovation is the collaborative work of open minds.




You are a methodical, self-motivated individual, capable of keeping your eye on the finish line amidst competing priorities. You have good interpersonal abilities which you will employ regularly, including:

Weekly team meetings
Transparent project tracking
Following security protocols to keep sensitive data safe
Supporting account managers with data science expertise




Your credentials

This position requires one of the following, where a relevant degree is in data science, statistics, natural science, mathematics, computer science, or other related field:

Relevant Masters and at least two years experience, or
Relevant Bachelors and at least three years experience




Your experience

You have a foundation in statistical inference
You have demonstrated practical applications of data science




Your technical background

You are comfortable with Python and SQL
You’re familiar with data visualization best practices
You have experience with classifier algorithms (e.g. decision trees)




Location and Benefits

This position is based in Burlington, VT, and offers competitive pay and benefits.




Benefits:

401(k)
Dental insurance
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Vision insurance




Schedule:

Monday to Friday




COVID-19 considerations:

The company is working remotely during the pandemic, but there is individual-use space available at our home office in Burlington, VT.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>About Faraday</strong></p><p>Faraday helps consumer brands find, convert, engage, and retain more customers using AI. Located in the historic Maltex Building in beautiful Burlington, Vermont, we're a fast-growing venture-backed startup founded in 2012.</p><p><br></p><p><strong>Our values</strong></p><p>We believe in&nbsp;<strong>privacy</strong>&nbsp;and are committed to ending the widespread proliferation of consumer data. We believe in&nbsp;<strong>science</strong>&nbsp;and the power of statistically significant conclusions. We believe in&nbsp;<strong>equality</strong>&nbsp;and reject all forms of algorithmic prejudice. We believe in&nbsp;<strong>health and fun</strong>&nbsp;and encourage a positive work/life balance.</p><p><br></p><p><strong>Our dedication to diversity</strong></p><p>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</p><p><br></p><p><strong>About our Data Science team</strong></p><p>At the heart of the Faraday AI platform is a shared machine learning pipeline framework built from the ground up. Our data scientists work with clients and their Faraday account managers to carefully define one or more business goals for deployment on the platform. The pipeline uses these ""outcome"" definitions to perform ETL, training data formation, feature engineering, model building, validation, scoring, and deployment.</p><p><br></p><p>Your team is also responsible for curating the Faraday Identity Graph from upstream data sources, preparing interpretive analysis for clients, and nurturing Faraday’s quantitative culture.</p><p><br></p><p><strong>About your role</strong></p><p>We're looking for an expert, curious, relentless, trustworthy data scientist to join us at Faraday. You will pursue a variety of challenges, including:</p><ul><li>Determining the best predictive approaches to meet clients’ business outcomes.</li><li>Driving research and development of new algorithms, tools, and methods</li><li>Communicating and providing context to clients.</li><li>Improving and maintaining Faraday data science products</li><li>Being curious—there’s so much we don’t know in the world of data science, and our only guaranteed driver of innovation is the collaborative work of open minds.</li></ul><p><br></p><p>You are a methodical, self-motivated individual, capable of keeping your eye on the finish line amidst competing priorities. You have good interpersonal abilities which you will employ regularly, including:</p><ul><li>Weekly team meetings</li><li>Transparent project tracking</li><li>Following security protocols to keep sensitive data safe</li><li>Supporting account managers with data science expertise</li></ul><p><br></p><p><strong>Your credentials</strong></p><p>This position requires one of the following, where a relevant degree is in data science, statistics, natural science, mathematics, computer science, or other related field:</p><ul><li>Relevant Masters and at least two years experience, or</li><li>Relevant Bachelors and at least three years experience</li></ul><p><br></p><p><strong>Your experience</strong></p><ul><li>You have a foundation in statistical inference</li><li>You have demonstrated practical applications of data science</li></ul><p><br></p><p><strong>Your technical background</strong></p><ul><li>You are comfortable with Python and SQL</li><li>You’re familiar with data visualization best practices</li><li>You have experience with classifier algorithms (e.g. decision trees)</li></ul><p><br></p><p><strong>Location and Benefits</strong></p><p>This position is based in Burlington, VT, and offers competitive pay and benefits.</p><p><br></p><p>Benefits:</p><ul><li>401(k)</li><li>Dental insurance</li><li>Flexible schedule</li><li>Flexible spending account</li><li>Health insurance</li><li>Health savings account</li><li>Life insurance</li><li>Paid time off</li><li>Parental leave</li><li>Vision insurance</li></ul><p><br></p><p>Schedule:</p><ul><li>Monday to Friday</li></ul><p><br></p><p>COVID-19 considerations:</p><p>The company is working remotely during the pandemic, but there is individual-use space available at our home office in Burlington, VT.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Engineer - Analytics,"Woonsocket, Rhode Island, United States",CVS Health,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-analytics-at-cvs-health-2426611139?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=dHrgniV5lIebVA%2Fi%2BbPiVA%3D%3D&position=20&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

As a Data Engineer, you will collaborate with business partners to identity opportunities to leverage big data technologies in support of Front Store Personalization with a common set of tools and infrastructure to make analytics faster, more insightful, and more efficient. You will build and architect next generation Big Data machine learning framework developed on a group of core Big Data technologies.

You will design highly scalable and extensible Big Data platforms which enables collection, storage, modeling, and analysis of massive data sets from numerous channels.

In this role, you will define and maintain data architecture, focusing on applying technology to enable business solutions. You will assess and provide recommendations on business relevance, with appropriate timing and deployment. You will perform architecture design, data modeling, and implement CVS Big Data platforms and analytic applications. You will bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies. You will develop prototypes and proof of concepts for the selected solutions and implement complex big data projects. You will apply a creative mindset to a focus on collecting, parsing, managing, and automating data feedback loops in support of business innovation

Required Qualifications

2+ years of experience in Snowflake data modeling, ELT/ETL using Snowflake SQL
1+ years of building real time applications
1+ years of experience leading a team of junior data engineers and/or analytics-focused teams to deliver complex analytics projects on aggressive timelines

Preferred Qualifications

Design and implement effective Analytics solutions and models with Snowflake.
Able to administer and monitor snowflake computing platform.
Examine and identify Data warehouse structural necessities by evaluating business requirements.
Assess Data warehouse implementation procedures to ensure they comply with internal and external regulations.
Prepare accurate Data warehouse design and architecture reports for management and executive teams.
Experience in creation and modification of user accounts and security groups per request

Network infrastructure and security best practices for the cloud

Use various SQL tools or scripts to monitor data quality, identify issues and implement solutions.
Platforms: Snowflake, Kubernetes, Kubeflow, Tensorflow, Azure Cloud, Teradata

Languages: Kubectl, SnowSQL, Python

Experience with scaling workloads on GPUs and deep neural networks
Experience with serving models using KFServing etc.,
Experience with scaling using Dask
Familiarity with building data pipelines, data modeling, architecture & governance concepts
Experience implementing ML models and building highly scalable and high availability systems
Experience operating in distributed environments including cloud (Azure, GCP, AWS etc.)
Experience building, launching and maintaining complex

analytics pipelines in production

Snowpro certification
Exposure to Healthcare Domain knowledge would be a plus.
Master’s in data science or Business Analytics
Experience with cloud computing environment (ideally Microsoft Azure).

Education
BA degree required with a minimum of 3 years of relevant experience; or a Master's degree or equivalent in an analytic discipline with 1+ years of relevant experience; or a PhD in an analytic discipline

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>As a Data Engineer, you will collaborate with business partners to identity opportunities to leverage big data technologies in support of Front Store Personalization with a common set of tools and infrastructure to make analytics faster, more insightful, and more efficient. You will build and architect next generation Big Data machine learning framework developed on a group of core Big Data technologies.<br><br>You will design highly scalable and extensible Big Data platforms which enables collection, storage, modeling, and analysis of massive data sets from numerous channels.<br><br>In this role, you will define and maintain data architecture, focusing on applying technology to enable business solutions. You will assess and provide recommendations on business relevance, with appropriate timing and deployment. You will perform architecture design, data modeling, and implement CVS Big Data platforms and analytic applications. You will bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies. You will develop prototypes and proof of concepts for the selected solutions and implement complex big data projects. You will apply a creative mindset to a focus on collecting, parsing, managing, and automating data feedback loops in support of business innovation<br><br><strong><u>Required Qualifications<br></u></strong><ul><li> 2+ years of experience in Snowflake data modeling, ELT/ETL using Snowflake SQL</li><li> 1+ years of building real time applications</li><li> 1+ years of experience leading a team of junior data engineers and/or analytics-focused teams to deliver complex analytics projects on aggressive timelines<br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> Design and implement effective Analytics solutions and models with Snowflake.</li><li> Able to administer and monitor snowflake computing platform.</li><li> Examine and identify Data warehouse structural necessities by evaluating business requirements.</li><li> Assess Data warehouse implementation procedures to ensure they comply with internal and external regulations.</li><li> Prepare accurate Data warehouse design and architecture reports for management and executive teams.</li><li> Experience in creation and modification of user accounts and security groups per request<br></li></ul>Network infrastructure and security best practices for the cloud<br><ul><li> Use various SQL tools or scripts to monitor data quality, identify issues and implement solutions.</li><li> Platforms: Snowflake, Kubernetes, Kubeflow, Tensorflow, Azure Cloud, Teradata<br></li></ul>Languages: Kubectl, SnowSQL, Python<br><ul><li> Experience with scaling workloads on GPUs and deep neural networks</li><li> Experience with serving models using KFServing etc.,</li><li> Experience with scaling using Dask</li><li> Familiarity with building data pipelines, data modeling, architecture &amp; governance concepts</li><li> Experience implementing ML models and building highly scalable and high availability systems</li><li> Experience operating in distributed environments including cloud (Azure, GCP, AWS etc.)</li><li> Experience building, launching and maintaining complex<br></li></ul>analytics pipelines in production<br><ul><li> Snowpro certification</li><li> Exposure to Healthcare Domain knowledge would be a plus.</li><li> Master’s in data science or Business Analytics</li><li> Experience with cloud computing environment (ideally Microsoft Azure).<br></li></ul><strong>Education<br></strong>BA degree required with a minimum of 3 years of relevant experience; or a Master's degree or equivalent in an analytic discipline with 1+ years of relevant experience; or a PhD in an analytic discipline<br><br><strong><u>Business Overview<br><br></u></strong>At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.<br><br>We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Financial Services, Hospital & Health Care"
Data Engineer- Automation,"Morristown, New Jersey, United States",Atlantic Health System,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-automation-at-atlantic-health-system-2397440021?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=fg7I4HuBnW%2FSyos7tXnKAQ%3D%3D&position=21&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

As a Data Engineer, you will collaborate with business partners to identity opportunities to leverage big data technologies in support of Front Store Personalization with a common set of tools and infrastructure to make analytics faster, more insightful, and more efficient. You will build and architect next generation Big Data machine learning framework developed on a group of core Big Data technologies.

You will design highly scalable and extensible Big Data platforms which enables collection, storage, modeling, and analysis of massive data sets from numerous channels.

In this role, you will define and maintain data architecture, focusing on applying technology to enable business solutions. You will assess and provide recommendations on business relevance, with appropriate timing and deployment. You will perform architecture design, data modeling, and implement CVS Big Data platforms and analytic applications. You will bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies. You will develop prototypes and proof of concepts for the selected solutions and implement complex big data projects. You will apply a creative mindset to a focus on collecting, parsing, managing, and automating data feedback loops in support of business innovation

Required Qualifications

2+ years of experience in Snowflake data modeling, ELT/ETL using Snowflake SQL
1+ years of building real time applications
1+ years of experience leading a team of junior data engineers and/or analytics-focused teams to deliver complex analytics projects on aggressive timelines

Preferred Qualifications

Design and implement effective Analytics solutions and models with Snowflake.
Able to administer and monitor snowflake computing platform.
Examine and identify Data warehouse structural necessities by evaluating business requirements.
Assess Data warehouse implementation procedures to ensure they comply with internal and external regulations.
Prepare accurate Data warehouse design and architecture reports for management and executive teams.
Experience in creation and modification of user accounts and security groups per request

Network infrastructure and security best practices for the cloud

Use various SQL tools or scripts to monitor data quality, identify issues and implement solutions.
Platforms: Snowflake, Kubernetes, Kubeflow, Tensorflow, Azure Cloud, Teradata

Languages: Kubectl, SnowSQL, Python

Experience with scaling workloads on GPUs and deep neural networks
Experience with serving models using KFServing etc.,
Experience with scaling using Dask
Familiarity with building data pipelines, data modeling, architecture & governance concepts
Experience implementing ML models and building highly scalable and high availability systems
Experience operating in distributed environments including cloud (Azure, GCP, AWS etc.)
Experience building, launching and maintaining complex

analytics pipelines in production

Snowpro certification
Exposure to Healthcare Domain knowledge would be a plus.
Master’s in data science or Business Analytics
Experience with cloud computing environment (ideally Microsoft Azure).

Education
BA degree required with a minimum of 3 years of relevant experience; or a Master's degree or equivalent in an analytic discipline with 1+ years of relevant experience; or a PhD in an analytic discipline

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>As a Data Engineer, you will collaborate with business partners to identity opportunities to leverage big data technologies in support of Front Store Personalization with a common set of tools and infrastructure to make analytics faster, more insightful, and more efficient. You will build and architect next generation Big Data machine learning framework developed on a group of core Big Data technologies.<br><br>You will design highly scalable and extensible Big Data platforms which enables collection, storage, modeling, and analysis of massive data sets from numerous channels.<br><br>In this role, you will define and maintain data architecture, focusing on applying technology to enable business solutions. You will assess and provide recommendations on business relevance, with appropriate timing and deployment. You will perform architecture design, data modeling, and implement CVS Big Data platforms and analytic applications. You will bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies. You will develop prototypes and proof of concepts for the selected solutions and implement complex big data projects. You will apply a creative mindset to a focus on collecting, parsing, managing, and automating data feedback loops in support of business innovation<br><br><strong><u>Required Qualifications<br></u></strong><ul><li> 2+ years of experience in Snowflake data modeling, ELT/ETL using Snowflake SQL</li><li> 1+ years of building real time applications</li><li> 1+ years of experience leading a team of junior data engineers and/or analytics-focused teams to deliver complex analytics projects on aggressive timelines<br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> Design and implement effective Analytics solutions and models with Snowflake.</li><li> Able to administer and monitor snowflake computing platform.</li><li> Examine and identify Data warehouse structural necessities by evaluating business requirements.</li><li> Assess Data warehouse implementation procedures to ensure they comply with internal and external regulations.</li><li> Prepare accurate Data warehouse design and architecture reports for management and executive teams.</li><li> Experience in creation and modification of user accounts and security groups per request<br></li></ul>Network infrastructure and security best practices for the cloud<br><ul><li> Use various SQL tools or scripts to monitor data quality, identify issues and implement solutions.</li><li> Platforms: Snowflake, Kubernetes, Kubeflow, Tensorflow, Azure Cloud, Teradata<br></li></ul>Languages: Kubectl, SnowSQL, Python<br><ul><li> Experience with scaling workloads on GPUs and deep neural networks</li><li> Experience with serving models using KFServing etc.,</li><li> Experience with scaling using Dask</li><li> Familiarity with building data pipelines, data modeling, architecture &amp; governance concepts</li><li> Experience implementing ML models and building highly scalable and high availability systems</li><li> Experience operating in distributed environments including cloud (Azure, GCP, AWS etc.)</li><li> Experience building, launching and maintaining complex<br></li></ul>analytics pipelines in production<br><ul><li> Snowpro certification</li><li> Exposure to Healthcare Domain knowledge would be a plus.</li><li> Master’s in data science or Business Analytics</li><li> Experience with cloud computing environment (ideally Microsoft Azure).<br></li></ul><strong>Education<br></strong>BA degree required with a minimum of 3 years of relevant experience; or a Master's degree or equivalent in an analytic discipline with 1+ years of relevant experience; or a PhD in an analytic discipline<br><br><strong><u>Business Overview<br><br></u></strong>At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.<br><br>We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Financial Services, Hospital & Health Care"
Data Engineer,"Charlotte, North Carolina, United States","Lowe's Companies, Inc.",2021-01-31,https://www.linkedin.com/jobs/view/data-engineer-at-lowe-s-companies-inc-2329363733?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=EkUmDASqtRhodcjfGUeYzg%3D%3D&position=22&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Atlantic Health System is building out an enterprise big data platform in AWS and is seeking a hands-on DevOps engineer to drive best practices in our cloud implementation. The platform will be used by all facets of the organization to steer the business towards data driven decisions.

The ideal candidate will want to work in a fast pace agile environment designing and implementing solutions to support the data lake and data warehouse. Automation is the key. Performance, distributed computing, asynchronous behavior are the challenges. We are problem solvers who take ideas from inception to production. The pipelines and tools we build will support our community of data scientists and data analyst. Innovation is encouraged, collaboration is required. We believe in active mentoring and continuous improvement.

The Primary Responsibilities Of This Position Are

This data engineer will operate in the role of DevOps Engineer. Manage the data lake application stack and conduct ongoing performance analysis to optimize query-ability and costs. Support the development team with necessary automation of build and deployment activities.

Architect and deploy secure and robust applications on AWS technologies.
Recommend best practices for building secure and reliable applications in AWS.
Work with networking team to ensure appropriate configurations.
Work with enterprise security team to ensure highest levels of security are implemented.
Support other members of the team with the ability to explain methodologies and assist in development.
Act as point person for all AWS related questions.


Requirements

Bachelors of Science degree in Computer Science or related field.
3+ years of industry experience.
AWS Experience or Certification is required.
Significant background with SQL and Python is required.
Background with ETL and database design is a plus.
Healthcare experience preferred but not required.


Atlantic Health System aims to deliver the highest quality, safety and care combined the best experience for our patients and their families. We are confident that you will find success within Atlantic Health System, which has been named for the 12th year in a row to Fortune’s “Top 100 Best U.S. Companies to Work For” list. We believe you will find that our culture of collaboration and care exemplifies the value we place on our patients, their families and our employees.

Atlantic Health System, Inc. is an equal employment opportunity employer and federal contractor or subcontractor and therefore abides by applicable laws to protect applicants and employees from discrimination in hiring, promotion, discharge, pay, fringe benefits, job training, classification, referral, and other aspects of employment, on the basis of race, color, religion, sex (including pregnancy, gender identity and sexual orientation), national origin, citizenship status, disability, age, genetics, or veteran status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Atlantic Health System is building out an enterprise big data platform in AWS and is seeking a hands-on DevOps engineer to drive best practices in our cloud implementation. The platform will be used by all facets of the organization to steer the business towards data driven decisions.<br><br>The ideal candidate will want to work in a fast pace agile environment designing and implementing solutions to support the data lake and data warehouse. Automation is the key. Performance, distributed computing, asynchronous behavior are the challenges. We are problem solvers who take ideas from inception to production. The pipelines and tools we build will support our community of data scientists and data analyst. Innovation is encouraged, collaboration is required. We believe in active mentoring and continuous improvement.<br><br><strong>The Primary Responsibilities Of This Position Are<br><br></strong>This data engineer will operate in the role of DevOps Engineer. Manage the data lake application stack and conduct ongoing performance analysis to optimize query-ability and costs. Support the development team with necessary automation of build and deployment activities.<br><ul><li>Architect and deploy secure and robust applications on AWS technologies.</li><li>Recommend best practices for building secure and reliable applications in AWS.</li><li>Work with networking team to ensure appropriate configurations.</li><li>Work with enterprise security team to ensure highest levels of security are implemented.</li><li>Support other members of the team with the ability to explain methodologies and assist in development.</li><li>Act as point person for all AWS related questions.<br><br></li></ul><strong>Requirements<br></strong><ul><li>Bachelors of Science degree in Computer Science or related field.</li><li>3+ years of industry experience.</li><li>AWS Experience or Certification is required.</li><li>Significant background with SQL and Python is required.</li><li>Background with ETL and database design is a plus.</li><li>Healthcare experience preferred but not required.<br><br></li></ul>Atlantic Health System aims to deliver the highest quality, safety and care combined the best experience for our patients and their families. We are confident that you will find success within Atlantic Health System, which has been named for the 12th year in a row to Fortune’s “Top 100 Best U.S. Companies to Work For” list. We believe you will find that our culture of collaboration and care exemplifies the value we place on our patients, their families and our employees.<br><br>Atlantic Health System, Inc. is an equal employment opportunity employer and federal contractor or subcontractor and therefore abides by applicable laws to protect applicants and employees from discrimination in hiring, promotion, discharge, pay, fringe benefits, job training, classification, referral, and other aspects of employment, on the basis of race, color, religion, sex (including pregnancy, gender identity and sexual orientation), national origin, citizenship status, disability, age, genetics, or veteran status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Health, Wellness and Fitness, Medical Practice, Hospital & Health Care"
"Software Engineer, Data","San Francisco, California, United States",Ripple,2021-01-29,https://www.linkedin.com/jobs/view/software-engineer-data-at-ripple-2385592511?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=XBK5cumBgdJRue55nXR6qg%3D%3D&position=23&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Job Summary

The primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver modules, stable application systems, and Data or Platform solutions. This includes developing, configuring, or modifying integrated business and/or enterprise infrastructure or application solutions within various computing environments. This role facilitates the implementation and maintenance of business and enterprise Data or Platform solutions to ensure successful deployment of released applications.

Key Responsibilities

Translates business requirements and specifications into logical program designs, modules, stable application systems, and data solutions with occasional guidance from senior colleagues; partners with Product Team to understand business needs and functional specifications
Develops, configures, or modifies integrated business and/or enterprise application solutions within various computing environments by designing and coding component-based applications using various programming languages
Conducts the implementation and maintenance of complex business and enterprise data solutions to ensure successful deployment of released applications
Supports systems integration testing (SIT) and user acceptance testing (UAT), provides insight into defining test plans, and ensures quality software deployment
Participates in the end-to-end product lifecycle by applying and sharing an in-depth understanding of company and industry methodologies, policies, standards, and controls
Understands Computer Science and/or Computer Engineering fundamentals; knows software architecture and readily applies this to Data or Platform solutions
Automates and simplifies team development, test, and operations processes; develops conceptual, logical and physical architectures consisting of one or more viewpoints (business, application, data, and infrastructure) required for business solution delivery
Solves difficult technical problems; solutions are testable, maintainable, and efficient


Data Engineering Responsibilities

Supports the build, maintenance and enhancements of data lake development; supports simple to medium complexity API, unstructured data parsing and streaming data ingestion
Excels in one more domain; understands pipelines and business metrics
Builds, tests and enhances data curation pipelines integration data from a wide variety of sources like DBMS, File systems and APIs for various KPIs and metrics development with high data quality and integrity
Supports the development of feature / inputs for data models in an Agile manner
Works with Data Science team to understand mathematical models and algorithms; participates in continuous improvement activities including training opportunities; continuously strives to learn analytic best practices and apply them to daily activities
Handles data manipulation (extract, load, transform), data visualization, and administration of data and systems securely and in accordance with enterprise data governance standards
Maintains the health and monitoring of assigned analytic capabilities for a specific data engineering solution; ensures high availability of the platform; monitors workload demands; works with Technology Job Description Page 2 of 3 Infrastructure Engineering teams to maintain the data platform; serves as an SME of one or more application


Minimum Qualifications

Bachelor\'s Degree in Engineering, Computer Science, CIS, or related field (or equivalent work experience in a related field)
2 years of experience in Data, BI or Platform Engineering, Data Warehousing/ETL, or Software Engineering
1 year of experience working on project(s) involving the implementation of solutions applying development life cycles (SDLC)


Preferred Qualifications

In most cases Lowe’s will not be able to provide sponsorship for roles located in the Tech Hub
Master\'s Degree in Computer Science, CIS, or related field
2 years of IT experience developing and implementing business systems within an organization
4 years of experience working with defect or incident tracking software
4 years of experience with technical documentation in a software development environment
2 years of experience working with an IT Infrastructure Library (ITIL) framework
2 years of experience leading teams, with or without direct reports
Experience with application and integration middleware
Experience with database technologies


Data Engineering Qualifications

2 years of experience in Hadoop or any Cloud Bigdata components (specific to the Data Engineering role)
Expertise in Java/Scala/Python, SQL, Scripting, Teradata, Hadoop (Sqoop, Hive, Pig, Map Reduce), Spark (Spark Streaming, MLib), Kafka or equivalent Cloud Bigdata components (specific to the Data Engineering role)


About Lowe’s

Lowe’s Companies, Inc. (NYSE: LOW) is a FORTUNE® 50 home improvement company serving approximately 18 million customers a week in the United States and Canada. With fiscal year 2019 sales of $72.1 billion, Lowe’s and its related businesses operate or service more than 2,200 home improvement and hardware stores and employ approximately 300,000 associates. Based in Mooresville, N.C., Lowe’s supports its hometown Charlotte region and all communities it serves through programs focused on creating safe, affordable housing and helping to develop the next generation of skilled trade experts. For more information, visit Lowes.com.

About Lowe’s In The Community

As a FORTUNE® 50 home improvement company, Lowe’s is committed to creating safe, affordable housing and helping to develop the next generation of skilled trade experts through nonprofit partnerships. Across every community we serve, Lowe’s associates donate their time and expertise through the Lowe’s Heroes volunteer program. For the latest news, visit Newsroom.Lowes.com or follow @LowesMedia on Twitter.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Summary<br><br></u></strong>The primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver modules, stable application systems, and Data or Platform solutions. This includes developing, configuring, or modifying integrated business and/or enterprise infrastructure or application solutions within various computing environments. This role facilitates the implementation and maintenance of business and enterprise Data or Platform solutions to ensure successful deployment of released applications.<br><br><strong><u>Key Responsibilities<br></u></strong><ul><li>Translates business requirements and specifications into logical program designs, modules, stable application systems, and data solutions with occasional guidance from senior colleagues; partners with Product Team to understand business needs and functional specifications</li><li>Develops, configures, or modifies integrated business and/or enterprise application solutions within various computing environments by designing and coding component-based applications using various programming languages</li><li>Conducts the implementation and maintenance of complex business and enterprise data solutions to ensure successful deployment of released applications</li><li>Supports systems integration testing (SIT) and user acceptance testing (UAT), provides insight into defining test plans, and ensures quality software deployment</li><li>Participates in the end-to-end product lifecycle by applying and sharing an in-depth understanding of company and industry methodologies, policies, standards, and controls</li><li>Understands Computer Science and/or Computer Engineering fundamentals; knows software architecture and readily applies this to Data or Platform solutions</li><li>Automates and simplifies team development, test, and operations processes; develops conceptual, logical and physical architectures consisting of one or more viewpoints (business, application, data, and infrastructure) required for business solution delivery</li><li>Solves difficult technical problems; solutions are testable, maintainable, and efficient<br><br></li></ul><strong><u>Data Engineering Responsibilities<br></u></strong><ul><li>Supports the build, maintenance and enhancements of data lake development; supports simple to medium complexity API, unstructured data parsing and streaming data ingestion</li><li>Excels in one more domain; understands pipelines and business metrics</li><li>Builds, tests and enhances data curation pipelines integration data from a wide variety of sources like DBMS, File systems and APIs for various KPIs and metrics development with high data quality and integrity</li><li>Supports the development of feature / inputs for data models in an Agile manner</li><li>Works with Data Science team to understand mathematical models and algorithms; participates in continuous improvement activities including training opportunities; continuously strives to learn analytic best practices and apply them to daily activities</li><li>Handles data manipulation (extract, load, transform), data visualization, and administration of data and systems securely and in accordance with enterprise data governance standards</li><li>Maintains the health and monitoring of assigned analytic capabilities for a specific data engineering solution; ensures high availability of the platform; monitors workload demands; works with Technology Job Description Page 2 of 3 Infrastructure Engineering teams to maintain the data platform; serves as an SME of one or more application<br><br></li></ul><strong><u>Minimum Qualifications<br></u></strong><ul><li>Bachelor\'s Degree in Engineering, Computer Science, CIS, or related field (or equivalent work experience in a related field)</li><li>2 years of experience in Data, BI or Platform Engineering, Data Warehousing/ETL, or Software Engineering</li><li>1 year of experience working on project(s) involving the implementation of solutions applying development life cycles (SDLC)<br><br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>In most cases Lowe’s will not be able to provide sponsorship for roles located in the Tech Hub</li></ul><ul><li>Master\'s Degree in Computer Science, CIS, or related field</li><li>2 years of IT experience developing and implementing business systems within an organization</li><li>4 years of experience working with defect or incident tracking software</li><li>4 years of experience with technical documentation in a software development environment</li><li>2 years of experience working with an IT Infrastructure Library (ITIL) framework</li><li>2 years of experience leading teams, with or without direct reports</li><li>Experience with application and integration middleware</li><li>Experience with database technologies<br><br></li></ul><strong><u>Data Engineering Qualifications<br></u></strong><ul><li>2 years of experience in Hadoop or any Cloud Bigdata components (specific to the Data Engineering role)</li><li>Expertise in Java/Scala/Python, SQL, Scripting, Teradata, Hadoop (Sqoop, Hive, Pig, Map Reduce), Spark (Spark Streaming, MLib), Kafka or equivalent Cloud Bigdata components (specific to the Data Engineering role)<br><br></li></ul><strong><u>About Lowe’s<br><br></u></strong>Lowe’s Companies, Inc. (NYSE: LOW) is a FORTUNE® 50 home improvement company serving approximately 18 million customers a week in the United States and Canada. With fiscal year 2019 sales of $72.1 billion, Lowe’s and its related businesses operate or service more than 2,200 home improvement and hardware stores and employ approximately 300,000 associates. Based in Mooresville, N.C., Lowe’s supports its hometown Charlotte region and all communities it serves through programs focused on creating safe, affordable housing and helping to develop the next generation of skilled trade experts. For more information, visit Lowes.com.<br><br><strong><u>About Lowe’s In The Community<br><br></u></strong>As a FORTUNE® 50 home improvement company, Lowe’s is committed to creating safe, affordable housing and helping to develop the next generation of skilled trade experts through nonprofit partnerships. Across every community we serve, Lowe’s associates donate their time and expertise through the Lowe’s Heroes volunteer program. For the latest news, visit Newsroom.Lowes.com or follow @LowesMedia on Twitter.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Retail, Financial Services"
Data Scientist - Job ID 12846,United States,Infor,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-job-id-12846-at-infor-2416720710?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=xfdHwiGVazkC80Ebr8%2BpdA%3D%3D&position=24&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Ripple is the world’s only enterprise blockchain solution for global payments. Today the world sends more than $155 trillion across borders, however, the underlying infrastructure is dated and flawed. Ripple solves this problem. We connect banks, payment providers, corporations, and digital asset exchanges via RippleNet to provide one frictionless experience to send money globally. Ripple’s distributed financial technology outperforms today’s banking infrastructure by driving down costs, increasing processing speeds and delivering end-to-end visibility into payment fees, timing and delivery.

Ripple is growing rapidly and we are looking for a results-oriented and passionate Software Engineer to help build our data platform. The platform enables everyone in the company to make data driven strategic decisions. You have a passion for the craft of software engineering and take pride in applying those skills to data challenges.

What You’ll Do

Building, improving, maintaining data pipelines and foundational frameworks for data ingestion and data transformation
Design and implement scalable and reliable backend infrastructure of the Data applications
Collaborate with partner engineering teams and business stakeholders to build new capabilities to the Data platform



What We’re Looking For

2+ years of experience in software engineering, ideally involving data oriented applications (Python, Java or other programming languages)
Experience in building ETL/ELT data pipelines
Experience in writing and optimizing complex SQL queries in data warehouses such as Redshift, BigQuery
Knowledge of building REST API endpoints
Exposure to NoSQL database a plus
Excellent written and verbal communication skills
Attention to detail and a commitment to excellence



What We Offer

The chance to work in a fast-paced start-up environment with experienced industry leaders
A learning environment where you can dive deep into the latest technologies and make an impact
Competitive salary and equity
100% paid medical and dental and 95% paid vision insurance for employees starting on your first day
401k (with match), fully paid parental leave, commuter benefits
Generous wellness reimbursement and weekly onsite programs
Flexible vacation policy - work with your manager to take time off when you need it
Employee giving match
Modern office in San Francisco’s Financial District
Fully-stocked kitchen with organic snacks, beverages, and coffee drinks
Weekly company meeting - ask me anything style discussion with our Leadership Team
Team outings to sports games, happy hours, game nights and more!



Who We Are

Ripple provides one frictionless experience to send money globally using the power of blockchain. By joining Ripple’s growing, global network (RippleNet), financial institutions can process their customers’ payments anywhere in the world instantly, reliably and cost-effectively. Banks and payment providers can use the digital asset XRP to further reduce their costs and access new markets.

With offices in San Francisco, New York, London, Mumbai, Singapore, São Paulo, Reykjavík, Washington D.C. and Dubai, Ripple has more than 300 customers around the world.

Ripple is an Equal Opportunity Employer. We’re committed to building a diverse and inclusive team. We do not discriminate against qualified employees or applicants because of race, color, religion, gender identity, sex, sexual preference, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other characteristic protected by local law or ordinance.

Please find our UK/EU applicant privacy notice here.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Ripple is the world’s only enterprise blockchain solution for global payments. Today the world sends more than $155 trillion across borders, however, the underlying infrastructure is dated and flawed. Ripple solves this problem. We connect banks, payment providers, corporations, and digital asset exchanges via RippleNet to provide one frictionless experience to send money globally. Ripple’s distributed financial technology outperforms today’s banking infrastructure by driving down costs, increasing processing speeds and delivering end-to-end visibility into payment fees, timing and delivery.<br><br>Ripple is growing rapidly and we are looking for a results-oriented and passionate Software Engineer to help build our data platform. The platform enables everyone in the company to make data driven strategic decisions. You have a passion for the craft of software engineering and take pride in applying those skills to data challenges.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Building, improving, maintaining data pipelines and foundational frameworks for data ingestion and data transformation</li> <li>Design and implement scalable and reliable backend infrastructure of the Data applications</li> <li>Collaborate with partner engineering teams and business stakeholders to build new capabilities to the Data platform</li> <br><br></ul><strong><u>What We’re Looking For<br></u></strong><ul> <li>2+ years of experience in software engineering, ideally involving data oriented applications (Python, Java or other programming languages)</li> <li>Experience in building ETL/ELT data pipelines</li> <li>Experience in writing and optimizing complex SQL queries in data warehouses such as Redshift, BigQuery</li> <li>Knowledge of building REST API endpoints </li> <li>Exposure to NoSQL database a plus</li> <li>Excellent written and verbal communication skills</li> <li>Attention to detail and a commitment to excellence</li> <br><br></ul><strong><u>What We Offer<br></u></strong><ul> <li>The chance to work in a fast-paced start-up environment with experienced industry leaders</li> <li>A learning environment where you can dive deep into the latest technologies and make an impact</li> <li>Competitive salary and equity</li> <li>100% paid medical and dental and 95% paid vision insurance for employees starting on your first day</li> <li>401k (with match), fully paid parental leave, commuter benefits</li> <li>Generous wellness reimbursement and weekly onsite programs</li> <li>Flexible vacation policy - work with your manager to take time off when you need it</li> <li>Employee giving match</li> <li>Modern office in San Francisco’s Financial District</li> <li>Fully-stocked kitchen with organic snacks, beverages, and coffee drinks</li> <li>Weekly company meeting - ask me anything style discussion with our Leadership Team</li> <li>Team outings to sports games, happy hours, game nights and more!</li> <br><br></ul><strong><u>Who We Are<br><br></u></strong>Ripple provides one frictionless experience to send money globally using the power of blockchain. By joining Ripple’s growing, global network (RippleNet), financial institutions can process their customers’ payments anywhere in the world instantly, reliably and cost-effectively. Banks and payment providers can use the digital asset XRP to further reduce their costs and access new markets.<br><br>With offices in San Francisco, New York, London, Mumbai, Singapore, São Paulo, Reykjavík, Washington D.C. and Dubai, Ripple has more than 300 customers around the world.<br><br><em>Ripple is an Equal Opportunity Employer. We’re committed to building a diverse and inclusive team. We do not discriminate against qualified employees or applicants because of race, color, religion, gender identity, sex, sexual preference, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other characteristic protected by local law or ordinance.<br><br></em><em>Please find our UK/EU applicant privacy notice here.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
"Data Solutions Engineer, Aerospace","Phoenix, Arizona, United States",Honeywell,2021-02-16,https://www.linkedin.com/jobs/view/data-solutions-engineer-aerospace-at-honeywell-2410586394?refId=4a867d78-43fd-48b9-9521-5d291e62a6f3&trackingId=5nNu%2F8BNHWwvSQLJyMVmZg%3D%3D&position=25&pageNum=3&trk=public_jobs_job-result-card_result-card_full-click,"Data Scientist
Location: Atlanta, GA or US Remote
About Infor
Infor delivers end-to-end ERP and strategic edge applications that are integrated and delivered in a multi-tenant cloud. We believe that customers need industry-specific solutions and that one size does not fit all.
We are proud to serve more than 68,000 companies worldwide. Infor is a standalone subsidiary of Koch Industries, Inc., which has annual revenues of over $110 billion.
For more information visit www.infor.com
Position Summary
Infor Decision Analytics and Science (IDeAS) team is responsible for setting the innovation strategy at Infor. We are a diverse, well-integrated, and customer-focused team of data scientists, data engineers, solution architects, application developers, and product managers with an ambitious vision to enable enterprise Machine Learning (ML) for all Infor customers across multiple industries and segments.
The data scientists in IDeAS are the brain behind every data-driven decision analytics. As a data scientist, you will design, create and operationalize large scale predictive and prescriptive analytics to solve business problems in demand forecasting, network and inventory optimization, anomaly detection and predictive maintenance using IoT data, price recommendation, media and image analytics, employee attrition, and customer churn, etc. A successful candidate is expected to have an in-depth knowledge of the most common machine learning and optimization techniques and their applications.
The data scientist role isn’t about building scientific models only. It also involves collaborating with engineering, product management, application development, and our customers to deliver solutions that realize business benefits. As a data scientist, you will play a central role in the team’s success and hold the key to deliver significant value to our customers.
A Day in The Life Typically Includes

Designing, developing, testing, deploying, monitoring, and improving machine learning and optimization models for enterprise applications.
Working with product managers and Infor customers to understand business problems, identifying internal and external data requirements, and formulating data enrichment strategies for enterprise applications.
Performing exploratory data analysis to assess and communicate data quality, and to extract and share insights from large and complex datasets.
Performing feature engineering, model selection, and model and performance tuning based on the metrics-driven approach.
Crafting, conducting, analyzing, and interpreting experiments and investigations.
Collaborating with data engineers and solution architects on data models and build required data transformations to support scientific models.
Executing Proof of Concepts (PoCs) and presenting results to Infor customers to demonstrate the value of enterprise ML through quick wins.
Creating technical reports and documentation for PoCs and use case templates.
Keeping up with advancements in machine learning, deep learning, reinforcement learning, optimization techniques, and other advanced analytical approaches.

What You Will Need
Basic Qualifications

Bachelors (or foreign equivalent) in Computer Science, Electrical Engineering, Statistics, Operations Research, Industrial Engineering, Mathematics, Physics, Computational Biology, Bioinformatics or a related quantitative discipline from an accredited university.
Demonstrated real-world experience in designing and implementing a full machine learning and optimization solution pipeline, from ETL to data pre-processing, to quantitative data analysis, to model prototyping, to model deployment and inference.
Strong programming skills in Python, R, or Scala and data-querying skills in SQL and/or PySpark, etc.
Experience with deep learning algorithms with frameworks such as TensorFlow, PyTorch, or Keras.
Ability to communicate your ideas/code clearly through blog posts, kernels, GitHub.
Effective verbal/written communication, and technical presentation skills. Ability to naturally explain difficult technical topics to everyone from data scientists to engineers to business partners.
Self-starter with a passion for growth, a real enthusiasm for continuous learning, and sharing findings across the team.
Able to work both independently and as part of a team.

What Will Put You Ahead?
Preferred Qualifications

Masters (or foreign equivalent) in Computer Science, Electrical Engineering, Statistics, Operations Research, Industrial Engineering, Mathematics, Physics, Computational Biology, Bioinformatics or a related quantitative discipline from an accredited university.
Contribution to research communities through peer-reviewed publications in leading journals and conferences.
Experience with one algebraic modeling language e.g., AIMMS, AMPL, or GAMS etc. and one commercial optimization solver e.g., Gurobi, CPLEX, or Xpress etc.
Experience in Natural Language Processing (NLP), Computer Vision and Artificial Intelligence (AI).
Demonstrated real-world experience in building and orchestrating big data pipelines of structured and unstructured data sets using Spark, Delta Lake, and Neo4j, etc.
Enjoy working with multiple levels and teams across organizations (engineering/research, product, sales, and marketing teams)
A proven desire to continue learning new technologies and techniques.

Infor values
Our Guiding Principles set the standard for how we work with one another. They define who we are as an organization and guide everything we do. By applying the same shared values that unleash prosperity in free societies—such as value creation, integrity, responsibility, free speech, and toleration—we encourage one another to take initiative and to challenge the status quo.
We have a relentless commitment to a culture based on a business philosophy called Market Based Management® (MBM®). Informed by the principles that allow a free and open society to flourish, MBM® prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.
Infor does not discriminate in employment opportunities or practices on the basis of race, color, creed, religion, sex, gender identity or expression, sexual orientation, national origin, genetics, disability, marital status, age, veteran status, protected veterans, military service obligation, citizenship status, individuals with disabilities, or any other characteristic protected by law applicable to the state in which you work. If you have a disability under the Americans with Disabilities Act or similar law, and you wish to discuss potential accommodations related to applying for employment at our company, please contact Human Resources at 470-548-7173 and/or ADAAA@infor.com.
Applicants to and employees of most United States private employers, state and local governments, educational institutions, employment agencies and labor organizations are protected under Federal law from discrimination. For additional information please see EEO is the Law poster, the EEO Supplemental as well as the Statement of Policy. If you would like to view a copy of the company’s affirmative action plan or policy statement, please email us.hrprograms@infor.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><em>Data Scientist<br></em><em>Location: Atlanta, GA or US Remote<br></em><strong><u>About Infor<br></u></strong>Infor delivers end-to-end ERP and strategic edge applications that are integrated and delivered in a multi-tenant cloud. We believe that customers need industry-specific solutions and that one size does not fit all.<br>We are proud to serve more than 68,000 companies worldwide. Infor is a standalone subsidiary of Koch Industries, Inc., which has annual revenues of over $110 billion.<br>For more information visit www.infor.com<br><strong><u>Position Summary<br></u></strong><u>I</u>nfor <u>De</u>cision <u>A</u>nalytics and <u>S</u>cience (IDeAS) team is responsible for setting the innovation strategy at Infor. We are a diverse, well-integrated, and customer-focused team of data scientists, data engineers, solution architects, application developers, and product managers with an ambitious vision to enable enterprise Machine Learning (ML) for all Infor customers across multiple industries and segments.<br>The data scientists in IDeAS are the brain behind every data-driven decision analytics. As a data scientist, you will design, create and operationalize large scale predictive and prescriptive analytics to solve business problems in demand forecasting, network and inventory optimization, anomaly detection and predictive maintenance using IoT data, price recommendation, media and image analytics, employee attrition, and customer churn, etc. A successful candidate is expected to have an in-depth knowledge of the most common machine learning and optimization techniques and their applications.<br>The data scientist role isn’t about building scientific models only. It also involves collaborating with engineering, product management, application development, and our customers to deliver solutions that realize business benefits. As a data scientist, you will play a central role in the team’s success and hold the key to deliver significant value to our customers.<br><strong>A Day in The Life Typically Includes<br></strong><ul><li>Designing, developing, testing, deploying, monitoring, and improving machine learning and optimization models for enterprise applications.</li></ul><ul><li>Working with product managers and Infor customers to understand business problems, identifying internal and external data requirements, and formulating data enrichment strategies for enterprise applications.</li></ul><ul><li>Performing exploratory data analysis to assess and communicate data quality, and to extract and share insights from large and complex datasets.</li></ul><ul><li>Performing feature engineering, model selection, and model and performance tuning based on the metrics-driven approach.</li></ul><ul><li>Crafting, conducting, analyzing, and interpreting experiments and investigations.</li></ul><ul><li>Collaborating with data engineers and solution architects on data models and build required data transformations to support scientific models.</li></ul><ul><li>Executing Proof of Concepts (PoCs) and presenting results to Infor customers to demonstrate the value of enterprise ML through quick wins.</li></ul><ul><li>Creating technical reports and documentation for PoCs and use case templates.</li></ul><ul><li>Keeping up with advancements in machine learning, deep learning, reinforcement learning, optimization techniques, and other advanced analytical approaches.<br></li></ul><strong><u>What You Will Need<br></u></strong><em>Basic Qualifications<br></em><ul><li>Bachelors (or foreign equivalent) in Computer Science, Electrical Engineering, Statistics, Operations Research, Industrial Engineering, Mathematics, Physics, Computational Biology, Bioinformatics or a related quantitative discipline from an accredited university.</li></ul><ul><li>Demonstrated real-world experience in designing and implementing a full machine learning and optimization solution pipeline, from ETL to data pre-processing, to quantitative data analysis, to model prototyping, to model deployment and inference.</li></ul><ul><li>Strong programming skills in Python, R, or Scala and data-querying skills in SQL and/or PySpark, etc.</li></ul><ul><li>Experience with deep learning algorithms with frameworks such as TensorFlow, PyTorch, or Keras.</li></ul><ul><li>Ability to communicate your ideas/code clearly through blog posts, kernels, GitHub.</li></ul><ul><li>Effective verbal/written communication, and technical presentation skills. Ability to naturally explain difficult technical topics to everyone from data scientists to engineers to business partners.</li></ul><ul><li>Self-starter with a passion for growth, a real enthusiasm for continuous learning, and sharing findings across the team.</li></ul><ul><li>Able to work both independently and as part of a team.<br></li></ul><strong>What Will Put You Ahead?<br></strong><strong><u>Preferred Qualifications<br></u></strong><ul><li>Masters (or foreign equivalent) in Computer Science, Electrical Engineering, Statistics, Operations Research, Industrial Engineering, Mathematics, Physics, Computational Biology, Bioinformatics or a related quantitative discipline from an accredited university.</li></ul><ul><li>Contribution to research communities through peer-reviewed publications in leading journals and conferences.</li></ul><ul><li>Experience with one algebraic modeling language e.g., AIMMS, AMPL, or GAMS etc. and one commercial optimization solver e.g., Gurobi, CPLEX, or Xpress etc.</li></ul><ul><li>Experience in Natural Language Processing (NLP), Computer Vision and Artificial Intelligence (AI).</li></ul><ul><li>Demonstrated real-world experience in building and orchestrating big data pipelines of structured and unstructured data sets using Spark, Delta Lake, and Neo4j, etc.</li></ul><ul><li>Enjoy working with multiple levels and teams across organizations (engineering/research, product, sales, and marketing teams)</li></ul><ul><li>A proven desire to continue learning new technologies and techniques.<br></li></ul><strong>Infor values<br></strong>Our Guiding Principles set the standard for how we work with one another. They define who we are as an organization and guide everything we do. By applying the same shared values that unleash prosperity in free societies—such as value creation, integrity, responsibility, free speech, and toleration—we encourage one another to take initiative and to challenge the status quo.<br>We have a relentless commitment to a culture based on a business philosophy called Market Based Management® (MBM®). Informed by the principles that allow a free and open society to flourish, MBM® prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.<br>Infor does not discriminate in employment opportunities or practices on the basis of race, color, creed, religion, sex, gender identity or expression, sexual orientation, national origin, genetics, disability, marital status, age, veteran status, protected veterans, military service obligation, citizenship status, individuals with disabilities, or any other characteristic protected by law applicable to the state in which you work. If you have a disability under the Americans with Disabilities Act or similar law, and you wish to discuss potential accommodations related to applying for employment at our company, please contact Human Resources at 470-548-7173 and/or ADAAA@infor.com.<br>Applicants to and employees of most United States private employers, state and local governments, educational institutions, employment agencies and labor organizations are protected under Federal law from discrimination. For additional information please see EEO is the Law poster, the EEO Supplemental as well as the Statement of Policy. If you would like to view a copy of the company’s affirmative action plan or policy statement, please email us.hrprograms@infor.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer II,"New York County, New York, United States",2U,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-ii-at-2u-2428121183?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=TzpJbFMhZut%2BQ%2BQpA5GMRg%3D%3D&position=1&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Join the industry leader to design the next generation of breakthroughs

Honeywell is charging into the Industrial IoT revolution with the establishment of Honeywell Connected Enterprise (HCE), building on our heritage of invention and deep, on-the-ground industry expertise. HCE is the leading industrial disruptor, building and connecting software solutions to streamline and centralize the assets, people and processes that help our customers make smarter, more accurate business decisions. Moving at the speed of software, we are creating, innovating and delivering solutions fast, challenging the way things have always been done, piloting new ways for all of us to work, and expecting our successes to set new standards for our customers and for Honeywell.

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.

JOB ACTIVITIES

As a Lead, you will be part of a team that delivers contemporary analytics solutions for customers of the Honeywell Engines product offerings including condition-based maintenance (CBM), performance monitoring and trending (PTMD) and health monitoring. You will build strong relationships with engineering, business and pursuit stakeholders to effectively design and deliver contemporary data analytics solutions that contribute directly to business success. You will develop solutions with various tools and systems viz. Python, MatLab, FORGE, etc.

You will identify and implement process improvements – and you don’t like to do the same thing twice so you will automate it if you can. You are always keeping an eye on scalability, optimization, and process. You have worked with Aerospace data before and are familiar with the various regulatory and certification parameters. You have experience with performance, maintenance and trend data and have the technical skills required to develop analytics that enhance ownership value for Honeywell assets.

You will work on a team including systems engineers, controls engineers, scrum masters, product owners, data architects, data engineers, data scientists, software developers, and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in a couple of sprints.

YOU MUST HAVE


Bachelor’s degree in Computer Science, Engineering, Applied Mathematics or related field
8 years+ years of aerospace engineering, analytics or data science
Mminimum 4 years of hands on experience with Aerospace engines systems, preferably with focus on product support or control systems
Minimum 2 years of experience working with pursuit and sales teams assisting with development of analytics requirements for RFP


WE VALUE


Aerospace propulsion systems engineering and integration experience
Data Science prototyping experience (Python and/or R tool-stack) using machine learning techniques and algorithms such as as k-means, k-NN, Naïve Bayes, SVM, Decision Trees
Experience in developing and building applications to process trending and maintenance data (structured and unstructured), including streaming and batch data Advanced degree in Computer Science, Engineering, Applied Mathematics or related field
Experience in writing complex SQL statements
Good understanding of branching, build, deployment, CI/CD methodologies
Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)
Experience with Aerospace diagnostic data
Experience with Streaming Analytics (i.e. Spark Streaming)
Experience with Recurrent Neural Network architectures
Experience with SQL
Experience with Tableau
Experience working with remote and global teams
Results driven with a positive can do attitude
Experience presenting and communicating with technical and business leadership


Additional Information


JOB ID: req264131
Category: Engineering
Location: 1944 E Sky Harbor Circle,Phoenix,Arizona,85034,United States
Exempt

Global (ALL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Join the industry leader to design the next generation of breakthroughs<br><br>Honeywell is charging into the Industrial IoT revolution with the establishment of Honeywell Connected Enterprise (HCE), building on our heritage of invention and deep, on-the-ground industry expertise. HCE is the leading industrial disruptor, building and connecting software solutions to streamline and centralize the assets, people and processes that help our customers make smarter, more accurate business decisions. Moving at the speed of software, we are creating, innovating and delivering solutions fast, challenging the way things have always been done, piloting new ways for all of us to work, and expecting our successes to set new standards for our customers and for Honeywell.<br><br>Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.<br><br>You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.<br><br><strong>JOB ACTIVITIES<br><br></strong>As a Lead, you will be part of a team that delivers contemporary analytics solutions for customers of the Honeywell Engines product offerings including condition-based maintenance (CBM), performance monitoring and trending (PTMD) and health monitoring. You will build strong relationships with engineering, business and pursuit stakeholders to effectively design and deliver contemporary data analytics solutions that contribute directly to business success. You will develop solutions with various tools and systems viz. Python, MatLab, FORGE, etc.<br><br>You will identify and implement process improvements – and you don’t like to do the same thing twice so you will automate it if you can. You are always keeping an eye on scalability, optimization, and process. You have worked with Aerospace data before and are familiar with the various regulatory and certification parameters. You have experience with performance, maintenance and trend data and have the technical skills required to develop analytics that enhance ownership value for Honeywell assets.<br><br>You will work on a team including systems engineers, controls engineers, scrum masters, product owners, data architects, data engineers, data scientists, software developers, and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in a couple of sprints.<br><br><strong>YOU MUST HAVE<br><br></strong><li> Bachelor’s degree in Computer Science, Engineering, Applied Mathematics or related field</li><li> 8 years+ years of aerospace engineering, analytics or data science</li><li> Mminimum 4 years of hands on experience with Aerospace engines systems, preferably with focus on product support or control systems</li><li> Minimum 2 years of experience working with pursuit and sales teams assisting with development of analytics requirements for RFP<br><br></li><strong>WE VALUE<br><br></strong><li> Aerospace propulsion systems engineering and integration experience</li><li> Data Science prototyping experience (Python and/or R tool-stack) using machine learning techniques and algorithms such as as k-means, k-NN, Naïve Bayes, SVM, Decision Trees</li><li> Experience in developing and building applications to process trending and maintenance data (structured and unstructured), including streaming and batch data Advanced degree in Computer Science, Engineering, Applied Mathematics or related field</li><li> Experience in writing complex SQL statements</li><li> Good understanding of branching, build, deployment, CI/CD methodologies</li><li> Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)</li><li> Experience with Aerospace diagnostic data</li><li> Experience with Streaming Analytics (i.e. Spark Streaming)</li><li> Experience with Recurrent Neural Network architectures</li><li> Experience with SQL</li><li> Experience with Tableau</li><li> Experience working with remote and global teams</li><li> Results driven with a positive can do attitude</li><li> Experience presenting and communicating with technical and business leadership<br><br></li>Additional Information<br><br><ul><li><strong>JOB ID: </strong>req264131</li><li><strong>Category: </strong>Engineering</li><li><strong>Location: </strong>1944 E Sky Harbor Circle,Phoenix,Arizona,85034,United States</li><li>Exempt<br></li></ul>Global (ALL)<br><br>Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Durham, North Carolina, United States",Labcorp,2021-02-11,https://www.linkedin.com/jobs/view/data-engineer-at-labcorp-2407616728?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=3s7DUyHQPFzpkb3nUZm2Nw%3D%3D&position=2&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"What We’re Looking For

The data engineering team is responsible for 2U’s analytical data warehouse and supporting data pipelines. We’re cloud based (AWS & Snowflake) and code mostly in Python. The team provides services for multiple stakeholders within the organization including senior management, and delivers multiple projects throughout the year.

We’re a fun bunch, everyone has a seat at the table and an ability to impact how we perform.

We are looking for a smart and collaborative data engineer with an avid interest in data and programming. Experience in system management & data pipelines is required, automated testing is a plus. As an engineer II, you’ll be a team member and an implementer of our tech stack (Python, AWS, Snowflake to mention a few). There is plenty of room for experimentation on how our stack can continue to evolve and it is highly encouraged.

Responsibilities Include, But Are Not Limited To

Write maintainable, high-performance code
Conduct exploratory and automated testing
Debug complex problems under time constraints
Implement technical work according to product / design specifications
Refactoring, to keep code maintainable
Provide technical guidance and feedback to other team-members
Planning and estimating development tasks and short-term projects
Running deployment software to put code on production
Participate in application level technical design
Participate in technical data architecture



Things That Should Be In Your Background

One or more programming languages, preferably Python and SQL, 2-5 years experience
1-3 years of experience working within an AWS (or equivalent) environment
Team work, and ability to collaborate with a variety of roles, such as Business Analysts, Product Managers and peer engineers
Ability to work effectively in a fast-paced team environment
Problem-solving and decision-making skills
Eager to learn and grow as an engineer
Attention to detail


About 2U Inc. (NASDAQ: TWOU)

2U is comprised of 3 lines of business: Graduate Degree Programs, Short Course, and Boot Camps. Going beyond traditional learning management systems, we use tech, people, and data to help top universities and enterprise organizations transform in the digital era—and eliminate the back row in higher ed. We support lifelong learning which means thinking beyond a single degree. It means finding ways for students to gain the skills they need to change careers, evolve their expertise, and meet the challenges of the changing world head-on. We help our partners fill those needs—developing new digital education technologies and offerings capable of supporting students at different points in their lives. Whether they need a simple refresher, to learn something new, or to change their career trajectories completely, our partners are there to help them succeed. Together with our partners, 2U has positively transformed the lives of more than 275,000 students and lifelong learners.

2U Diversity and Inclusion Statement

At 2U, we are committed to creating and sustaining a culture that embodies diverse walks of life, ideas, genders, ages, races, cultures, sexual orientations, abilities and other unique qualities of our employees. We strive to offer a workplace where every employee feels empowered by the ways in which we are different, as well as the ways in which we are the same.

Benefits & Culture

Working at 2U means working with individuals that are passionate and mission driven. We collaborate on tough problems to deliver the best outcomes for our partners, students, and each other. You will find team members working together in our open office spaces, gathered in the kitchen grabbing a snack, or taking a break in our game rooms.

2U Offers a Comprehensive Benefits Package

Medical, dental, and vision coverage
Life insurance, disability and 401(k)
Unlimited snacks and drinks
Tuition reimbursement program
Generous paid leave policies including unlimited PTO
Additional time off benefits include:
time off to volunteer for non-profit organizations
parental leave after 9 months of employment
holidays that include a winter break from Christmas through New Years!

To learn more, visit 2U.com. #NoBackRow

Note: The above statements are intended to describe the general nature and level of work performed by individuals assigned to this position, and are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.

2U is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race, creed, color, religion, sex, sexual orientation, pregnancy, national origin, age, marital status, disability, citizenship, military or veterans’ status, or any other classifications protected by applicable federal, state or local laws. 2U’s equal opportunity policy applies to all terms and conditions of employment, including but not limited to recruiting, hiring, training, promotion, job benefits, pay and dismissal.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>What We’re Looking For<br><br></u></strong>The data engineering team is responsible for 2U’s analytical data warehouse and supporting data pipelines. We’re cloud based (AWS &amp; Snowflake) and code mostly in Python. The team provides services for multiple stakeholders within the organization including senior management, and delivers multiple projects throughout the year.<br><br>We’re a fun bunch, everyone has a seat at the table and an ability to impact how we perform.<br><br>We are looking for a smart and collaborative data engineer with an avid interest in data and programming. Experience in system management &amp; data pipelines is required, automated testing is a plus. As an engineer II, you’ll be a team member and an implementer of our tech stack (Python, AWS, Snowflake to mention a few). There is plenty of room for experimentation on how our stack can continue to evolve and it is highly encouraged.<br><br><strong><u>Responsibilities Include, But Are Not Limited To<br></u></strong><ul> <li>Write maintainable, high-performance code</li> <li>Conduct exploratory and automated testing</li> <li>Debug complex problems under time constraints</li> <li>Implement technical work according to product / design specifications</li> <li>Refactoring, to keep code maintainable</li> <li>Provide technical guidance and feedback to other team-members</li> <li>Planning and estimating development tasks and short-term projects</li> <li>Running deployment software to put code on production</li> <li>Participate in application level technical design </li> <li>Participate in technical data architecture</li> <br><br></ul><strong><u>Things That Should Be In Your Background<br></u></strong><ul> <li>One or more programming languages, preferably Python and SQL, 2-5 years experience</li> <li>1-3 years of experience working within an AWS (or equivalent) environment</li> <li>Team work, and ability to collaborate with a variety of roles, such as Business Analysts, Product Managers and peer engineers</li> <li>Ability to work effectively in a fast-paced team environment</li> <li>Problem-solving and decision-making skills</li> <li>Eager to learn and grow as an engineer</li> <li>Attention to detail </li> <br></ul><strong>About 2U Inc. (NASDAQ: TWOU)<br><br></strong>2U is comprised of 3 lines of business: Graduate Degree Programs, Short Course, and Boot Camps. Going beyond traditional learning management systems, we use tech, people, and data to help top universities and enterprise organizations transform in the digital era—and eliminate the back row in higher ed. We support lifelong learning which means thinking beyond a single degree. It means finding ways for students to gain the skills they need to change careers, evolve their expertise, and meet the challenges of the changing world head-on. We help our partners fill those needs—developing new digital education technologies and offerings capable of supporting students at different points in their lives. Whether they need a simple refresher, to learn something new, or to change their career trajectories completely, our partners are there to help them succeed. Together with our partners, 2U has positively transformed the lives of more than 275,000 students and lifelong learners.<br><br><strong>2U Diversity and Inclusion Statement<br><br></strong>At 2U, we are committed to creating and sustaining a culture that embodies diverse walks of life, ideas, genders, ages, races, cultures, sexual orientations, abilities and other unique qualities of our employees. We strive to offer a workplace where every employee feels empowered by the ways in which we are different, as well as the ways in which we are the same.<br><br><strong><u>Benefits &amp; Culture<br><br></u></strong>Working at 2U means working with individuals that are passionate and mission driven. We collaborate on tough problems to deliver the best outcomes for our partners, students, and each other. You will find team members working together in our open office spaces, gathered in the kitchen grabbing a snack, or taking a break in our game rooms.<br><br><strong><u>2U Offers a Comprehensive Benefits Package<br></u></strong><ul> <li>Medical, dental, and vision coverage</li> <li>Life insurance, disability and 401(k)</li> <li>Unlimited snacks and drinks</li> <li>Tuition reimbursement program</li> <li>Generous paid leave policies including unlimited PTO </li> <li>Additional time off benefits include:</li></ul><ul> <li>time off to volunteer for non-profit organizations</li> <li>parental leave after 9 months of employment</li> <li>holidays that include a winter break from Christmas through New Years!</li> </ul> <br>To learn more, visit 2U.com. #NoBackRow<br><br>Note: The above statements are intended to describe the general nature and level of work performed by individuals assigned to this position, and are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.<br><br>2U is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race, creed, color, religion, sex, sexual orientation, pregnancy, national origin, age, marital status, disability, citizenship, military or veterans’ status, or any other classifications protected by applicable federal, state or local laws. 2U’s equal opportunity policy applies to all terms and conditions of employment, including but not limited to recruiting, hiring, training, promotion, job benefits, pay and dismissal.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Data Engineer,"Detroit, Michigan, United States",Rocket Loans,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-rocket-loans-2351192724?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=9k%2FBIqzhvPd8sjutUiL2MA%3D%3D&position=3&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Labcorp is recruiting a qualified Data Engineer to join our Informatics Team in RTP, NC. This is an ideal job if you are an engineer who wants to be part of an highly skilled team, values total ownership of your work, and can't imagine a day without coding. Most importantly, your work will help deliver on Labcorp's mission to help improve lives and improve health through diagnostics testing and the development of new and innovative medicines and therapeutics. We're looking for a creative, focused, technically curious individual who enjoys both architecture as well as working hands-on with the code in a fast-paced startup culture. If you are a skilled developer, with professional experience in modern data pipelines, we want to speak to you! Healthcare experience is a big plus. You will be building data mining, research and patient recruitment tools for researchers and drug development experts with a focus on oncology and genetics. The most important skill for this role is being a good listener. You will need to understand the end-users needs and challenges to help build data pipelines that meet or exceed the client expectations.

Key Responsibilities Include

Designs, implements, tests, and reviews data pipelines involving multiple technologies, including PySpark, SQL and orchestration tools such as Apache Airflow
Proficient in all aspects of enterprise SDLC and follows with minimal oversight best practices relating to: peer review techniques, principles of software composition, branching, deployment, and documentation
Understands the best patterns, frameworks, and techniques for Data Engineering and can recognize where the codebase deviates from established coding standards
Actively communicates daily progress on a cross-functional team. Requires minimal intervention from the team lead to coordinate with other members of the team



Requirements

License/Certification/Education: Normally requires a B.S. Degree in Computer Science w/6+ years of experience.

Qualifying Requirements, In Order Of Importance

4+ years of experience in design and implementation of complex solutions
PySpark or ○ Apache Spark and Python
Big Data. Must have experience with large datasets and hands-on performance tuning of distributed workloads
Strong SQL
Solid computer science fundamentals



Preferred Experience

PySpark on CDH and AWS
Linux scripting
ETL design
Proficiency with data structure, algorithm analysis, and concurrency
UML or other diagraming skills



Education / Training

Bachelor's Degree in Engineering or Computer Science, equivalent work experience can be substituted for a degree



Nice To Have Skills

Healthcare experience
Terraform
Jenkins
Java



Shift
1

Schedule
9AM-5PM Mon-Fri
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Labcorp is recruiting a qualified Data Engineer to join our Informatics Team in RTP, NC. This is an ideal job if you are an engineer who wants to be part of an highly skilled team, values total ownership of your work, and can't imagine a day without coding. Most importantly, your work will help deliver on Labcorp's mission to help improve lives and improve health through diagnostics testing and the development of new and innovative medicines and therapeutics. We're looking for a creative, focused, technically curious individual who enjoys both architecture as well as working hands-on with the code in a fast-paced startup culture. If you are a skilled developer, with professional experience in modern data pipelines, we want to speak to you! Healthcare experience is a big plus. You will be building data mining, research and patient recruitment tools for researchers and drug development experts with a focus on oncology and genetics. The most important skill for this role is being a good listener. You will need to understand the end-users needs and challenges to help build data pipelines that meet or exceed the client expectations.<br><br><strong><u>Key Responsibilities Include<br></u></strong><ul> <li>Designs, implements, tests, and reviews data pipelines involving multiple technologies, including PySpark, SQL and orchestration tools such as Apache Airflow </li> <li>Proficient in all aspects of enterprise SDLC and follows with minimal oversight best practices relating to: peer review techniques, principles of software composition, branching, deployment, and documentation </li> <li>Understands the best patterns, frameworks, and techniques for Data Engineering and can recognize where the codebase deviates from established coding standards </li> <li>Actively communicates daily progress on a cross-functional team. Requires minimal intervention from the team lead to coordinate with other members of the team </li> <br><br></ul><strong><u>Requirements<br><br></u></strong><strong>License/Certification/Education:</strong> Normally requires a B.S. Degree in Computer Science w/6+ years of experience.<br><br><strong><u>Qualifying Requirements, In Order Of Importance<br></u></strong><ul> <li>4+ years of experience in design and implementation of complex solutions </li> <li>PySpark or ○ Apache Spark and Python </li> <li>Big Data. Must have experience with large datasets and hands-on performance tuning of distributed workloads </li> <li>Strong SQL </li> <li>Solid computer science fundamentals </li> <br><br></ul><strong><u>Preferred Experience<br></u></strong><ul> <li>PySpark on CDH and AWS </li> <li>Linux scripting </li> <li>ETL design </li> <li>Proficiency with data structure, algorithm analysis, and concurrency </li> <li>UML or other diagraming skills </li> <br><br></ul><strong><u>Education / Training<br></u></strong><ul> <li>Bachelor's Degree in Engineering or Computer Science, equivalent work experience can be substituted for a degree </li> <br><br></ul><strong><u>Nice To Have Skills<br></u></strong><ul> <li>Healthcare experience </li> <li>Terraform </li> <li>Jenkins </li> <li>Java</li> <br><br></ul>Shift<br>1<br><br>Schedule<br>9AM-5PM Mon-Fri</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Financial Services, Hospital & Health Care"
Data and Analytics Engineer,"Rochester, New York, United States",Kodak Alaris,2021-01-28,https://www.linkedin.com/jobs/view/data-and-analytics-engineer-at-kodak-alaris-2398253003?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=Ivvp5VNG2AR4rAjEoDUEbQ%3D%3D&position=4&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Preferred Qualifications

Bachelor's degree in engineering, computer science, information technology or a related field
3 years of hands-on experience as a Data Engineer/ETL Developer working with data lake and data warehouse technologies
Experience with Python or R for data manipulation
SQL expertise in one or more relational databases
Architectural understanding of integration patterns, approaches, best practices and standards
Understanding of the technology processes such as the software development life cycle using the Agile methodology, testing approaches and software release management
Understanding of application integration concepts; familiarity with platforms such as Azure Data Factory or Informatica
Experience working with cloud infrastructure such as AWS or Azure


Job Summary

The Data Engineer specializes in the design and development of data and application integration solutions. From refining our wealth of raw data to bringing in new data sources, the Data Engineer continuously enables better analytics and automated insights. This team member is a key player on the team as we build the next-generation data infrastructure that will power our analytics engine and fuel our company’s growth.

Responsibilities

Design, develop and support the data and application integration processes
Assist in gathering requirements for data solutions and maintaining data mapping specifications
Collaborate with data analysts and data scientists on the design of data structures to support reporting and machine learning solutions
Understand, follow and drive design principles and best practices for the integration techniques and architecture
Monitor and troubleshoot production issues related to the integration jobs


Who We Are

Rocket Loans is an online platform revolutionizing how individuals get a personal loan. Every day, more and more people are able to consolidate high-interest rate credit cards, make home improvements or take a dream vacation because Rocket Loans helps them obtain a personal loan.

Disclaimer

This is an outline of the primary responsibilities of this position. As with everything in life, things change. The tasks and responsibilities can be changed, added to, removed, amended, deleted and modified at any time by the leadership group.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Preferred Qualifications<br></u></strong><ul><li>Bachelor's degree in engineering, computer science, information technology or a related field</li><li>3 years of hands-on experience as a Data Engineer/ETL Developer working with data lake and data warehouse technologies</li><li>Experience with Python or R for data manipulation</li><li>SQL expertise in one or more relational databases</li><li>Architectural understanding of integration patterns, approaches, best practices and standards</li><li>Understanding of the technology processes such as the software development life cycle using the Agile methodology, testing approaches and software release management</li><li>Understanding of application integration concepts; familiarity with platforms such as Azure Data Factory or Informatica</li><li>Experience working with cloud infrastructure such as AWS or Azure<br><br></li></ul><strong><u>Job Summary<br><br></u></strong>The Data Engineer specializes in the design and development of data and application integration solutions. From refining our wealth of raw data to bringing in new data sources, the Data Engineer continuously enables better analytics and automated insights. This team member is a key player on the team as we build the next-generation data infrastructure that will power our analytics engine and fuel our company’s growth.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Design, develop and support the data and application integration processes</li><li>Assist in gathering requirements for data solutions and maintaining data mapping specifications</li><li>Collaborate with data analysts and data scientists on the design of data structures to support reporting and machine learning solutions</li><li>Understand, follow and drive design principles and best practices for the integration techniques and architecture</li><li>Monitor and troubleshoot production issues related to the integration jobs<br><br></li></ul><strong><u>Who We Are<br><br></u></strong>Rocket Loans is an online platform revolutionizing how individuals get a personal loan. Every day, more and more people are able to consolidate high-interest rate credit cards, make home improvements or take a dream vacation because Rocket Loans helps them obtain a personal loan.<br><br><strong>Disclaimer<br><br></strong>This is an outline of the primary responsibilities of this position. As with everything in life, things change. The tasks and responsibilities can be changed, added to, removed, amended, deleted and modified at any time by the leadership group.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Other,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Dania, Florida, United States",Chewy,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-chewy-2427519041?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=pz5AtbfZH1ZVj9aeZ2N%2F9w%3D%3D&position=5&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Kodak Alaris is a global technology company that's delivering future value through customer solutions in the present day. Our advanced, patented intellectual property combines breakthrough technologies, machine learning and human know-how to unlock the power of images and information. We make businesses run faster, governments run smarter and provide consumers what they want before they know they want it. Across all of our businesses, at Kodak Alaris, we focus on solving tomorrow's challenge with the delivery of high impact solutions - today.

Kodak Moments is a leading global provider of photo products and services to retailers, consumers, and entertainment properties. We inspire consumers to bring their memories to life--delivering innovative, high-quality photo products and experiences they find truly meaningful. Powered by over 100,000 consumer touchpoints across 30 countries globally, it's our mission to be the brand consumers choose to celebrate and preserve life's memories, from the big events to the everyday moments that matter.

Position Summary

Kodak Alaris is seeking a self-motivated, well-rounded candidate to provide development and support for the Kodak Moments Analytics Team. The candidate will be part of a team designing, developing and extending our data warehousing, analytic reporting and data science capabilities. The goal of this team is to capture raw transactional data, transform that raw data into BI model(s) using Microsoft (MS) tools & business logic, then facilitate access to the model(s) to provide actionable insights. One of the primary deliverables will be to facilitate the development of a Common Data Platform that can support the needs of the Kodak Moments organization using cloud services platforms such as Azure. A platform that can provide daily insight into business operations.

During the development phase the individual will work with the development team to help interpret, analyze and trade off requirement and to recommend a path forward.

Development may consist of writing SQL, DAX, Java or C#. Tools such as Azure Data factory, SSIS maybe used to move data. Data stores range from Oracle, SQL server, Cosmos DB, MariaDB, Azure Data Lake, Google Analytics, Big Query etc., depending on the requirements may be the source or destination of the data.

Post-delivery the individual will work with the service and operations groups to understand their top concerns and to ensure that the product has a sustainable support model that address these concerns. Where appropriate new requirements should be collected and feedback into the development process.

This role requires initiative and know-how to investigate alternatives and make recommendations for new technology choices or process improvements.

In summary the individual will need to review requirements, evaluate new tools and techniques, propose an appropriate solution and write or develop new dataflows to accomplish the transforms desired.

Responsibilities

Work on a team dedicated to developing reporting data warehouse built in the Azure cloud with Microsoft BI tool kit
Using a variety of tools build data pipelines for Extracting, Transforming and Loading data
Explore opportunities for using AI and Machine learning (using Python Scala, R) to gain insight into the business' data
Develop or extend star and snowflake data models to support business needs.
Develop queries for Oracle, Microsoft SQL server and Maria database.
Execute a software configuration management process for Code, DB scripts, ETL scripts and other workflow products developed with one of the supported tools: ClearCase, Teams or GIT.
Create clear documentation to allow reusability and maintenance of the code
Establish interfaces that allows events external to Azure to trigger Azure PowerShell or ADF.
Use Azure tool kit including Azure Data factory (ADF) to collect business data for analysis
Support Process Improvement and Performance Improvement efforts
Create, Revise and improve Azure PowerShell scripts for processing cube.
Develop reports using Power BI that utilize the SSAS BI cube and computations executed in DAX



Requirements

At minimum bachelor's degree with a minimum 3.0 cumulative GPA in Computer Science or related discipline with 4 or more years of experience in the field.
Ability to work independently and as part of a larger team
Demonstrate a high level of personal integrity and strong work ethic and ability to learn quickly
Ability to present a clear, concise, visual message through data, both in summary and detail
Orientation toward detail and thoroughness
Excellent communication (verbal and written) and interpersonal skill
Familiarity with the software development lifecycle from requirements gathering to product delivery and maintenance.
Familiar with Azure or an equivalent cloud services provider and their data engineering and analytics tool set.
An understanding of transactional and data warehouse database design patterns.
Familiar with normalized, denormalized, slowly changing dimensions and data model design principles
Technical knowledge regarding data models, database design & development, data mining and analysis.
Familiarity with various database querying language, and report development and presentation tools and techniques
Working knowledge of the following Tools, Applications and programming language:

Oracle, SQL Server, MySQL, Cosmos DB, Data Lake
SQL, T-SQL, PL-SQL, DAX, SSDT
Microsoft Power BI or Tableau, Excel
Familiarity with.net, VB.net, C# or Java



Skills & Competencies

Knowledge and understanding of software or hardware development process
Ability to communicate customer requirements using a variety of techniques from formal specification, user stories to use cases.
Familiarity with Agile product delivery



Kodak Alaris provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Kodak Alaris</strong> is a global technology company that's delivering future value through customer solutions in the present day. Our advanced, patented intellectual property combines breakthrough technologies, machine learning and human know-how to unlock the power of images and information. We make businesses run faster, governments run smarter and provide consumers what they want before they know they want it. Across all of our businesses, at Kodak Alaris, we focus on solving tomorrow's challenge with the delivery of high impact solutions - today.<br><br><strong>Kodak Moments</strong> is a leading global provider of photo products and services to retailers, consumers, and entertainment properties. We inspire consumers to bring their memories to life--delivering innovative, high-quality photo products and experiences they find truly meaningful. Powered by over 100,000 consumer touchpoints across 30 countries globally, it's our mission to be the brand consumers choose to celebrate and preserve life's memories, from the big events to the everyday moments that matter.<br><br><strong><u>Position Summary<br><br></u></strong>Kodak Alaris is seeking a self-motivated, well-rounded candidate to provide development and support for the Kodak Moments Analytics Team. The candidate will be part of a team designing, developing and extending our data warehousing, analytic reporting and data science capabilities. The goal of this team is to capture raw transactional data, transform that raw data into BI model(s) using Microsoft (MS) tools &amp; business logic, then facilitate access to the model(s) to provide actionable insights. One of the primary deliverables will be to facilitate the development of a Common Data Platform that can support the needs of the Kodak Moments organization using cloud services platforms such as Azure. A platform that can provide daily insight into business operations.<br><br>During the development phase the individual will work with the development team to help interpret, analyze and trade off requirement and to recommend a path forward.<br><br>Development may consist of writing SQL, DAX, Java or C#. Tools such as Azure Data factory, SSIS maybe used to move data. Data stores range from Oracle, SQL server, Cosmos DB, MariaDB, Azure Data Lake, Google Analytics, Big Query etc., depending on the requirements may be the source or destination of the data.<br><br>Post-delivery the individual will work with the service and operations groups to understand their top concerns and to ensure that the product has a sustainable support model that address these concerns. Where appropriate new requirements should be collected and feedback into the development process.<br><br>This role requires initiative and know-how to investigate alternatives and make recommendations for new technology choices or process improvements.<br><br>In summary the individual will need to review requirements, evaluate new tools and techniques, propose an appropriate solution and write or develop new dataflows to accomplish the transforms desired.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li> Work on a team dedicated to developing reporting data warehouse built in the Azure cloud with Microsoft BI tool kit</li> <li> Using a variety of tools build data pipelines for Extracting, Transforming and Loading data </li> <li> Explore opportunities for using AI and Machine learning (using Python Scala, R) to gain insight into the business' data</li> <li> Develop or extend star and snowflake data models to support business needs.</li> <li> Develop queries for Oracle, Microsoft SQL server and Maria database.</li> <li> Execute a software configuration management process for Code, DB scripts, ETL scripts and other workflow products developed with one of the supported tools: ClearCase, Teams or GIT.</li> <li> Create clear documentation to allow reusability and maintenance of the code</li> <li> Establish interfaces that allows events external to Azure to trigger Azure PowerShell or ADF.</li> <li> Use Azure tool kit including Azure Data factory (ADF) to collect business data for analysis</li> <li> Support Process Improvement and Performance Improvement efforts</li> <li> Create, Revise and improve Azure PowerShell scripts for processing cube.</li> <li> Develop reports using Power BI that utilize the SSAS BI cube and computations executed in DAX</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li> At minimum bachelor's degree with a minimum 3.0 cumulative GPA in Computer Science or related discipline with 4 or more years of experience in the field.</li> <li> Ability to work independently and as part of a larger team</li> <li> Demonstrate a high level of personal integrity and strong work ethic and ability to learn quickly</li> <li> Ability to present a clear, concise, visual message through data, both in summary and detail</li> <li> Orientation toward detail and thoroughness</li> <li> Excellent communication (verbal and written) and interpersonal skill</li> <li> Familiarity with the software development lifecycle from requirements gathering to product delivery and maintenance.</li> <li> Familiar with Azure or an equivalent cloud services provider and their data engineering and analytics tool set.</li> <li> An understanding of transactional and data warehouse database design patterns. </li> <li> Familiar with normalized, denormalized, slowly changing dimensions and data model design principles</li> <li> Technical knowledge regarding data models, database design &amp; development, data mining and analysis.</li> <li> Familiarity with various database querying language, and report development and presentation tools and techniques</li> <li> Working knowledge of the following Tools, Applications and programming language:<br><ul> <li> Oracle, SQL Server, MySQL, Cosmos DB, Data Lake</li> <li> SQL, T-SQL, PL-SQL, DAX, SSDT</li> <li> Microsoft Power BI or Tableau, Excel</li> <li> Familiarity with.net, VB.net, C# or Java</li> </ul> </li> <br><br></ul><strong><u>Skills &amp; Competencies<br></u></strong><ul> <li> Knowledge and understanding of software or hardware development process </li> <li> Ability to communicate customer requirements using a variety of techniques from formal specification, user stories to use cases.</li> <li> Familiarity with Agile product delivery</li> <br><br></ul><strong><em>Kodak Alaris provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.</em></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Services
Data Engineer,"Atlanta, Georgia, United States",Sharecare,2021-02-08,https://www.linkedin.com/jobs/view/data-engineer-at-sharecare-2430672306?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=O%2BLgHozCqR%2BeJpdMP9pOvA%3D%3D&position=6&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Chewy's Supply Chain Team is seeking a Data Scientist to join the growing Supply Chain Analytics team in Seattle, WA. Combining a background in Supply Chain with a deep understanding of analytics and data science, you will be a part of a team responsible for strategic planning and research initiatives centered around our inventory and fulfillment network. This includes optimizing the way that we predict customer demand; and purchase, position, transport, store and ship inventory to our customers. The Supply Chain team operates in a fast-paced environment where every day brings new challenges and new opportunities. You will be responsible for designing and implementing solutions and technologies which will handle the growing business needs and play a key role in redefining what it means to be a world-class Operations Research organization.

What You'll Do

Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations
Partner with Supply Chain’s functional areas (with Demand Planning, S&OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board
Work with IT and Data Warehousing teams to develop and enhance systems
Be a subject matter expert for Supply Chain Analytics
Predict, simulate and optimize Supply Chain operations
Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain



What You'll Need

An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications
Ability to understand and apply advanced mathematics
R or Python mastery
Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification
Ability to translate complex data sets and research into simple business recommendations
Ability to manage multiple projects
Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools
Position may require travel


Bonus

Strong leadership skills and outgoing
Ability to effectively operate both independently and as part of a team
E-com, Retail or startup experience is a plus



Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members.

If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at Chewy, please contact HR@Chewy.com.

To access Chewy’s Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: https://www.chewy.com/app/content/privacy).
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Chewy's Supply Chain Team is seeking a<strong> Data Scientist </strong>to join the growing Supply Chain Analytics team in Seattle, WA. Combining a background in Supply Chain with a deep understanding of analytics and data science, you will be a part of a team responsible for strategic planning and research initiatives centered around our inventory and fulfillment network. This includes optimizing the way that we predict customer demand; and purchase, position, transport, store and ship inventory to our customers. The Supply Chain team operates in a fast-paced environment where every day brings new challenges and new opportunities. You will be responsible for designing and implementing solutions and technologies which will handle the growing business needs and play a key role in redefining what it means to be a world-class Operations Research organization.<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations</li> <li>Partner with Supply Chain’s functional areas (with Demand Planning, S&amp;OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board</li> <li>Work with IT and Data Warehousing teams to develop and enhance systems</li> <li>Be a subject matter expert for Supply Chain Analytics</li> <li>Predict, simulate and optimize Supply Chain operations</li> <li>Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain</li> <br><br></ul><strong><u>What You'll Need<br></u></strong><ul> <li>An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications</li> <li>Ability to understand and apply advanced mathematics</li> <li>R or Python mastery</li> <li>Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification</li> <li>Ability to translate complex data sets and research into simple business recommendations</li> <li>Ability to manage multiple projects</li> <li>Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools</li> <li>Position may require travel </li> <br></ul><strong>Bonus<br></strong><ul> <li>Strong leadership skills and outgoing</li> <li>Ability to effectively operate both independently and as part of a team</li> <li>E-com, Retail or startup experience is a plus</li> <br><br></ul>Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members.<br><br>If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at Chewy, please contact <u>HR@Chewy.com</u>.<br><br>To access Chewy’s Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: https://www.chewy.com/app/content/privacy).</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Seattle, Washington, United States",Amerisoftpro Systems,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-amerisoftpro-systems-2430502815?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=X3E1nGrRqkL9m962PgxOKw%3D%3D&position=7&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Sharecare is the digital health company that helps people manage all their health in one place. The Sharecare platform provides each person -- no matter where they are in their health journey -- with a comprehensive and personalized health profile, where they can dynamically and easily connect to the information, evidence-based programs and health professionals they need to live their healthiest, happiest and most productive life. With award-winning and innovative frictionless technologies, scientifically validated clinical protocols and best-in-class coaching tools, Sharecare helps providers, employers and health plans effectively scale outcomes-based health and wellness solutions across their entire populations. We are always looking for people that value the opportunity to work hard, have fun on the job, and make a difference in the lives of others through their work every day!

Job Summary

We are seeking a Data Engineer to be part of an established team delivering complex data solutions to our internal and external consumers. This candidate will work with Engineering, Product, QA, Operations, and Analytics as well as external development and testing teams.

The candidate must be technically capable with extensive experience in Python and SQL, as well as experience solving complex technical problems. We are looking for someone who is an expert at productionizing complex data operations, and employing scripting solutions on established BI tools.

This role will also be analytical in nature and requires critical thinkers who have an interest in understanding and shaping a data story.

Essential Functions

Responsible for designing and implementing ETL processes and data standardization solutions
Responsible for populating the data warehouse and all related extraction, transformation and load of data functions
Support all facets of the business in data analysis and critical ad hoc reporting
Perform tests, validate data flows and prepare all ETL processes, incorporating business requirements into all design specifications
Design and develop all data mapping techniques for all data models in systems
Document technical and system specifications for all ETL processes
Analyze and interpret complex data on all target systems, coordinating with internal and external stakeholders to validate requirements
Perform root cause analysis, resolve and validate all production data issues



Qualifications

Bachelor's degree (or higher) in Computer Science or related field
Knowledge and experience with Agile development practices
Experience interacting with RESTful service APIs
3+ years' experience with Python mandatory. R and HTML a plus.
5+ years' experience with database technologies such as SQL, Vertica, Mongo and/or Elastic
3+ years' experience with data warehousing architecture concepts and BI tools. Qlik a plus.



Specific Skills/Attributes

Excellent written and verbal communication skills to lead meetings with technical peers regarding the solution designs
Ability to work in team environment
Ability to interface with client and/or Product Management



Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Sharecare is the digital health company that helps people manage all their health in one place. The Sharecare platform provides each person -- no matter where they are in their health journey -- with a comprehensive and personalized health profile, where they can dynamically and easily connect to the information, evidence-based programs and health professionals they need to live their healthiest, happiest and most productive life. With award-winning and innovative frictionless technologies, scientifically validated clinical protocols and best-in-class coaching tools, Sharecare helps providers, employers and health plans effectively scale outcomes-based health and wellness solutions across their entire populations. We are always looking for people that value the opportunity to work hard, have fun on the job, and make a difference in the lives of others through their work every day!<br><br><strong><u>Job Summary<br><br></u></strong>We are seeking a Data Engineer to be part of an established team delivering complex data solutions to our internal and external consumers. This candidate will work with Engineering, Product, QA, Operations, and Analytics as well as external development and testing teams.<br><br>The candidate must be technically capable with extensive experience in Python and SQL, as well as experience solving complex technical problems. We are looking for someone who is an expert at productionizing complex data operations, and employing scripting solutions on established BI tools.<br><br>This role will also be analytical in nature and requires critical thinkers who have an interest in understanding and shaping a data story.<br><br><strong><u>Essential Functions<br></u></strong><ul> <li>Responsible for designing and implementing ETL processes and data standardization solutions</li> <li>Responsible for populating the data warehouse and all related extraction, transformation and load of data functions</li> <li>Support all facets of the business in data analysis and critical ad hoc reporting</li> <li>Perform tests, validate data flows and prepare all ETL processes, incorporating business requirements into all design specifications</li> <li>Design and develop all data mapping techniques for all data models in systems</li> <li>Document technical and system specifications for all ETL processes</li> <li>Analyze and interpret complex data on all target systems, coordinating with internal and external stakeholders to validate requirements</li> <li>Perform root cause analysis, resolve and validate all production data issues</li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li> Bachelor's degree (or higher) in Computer Science or related field</li> <li> Knowledge and experience with Agile development practices</li> <li> Experience interacting with RESTful service APIs</li> <li> 3+ years' experience with Python mandatory. R and HTML a plus.</li> <li> 5+ years' experience with database technologies such as SQL, Vertica, Mongo and/or Elastic</li> <li> 3+ years' experience with data warehousing architecture concepts and BI tools. Qlik a plus.</li> <br><br></ul><strong><u>Specific Skills/Attributes<br></u></strong><ul> <li> Excellent written and verbal communication skills to lead meetings with technical peers regarding the solution designs </li> <li> Ability to work in team environment</li> <li> Ability to interface with client and/or Product Management</li> <br><br></ul>Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Data Engineer,"Remote, Oregon, United States",Pantheon Platform,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-pantheon-platform-2326288906?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=wzoZedDbTB5YXP2bPisdlQ%3D%3D&position=8&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Top Skills SQL Python ETL AWS Redshift or Snowflake (bonus)

JOB DESCRIPTION Solution-oriented Data Engineer to build complex analytical solutions that deepen our collective understanding of customers, influence innovation, and deliver actionable insights for our video streaming service. The ideal candidate will be a self-starter who is comfortable driving complex analysis, coupled with a demonstrated ability to think broadly and strategically about customer and business implications. You will encounter a wide range of problem-solving situations, strategic to real-time, requiring extensive use of data collection and analysis. The insights that you deliver drive strategic decision making for prime video and its partner teams and are critical inputs to influence the way we think about our video streaming service. As a Data Engineer on our team you will wear many hats and work in a highly collaborative environment thatrsquos more startup than big company. Wersquoll need to tackle problems that span a variety of domains Machine learning, Artificial intelligence, Natural Language processing, real-time and distributed systems. In addition to continuously improving the execution of this core mission the Business Intelligence Engineer will design new data models, create new metrics and quantify opportunities for product development with internal stakeholders in product management, engineering, user experience and personalization. In this role you will have an opportunity to collaborate with a team of BIErsquos, DErsquos, SDErsquos and MLAI scientists. Successful candidates have a solid background in analyzing and solving business problems at their root bull Stepping back to understand the broader context bull Develop solutions that utilize the highest standards of analytical rigor and data integrity bull Utilize database technologies, including SQL (SME) is required, ETL and Redshift to design, develop, and evaluate analyses and highly innovative business intelligence tools and reporting. bull Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation. bull This role will be presenting video data from SQL queries to Director and VP level on a weekly basis, so having high quality standards and refined soft skills is critical. Leadership Principle (have 1) bull Deliver Results Leaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion. Despite setbacks, they rise to the occasion and never settle. bull Bias for Action Speed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking bull Ownership Leaders are owners. They think long term and donrsquot sacrifice long-term value for short-term results. They act on behalf of the entire company, beyond just their own team. They never say ldquothatrsquos not my job."" bull Insist on the Highest Standards Leaders have relentlessly high standards mdash many people may think these standards are unreasonably high. Leaders are continually raising the bar and drive their teams to deliver high quality products, services, and processes. Leaders ensure that defects do not get sent down the line and that problems are fixed so they stay fixed. Degrees or certifications required Degree in Computer Science, Engineering, Mathematics, or a related field
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Top Skills SQL Python ETL AWS Redshift or Snowflake (bonus)<br><br>JOB DESCRIPTION Solution-oriented Data Engineer to build complex analytical solutions that deepen our collective understanding of customers, influence innovation, and deliver actionable insights for our video streaming service. The ideal candidate will be a self-starter who is comfortable driving complex analysis, coupled with a demonstrated ability to think broadly and strategically about customer and business implications. You will encounter a wide range of problem-solving situations, strategic to real-time, requiring extensive use of data collection and analysis. The insights that you deliver drive strategic decision making for prime video and its partner teams and are critical inputs to influence the way we think about our video streaming service. As a Data Engineer on our team you will wear many hats and work in a highly collaborative environment thatrsquos more startup than big company. Wersquoll need to tackle problems that span a variety of domains Machine learning, Artificial intelligence, Natural Language processing, real-time and distributed systems. In addition to continuously improving the execution of this core mission the Business Intelligence Engineer will design new data models, create new metrics and quantify opportunities for product development with internal stakeholders in product management, engineering, user experience and personalization. In this role you will have an opportunity to collaborate with a team of BIErsquos, DErsquos, SDErsquos and MLAI scientists. Successful candidates have a solid background in analyzing and solving business problems at their root bull Stepping back to understand the broader context bull Develop solutions that utilize the highest standards of analytical rigor and data integrity bull Utilize database technologies, including SQL (SME) is required, ETL and Redshift to design, develop, and evaluate analyses and highly innovative business intelligence tools and reporting. bull Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation. bull This role will be presenting video data from SQL queries to Director and VP level on a weekly basis, so having high quality standards and refined soft skills is critical. Leadership Principle (have 1) bull Deliver Results Leaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion. Despite setbacks, they rise to the occasion and never settle. bull Bias for Action Speed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking bull Ownership Leaders are owners. They think long term and donrsquot sacrifice long-term value for short-term results. They act on behalf of the entire company, beyond just their own team. They never say ldquothatrsquos not my job."" bull Insist on the Highest Standards Leaders have relentlessly high standards mdash many people may think these standards are unreasonably high. Leaders are continually raising the bar and drive their teams to deliver high quality products, services, and processes. Leaders ensure that defects do not get sent down the line and that problems are fixed so they stay fixed. Degrees or certifications required Degree in Computer Science, Engineering, Mathematics, or a related field</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientists Analysts,"Dearborn, Michigan, United States",Altair,2021-02-18,https://www.linkedin.com/jobs/view/data-scientists-analysts-at-altair-2429644552?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=N6Gr3yHdppWqlEWiZYrYDg%3D%3D&position=9&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"About Pantheon

Pantheon is the only WebOps platform built from the ground up for agility. We help our customers win, where the digital experience starts and matters most - their websites. We empower teams of developers, marketers, and IT professionals to focus on delivering business results while Pantheon handles uptime, performance, scalability, and security. We are the fastest growing Drupal and WordPress platform in the world, powering over 285,000 sites and serving billions of pages every month. Happy customers include some of the most recognized names in high tech, higher education, and NGOs, such as Patch, Apigee, UC Berkeley, Arizona State University, and the United Nations.

With 35% of the web running open-source and significant investments in a $200 billion total addressable market, we are growing aggressively into a huge market opportunity and looking to expand our sales organization.

The Role

You are an experienced Data Platform Engineer that is open to work remotely or onsite at our San Francisco or Minneapolis office (on US hours.) Your expertise will help us continue to innovate and manage complexity as we (and our data) grow in size, feature depth and across data centers. Pantheon’s core company values are Trust, Teamwork, Passion, and Customers First. At Pantheon, we work hard and play harder, valuing individuality, humor, and balance. We're enthusiastic participants in several open-source communities and have real relationships with many of our most active customers. If all of this sounds interesting to you, read on!

Cool Stuff You'll Do

Create an automated, state of the art, data platform for various job types and sizes
Help stabilize a standard deployment pattern that will enable us to grow our data platform service capabilities for the company
Close collaboration with the wider engineering team to both deliver platform improvements and provide subject-matter-expertise for other technology initiatives
Continuous improvements to our standard of engineering excellence by implementing best practices for coding, testing, deploying and communication



What You Bring To The Table

Knowledge of large-scale platforms and the design of scalable, robust services in the real world, especially for data transfers and manipulations (both streaming and batch)
Experience with a variety of data store types, tech stacks, and the tradeoffs between them.
Experience with scripting the creation of dynamic platform infrastructures hosted by one or more cloud providers such as Google or AWS.
Desire to work on a new project and participate in the design and documentation activities related to the creation of new infrastructure.


Bonus Points for

Strong experience in Python
Automating infrastructure with kubernetes
Scheduling ETLs using Airflow
Exposure to frameworks such as Django
Experience working on new “greenfield” projects
Experience supporting data scientists and analysts through PaaS



What We Offer

We have all the usual perks and benefits but what we can really offer you is a fantastic work environment powered by an amazing team.

Industry competitive compensation
Stock options
Vacation days and time off
Full medical coverage (medical, dental, vision)
top-of-line equipment
Fun at Drupal community events
Discounts on custom bicycles - the founders of Pantheon also Founded Mission Bicycle
Training stipend to attend industry conferences



Pantheon is an equal opportunity/affirmative action employer and we welcome applications from all backgrounds regardless of race, color, religion, sex, national origin, ancestry, age, marital status, sexual orientation, gender identity, veteran status, disability, or any other classification protected by law. Visa Sponsorship is not available at this time.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Pantheon<br><br></u></strong>Pantheon is the only WebOps platform built from the ground up for agility. We help our customers win, where the digital experience starts and matters most - their websites. We empower teams of developers, marketers, and IT professionals to focus on delivering business results while Pantheon handles uptime, performance, scalability, and security. We are the fastest growing Drupal and WordPress platform in the world, powering over 285,000 sites and serving billions of pages every month. Happy customers include some of the most recognized names in high tech, higher education, and NGOs, such as Patch, Apigee, UC Berkeley, Arizona State University, and the United Nations.<br><br>With 35% of the web running open-source and significant investments in a $200 billion total addressable market, we are growing aggressively into a huge market opportunity and looking to expand our sales organization.<br><br><strong>The Role<br><br></strong>You are an experienced Data Platform Engineer that is open to work remotely or onsite at our San Francisco or Minneapolis office (on US hours.) Your expertise will help us continue to innovate and manage complexity as we (and our data) grow in size, feature depth and across data centers. Pantheon’s core company values are <strong>Trust, Teamwork, Passion, and Customers First.</strong> At Pantheon, we work hard and play harder, valuing individuality, humor, and balance. We're enthusiastic participants in several open-source communities and have real relationships with many of our most active customers. If all of this sounds interesting to you, read on!<br><br><strong>Cool Stuff You'll Do<br></strong><ul> <li> Create an automated, state of the art, data platform for various job types and sizes </li> <li> Help stabilize a standard deployment pattern that will enable us to grow our data platform service capabilities for the company </li> <li> Close collaboration with the wider engineering team to both deliver platform improvements and provide subject-matter-expertise for other technology initiatives </li> <li> Continuous improvements to our standard of engineering excellence by implementing best practices for coding, testing, deploying and communication </li> <br><br></ul><strong><u>What You Bring To The Table<br></u></strong><ul> <li> Knowledge of large-scale platforms and the design of scalable, robust services in the real world, especially for data transfers and manipulations (both streaming and batch) </li> <li> Experience with a variety of data store types, tech stacks, and the tradeoffs between them. </li> <li> Experience with scripting the creation of dynamic platform infrastructures hosted by one or more cloud providers such as Google or AWS. </li> <li> Desire to work on a new project and participate in the design and documentation activities related to the creation of new infrastructure. </li> <br></ul><strong>Bonus Points for<br></strong><ul> <li> Strong experience in Python </li> <li> Automating infrastructure with kubernetes </li> <li> Scheduling ETLs using Airflow </li> <li> Exposure to frameworks such as Django </li> <li> Experience working on new “greenfield” projects </li> <li> Experience supporting data scientists and analysts through PaaS </li> <br><br></ul><strong><u>What We Offer<br><br></u></strong>We have all the usual perks and benefits but what we can really offer you is a fantastic work environment powered by an amazing team.<br><ul> <li> Industry competitive compensation </li> <li> Stock options </li> <li> Vacation days and time off </li> <li> Full medical coverage (medical, dental, vision) </li> <li> top-of-line equipment </li> <li> Fun at Drupal community events </li> <li> Discounts on custom bicycles - the founders of Pantheon also Founded Mission Bicycle </li> <li> Training stipend to attend industry conferences </li> <br><br></ul>Pantheon is an equal opportunity/affirmative action employer and we welcome applications from all backgrounds regardless of race, color, religion, sex, national origin, ancestry, age, marital status, sexual orientation, gender identity, veteran status, disability, or any other classification protected by law. Visa Sponsorship is not available at this time.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Remote, Oregon, United States",thredUP,2021-02-15,https://www.linkedin.com/jobs/view/data-scientist-at-thredup-2424832572?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=eQLyl0jJk%2BKRY0ZpgD3d4Q%3D%3D&position=10&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Transforming the Future with Convergence of Simulation and Data

Data Scientist Analysts

Job Summary

Our client in Dearborn, MI is looking for a Data Scientist Analysts. This is a contract position.

What You Will Do

Perform analysis and modeling of residual values, auction prices, and market drivers to support Business and Sales Planning Analytics (BSPA) Used Vehicle Valuations team and customers Scope: U.S. Residual Values and Used Vehicle Market

Responsibilities

Develop and maintain models to quantify the relationship between auction prices and key residual values drivers
Develop and maintain models to optimize the distribution of remarketing vehicles
Apply and integrate latest analytical tools and data sources to more accurately model used vehicle prices
Execute both descriptive and inferential ad hoc requests for management and business customers in a timely manner
Provide data analysis visualization and prepare presentation materials to share with management and business customers
Analyzes and evaluates remarketing programs development, progress and performance



Basics

Advanced modeling (including machine / deep learning, statistical, econometric, optimization, etc.) and simulation techniques in a business or academic environment
Ability to effectively communicate, both verbal and written, across different levels of the organizations
Experience with Excel and PowerPoint
2+ years of experience using advanced modeling (including machine / deep learning, statistical, econometric, optimization, etc.) and simulation techniques in a business or academic environment
2+ years of experience with one or more of the following tools: Data Gathering & Analysis skills/tools (e.g. SAS, Python, SQL, Hadoop, Teradata, Business Objects, Alteryx, etc.) AND Visualization skills/tools (e.g. QlikView, Tableau, WebFocus, etc.)
Master’s degree in Statistics, Econometrics, Data Science, or related field of study



Preferred

SAS experience preferred Have excellent time management skills and be able to handle working on multiple projects at the same time
Be able to make reasonable judgments and conclusions with limited information and resources
Be able to utilize all major modeling techniques as applied to short and long-term volume and price forecasts
Be able to quickly convert a real business requirement into a solvable modeling problem, sort out relevant information, and judge the solution against business reality
Be aspirational and curious in technical excellence and innovation
Have a lifetime learning attitude
3+ years of auto industry related work (auto marketing and sales experience a plus)



How You Will Be Successful

Envision the Future
Communicate Honestly and Broadly
Seek Technology and Business “First”
Embrace Diversity and Take Risks



What We Offer

Competitive Salary
Comprehensive Benefit Package
401(k) with matching contributions
Paid Time Off
Employee Discounts
Free training on all Altair products



Why Work With Us

Altair is a global technology company that provides software and cloud solutions in the area of data analytics, product development, and high-performance computing (HPC). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists, and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.

Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing.

For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com

Ready to go? #ONLYFORWARD

At our core we are explorers; adventures; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and unchartered waters, we dive headfirst. We are the original trailblazers that make the impossible possible, discovering new solutions to our customer’s toughest challenges.

Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair’s history demonstrations a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Transforming the Future with Convergence of Simulation and Data <br><br></strong><strong> Data Scientist Analysts <br><br></strong><strong><u>Job Summary<br><br></u></strong>Our client in Dearborn, MI is looking for a Data Scientist Analysts. This is a contract position.<br><br><strong><u>What You Will Do<br><br></u></strong>Perform analysis and modeling of residual values, auction prices, and market drivers to support Business and Sales Planning Analytics (BSPA) Used Vehicle Valuations team and customers Scope: U.S. Residual Values and Used Vehicle Market<br><br><strong><u>Responsibilities<br></u></strong><ul> <li> Develop and maintain models to quantify the relationship between auction prices and key residual values drivers </li> <li> Develop and maintain models to optimize the distribution of remarketing vehicles </li> <li> Apply and integrate latest analytical tools and data sources to more accurately model used vehicle prices </li> <li> Execute both descriptive and inferential ad hoc requests for management and business customers in a timely manner </li> <li> Provide data analysis visualization and prepare presentation materials to share with management and business customers </li> <li> Analyzes and evaluates remarketing programs development, progress and performance </li> <br><br></ul><strong><u>Basics<br></u></strong><ul> <li> Advanced modeling (including machine / deep learning, statistical, econometric, optimization, etc.) and simulation techniques in a business or academic environment </li> <li> Ability to effectively communicate, both verbal and written, across different levels of the organizations </li> <li> Experience with Excel and PowerPoint </li> <li> 2+ years of experience using advanced modeling (including machine / deep learning, statistical, econometric, optimization, etc.) and simulation techniques in a business or academic environment </li> <li> 2+ years of experience with one or more of the following tools: Data Gathering &amp; Analysis skills/tools (e.g. SAS, Python, SQL, Hadoop, Teradata, Business Objects, Alteryx, etc.) AND Visualization skills/tools (e.g. QlikView, Tableau, WebFocus, etc.) </li> <li> Master’s degree in Statistics, Econometrics, Data Science, or related field of study </li> <br><br></ul><strong><u>Preferred<br></u></strong><ul> <li> SAS experience preferred Have excellent time management skills and be able to handle working on multiple projects at the same time </li> <li> Be able to make reasonable judgments and conclusions with limited information and resources </li> <li> Be able to utilize all major modeling techniques as applied to short and long-term volume and price forecasts </li> <li> Be able to quickly convert a real business requirement into a solvable modeling problem, sort out relevant information, and judge the solution against business reality </li> <li> Be aspirational and curious in technical excellence and innovation </li> <li> Have a lifetime learning attitude </li> <li> 3+ years of auto industry related work (auto marketing and sales experience a plus) </li> <br><br></ul><strong><u>How You Will Be Successful<br></u></strong><ul> <li> <strong> Envision the Future </strong> </li> <li> <strong> Communicate Honestly and Broadly </strong> </li> <li> <strong> Seek Technology and Business “First” </strong> </li> <li> <strong> Embrace Diversity and Take Risks </strong> </li> <br><br></ul><strong><u>What We Offer<br></u></strong><ul> <li> Competitive Salary </li> <li> Comprehensive Benefit Package </li> <li> 401(k) with matching contributions </li> <li> Paid Time Off </li> <li> Employee Discounts </li> <li> Free training on all Altair products </li> <br><br></ul><strong><u>Why Work With Us<br><br></u></strong>Altair is a global technology company that provides software and cloud solutions in the area of data analytics, product development, and high-performance computing (HPC). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists, and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.<br><br><strong> Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing. <br><br></strong>For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com<br><br><strong> Ready to go? #ONLYFORWARD <br><br></strong>At our core we are explorers; adventures; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and unchartered waters, we dive headfirst. We are the original trailblazers that make the impossible possible, discovering new solutions to our customer’s toughest challenges.<br><br>Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair’s history demonstrations a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
"Data Scientist, Product Analytics",Utica-Rome Area,Gusto,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-gusto-2415384912?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=PzG%2FT26IgxnFNMmgRLt4Ng%3D%3D&position=11&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"About ThredUP

In 2009, thredUP set out to make used clothes the new normal and create a more sustainable future for fashion. The company designed a modern resale experience that took the work and risk out of thrift, and converted a generation of secondhand skeptics to fans. Sellers send clothes directly to thredUP by the bagful, and buyers shop quality-checked items from over 35,000 brands at steep discounts. To power this marketplace, thredUP built an infrastructure that has recirculated 100 million unique garments via proprietary technology, data and logistics. thredUP most recently expanded its platform with Resale-as-a-Service (RaaS) to power resale for the world’s leading fashion brands. As a circular fashion pioneer, thredUP is reducing fashion’s impact on the planet and unlocking economic value for consumers and brands alike.

At thredUP, we’re working to revolutionize the clothing industry and we're looking for a curious and creative Data Scientist to help manage our complex multi-sided marketplace. As part of our data science team, you will report on marketplace insights and work cross-functionally to build the algorithms that drive pricing, search, supplier acquisition, and inventory management efforts. You will work with an interdisciplinary team of data scientists, software engineers, analysts, and product managers. If you get excited about data-driven decision making and want to play a role in managing a highly dynamic marketplace, we’d love to hear from you.

What You'll Do

Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every month
Uncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participants
Develop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortment
Develop rigorous forecasting systems to bring predictability to our planning around inventory growth and economics
Create mathematical representations of the flow of items into and out of our marketplace
Drive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mix
Participate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up


Requirements

At least 3 years of full time, professional experience in data analytics, data science, or software engineering roles
Ability to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborations
Innate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truth
Well-rounded skill set in statistics, machine learning, software development, and project management
Advanced knowledge of SQL and Python, and experience writing code in a collaborative environment
Prior experience working with marketplaces and/or a relevant background in economics or operations research is a plus


What We Offer


The opportunity to make a massive impact & influence outcomes for our business and customers alongside passionate coworkers
Autonomy. The ability to make, own, and carry out decisions
Competitive salary, equity and full benefits (health/dental/vision insurance & 401k)
Flexible PTO


We believe diversity, inclusion and belonging is key for our team.

At thredUP, our mission has been built on extending the lives of millions of unique clothing items. Much like our inventory, we are proud to have fostered a workplace that is one-of-a-kind. As a company focused on diversity, inclusion and belonging, we are committed to ensuring our employees are comfortable bringing their authentic selves to work every day. A unique perspective is critical to solving complex problems and inspiring a new generation to think secondhand first. Be you.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About ThredUP<br><br></u></strong>In 2009, thredUP set out to make used clothes the new normal and create a more sustainable future for fashion. The company designed a modern resale experience that took the work and risk out of thrift, and converted a generation of secondhand skeptics to fans. Sellers send clothes directly to thredUP by the bagful, and buyers shop quality-checked items from over 35,000 brands at steep discounts. To power this marketplace, thredUP built an infrastructure that has recirculated 100 million unique garments via proprietary technology, data and logistics. thredUP most recently expanded its platform with Resale-as-a-Service (RaaS) to power resale for the world’s leading fashion brands. As a circular fashion pioneer, thredUP is reducing fashion’s impact on the planet and unlocking economic value for consumers and brands alike.<br><br>At thredUP, we’re working to revolutionize the clothing industry and we're looking for a curious and creative Data Scientist to help manage our complex multi-sided marketplace. As part of our data science team, you will report on marketplace insights and work cross-functionally to build the algorithms that drive pricing, search, supplier acquisition, and inventory management efforts. You will work with an interdisciplinary team of data scientists, software engineers, analysts, and product managers. If you get excited about data-driven decision making and want to play a role in managing a highly dynamic marketplace, we’d love to hear from you.<br><br><strong><u>What You'll Do<br></u></strong><ul><ul><li>Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every month</li><li>Uncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participants</li><li>Develop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortment</li><li>Develop rigorous forecasting systems to bring predictability to our planning around inventory growth and economics</li><li>Create mathematical representations of the flow of items into and out of our marketplace</li><li>Drive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mix</li><li>Participate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up<br><br></li></ul></ul><strong><u>Requirements<br></u></strong><ul><ul><li>At least <strong>3 years of full time, professional experience</strong> in data analytics, data science, or software engineering roles</li><li>Ability to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborations</li><li>Innate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truth</li><li>Well-rounded skill set in statistics, machine learning, software development, and project management</li><li>Advanced knowledge of SQL and Python, and experience writing code in a collaborative environment</li><li>Prior experience working with marketplaces and/or a relevant background in economics or operations research is a plus<br><br></li></ul></ul><strong><u>What We Offer<br><br></u></strong><li> The opportunity to make a massive impact &amp; influence outcomes for our business and customers alongside passionate coworkers</li><li> Autonomy. The ability to make, own, and carry out decisions</li><li> Competitive salary, equity and full benefits (health/dental/vision insurance &amp; 401k)</li><li> Flexible PTO<br><br></li><strong>We believe diversity, inclusion and belonging is key for our team.<br><br></strong>At thredUP, our mission has been built on extending the lives of millions of unique clothing items. Much like our inventory, we are proud to have fostered a workplace that is one-of-a-kind. As a company focused on diversity, inclusion and belonging, we are committed to ensuring our employees are comfortable bringing their authentic selves to work every day. A unique perspective is critical to solving complex problems and inspiring a new generation to think secondhand first. Be you.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Internet, Retail"
Data Scientist - U.S. Telecommute,"San Antonio, Texas, United States",Optum,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-u-s-telecommute-at-optum-2417239641?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=AL9uzuqFXCcF%2FolAiRa%2FXQ%3D%3D&position=12&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"About Gusto

Gusto is a modern, online people platform that helps small businesses take care of their teams. On top of full-service payroll, Gusto offers health insurance, 401(k)s, expert HR, and team management tools. Today, Gusto offices in Denver, San Francisco, and New York serve more than 100,000 businesses nationwide.

Our mission is to create a world where work empowers a better life, and it starts right here at Gusto. That’s why we’re committed to building a collaborative and inclusive workplace, both physically and virtually. Learn more about our Total Rewards philosophy.

Gusto is looking for an ambitious mid- or early-career product analyst with a solid grounding in statistics and data science and at least a few years experience applying this knowledge in a business environment. In this role you will work closely with other members of our Data Science team, as well as our Engineering, Product and Design teams to define and track product metrics, design customer-facing experiments and dive deep into our Payroll, Benefits and HR data to deliver insights.

Gusto’s Data Science team leverages Gusto’s data to deliver data-informed insights for our customers and guide product direction and decision-making. We operate full-stack, working closely with product managers to apply data insights to strategy and product decisions, conducting analyses, prototyping and deploying predictive models and statistical tools both for internal use and for our customers.

Here’s What You’ll Do Day-to-day

Work closely with product groups to define, measure and report on core product and feature metrics, and to define standards and practices for how product groups work with data
Perform in-depth analyses of our Payroll, Benefits and HR product data to inform and guide product direction and strategy
Design and analyze customer-facing experiments
Work with our business intelligence teams to turn your insights and analyses into clean and consistent reporting
Be a strong voice for a data-informed point of view within our engineering, product and design organization
Collaborate with UX research to design surveys and provide quantitative insights on customer experience



Here’s What We're Looking For

At least 2 years experience in a similar role, ideally at a product-focused software company
Strong SQL skills, and comfortable in at least one scripting or statistical programming language (ideally Python and/or R)
Strong knowledge of statistics and experiment design and ability to apply these to conducting and interpreting analyses, data visualization, presentation and recommendations
Excellent communicator - able to effectively deliver findings and recommendations to non-technical stakeholders in a clear and compelling fashion
Passionate about teaching and evangelizing a data-informed approach to product development to product managers, designers and engineers
MS or PhD in a quantitative field + at least 1-2 years experience in a business environment, or BS or Data Science Bootcamp graduate + equivalent experience in a business setting considered


Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.

Gusto’s mission is to create a world where work empowers a better life. By making complicated, impersonal business tasks simple and personal, Gusto is reimagining HR, payroll, and benefits for over 100,000 companies nationwide. Gusto has offices in San Francisco, Denver, and New York, and the company’s investors include Google Capital, General Catalyst, Kleiner Perkins Caufield & Byers, as well as the founders of Instagram, Stripe, Nest, PayPal, Yelp, Dropbox, and Eventbrite, among others.

Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@gusto.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Gusto<br><br></u></strong>Gusto is a modern, online people platform that helps small businesses take care of their teams. On top of full-service payroll, Gusto offers health insurance, 401(k)s, expert HR, and team management tools. Today, Gusto offices in Denver, San Francisco, and New York serve more than 100,000 businesses nationwide.<br><br>Our mission is to create a world where work empowers a better life, and it starts right here at Gusto. That’s why we’re committed to building a collaborative and inclusive workplace, both physically and virtually. Learn more about our Total Rewards philosophy.<br><br>Gusto is looking for an ambitious mid- or early-career product analyst with a solid grounding in statistics and data science and at least a few years experience applying this knowledge in a business environment. In this role you will work closely with other members of our Data Science team, as well as our Engineering, Product and Design teams to define and track product metrics, design customer-facing experiments and dive deep into our Payroll, Benefits and HR data to deliver insights.<br><br>Gusto’s Data Science team leverages Gusto’s data to deliver data-informed insights for our customers and guide product direction and decision-making. We operate full-stack, working closely with product managers to apply data insights to strategy and product decisions, conducting analyses, prototyping and deploying predictive models and statistical tools both for internal use and for our customers.<br><br><strong><u>Here’s What You’ll Do Day-to-day<br></u></strong><ul> <li>Work closely with product groups to define, measure and report on core product and feature metrics, and to define standards and practices for how product groups work with data</li> <li>Perform in-depth analyses of our Payroll, Benefits and HR product data to inform and guide product direction and strategy</li> <li>Design and analyze customer-facing experiments</li> <li>Work with our business intelligence teams to turn your insights and analyses into clean and consistent reporting</li> <li>Be a strong voice for a data-informed point of view within our engineering, product and design organization</li> <li>Collaborate with UX research to design surveys and provide quantitative insights on customer experience</li> <br><br></ul><strong><u>Here’s What We're Looking For<br></u></strong><ul> <li>At least 2 years experience in a similar role, ideally at a product-focused software company</li> <li>Strong SQL skills, and comfortable in at least one scripting or statistical programming language (ideally Python and/or R)</li> <li>Strong knowledge of statistics and experiment design and ability to apply these to conducting and interpreting analyses, data visualization, presentation and recommendations</li> <li>Excellent communicator - able to effectively deliver findings and recommendations to non-technical stakeholders in a clear and compelling fashion</li> <li>Passionate about teaching and evangelizing a data-informed approach to product development to product managers, designers and engineers</li> <li>MS or PhD in a quantitative field + at least 1-2 years experience in a business environment, or BS or Data Science Bootcamp graduate + equivalent experience in a business setting considered</li> <br></ul>Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.<br><br>Gusto’s mission is to create a world where work empowers a better life. By making complicated, impersonal business tasks simple and personal, Gusto is reimagining HR, payroll, and benefits for over 100,000 companies nationwide. Gusto has offices in San Francisco, Denver, and New York, and the company’s investors include Google Capital, General Catalyst, Kleiner Perkins Caufield &amp; Byers, as well as the founders of Instagram, Stripe, Nest, PayPal, Yelp, Dropbox, and Eventbrite, among others.<br><br>Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@gusto.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Software, Internet, Financial Services"
Data Engineer,"Salt Lake City, Utah, United States",Snap Finance,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-at-snap-finance-2398030581?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=4fM0A1U6ALDTmYStktYXUg%3D%3D&position=13&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Energize your career with one of Healthcare’s fastest growing companies.

You dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it is a dream that definitely can come true. Already one of the world’s leading Healthcare companies, UnitedHealth Group is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.

This opportunity is with one of our most exciting business areas: Optum – a growing part of our family of companies that make UnitedHealth Group a Fortune 6 leader.

Optum Analytics solutions create a longitudinal view of both individual patients and patient populations. We gather, normalize, and analyze data from disparate sources that, uniquely, span the continuum of care--including EHRs, Practice Management Systems and claims. Our EHR data alone accounts for over 80M patient lives across the U.S.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

We are looking for a data scientist who is eager to tackle the challenges of extracting insights from vast amounts of EHR data originating from multiple sources
You will work with a diverse set of Optum researchers, clinicians, internal and external clients to define the projects and see them through to completion that cover a range of clinical focus
You would be participating in the development of our end-to-end NLP pipeline, building descriptive and predictive analytics and producing research validations
Specifically, as a member of our collaborative team you will be working with structured and unstructured data to explore the data, develop models, and performing research analytics
You will have the opportunity to work with open-source distributed data processing frameworks, such as Apache Spark and build scalable machine learning applications and deploy them in production
The right candidate will have strong prioritization skills, ability to manage ad hoc requests in parallel with ongoing projects


If you have the experience, curiosity and entrepreneurial spirit to tackle these challenges, we want to talk to you.

You'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelor’s degree in Science, Technology, Engineering, Math, or Linguistics or equivalent degree area
3+ years of experience as a hands-on data scientist, non-managerial role and executing on data science, analytics, or programming projects (1 year of academic projects maybe considered to equal 3+ years-projects need to be clearly outlined in the resume)
2+ years of experience in machine learning, predictive modeling, or natural language processing
2+ years of experience in Python
Experience with leveraging best practices conducting advanced analytics projects
If you need to enter a work site for any reason, you will be required to screen for symptoms using the ProtectWell mobile app, Interactive Voice Response (i.e., entering your symptoms via phone system) or a similar UnitedHealth Group-approved symptom screener. When in a UnitedHealth Group building, employees are required to wear a mask in common areas. In addition, employees must comply with any state and local masking orders.



Preferred Qualifications

Experience with Pandas, Scikit-learn, TensorFlow, or spaCy
Experience with open-source distributed data processing frameworks, such as Spark
Experience in Biostatistics or related field
Experience with SQL or relational databases
Familiarity with EHR data and standards


UnitedHealth Group is an essential business. The health and safety of our team members is our highest priority, so we are taking a science driven approach to slowly welcome and transition some of our workforce back to the office with many safety protocols in place. We continue to monitor and assess before we confirm the return of each wave, paying specific attention to geography-specific trends. At this time, 90% of our non-clinical workforce transitioned to a work at home (remote) status. We have taken steps to ensure the safety of our 325,000 team members and their families, providing them with resources and support as they continue to serve the members, patients and customers who depend on us.

You can learn more about all we are doing to fight COVID-19 and support impacted communities: click here.


All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.


Colorado Residents Only: The salary range for Colorado residents is $64,800 to $116,000. Pay is based on several factors including but not limited to education, work experience, certifications, etc. As of the date of this posting, In addition to your salary, UHG offers the following benefits for this position, subject to applicable eligibility requirements: Health, dental, and vision plans; wellness program; flexible spending accounts; paid parking or public transportation costs; 401(k) retirement plan; employee stock purchase plan; life insurance, short-term disability insurance, and long-term disability insurance; business travel accident insurance; Employee Assistance Program; PTO; and employee-paid critical illness and accident insurance.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: UnitedHealth Group, Optum, Optum Analytics, data scientist, machine learning, predictive modeling, Python, data analytics, telecommute, remote, work from home, work at home, WFH, WAH, hiring immediately
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Energize your career with one of Healthcare’s fastest growing companies.<br><br>You dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it is a dream that definitely can come true. Already one of the world’s leading Healthcare companies, UnitedHealth Group is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.<br><br>This opportunity is with one of our most exciting business areas: Optum – a growing part of our family of companies that make UnitedHealth Group a Fortune 6 leader.<br><br>Optum Analytics solutions create a longitudinal view of both individual patients and patient populations. We gather, normalize, and analyze data from disparate sources that, uniquely, span the continuum of care--including EHRs, Practice Management Systems and claims. Our EHR data alone accounts for over 80M patient lives across the U.S.<br><br>You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.<br><br><strong><u>Primary Responsibilities<br></u></strong><ul> <li>We are looking for a data scientist who is eager to tackle the challenges of extracting insights from vast amounts of EHR data originating from multiple sources</li> <li>You will work with a diverse set of Optum researchers, clinicians, internal and external clients to define the projects and see them through to completion that cover a range of clinical focus</li> <li>You would be participating in the development of our end-to-end NLP pipeline, building descriptive and predictive analytics and producing research validations</li> <li>Specifically, as a member of our collaborative team you will be working with structured and unstructured data to explore the data, develop models, and performing research analytics</li> <li>You will have the opportunity to work with open-source distributed data processing frameworks, such as Apache Spark and build scalable machine learning applications and deploy them in production</li> <li>The right candidate will have strong prioritization skills, ability to manage ad hoc requests in parallel with ongoing projects</li> <br></ul>If you have the experience, curiosity and entrepreneurial spirit to tackle these challenges, we want to talk to you.<br><br>You'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.<br><br><strong><u>Required Qualifications<br></u></strong><ul> <li>Bachelor’s degree in Science, Technology, Engineering, Math, or Linguistics or equivalent degree area</li> <li>3+ years of experience as a hands-on data scientist, non-managerial role and executing on data science, analytics, or programming projects (1 year of academic projects maybe considered to equal 3+ years-projects need to be clearly outlined in the resume)</li> <li>2+ years of experience in machine learning, predictive modeling, or natural language processing </li> <li>2+ years of experience in Python</li> <li>Experience with leveraging best practices conducting advanced analytics projects</li> <li>If you need to enter a work site for any reason, you will be required to screen for symptoms using the ProtectWell mobile app, Interactive Voice Response (i.e., entering your symptoms via phone system) or a similar UnitedHealth Group-approved symptom screener. When in a UnitedHealth Group building, employees are required to wear a mask in common areas. In addition, employees must comply with any state and local masking orders.</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Experience with Pandas, Scikit-learn, TensorFlow, or spaCy</li> <li>Experience with open-source distributed data processing frameworks, such as Spark</li> <li>Experience in Biostatistics or related field</li> <li>Experience with SQL or relational databases</li> <li>Familiarity with EHR data and standards</li> <br></ul>UnitedHealth Group is an essential business. The health and safety of our team members is our highest priority, so we are taking a science driven approach to slowly welcome and transition some of our workforce back to the office with many safety protocols in place. We continue to monitor and assess before we confirm the return of each wave, paying specific attention to geography-specific trends. At this time, 90% of our non-clinical workforce transitioned to a work at home (remote) status. We have taken steps to ensure the safety of our 325,000 team members and their families, providing them with resources and support as they continue to serve the members, patients and customers who depend on us.<br><br>You can learn more about all we are doing to fight COVID-19 and support impacted communities: click here.<br><br><li>All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.<br><br></li><strong>Colorado Residents Only: </strong>The salary range for Colorado residents is $64,800 to $116,000. Pay is based on several factors including but not limited to education, work experience, certifications, etc. As of the date of this posting, In addition to your salary, UHG offers the following benefits for this position, subject to applicable eligibility requirements: Health, dental, and vision plans; wellness program; flexible spending accounts; paid parking or public transportation costs; 401(k) retirement plan; employee stock purchase plan; life insurance, short-term disability insurance, and long-term disability insurance; business travel accident insurance; Employee Assistance Program; PTO; and employee-paid critical illness and accident insurance.<br><br><em>Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.<br><br></em><em>UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.<br><br></em>Job Keywords: UnitedHealth Group, Optum, Optum Analytics, data scientist, machine learning, predictive modeling, Python, data analytics, telecommute, remote, work from home, work at home, WFH, WAH, hiring immediately</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Hospital & Health Care
Entry Level Data Engineer Analyst / Python Developer,"Houston, Texas, United States",Enhance IT,2021-02-03,https://www.linkedin.com/jobs/view/entry-level-data-engineer-analyst-python-developer-at-enhance-it-2409737327?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=sv0rgs5hREYgfhdhDTxxsA%3D%3D&position=14&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Are you looking for a friendly, fast-paced workplace with an emphasis on helping customers and empowering team members? Snap Finance is a thriving leader in the financial services industry, and our team members are the foundation of our success. Snap knows that happy, empowered, and engaged team members are essential to innovation and business success- and our approach is working. Come join us!

Become part of an amazing Analytics team at Snap! We are looking for a Data Engineer to help us design and maintain scalable, secure, and reliable data solutions across our operational and analytics systems. This will involve building pipelines to integrate data sources using a variety of languages and tools. The ideal candidate is eager to learn and driven toward finding excellent solutions to complex problems. The Data Engineer will support our developers, data scientists, business intelligence analysts, and machine learning engineers in ensuring consistent, accurate data delivery.

The Job…


Work with stakeholders to assist with data-related technical issues and support their data needs
Apply security best practices to ensure that data is appropriately protected.
Create tools for monitoring data quality and generating alerts.
Identify, design, and implement internal process improvements: automating manual processes, re-designing infrastructure for greater scalability, etc.


You…


Bachelor's degree, or higher, in Computer Science or other STEM field
2+ years of relevant experience (internship experience is OK)
SQL and relational databases such as PostgreSQL
Programming using Python, Java, and/or Scala
Source control systems: git, GitHub
Working with unstructured or semi-structured dataset
Strong analytical and problem-solving skills
Top-notch communication
Team-oriented but able to complete tasks independently at a high standard
Structured, organized, and detail-oriented
Proactive, enthusiastic, and flexible
Fluency in English, both in oral and written form
Ability to take projects from conceptualization to implementation
Must be able to work onsite in our Salt Lake City office and be legal to work in the United States


  Preferred Skills (3+ of the following):


Streaming data systems such as Kafka or Kinesis
Distributed processing using tools such as Spark and Flink
Message queuing systems such as RabbitMQ
Distributed database and caching systems such as Citus, CockroachDB, Redis, memcached, Alluxio
Column-oriented data formats such as Parquet, ORC
Automated workflows and CI/CD tools: Airflow, Argo, Jenkins, etc.
Container-based deployments using Docker and Kubernetes
Amazon Web Services: S3, EC2, ECR, ELB, RDS, DynamoDB, etc.
Declarative infrastructure using tools such as Terraform


Why You'll Love It Here…


Generous paid time off
Competitive medical, dental & vision coverage
401K with company match
Company-paid life insurance
Company-paid short-term and long-term disability
Legal coverage and other supplemental options
Pet insurance, free snacks, and fun events
A value-based culture where growth opportunities are endless


 

More…

Snap values diversity, and all qualified applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Learn more by visiting our website at www.snapfinance.com
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Are you looking for a friendly, fast-paced workplace with an emphasis on helping customers and empowering team members? Snap Finance is a thriving leader in the financial services industry, and our team members are the foundation of our success. Snap knows that happy, empowered, and engaged team members are essential to innovation and business success- and our approach is working. Come join us!<br><br>Become part of an amazing Analytics team at Snap! We are looking for a Data Engineer to help us design and maintain scalable, secure, and reliable data solutions across our operational and analytics systems. This will involve building pipelines to integrate data sources using a variety of languages and tools. The ideal candidate is eager to learn and driven toward finding excellent solutions to complex problems. The Data Engineer will support our developers, data scientists, business intelligence analysts, and machine learning engineers in ensuring consistent, accurate data delivery.<br><br><strong>The Job…<br><br></strong><ul> <li>Work with stakeholders to assist with data-related technical issues and support their data needs </li> <li>Apply security best practices to ensure that data is appropriately protected. </li> <li>Create tools for monitoring data quality and generating alerts. </li> <li>Identify, design, and implement internal process improvements: automating manual processes, re-designing infrastructure for greater scalability, etc. </li> <br></ul><strong>You…<br><br></strong><ul> <li>Bachelor's degree, or higher, in Computer Science or other STEM field </li> <li>2+ years of relevant experience (internship experience is OK) </li> <li>SQL and relational databases such as PostgreSQL </li> <li>Programming using Python, Java, and/or Scala</li> <li>Source control systems: git, GitHub</li> <li>Working with unstructured or semi-structured dataset</li> <li>Strong analytical and problem-solving skills </li> <li>Top-notch communication </li> <li>Team-oriented but able to complete tasks independently at a high standard </li> <li>Structured, organized, and detail-oriented </li> <li>Proactive, enthusiastic, and flexible </li> <li>Fluency in English, both in oral and written form </li> <li>Ability to take projects from conceptualization to implementation </li> <li>Must be able to work onsite in our Salt Lake City office and be legal to work in the United States </li> <br></ul>  <strong>Preferred Skills (3+ of the following):<br><br></strong><ul> <li>Streaming data systems such as Kafka or Kinesis</li> <li>Distributed processing using tools such as Spark and Flink </li> <li>Message queuing systems such as RabbitMQ </li> <li>Distributed database and caching systems such as Citus, CockroachDB, Redis, memcached, Alluxio </li> <li>Column-oriented data formats such as Parquet, ORC </li> <li>Automated workflows and CI/CD tools: Airflow, Argo, Jenkins, etc.</li> <li>Container-based deployments using Docker and Kubernetes </li> <li>Amazon Web Services: S3, EC2, ECR, ELB, RDS, DynamoDB, etc. </li> <li>Declarative infrastructure using tools such as Terraform </li> <br></ul><strong>Why </strong><strong>You'll</strong><strong> Love It Here…<br><br></strong><ul> <li>Generous paid time off </li> <li>Competitive medical, dental &amp; vision coverage </li> <li>401K with company match </li> <li>Company-paid life insurance </li> <li>Company-paid short-term and long-term disability </li> <li>Legal coverage and other supplemental options </li> <li>Pet insurance, free snacks, and fun events </li> <li>A value-based culture where growth opportunities are endless </li> <br></ul> <br><br><strong>More…<br><br></strong>Snap values diversity, and all qualified applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.<br><br>Learn more by visiting our website at www.snapfinance.com</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Financial Services"
Software Engineer: Python,"Chicago, Illinois, United States",Sav.com,2021-02-14,https://www.linkedin.com/jobs/view/software-engineer-python-at-sav-com-2393311655?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=H6iton5sLZbDnKvKftWBJA%3D%3D&position=15&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Who We Are

Enhance IT is an IT/Management firm that specializes in training, placement and IT consultation. We are an industry leader in providing top-level skilled and experienced consultants in a variety of technologies to meet our client’s needs in today’s fast paced environment.

What You Will Be Doing

You will be joining our ever-expanding data scientist team as it grows to meet the needs of the market. We want individuals who think “outside the box” and are comfortable asking “why?” The ideal candidate for this role is highly analytical with a knack for analysis, math and statistics. They are a team player possessing critical thinking and problem-solving skills with a passion for machine-learning and research. They need to possess the technical skills to explain the “how” and “what” behind technical decisions to non-tech stakeholders.

What You Need For This Position

Master's degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant.
Strong Proficiency in Python or Java programming language, or expertise with functional/object-oriented programming.
Ability to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful execution.
Ability to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non-technical audiences.
Availability to travel and live in the U.S.

Bonus Points

Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environment.
Experience in machine learning, artificial intelligence and/or artificial neural networks.
Proficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysis.
Broad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive).
Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI).
Experience delivering solutions in an Agile environment.
Experience with Tensorflow, Theano or Keras.
Portfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)
Publications in peer-reviewed journals.
Other programming languages such as Scala, Java, R
Benefits & Perks
Full benefits including Medical/Dental/Vision
Paid travel to and from the Atlanta HQ
Paid Time Off
401(k) savings plan
12-week training in Atlanta, GA prior to going on live projects
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Who We Are<br><br></u></strong>Enhance IT is an IT/Management firm that specializes in training, placement and IT consultation. We are an industry leader in providing top-level skilled and experienced consultants in a variety of technologies to meet our client’s needs in today’s fast paced environment.<br><br><strong><u>What You Will Be Doing<br><br></u></strong>You will be joining our ever-expanding data scientist team as it grows to meet the needs of the market. We want individuals who think “outside the box” and are comfortable asking “why?” The ideal candidate for this role is highly analytical with a knack for analysis, math and statistics. They are a team player possessing critical thinking and problem-solving skills with a passion for machine-learning and research. They need to possess the technical skills to explain the “how” and “what” behind technical decisions to non-tech stakeholders.<br><br><strong><u>What You Need For This Position<br><br></u></strong>Master's degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant.<br>Strong Proficiency in Python or Java programming language, or expertise with functional/object-oriented programming.<br>Ability to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful execution.<br>Ability to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non-technical audiences.<br>Availability to travel and live in the U.S.<br><br><strong><u>Bonus Points<br><br></u></strong>Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environment.<br>Experience in machine learning, artificial intelligence and/or artificial neural networks.<br>Proficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysis.<br>Broad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive).<br>Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI).<br>Experience delivering solutions in an Agile environment.<br>Experience with Tensorflow, Theano or Keras.<br>Portfolio of public &amp; private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)<br>Publications in peer-reviewed journals.<br>Other programming languages such as Scala, Java, R<br>Benefits &amp; Perks<br>Full benefits including Medical/Dental/Vision<br>Paid travel to and from the Atlanta HQ<br>Paid Time Off<br>401(k) savings plan<br>12-week training in Atlanta, GA prior to going on live projects</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Research"
Data Scientist,"Atlanta, Georgia, United States",Georgia-Pacific LLC,2021-02-16,https://www.linkedin.com/jobs/view/data-scientist-at-georgia-pacific-llc-2408031119?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=YhaH0szIwhhhrhaZROmMsA%3D%3D&position=16&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Sav.com was founded in 2019 with a mission of empowering creators with digital identities designed in seconds. Our core business, an ICANN accredited domain registrar, is quickly growing so we are looking to expand our small engineering team. You will work in multiple languages, own your projects, make your own technical decisions and use brand new technologies like AI and serverless applications.




Requirements:

Solid understanding of Python and experience using it to architect web applications.
Understanding of MySQL query design/optimization and database normalization.
Ability to accurately estimate and meet project timelines.
Ability to work with minimal direction and oversight on multiple projects with efficient timelines.
Work from our office in Chicago.




Nice to Have:

Proficiency in container technologies like Docker.
Basic understanding of container orchestration systems preferably Kubernetes.
AWS Lambda, Step Functions and SQS.




Benefits:

Casual Office Environment
Health, Vision & Dental
Paid Time Off & Company Holidays
401K with Employer Match
And Many More




While it's appreciated for people from around the country to apply, we prefer candidates located in the Chicago area

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Sav.com was founded in 2019 with a mission of empowering creators with digital identities designed in seconds. Our core business, an ICANN accredited domain registrar, is quickly growing so we are looking to expand our small engineering team. You will work in multiple languages, own your projects, make your own technical decisions and use brand new technologies like AI and serverless applications.</p><p><br></p><p>Requirements:</p><ul><li>Solid understanding of Python and experience using it to architect web applications.</li><li>Understanding of MySQL query design/optimization and database normalization.</li><li>Ability to accurately estimate and meet project timelines.</li><li>Ability to work with minimal direction and oversight on multiple projects with efficient timelines.</li><li>Work from our office in Chicago.</li></ul><p><br></p><p>Nice to Have:</p><ul><li>Proficiency in container technologies like Docker.</li><li>Basic understanding of container orchestration systems preferably Kubernetes.</li><li>AWS Lambda, Step Functions and SQS.</li></ul><p><br></p><p>Benefits:</p><ul><li>Casual Office Environment</li><li>Health, Vision &amp; Dental</li><li>Paid Time Off &amp; Company Holidays</li><li>401K with Employer Match</li><li>And Many More</li></ul><p><br></p><p>While it's appreciated for people from around the country to apply, we prefer candidates located in the Chicago area</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Internet
Data Engineer,"Hartford, Connecticut, United States",The Hartford,2021-01-21,https://www.linkedin.com/jobs/view/data-engineer-at-the-hartford-2419005342?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=%2FMO%2FRVgYwDGzSb5YC%2Fr0oA%3D%3D&position=17&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Description

You know us already! We make Brawny® paper towels; Dixie® paper cups and plates; Angel Soft® bath tissue; enMotion® paper towel dispensers, DensGlass® gypsum board and Plytanium® plywood you see in your big box home improvement stores and much more! We employ about 35,000 people who want to make a positive difference in today’s world by creating real long-term value for our customers.

We have an opportunity on the Data Science team at Georgia-Pacific’s Collaboration & Support Center, located in Tech Square Labs in Atlanta, GA. We are looking for an experienced Data Scientist to join a team of Data Scientists and Associate Data Scientists, to focus on providing support and solutions to our manufacturing operations. Working closely with business partners and engineers, the Data Scientists support operations through development and deployment of useful and scalable statistical, machine learning, and deep learning models that make our facilities safe, efficient, and optimal.

What You Will Do In Your Role

Analytics Project Ownership: Own all aspects of analytics projects from start to finish – pursuing innovative ideas, developing models, uncovering and communicating actionable insights, and implementing solutions to capture value.
Works with various engineering teams, owns end-to-end solution development and scaling focused on Operations (manufacturing) challenges.
Partnership: Develop and maintain relationships with key business partners to enable improved decision making.
Focus needs to remain on building minimum viable product towards solving majority of the issue instead of “perfecting” the solution, unless critical to safety.
Ability to operate independently and self-manage


The Experience You Will Bring

Requirements

Bachelor’s Degree or higher in a field related to data science such as Mathematics, Statistics, Computer Science, Engineering, Data Science, or Business Analytics.
2 or more years of experience creatively applying machine learning, outside of academic datasets, using a formal programming language (Python, R, SAS).
2 or more years of technical and analytical problem-solving experience
Experience working with SAS Code for the purpose of statistics or machine learning
Experience with analyzing time series. Must be able to clean, manipulate, analyze, and model time series data in both SAS and open-source technologies
Experience in data science that encompass having multiple models deployed to production with successful outcomes for users
Experience manipulating data, computing, memory, optimization; experience with cloud computing (AWS)
Experience working with unsupervised and supervised machine learning
Experience working with large data sets (>50 GB)


What Will Put You Ahead

Master's Degree or higher in a field related to data science such as Mathematics, Statistics, Computer Science, Engineering, Data Science, or Business Analytics.
Experience with SAS Event Stream Processing
Experience working with loT
Experience working with Manufacturing Operations
Experience with PySpark and Kinesis
Experience architecting high performance data pipelines
Experience mentoring associate / junior data scientists (previous leadership experience)


Salary And Benefits Commensurate With Experience.

Equal Opportunity Employer.
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>You know us already! We make Brawny® paper towels; Dixie® paper cups and plates; Angel Soft® bath tissue; enMotion® paper towel dispensers, DensGlass® gypsum board and Plytanium® plywood you see in your big box home improvement stores and much more! We employ about 35,000 people who want to make a positive difference in today’s world by creating real long-term value for our customers.<br><br>We have an opportunity on the Data Science team at Georgia-Pacific’s Collaboration &amp; Support Center, located in Tech Square Labs in Atlanta, GA. We are looking for an experienced Data Scientist to join a team of Data Scientists and Associate Data Scientists, to focus on providing support and solutions to our manufacturing operations. Working closely with business partners and engineers, the Data Scientists support operations through development and deployment of useful and scalable statistical, machine learning, and deep learning models that make our facilities safe, efficient, and optimal.<br><br>What You Will Do In Your Role<br><ul><li>Analytics Project Ownership: Own all aspects of analytics projects from start to finish – pursuing innovative ideas, developing models, uncovering and communicating actionable insights, and implementing solutions to capture value. </li><li>Works with various engineering teams, owns end-to-end solution development and scaling focused on Operations (manufacturing) challenges.</li><li>Partnership: Develop and maintain relationships with key business partners to enable improved decision making.</li><li>Focus needs to remain on building minimum viable product towards solving majority of the issue instead of “perfecting” the solution, unless critical to safety. </li><li>Ability to operate independently and self-manage <br><br></li></ul>The Experience You Will Bring<br><br><strong><u>Requirements<br></u></strong><ul><li>Bachelor’s Degree or higher in a field related to data science such as Mathematics, Statistics, Computer Science, Engineering, Data Science, or Business Analytics.</li><li>2 or more years of experience creatively applying machine learning, outside of academic datasets, using a formal programming language (Python, R, SAS).</li><li>2 or more years of technical and analytical problem-solving experience</li><li>Experience working with SAS Code for the purpose of statistics or machine learning</li><li>Experience with analyzing time series. Must be able to clean, manipulate, analyze, and model time series data in both SAS and open-source technologies</li><li>Experience in data science that encompass having multiple models deployed to production with successful outcomes for users</li><li>Experience manipulating data, computing, memory, optimization; experience with cloud computing (AWS)</li><li>Experience working with unsupervised and supervised machine learning</li><li>Experience working with large data sets (&gt;50 GB)<br><br></li></ul>What Will Put You Ahead<br><ul><li>Master's Degree or higher in a field related to data science such as Mathematics, Statistics, Computer Science, Engineering, Data Science, or Business Analytics.</li><li>Experience with SAS Event Stream Processing</li><li>Experience working with loT</li><li>Experience working with Manufacturing Operations</li><li>Experience with PySpark and Kinesis</li><li>Experience architecting high performance data pipelines </li><li>Experience mentoring associate / junior data scientists (previous leadership experience)<br><br></li></ul><strong><u>Salary And Benefits Commensurate With Experience.<br><br></u></strong>Equal Opportunity Employer.<br>Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.<br><br>This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Engineering",Full-time,"Construction, Consumer Goods, Financial Services"
"Software Engineer, Data","Remote, Oregon, United States",Knock,2021-02-01,https://www.linkedin.com/jobs/view/software-engineer-data-at-knock-2414733891?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=P4TYohlYB3jTRB1w1SEZuw%3D%3D&position=18&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile team in The Hartford’s Enterprise Data Organization to unlock Data Capabilities for our Group Benefits business. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous data delivery, while growing your knowledge with emerging technologies. We use the latest data technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation.

This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.

What’s in it for you?

Experience deeper understanding of Data analytics, Emerging technologies and Development practices
Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholders engagement
Opportunity to expand your communication, analytical, interpersonal, and organization capabilities
Experience working in a fast paced environment – driving business outcomes in Agile ways of working
Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives
Enhance your entrepreneurial mindset – network opportunity and influencing outcomes
Hone your development skills using various tools such as Talend, Snowflake, Informatica, B2B, PL/SQL, Hadoop, etc. to build data assets that enable business value generation
Appreciation and opportunity to learn and support rapid software construction and deployment using DevOps and Cloud based future technologies
Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance
Optimize business value by leveraging your DATA experience and depth
Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes
Act as a resource for colleagues with less experience


Qualifications

Must be authorized to work in the U.S. without company sponsorship .
Bachelor’s degree (or foreign equivalent) in Computer Science, Computer Engineering or a related field.
At least 2 years' experience in data engineering, big data, analytics and operations concepts: SQL, ETL, performance tuning, production engineering, job scheduling, continuous deployment and operations support
Experience with ETL tools like Talend or Informatica
Minimal knowledge on programming languages such as Python, Java, Spark; version control tools like GitHub.
Preferred experience with Cloud technologies such as AWS, Snowflake, Dremio
Preferred experience in PL/SQL and use of databases such as Oracle and SQL Server;
Experience in Agile development methodologies with a preference of Scrum and/or SAFe a strong preference.
Experience with end-to-end Data Warehousing architecture and concepts and ETL best practices
Delivery experience including full lifecycle from conception to successful implementation.
Experience with Insurance domain

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age
Data Engineer - GE08AE
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day &amp; not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.<br><br>Join a fast-paced and talented Agile team in The Hartford’s Enterprise Data Organization to unlock Data Capabilities for our Group Benefits business. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous data delivery, while growing your knowledge with emerging technologies. We use the latest data technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation.<br><br>This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.<br><br>What’s in it for you?<br><ul><li> Experience deeper understanding of Data analytics, Emerging technologies and Development practices </li><li> Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholders engagement </li><li> Opportunity to expand your communication, analytical, interpersonal, and organization capabilities </li><li> Experience working in a fast paced environment – driving business outcomes in Agile ways of working </li><li> Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives </li><li> Enhance your entrepreneurial mindset – network opportunity and influencing outcomes </li><li> Hone your development skills using various tools such as Talend, Snowflake, Informatica, B2B, PL/SQL, Hadoop, etc. to build data assets that enable business value generation </li><li> Appreciation and opportunity to learn and support rapid software construction and deployment using DevOps and Cloud based future technologies </li><li> Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance </li><li> Optimize business value by leveraging your DATA experience and depth </li><li> Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes </li><li> Act as a resource for colleagues with less experience <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> Must be authorized to work in the U.S. without company sponsorship .</li><li> Bachelor’s degree (or foreign equivalent) in Computer Science, Computer Engineering or a related field. </li><li> At least 2 years' experience in data engineering, big data, analytics and operations concepts: SQL, ETL, performance tuning, production engineering, job scheduling, continuous deployment and operations support </li><li> Experience with ETL tools like Talend or Informatica </li><li> Minimal knowledge on programming languages such as Python, Java, Spark; version control tools like GitHub. </li><li> Preferred experience with Cloud technologies such as AWS, Snowflake, Dremio </li><li> Preferred experience in PL/SQL and use of databases such as Oracle and SQL Server; </li><li> Experience in Agile development methodologies with a preference of Scrum and/or SAFe a strong preference. </li><li> Experience with end-to-end Data Warehousing architecture and concepts and ETL best practices </li><li> Delivery experience including full lifecycle from conception to successful implementation. </li><li> Experience with Insurance domain <br></li></ul>Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age<br>Data Engineer - GE08AE</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Insurance, Financial Services"
Data Engineer,"Ithaca, New York, United States",Cornell University,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-at-cornell-university-2397928252?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=HyfWW%2BAO5denw4%2BOINz%2FhQ%3D%3D&position=19&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Knock is on a mission to empower people to move freely. The Knock Home Swap™ makes it easy for consumers to buy their new home before selling their old one, skipping the hassles of living through repairs and showings, paying only one mortgage at a time, and having home prep covered upfront so their old house sells for the highest possible price. Knock currently offers the Home Swap in 17 markets in six states and plans to expand to at least 21 markets by mid-2021.

Launched in 2015 by founding team members of Trulia.com , Knock has raised more than $600 million in debt and equity from top tier investors, including RRE Ventures, Foundry Group, Redpoint, Greycroft, Corazon Capital, Correlation Ventures, Great Oaks Venture Capital and FJ Labs.

We are seeking a Software Engineer, Data to help Knock build a comprehensive data platform that offers a diverse property database to internal and external users. This person will be excited to dive into the onboarding of new data, while data analysis is your key strength.

We are looking for someone who is passionate about creating great products to help millions of people buy or sell a home without risk, stress, and uncertainty. This is a unique opportunity to work on both data engineering and software development.

At Knock, we have fun, we move fast, we celebrate & support our fellow teammates, and we live by our POPSICLE values.

As a Software Engineer, Data you will:

Build data pipelines and aggregate data.
Design data schemas and optimize internal data warehouses, augmenting data from multiple sources.
Design, build, and maintain REST APIs to serve data to customers
Cross-functionally collaborate with our Data Science and Machine Learning teams.
Understand the data that powers our applications, and be able to propose appropriate data models for new features.
Build new ETL jobs from scratch, as well as maintain existing jobs.
Be committed to good engineering practice of testing, logging, alerting and deployment processes.
Monitor and troubleshoot operational or data issues in the data pipelines.
Drive architectural plans and implementation for future data storage, reporting, and analytic solutions.


We’re looking for Knockstars who:

Have experience building data pipelines and utilizing programming tools to do so. Here Knock we use Apache Spark, Scala, Rust, Go, Python, and Rest APIs - but you can learn these technologies on the job
You should be versed in developing APIs to serve data produced by ETL jobs
You have a desire to work at a rapidly growing startup and make it a success, and are comfortable learning new technologies and tools
Your experience in SQL, MySQL, or Postgres will be valuable here to identify slow queries and debugging
All of our teams have a strong customer-first mindset and data-driven approach to our work, and that should be your approach as well
Believe in creating diverse, equitable, and inclusive practices and programs that will further Knock’s commitment to making an impact, learning, putting people first, being open, and courageous.
Have proven success working 100% remote in prior positions & are experienced working with a distributed, national team.
We encourage you to apply even if you don’t have every listed requirement.


What We can Offer You:

Equitable compensation offered based on your accomplishments, experience, and what market data shows in your geographic region.
Offering full medical, dental, vision benefits, flexible work schedules, unlimited vacation (2 weeks mandatory), 401k, paid parental leave, and many amazing benefits to impact our people’s lives.
Flexibility to live and work anywhere within the continental United States.
This is a 100% remote, work from home, full-time career at Knock.


We are proud to be a distributed company from our founding with employees in 28 states and counting. This is an amazing opportunity to be an integral part of building a multi-billion dollar consumer brand in an industry that is long overdue for a new way of doing things. You will be working with a passionate team that is disrupting the status quo.

Knock, and its subsidiaries, are committed to creating a diverse, inclusive, and equitable environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Please no recruitment firm or agency inquiries, you will not receive a reply from us.

This position is in the continental United States.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><em>Knock is on a mission to empower people to move freely. The Knock Home Swap™ makes it easy for consumers to buy their new home before selling their old one, skipping the hassles of living through repairs and showings, paying only one mortgage at a time, and having home prep covered upfront so their old house sells for the highest possible price. Knock currently offers the Home Swap in 17 markets in six states and plans to expand to at least 21 markets by mid-2021. <br><br></em><em>Launched in 2015 by founding team members of </em> <em>Trulia.com</em> <em>, Knock has raised more than $600 million in debt and equity from top tier investors, including RRE Ventures, Foundry Group, Redpoint, Greycroft, Corazon Capital, Correlation Ventures, Great Oaks Venture Capital and FJ Labs.<br><br></em>We are seeking a Software Engineer, Data to help Knock build a comprehensive data platform that offers a diverse property database to internal and external users. This person will be excited to dive into the onboarding of new data, while data analysis is your key strength.<br><br>We are looking for someone who is passionate about creating great products to help millions of people buy or sell a home without risk, stress, and uncertainty. This is a unique opportunity to work on both data engineering and software development.<br><br>At Knock, we have fun, we move fast, we celebrate &amp; support our fellow teammates, and we live by our POPSICLE values.<br><br><strong>As a Software Engineer, Data you will: <br></strong><ul><ul><li>Build data pipelines and aggregate data.</li><li>Design data schemas and optimize internal data warehouses, augmenting data from multiple sources.</li><li>Design, build, and maintain REST APIs to serve data to customers</li><li>Cross-functionally collaborate with our Data Science and Machine Learning teams. </li><li>Understand the data that powers our applications, and be able to propose appropriate data models for new features.</li><li>Build new ETL jobs from scratch, as well as maintain existing jobs.</li><li>Be committed to good engineering practice of testing, logging, alerting and deployment processes.</li><li>Monitor and troubleshoot operational or data issues in the data pipelines.</li><li>Drive architectural plans and implementation for future data storage, reporting, and analytic solutions.<br><br></li></ul></ul><strong>We’re looking for Knockstars who: <br></strong><ul><ul><li>Have experience building data pipelines and utilizing programming tools to do so. Here Knock we use Apache Spark, Scala, Rust, Go, Python, and Rest APIs - but you can learn these technologies on the job</li><li>You should be versed in developing APIs to serve data produced by ETL jobs</li><li>You have a desire to work at a rapidly growing startup and make it a success, and are comfortable learning new technologies and tools</li><li>Your experience in SQL, MySQL, or Postgres will be valuable here to identify slow queries and debugging</li><li>All of our teams have a strong customer-first mindset and data-driven approach to our work, and that should be your approach as well </li><li>Believe in creating diverse, equitable, and inclusive practices and programs that will further Knock’s commitment to making an impact, learning, putting people first, being open, and courageous.</li><li>Have proven success working 100% remote in prior positions &amp; are experienced working with a distributed, national team. </li><li>We encourage you to apply even if you don’t have every listed requirement. <br><br></li></ul></ul><strong>What We can Offer You:<br></strong><ul><ul><li>Equitable compensation offered based on your accomplishments, experience, and what market data shows in your geographic region.</li><li>Offering full medical, dental, vision benefits, flexible work schedules, unlimited vacation (2 weeks mandatory), 401k, paid parental leave, and many amazing benefits to impact our people’s lives. </li><li>Flexibility to live and work anywhere within the continental United States. </li><li>This is a 100% remote, work from home, full-time career at Knock.<br><br></li></ul></ul>We are proud to be a distributed company from our founding with employees in 28 states and counting. This is an amazing opportunity to be an integral part of building a multi-billion dollar consumer brand in an industry that is long overdue for a new way of doing things. You will be working with a passionate team that is disrupting the status quo.<br><br>Knock, and its subsidiaries, are committed to creating a diverse, inclusive, and equitable environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.<br><br><strong>Please no recruitment firm or agency inquiries, you will not receive a reply from us.<br><br></strong><strong>This position is in the continental United States.</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Real Estate
Data Engineer,"New York, New York, United States",Dashlane,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-at-dashlane-2391426914?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=Y5A%2FDsjet7is2dZUzqe4YA%3D%3D&position=20&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Data Engineer

Ithaca (Main Campus)
As a member of Cornell Information Technologies’ Data Warehousing and Integrations team, theData Engineer is part of a sub-team who develops robust, reliable, and standardized data solutions in support of data analytic needs across campus. This is an area of rapid change where candidate would be expected to be able to learn and apply new technical skills on an ongoing basis. The Data Engineer is a member of the team who develop and support Cornell’s data warehousing and data lake echo system. The Data Engineer will work daily with customers and colleagues to develop and support a vast data environment.

VISA sponsorship is not available for this position.

Primary Responsibilities Include

Work collaboratively with customers and IT team members to develop new data lake/data warehouse content that is enterprise grade and supportable.
Proactively support the many data feeds, transformations, and updates which make up Cornell’ DL/DW echo system.
Act as a DL/DW liaison, and subject matter expert, to project teams requesting DL/DW resources.
Research and conduct impact analysis of changing schema and data model requirements.
Develop and maintain documentation and standard operating procedures.
Support the migration of ETL code and database objects.
Learn new tools and environments quickly as the data analytics space evolves.
Participate in the 24X7 DL/DW On Call support rotation.



The Person

Cornell University seeks an IT professional who has a strong desire to become highly proficient in a new and rapidly evolving technical space, and enjoys and has demonstrated successful experience in a rapidly changing, continual learning IT/Business environment with a demonstrated proficiency developing technical skills and performing problem solving.

The Data Engineer will have the following experiences, capabilities, and attributes:

Bachelor's degree with a minimum of three to five years of related experience, with a focus on SQL (DDL and DML)
Development experience within a Relational Database such as: Postgres, Oracle, MS SQL Developer. Proven experience developing data transformation solutions in one or more programing languages
One to two years of related experience in at least 2 of the following: data analysis, data lake/data warehouse design/construction, or report/dashboard development
Strong development skills (e.g. ability to quickly learn specific functional need and effectively and efficiently apply solutions to desired outcome)
Demonstration of excellent technical, verbal and written communications skills and ability to multi-task within a team-oriented environment


If you have any of the following, it’s a great bonus:

Experience developing and supporting data transformations using an ETL product such as: Informatica, Data Stage, WhereScape, Talend, etc.
Experience with a database procedural language
Experience with Python
Understanding of dimensional data modeling concepts
Experience with cloud services, such as AWS (S3, Redshift, Glue, Athena, RDS, EMR)



What We Offer

Great benefits that include educational benefits, access to a plethora of wellness programs, employee discounts with local and national retail brands, health care options to choose from, generous paid leave provisions: 3 weeks of vacation, 12 university paid holidays (including end of year winter break through New Year’s Day) and superior retirement contributions.

An active and diverse community to work and thrive in! Cornell is situated in picturesque Ithaca, New York, the heart of the Finger Lakes. Ithaca is home to two academic institutions, state parks, waterfalls, gorges, and a wide range of art galleries, theaters, eateries, wineries, and breweries. Ithaca has something to suit all ages and interests!

No Visa sponsorship available for this position.

University Job Title

Business Intelligence Eng III

Level

F

Pay Rate Type

Salary

Company

Endowed

Contact Name

Cyndi Morris

Number Of Openings

1

Current Employees

If you currently work at Cornell University, please exit this website and log in to Workday using your Net ID and password. Select the Career icon on your Home dashboard to view jobs at Cornell.

Online Submission Guidelines

Most positions at Cornell will require you to apply online and submit both a resume/CV and cover letter. You can upload documents either by “dragging and dropping” them into the dropbox or by using the “upload” icon on the application page. For more detailed instructions on how to apply to a job at Cornell, visit How We Hire on the HR website.

Employment Assistance

If you require an accommodation for a disability in order to complete an employment application or to participate in the recruiting process, you are encouraged to contact Cornell University's Department of Inclusion and Workforce Diversity at voice (607) 255-3976, fax (607) 255-7481, or email at owdi@cornell.edu .

For general questions about the position or the application process, please contact the Recruiter listed in the job posting.

Applicants that do not have internet access are encouraged to visit your local library, or local Department of Labor. You may also visit the office of Workforce Recruitment and Retention Monday - Friday between the hours of 8:30 a.m. – 4:30 p.m. to use a dedicated workstation to complete an online application.

Notice To Applicants

Please read the required Notice to Applicants statement by clicking here . This notice contains important information about applying for a position at Cornell as well as some of your rights and responsibilities as an applicant.

EEO Statement

Diversity and Inclusion are a part of Cornell University’s heritage. We are a recognized employer and educator valuing AA/EEO, Protected Veterans and Individuals with Disabilities. We also recognize a lawful preference in employment practices for Native Americans living on or near Indian reservations. Cornell University is an innovative Ivy League university and a great place to work. Our inclusive community of scholars, students, and staff impart an uncommon sense of larger purpose, and contribute creative ideas to further the university's mission of teaching, discovery, and engagement.
2021-01-27-08:00

Posted 21 Days Ago Full time WDR-00024745
Cornell University is an innovative Ivy League university and a great place to work. Our inclusive community of scholars, students and staff impart an uncommon sense of larger purpose and contribute creative ideas to further the university's mission of teaching, discovery and engagement. With our main campus located in Ithaca, NY, Cornell's far-flung global presence includes the medical college's campuses on the Upper East Side of Manhattan and Doha, Qatar, as well as the Cornell Tech campus located on Roosevelt Island in the heart of New York City. We offer a rich array of services, programs and benefits to help employees advance in their career and enhance the quality of personal life, including employee wellness, workshops, childcare and adoption assistance, parental leave and flexible work options.

Statistical Consultant (Statistician II), Statistics and Data Science
Posted 30+ Days Ago
Ithaca (Main Campus)
Visual Analytics Developer
Posted Yesterday
Ithaca (Main Campus)
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Data Engineer<br><br></strong>Ithaca (Main Campus)<br>As a member of Cornell Information Technologies’ Data Warehousing and Integrations team, the<strong>Data Engineer</strong> is part of a sub-team who develops robust, reliable, and standardized data solutions in support of data analytic needs across campus. This is an area of rapid change where candidate would be expected to be able to learn and apply new technical skills on an ongoing basis. The Data Engineer is a member of the team who develop and support Cornell’s data warehousing and data lake echo system. The Data Engineer will work daily with customers and colleagues to develop and support a vast data environment.<br><br><u>VISA sponsorship is not available for this position.<br><br></u><strong><u>Primary Responsibilities Include<br></u></strong><ul> <li>Work collaboratively with customers and IT team members to develop new data lake/data warehouse content that is enterprise grade and supportable.</li> <li>Proactively support the many data feeds, transformations, and updates which make up Cornell’ DL/DW echo system.</li> <li>Act as a DL/DW liaison, and subject matter expert, to project teams requesting DL/DW resources.</li> <li>Research and conduct impact analysis of changing schema and data model requirements.</li> <li>Develop and maintain documentation and standard operating procedures.</li> <li>Support the migration of ETL code and database objects.</li> <li>Learn new tools and environments quickly as the data analytics space evolves.</li> <li>Participate in the 24X7 DL/DW On Call support rotation.</li> <br><br></ul><strong><u>The Person<br><br></u></strong>Cornell University seeks an IT professional who has a strong desire to become highly proficient in a new and rapidly evolving technical space, and enjoys and has demonstrated successful experience in a rapidly changing, continual learning IT/Business environment with a demonstrated proficiency developing technical skills and performing problem solving.<br><br>The Data Engineer will have the following experiences, capabilities, and attributes:<br><ul> <li>Bachelor's degree with a minimum of three to five years of related experience, with a focus on SQL (DDL and DML)</li> <li>Development experience within a Relational Database such as: Postgres, Oracle, MS SQL Developer. Proven experience developing data transformation solutions in one or more programing languages</li> <li>One to two years of related experience in at least 2 of the following: data analysis, data lake/data warehouse design/construction, or report/dashboard development</li> <li>Strong development skills (e.g. ability to quickly learn specific functional need and effectively and efficiently apply solutions to desired outcome)</li> <li>Demonstration of excellent technical, verbal and written communications skills and ability to multi-task within a team-oriented environment</li> <br></ul>If you have any of the following, it’s a great bonus:<br><ul> <li>Experience developing and supporting data transformations using an ETL product such as: Informatica, Data Stage, WhereScape, Talend, etc.</li> <li>Experience with a database procedural language</li> <li>Experience with Python</li> <li>Understanding of dimensional data modeling concepts</li> <li>Experience with cloud services, such as AWS (S3, Redshift, Glue, Athena, RDS, EMR)</li> <br><br></ul><strong><u>What We Offer<br><br></u></strong>Great benefits that include educational benefits, access to a plethora of wellness programs, employee discounts with local and national retail brands, health care options to choose from, generous paid leave provisions: 3 weeks of vacation, 12 university paid holidays (including end of year winter break through New Year’s Day) and superior retirement contributions.<br><br>An active and diverse community to work and thrive in! Cornell is situated in picturesque Ithaca, New York, the heart of the Finger Lakes. Ithaca is home to two academic institutions, state parks, waterfalls, gorges, and a wide range of art galleries, theaters, eateries, wineries, and breweries. Ithaca has something to suit all ages and interests!<br><br>No Visa sponsorship available for this position.<br><br><strong><u>University Job Title<br><br></u></strong>Business Intelligence Eng III<br><br><strong><u>Level<br><br></u></strong>F<br><br><strong><u>Pay Rate Type<br><br></u></strong>Salary<br><br><strong><u>Company<br><br></u></strong>Endowed<br><br><strong><u>Contact Name<br><br></u></strong>Cyndi Morris<br><br><strong><u>Number Of Openings<br><br></u></strong>1<br><br><strong><u>Current Employees<br><br></u></strong>If you currently work at Cornell University, please exit this website and log in to Workday using your Net ID and password. Select the Career icon on your <strong><u>Home</u></strong> dashboard to view jobs at Cornell.<br><br><strong><u>Online Submission Guidelines<br><br></u></strong>Most positions at Cornell will require you to apply online and submit both a resume/CV and cover letter. You can upload documents either by “dragging and dropping” them into the dropbox or by using the “upload” icon on the application page. For more detailed instructions on how to apply to a job at Cornell, visit How We Hire on the HR website.<br><br><strong><u>Employment Assistance<br><br></u></strong>If you require an accommodation for a disability in order to complete an employment application or to participate in the recruiting process, you are encouraged to contact Cornell University's Department of Inclusion and Workforce Diversity at voice (607) 255-3976, fax (607) 255-7481, or email at owdi@cornell.edu .<br><br>For general questions about the position or the application process, please contact the Recruiter listed in the job posting.<br><br>Applicants that do not have internet access are encouraged to visit your local library, or local Department of Labor. You may also visit the office of Workforce Recruitment and Retention Monday - Friday between the hours of 8:30 a.m. – 4:30 p.m. to use a dedicated workstation to complete an online application.<br><br><strong><u>Notice To Applicants<br><br></u></strong>Please read the required Notice to Applicants statement by <strong>clicking here</strong> . This notice contains important information about applying for a position at Cornell as well as some of your rights and responsibilities as an applicant.<br><br><strong><u>EEO Statement<br><br></u></strong>Diversity and Inclusion are a part of Cornell University’s heritage. We are a recognized employer and educator valuing AA/EEO, Protected Veterans and Individuals with Disabilities. We also recognize a lawful preference in employment practices for Native Americans living on or near Indian reservations. Cornell University is an innovative Ivy League university and a great place to work. Our inclusive community of scholars, students, and staff impart an uncommon sense of larger purpose, and contribute creative ideas to further the university's mission of teaching, discovery, and engagement.<br>2021-01-27-08:00<br><br>Posted 21 Days Ago Full time WDR-00024745<br><strong> Cornell University is an innovative Ivy League university and a great place to work. Our inclusive community of scholars, students and staff impart an uncommon sense of larger purpose and contribute creative ideas to further the university's mission of teaching, discovery and engagement. With our main campus located in Ithaca, NY, Cornell's far-flung global presence includes the medical college's campuses on the Upper East Side of Manhattan and Doha, Qatar, as well as the Cornell Tech campus located on Roosevelt Island in the heart of New York City. </strong> <strong><strong>We offer a rich array of services, programs and benefits to help employees advance in their career and enhance the quality of personal life, including employee wellness, workshops, childcare and adoption assistance, parental leave and flexible work options.<br></strong></strong><ul> <li>Statistical Consultant (Statistician II), Statistics and Data Science</li> </ul><ul> <li>Posted 30+ Days Ago</li> </ul><ul> <li>Ithaca (Main Campus)</li> </ul><ul> <li>Visual Analytics Developer</li> </ul><ul> <li>Posted Yesterday</li> </ul><ul> <li>Ithaca (Main Campus)</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Nonprofit Organization Management, Higher Education, Hospital & Health Care"
Analytics Engineer,"Atlanta, Georgia, United States",Cox Communications,2021-02-17,https://www.linkedin.com/jobs/view/analytics-engineer-at-cox-communications-2427211885?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=k%2BUxxw8ry9Tfb0U5n%2BYzug%3D%3D&position=21&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"We continue to hire passionate people to join our mission of fixing the UX of the internet. Due to the ongoing public health crisis, our interview and onboarding processes will remain fully remote until further notice. At times like this, we're even more committed to providing you support and flexibility while you interview and onboard for your new job.
Are you an engineer that enjoys using data to drive insight and promote transparency? Join Dashlane as a Data Engineer and take part in building data systems that influence key decisions for our company's growth.

About Dashlane

The internet has become integrated with nearly every part of our lives, from work to personal to play. Yet somehow, it’s not getting any easier or safer—especially not when it comes to protecting and accessing sensitive info in a secure way. Dashlane is an award-winning app that lets you access and share business and personal passwords anytime, anywhere.

Our business plans help organizations protect against data breaches and misuse through features like advanced user management , the ability to track security improvements over time , and a simple interface that employees will e njoy using . Our personal plans offer the same level of encryption and ease , so everyone can autofill their passwords, payments, and personal info with just a click . The Dashlane app works across every major operating system and browser — so every user can enjoy a simpler, safer internet.

Our team in Paris, New York, and Lisbon is united by our passion for improving the digital experience and the belief that with the right tools, we can help everyone simplify their online lives . Dashlane has empowered over 1 5 million users and 20,000 businesses in 180 countries to enjoy a faster, simpler, and more secure internet.

About The Role

Dashlane is looking for a talented Data Engineer to optimize our data to enable our company to scale in the coming years. Inside our Data Engineering team, you will be designing pipelines and warehouses to model data from multiple sources that will allow us to derive business insight. Using AWS and open-source technologies, such as Airflow and Spark, you will design and build our next-generation ETL pipelines and data models.

You will be based in New York.

At Dashlane You Will

Build data pipelines and python-based ETL tools for acquiring, processing, and delivering data
Develop data models and schemas in our data warehouse that enable performant, intuitive analysis
Handle the challenges that come with managing terabytes of data
Collaborate with business leaders and analysts to define key metrics and build reporting to monitor and understand company performance
Develop the server applications and APIs that are used by our Data Team



Requirements

You have 3+ years of experience as a data engineer, business intelligence analyst, or in a highly analytical role
You have 3+ years of experience with a scripting language (preferably Python) for data processing and analysis
You have experience designing SQL tables, choosing indexes, tuning queries, and optimizations ac ross different functional en vironments.
You have experience writing complex SQL queries and using a BI tool



We're Also Looking For

You have a passion for sharing the value of data and communicating insights to a broad audience with varying levels of technical expertise
You have experience with data lakes and designing and maintaining data solutions using Spark and AWS serverless services such as Kinesis, Lambda, or SQS
You have experience administrating, ingesting, and monitoring data in data warehouses such as Amazon Redshift or Microsoft SQL Server
You are a self-starter that can work in a fast-paced, distributed environment, as you will be collaborating with our Paris and Lisbon teams



Diversity, Equity, Inclusion And Belonging At Dashlane

As a truly international company - founded in Paris and split between Paris, New York, and Lisbon, Dashlane thrives off diverse perspectives. We value all aspects of diversity: gender identity, sexual orientation, ability, ethnic origin, social background, age, lifestyle, and more - and are committed to hiring a diverse community and fostering a culture where everyone is heard and belongs.

Your Interview Experience

To know what to expect once you’ve sent your application, read about how we interview and hire at Dashlane in this blog article written by our Talent team. Feel free to browse our blog to find more information about our product and how we work.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><strong>We continue to hire passionate people to join our mission of fixing the UX of the internet. Due to the ongoing public health crisis, our interview and onboarding processes will remain fully remote until further notice. At times like this, we're even more committed to providing you support and flexibility while you interview and onboard for your new job. <br></strong></strong>Are you an engineer that enjoys using data to drive insight and promote transparency? Join Dashlane as a Data Engineer and take part in building data systems that influence key decisions for our company's growth.<br><br><strong><u>About Dashlane<br><br></u></strong>The internet has become integrated with nearly every part of our lives, from work to personal to play. Yet somehow, it’s not getting any easier or safer—especially not when it comes to protecting and accessing sensitive info in a secure way. Dashlane is an award-winning app that lets you access and share business and personal passwords anytime, anywhere.<br><br>Our business plans help organizations protect against data breaches and misuse through features like advanced user management , the ability to track security improvements over time , and a simple interface that employees will e njoy using . Our personal plans offer the same level of encryption and ease , so everyone can autofill their passwords, payments, and personal info with just a click . The Dashlane app works across every major operating system and browser — so every user can enjoy a simpler, safer internet.<br><br>Our team in Paris, New York, and Lisbon is united by our passion for improving the digital experience and the belief that with the right tools, we can help everyone simplify their online lives . Dashlane has empowered over 1 5 million users and 20,000 businesses in 180 countries to enjoy a faster, simpler, and more secure internet.<br><br><strong><u>About The Role<br><br></u></strong>Dashlane is looking for a talented Data Engineer to optimize our data to enable our company to scale in the coming years. Inside our Data Engineering team, you will be designing pipelines and warehouses to model data from multiple sources that will allow us to derive business insight. Using AWS and open-source technologies, such as Airflow and Spark, you will design and build our next-generation ETL pipelines and data models.<br><br>You will be based in New York.<br><br><strong><u>At Dashlane You Will<br></u></strong><ul> <li>Build data pipelines and python-based ETL tools for acquiring, processing, and delivering data</li> <li>Develop data models and schemas in our data warehouse that enable performant, intuitive analysis</li> <li>Handle the challenges that come with managing terabytes of data</li> <li>Collaborate with business leaders and analysts to define key metrics and build reporting to monitor and understand company performance</li> <li>Develop the server applications and APIs that are used by our Data Team</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li> You have 3+ years of experience as a data engineer, business intelligence analyst, or in a highly analytical role </li> <li>You have 3+ years of experience with a scripting language (preferably Python) for data processing and analysis</li> <li>You have experience designing SQL tables, choosing indexes, tuning queries, and optimizations ac ross different functional en vironments. </li> <li> You have experience writing complex SQL queries and using a BI tool </li> <br><br></ul><strong><u>We're Also Looking For<br></u></strong><ul> <li>You have a passion for sharing the value of data and communicating insights to a broad audience with varying levels of technical expertise</li> <li>You have experience with data lakes and designing and maintaining data solutions using Spark and AWS serverless services such as Kinesis, Lambda, or SQS</li> <li>You have experience administrating, ingesting, and monitoring data in data warehouses such as Amazon Redshift or Microsoft SQL Server</li> <li>You are a self-starter that can work in a fast-paced, distributed environment, as you will be collaborating with our Paris and Lisbon teams</li> <br><br></ul><strong><u>Diversity, Equity, Inclusion And Belonging At Dashlane<br><br></u></strong>As a truly international company - founded in Paris and split between Paris, New York, and Lisbon, Dashlane thrives off diverse perspectives. We value all aspects of diversity: gender identity, sexual orientation, ability, ethnic origin, social background, age, lifestyle, and more - and are committed to hiring a diverse community and fostering a culture where everyone is heard and belongs.<br><br><strong><u>Your Interview Experience<br><br></u></strong>To know what to expect once you’ve sent your application, read about how we interview and hire at Dashlane in this blog article written by our Talent team. Feel free to browse our blog to find more information about our product and how we work.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer - Python/R/Numpy (3-20 yrs) Any Location (Analytics & Data Science),"Evansville, Indiana, United States",Turing,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-python-r-numpy-3-20-yrs-any-location-analytics-data-science-at-turing-2429153437?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=r5QtAowgaOTcGYHOxdHXWw%3D%3D&position=22&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"Primary Location: 6305 Peachtree Dunwoody Rd, Atlanta, GA, USA

Division: Cox Communications Inc

Job Level: Individual Contributor

Travel: No

Schedule: Full-time

Shift: Day Job

Requisition Number: 211122

Cox Communications, Analytics Center of Excellence (CoE) is looking for an Analytics Engineer to join the Data Analysis team. This role will be responsible for developing actionable insights for Cox Communications' lines of businesses. The Analytics Engineer is required to have strong development, systems, and problem-solving skills to enable data-driven decision making.

Responsibilities

Identify, research, interpret, catalog, source, manipulate, and enrich Cox Communications' structured and unstructured data assets to facilitate effective analytics
Use foundational data science methodologies to identify relationships/drivers of key metrics to improve customer experience, network performance, quality of service, profitability of products, and personalized offerings
Build and maintain processes and functionalities for analytics solution needs and transfer of solutions to partner teams
Prepare documentation and visualizations
Test new technologies, tools, and data
Keep up-to-date on new technologies, standards and practices.



Qualifications

Minimum:

Expertise in (at least one) SQL language and Python. Experience with writing complex programs in these environments
Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, C++, Hadoop, Hive, SQL, SAS, Tableau, etc.
Familiarity with TensorFlow, Keras, Caffe, MXNet, Spark MLlib
Understanding of the mathematical and computational concepts behind advanced analytics algorithms
Understanding cloud environments such as Google, Microsoft, or Amazon
Understanding of one of the following core domains: customer care, network, field services, finance, business operations
Strong communication skills. Ability to successfully comprehend and communicate business insights to business partners. Ability to work in a diverse team



Preferred

Graduate degree in Data Science, Machine Learning, Statistics, Mathematics, Computer Science, Operations Research, Analytics, Engineering or closely related field. Ph.D. strongly preferred
Experience in data visualization solutions and data visualization tools



Who We Are

About Cox Communications

Cox Communications is committed to creating meaningful moments of human connection through broadband applications and services. The largest private telecom company in America, we proudly serve six million homes and businesses across 18 states. We're dedicated to empowering others to build a better future and celebrate diverse products, people, suppliers, communities and the characteristics that makes each one unique.

About Cox

We are the Cox family of businesses. We’ve been making our mark since 1898 by building and evolving world-class businesses, staying true to our values, and encouraging top talent to always look for growth and impact while building a career with us. Our primary divisions - Cox Communications and Cox Automotive - are driving a new wave of innovation, powering smart cities with powerhouse broadband communications and pioneering greener, more progressive transportation alternatives for individuals and fleet operators. We’re also expanding into new spaces like cleantech and healthcare to rev up our momentum toward building a better future for the next generation. We’re looking for the talent today who will be our leaders tomorrow. Sound intriguing? Learn more about where we are today, where we hope you’ll be going with us, and the common purpose that unites us at coxenterprises.com.

Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual’s age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Primary Location: </strong>6305 Peachtree Dunwoody Rd, Atlanta, GA, USA<br><br><strong>Division: </strong>Cox Communications Inc<br><br><strong>Job Level: </strong>Individual Contributor<br><br><strong>Travel: </strong>No<br><br><strong>Schedule: </strong>Full-time<br><br><strong>Shift: </strong>Day Job<br><br><strong>Requisition Number: </strong>211122<br><br>Cox Communications, Analytics Center of Excellence (CoE) is looking for an Analytics Engineer to join the Data Analysis team. This role will be responsible for developing actionable insights for Cox Communications' lines of businesses. The Analytics Engineer is required to have strong development, systems, and problem-solving skills to enable data-driven decision making.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Identify, research, interpret, catalog, source, manipulate, and enrich Cox Communications' structured and unstructured data assets to facilitate effective analytics</li> <li>Use foundational data science methodologies to identify relationships/drivers of key metrics to improve customer experience, network performance, quality of service, profitability of products, and personalized offerings</li> <li>Build and maintain processes and functionalities for analytics solution needs and transfer of solutions to partner teams</li> <li>Prepare documentation and visualizations</li> <li>Test new technologies, tools, and data</li> <li>Keep up-to-date on new technologies, standards and practices.</li> <br><br></ul><strong><u>Qualifications<br><br></u></strong><strong>Minimum:<br></strong><ul> <li>Expertise in (at least one) SQL language and Python. Experience with writing complex programs in these environments</li> <li>Strong programming skills and ability to utilize a variety of software/languages/tools; e.g., Spark, R, Python, Scala, Java, C++, Hadoop, Hive, SQL, SAS, Tableau, etc.</li> <li>Familiarity with TensorFlow, Keras, Caffe, MXNet, Spark MLlib</li> <li>Understanding of the mathematical and computational concepts behind advanced analytics algorithms</li> <li>Understanding cloud environments such as Google, Microsoft, or Amazon</li> <li>Understanding of one of the following core domains: customer care, network, field services, finance, business operations</li> <li>Strong communication skills. Ability to successfully comprehend and communicate business insights to business partners. Ability to work in a diverse team</li> <br><br></ul><strong><u>Preferred<br></u></strong><ul> <li>Graduate degree in Data Science, Machine Learning, Statistics, Mathematics, Computer Science, Operations Research, Analytics, Engineering or closely related field. Ph.D. strongly preferred</li> <li>Experience in data visualization solutions and data visualization tools</li> <br><br></ul>Who We Are<br><br><strong><u>About Cox Communications<br><br></u></strong>Cox Communications is committed to creating meaningful moments of human connection through broadband applications and services. The largest private telecom company in America, we proudly serve six million homes and businesses across 18 states. We're dedicated to empowering others to build a better future and celebrate diverse products, people, suppliers, communities and the characteristics that makes each one unique.<br><br><strong><u>About Cox<br><br></u></strong>We are the Cox family of businesses. We’ve been making our mark since 1898 by building and evolving world-class businesses, staying true to our values, and encouraging top talent to always look for growth and impact while building a career with us. Our primary divisions - Cox Communications and Cox Automotive - are driving a new wave of innovation, powering smart cities with powerhouse broadband communications and pioneering greener, more progressive transportation alternatives for individuals and fleet operators. We’re also expanding into new spaces like cleantech and healthcare to rev up our momentum toward building a better future for the next generation. We’re looking for the talent today who will be our leaders tomorrow. Sound intriguing? Learn more about where we are today, where we hope you’ll be going with us, and the common purpose that unites us at coxenterprises.com.<br><br>Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual’s age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.<br><br>Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Telecommunications"
Data Engineer,"Boston, Massachusetts, United States",Takeda,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-takeda-2396573123?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=RN%2BQqMtTjbaePLg9WQS43A%3D%3D&position=23&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"About Turing

Turing.com connects world-class developers to top remote jobs at world-class companies. 100+ companies, including those backed by Google Ventures, Andreessen, Founders Fund, Kleiner, and Bloomberg, have hired our developers. Over 180,000 developers from across 130 countries have chosen the Turing jobs platform as their preferred avenue for landing remote software jobs.

Responsibilities

Here's what one of our remote Data Engineering jobs would entail:

Automate common file system tasks, and build new API integrations to handle large databases
Build high-performance databases, and improve data models
Implement data security and protection practices
Write unit/integration tests to maintain accuracy in the data models
Perform data analysis and implement solutions to improve :

We, at Turing, hire software engineers who meet the following requirements :

Bachelor- s/Master's degree in Computer Science (or equivalent experience)
3+ years of experience working as a Data Engineer or similar roles (we make rare exceptions if you are highly skilled)
Proficiency in Python development
Experience with SQL, dimensional data modeling, and schema design
Experience with common data science toolkits such as NumPy, R, MatLab, etc.
Good understanding of applied statistics: regression, distributions, statistical testing, etc.
Fluency in English and the communication skills to effortlessly collaborate with engineering managers at US software companies
The ability to work full-time (40 hours/week) concurrently with US time zones for a minimum of 4 hours/day

Additionally, Turing reviews communication skills and English fluency to ensure effortless collaboration with engineering managers at U.S. software companies.
(ref:hirist.com)
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Turing<br><br></u></strong>Turing.com connects world-class developers to top remote jobs at world-class companies. 100+ companies, including those backed by Google Ventures, Andreessen, Founders Fund, Kleiner, and Bloomberg, have hired our developers. Over 180,000 developers from across 130 countries have chosen the Turing jobs platform as their preferred avenue for landing remote software jobs.<br><br><strong><u>Responsibilities<br><br></u></strong>Here's what one of our remote Data Engineering jobs would entail:<br><ul><li> Automate common file system tasks, and build new API integrations to handle large databases</li><li> Build high-performance databases, and improve data models</li><li> Implement data security and protection practices</li><li> Write unit/integration tests to maintain accuracy in the data models</li><li> Perform data analysis and implement solutions to improve :<br></li></ul>We, at Turing, hire software engineers who meet the following requirements :<br><ul><li> Bachelor- s/Master's degree in Computer Science (or equivalent experience)</li><li> 3+ years of experience working as a Data Engineer or similar roles (we make rare exceptions if you are highly skilled)</li><li> Proficiency in Python development</li><li> Experience with SQL, dimensional data modeling, and schema design</li><li> Experience with common data science toolkits such as NumPy, R, MatLab, etc.</li><li> Good understanding of applied statistics: regression, distributions, statistical testing, etc.</li><li> Fluency in English and the communication skills to effortlessly collaborate with engineering managers at US software companies</li><li> The ability to work full-time (40 hours/week) concurrently with US time zones for a minimum of 4 hours/day<br></li></ul>Additionally, Turing reviews communication skills and English fluency to ensure effortless collaboration with engineering managers at U.S. software companies.<br>(ref:hirist.com)</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Huntsville, Alabama, United States",Lockheed Martin,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-lockheed-martin-2430552404?refId=9c5774f9-6f20-44af-9953-8cc89e9ac883&trackingId=tkVTRRhJEs%2Fs5WSmVofEKQ%3D%3D&position=24&pageNum=4&trk=public_jobs_job-result-card_result-card_full-click,"By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that I agree with Takeda’s Privacy Notice, Privacy Policy and Terms of Use.

Job Description

Millennium Pharmaceuticals, Inc. is seeking a Data Engineer in Cambridge, MA with the following requirements Bachelors degree in Computer Science or related field or foreign equivalent degree. Masters level project/coursework in the Computer Science field covering the below required skills. Required skills author and implement Python, and Java languages to achieve a programmatic or analytic result; author and Implement Spark at scale to achieve a programmatic or analytic result; use Application of Machine Learning and / or Deep Learning to find hidden information/patterns in data; Apply data wrangling, manipulation and management of technologies to create structured datasets accessible through databases for further analysis using Deep and Machine Learning techniques.

Apply on-line at www.takedajobs.com and search for Req #R0027567.

Locations

Boston, MA

Worker Type

Employee

Worker Sub-Type

Regular

Time Type

Full time
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that I agree with Takeda’s Privacy Notice, Privacy Policy and Terms of Use.<br><br><strong><u>Job Description<br><br></u></strong>Millennium Pharmaceuticals, Inc. is seeking a Data Engineer in Cambridge, MA with the following requirements Bachelors degree in Computer Science or related field or foreign equivalent degree. Masters level project/coursework in the Computer Science field covering the below required skills. Required skills author and implement Python, and Java languages to achieve a programmatic or analytic result; author and Implement Spark at scale to achieve a programmatic or analytic result; use Application of Machine Learning and / or Deep Learning to find hidden information/patterns in data; Apply data wrangling, manipulation and management of technologies to create structured datasets accessible through databases for further analysis using Deep and Machine Learning techniques.<br><br>Apply on-line at www.takedajobs.com and search for Req #R0027567.<br><br><strong>Locations<br><br></strong>Boston, MA<br><br><strong>Worker Type<br><br></strong>Employee<br><br><strong>Worker Sub-Type<br><br></strong>Regular<br><br><strong>Time Type<br><br></strong>Full time</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Pharmaceuticals
Data Engineer. Data Science,"Chicago, Illinois, United States",Numerator,2021-01-21,https://www.linkedin.com/jobs/view/data-engineer-data-science-at-numerator-2388990170?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=iDMKi0NQySGa4HnazWJp%2FQ%3D%3D&position=1&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Description:At Lockheed Rotary and Mission System (RMS), we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and visionary thinking, everything is within our reach – and yours as a Lockheed Martin employee. Lockheed Martin values your skills, training and education.

This position is critical to the NOBLE program. The Data Scientist will design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources. Develops and uses advanced software programs, algorithms, querying and automated processes to cleanse, integrate and evaluate datasets and models complex business problems. Is familiar with disciplines such as Natural Language Processing, Machine Learning, Predictive modeling, Statistical Analysis and Hypothesis testing. Works with cross-discipline teams in order to ensure connectivity between various databases and systems.
Experience designing efficient algorithms with programming languages and tools for data manipulation and statistical analysis. Experience designing efficient data mining and text mining frameworks with related tools.

Basic Qualifications

The candidate must show a proven ability in creative problem solving skills and be comfortable working in a highly dynamic, fast-paced environment. Candidate must be able to maintain high quality output.

The candidate must be highly proficient in Python, Data Management, MS Excel, MS PowerPoint and MS Access or other database engines. Working knowledge of military logistics is desired.

The candidate must be able to present analysis, results and methodology in order to feed the process of corrective action investigation on logistics and engineering issues. Candidate must be a self-starting, highly motivated, analytical, team player with leadership traits.

Desired Skills

Skilled in Python, Tableau, SQL, .net, Java, JavaScript or other basic programming knowledge.

Job.Qualifications

BASIC QUALIFICATIONS:

Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.

Experience Level

Experienced Professional
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Description:</strong>At Lockheed Rotary and Mission System (RMS), we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and visionary thinking, everything is within our reach – and yours as a Lockheed Martin employee. Lockheed Martin values your skills, training and education.<br><br>This position is critical to the NOBLE program. The Data Scientist will design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources. Develops and uses advanced software programs, algorithms, querying and automated processes to cleanse, integrate and evaluate datasets and models complex business problems. Is familiar with disciplines such as Natural Language Processing, Machine Learning, Predictive modeling, Statistical Analysis and Hypothesis testing. Works with cross-discipline teams in order to ensure connectivity between various databases and systems.<br>Experience designing efficient algorithms with programming languages and tools for data manipulation and statistical analysis. Experience designing efficient data mining and text mining frameworks with related tools.<br><br><strong><u>Basic Qualifications<br><br></u></strong>The candidate must show a proven ability in creative problem solving skills and be comfortable working in a highly dynamic, fast-paced environment. Candidate must be able to maintain high quality output.<br><br>The candidate must be highly proficient in Python, Data Management, MS Excel, MS PowerPoint and MS Access or other database engines. Working knowledge of military logistics is desired.<br><br>The candidate must be able to present analysis, results and methodology in order to feed the process of corrective action investigation on logistics and engineering issues. Candidate must be a self-starting, highly motivated, analytical, team player with leadership traits.<br><br><strong><u>Desired Skills<br><br></u></strong>Skilled in Python, Tableau, SQL, .net, Java, JavaScript or other basic programming knowledge.<br><br><strong><u>Job.Qualifications<br><br></u></strong><strong>BASIC QUALIFICATIONS:<br><br></strong><strong>Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.<br></strong>Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.<br><br>As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.<br><br><strong><u>Experience Level<br><br></u></strong>Experienced Professional</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Information Technology and Services, Computer Software"
Data Scientist,"Middletown, Connecticut, United States",ISO,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-iso-2415657389?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=%2FT9Rf%2BxzOeNUPwrshsXoTw%3D%3D&position=2&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Numerator is looking for a Data Engineer, Data Science to help us drive decision-making, find bigger opportunities and work with our established and rapidly evolving platforms that handle millions of requests and massive amounts of events, and other data. In this position, you will be responsible for taking on new initiatives to automate, enhance, maintain, and scale services in a rapidly-scaling environment.

The details

As a Data Engineer, Data Science at Numerator, you will help our team make better decisions by advocating for data-driven approaches across the organization. The role is cross-functional by nature and is responsible for developing data products and analytics, defining methodologies, conducting research and analysis on a variety of subject areas, and driving bottom-line growth through building operational efficiencies and leading special projects for our clients.

A major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and delivering to production.

You will have a broad impact and exposure across Numerator as you help build out and expand our technology platforms across several software products. This is a fast-paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production.

What you get to do!

Identify new opportunities to build and/or improve new product features and data products.
Partner with Product, Data, and Engineering teams to identify, investigate and deliver solutions related to product and back-end data issues.
Deliver complex, end-to-end projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.).
Lead the discovery and development of new and existing methodologies, tools, and algorithms.
Regularly communicate outcomes, new initiatives, and improvements, etc. to stakeholders.
Provide data science engineering consulting and support to both internal and external clients.



Skills & Requirements

What we are looking for

2+ years in building a data warehouse and data pipelines. OR, 3+ years in a data intensive engineering role.
Proficient software engineering experience in one major language ( preferably Python and/or R) along with SQL. You strive to write beautiful code.
Experience with ETL tooling (especially Airflow) and data processing, and knowing how to transform data to meet business goals.
You have a strong background in distributed data processing, software engineering and data modeling.
Outstanding written and verbal data storytelling, demonstrated consulting skill and ability to tailor communication style and depth to a variety of audiences.
Highly autonomous, versatile, intellectually curious, and resilient within a dynamic and fast-paced organization.
BS in Mathematics, Statistics, Computer Science, Engineering, Economics, Physics, or other behavioral and/or equivalent quantitative science.


Extra, nice to haves

Experience with developing, deploying and maintaining back-end production code, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.).
Exposure to AWS, Azure, or GCP.
Proven track record of delivering solutions to a production environment.
Experience with understanding, analyzing and modeling user data and behavioral trends.
Experience working with marketing insights, shopping data or in the retail industry.



What We Offer

An inclusive and collaborative company culture- we work in an open environment while working together to get things done, and adapt to the changing needs as they come.
Market competitive total compensation package.
Volunteer time off and charitable donation matching.
Regular hackathons to build your own projects and work with people across the entire company
Strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups.
Great benefits package including health/vision/dental, exceptional maternity leave coverage, unlimited PTO, flexible schedule, 401K/RRSP matching, travel reimbursement and much more.


If this sounds like something you would like to be part of, we'd love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology and methodologies we use are constantly changing and we value talent and interest over specific experience.

We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Job Description<br><br></strong><strong>Numerator</strong> is looking for a <strong>Data Engineer, Data Science </strong>to help us drive decision-making, find bigger opportunities and work with our established and rapidly evolving platforms that handle millions of requests and massive amounts of events, and other data. In this position, you will be responsible for taking on new initiatives to automate, enhance, maintain, and scale services in a rapidly-scaling environment.<br><br><strong>The details<br><br></strong>As a <strong>Data Engineer, Data Science </strong>at Numerator, you will help our team make better decisions by advocating for data-driven approaches across the organization. The role is cross-functional by nature and is responsible for developing data products and analytics, defining methodologies, conducting research and analysis on a variety of subject areas, and driving bottom-line growth through building operational efficiencies and leading special projects for our clients.<br><br>A major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and delivering to production.<br><br>You will have a broad impact and exposure across Numerator as you help build out and expand our technology platforms across several software products. This is a fast-paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production.<br><br><strong>What you get to do!<br></strong><ul> <li>Identify new opportunities to build and/or improve new product features and data products.</li> <li>Partner with Product, Data, and Engineering teams to identify, investigate and deliver solutions related to product and back-end data issues.</li> <li>Deliver complex, end-to-end projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.).</li> <li>Lead the discovery and development of new and existing methodologies, tools, and algorithms.</li> <li>Regularly communicate outcomes, new initiatives, and improvements, etc. to stakeholders.</li> <li>Provide data science engineering consulting and support to both internal and external clients.</li> <br><br></ul><strong>Skills &amp; Requirements<br><br></strong><strong>What we are looking for <br></strong><ul> <li>2+ years in building a data warehouse and data pipelines. OR, 3+ years in a data intensive engineering role. </li> <li>Proficient software engineering experience in one major language ( preferably Python and/or R) along with SQL. You strive to write beautiful code.</li> <li>Experience with ETL tooling (especially Airflow) and data processing, and knowing how to transform data to meet business goals.</li> <li>You have a strong background in distributed data processing, software engineering and data modeling.</li> <li>Outstanding written and verbal data storytelling, demonstrated consulting skill and ability to tailor communication style and depth to a variety of audiences.</li> <li>Highly autonomous, versatile, intellectually curious, and resilient within a dynamic and fast-paced organization.</li> <li>BS in Mathematics, Statistics, Computer Science, Engineering, Economics, Physics, or other behavioral and/or equivalent quantitative science.</li> <br></ul><strong>Extra, nice to haves<br></strong><ul> <li>Experience with developing, deploying and maintaining back-end production code, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.).</li> <li>Exposure to AWS, Azure, or GCP.</li> <li>Proven track record of delivering solutions to a production environment.</li> <li>Experience with understanding, analyzing and modeling user data and behavioral trends.</li> <li>Experience working with marketing insights, shopping data or in the retail industry.</li> <br><br></ul><strong>What We Offer<br></strong><ul> <li>An inclusive and collaborative company culture- we work in an open environment while working together to get things done, and adapt to the changing needs as they come.</li> <li>Market competitive total compensation package.</li> <li>Volunteer time off and charitable donation matching.</li> <li>Regular hackathons to build your own projects and work with people across the entire company</li> <li>Strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups. </li> <li>Great benefits package including health/vision/dental, exceptional maternity leave coverage, unlimited PTO, flexible schedule, 401K/RRSP matching, travel reimbursement and much more.</li> <br></ul>If this sounds like something you would like to be part of, we'd love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology and methodologies we use are constantly changing and we value talent and interest over specific experience.<br><br><em>We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Project Management, Information Technology, Product Management",Full-time,"Information Technology and Services, Market Research, Information Services"
Data Engineer,"Downers Grove, Illinois, United States",Cooper's Hawk Winery and Restaurants,2021-02-01,https://www.linkedin.com/jobs/view/data-engineer-at-cooper-s-hawk-winery-and-restaurants-2404990448?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=qPKXLvniIQuLPHON2IjibQ%3D%3D&position=3&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Company Description

ISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at:  www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fourth consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.

Job Description

We seek to fill an entry-level position on the ISO MarketStance Data Science team, transforming dozens of disparate data sources into comprehensive insurance market exposure and premium estimates.

You must have a strong analytical and research background and demonstrate a high degree of proficiency programming in Microsoft SQL Server or similar relational database language to perform well in this position.

Experience in the property and casualty industry, economic and business statistics published by the federal government

Responsibilities

Operate and maintain data modeling and manipulation procedures in a Microsoft SQL Server environment, predominantly consisting of Transact-SQL scripts and relational database objects
Create data models, metadata and conduct quality assurance for all MarketStance products and consulting projects, as assigned
Conduct secondary research related to commercial insurance
Present research findings and data for inside and outside clients


Qualifications

Undergraduate degree in a strong research and problem-solving field—economics, natural sciences, math/statistics, or computer science
MS SQL Server and/or MS Access
MS Excel
MS PowerPoint
Excellence in technical/analytical writing
Ability to work both collaboratively and independently, but without task-to-task oversight
Ability to work tasks and projects with which you have little or no prior expertise or familiarity


Preferred

Experience in one or more of the following areas of commercial lines insurance: underwriting, actuarial, audit, claims, marketing/distribution
Experience with R or SAS


Other Desired Experience

Experience with open source GIS software and libraries
MS SQL Server Integration Services
Mozenda
Python


Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company Description<br><br></u></strong>ISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at:  www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!<br><br>At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.<br><br>Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.<br><br>But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.<br><br>It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.<br><br>At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.<br><br>At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fourth consecutive year. We’ve been recognized by <em>Forbes</em> as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.<br><br><strong><u>Job Description<br><br></u></strong>We seek to fill an entry-level position on the ISO MarketStance Data Science team, transforming dozens of disparate data sources into comprehensive insurance market exposure and premium estimates.<br><br>You must have a strong analytical and research background and demonstrate a high degree of proficiency programming in Microsoft SQL Server or similar relational database language to perform well in this position.<br><br>Experience in the property and casualty industry, economic and business statistics published by the federal government<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Operate and maintain data modeling and manipulation procedures in a Microsoft SQL Server environment, predominantly consisting of Transact-SQL scripts and relational database objects</li><li>Create data models, metadata and conduct quality assurance for all MarketStance products and consulting projects, as assigned</li><li>Conduct secondary research related to commercial insurance</li><li>Present research findings and data for inside and outside clients<br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>Undergraduate degree in a strong research and problem-solving field—economics, natural sciences, math/statistics, or computer science</li><li>MS SQL Server and/or MS Access</li><li>MS Excel</li><li>MS PowerPoint</li><li>Excellence in technical/analytical writing</li><li>Ability to work both collaboratively and independently, but without task-to-task oversight</li><li>Ability to work tasks and projects with which you have little or no prior expertise or familiarity<br><br></li></ul><strong><u>Preferred<br></u></strong><ul><li>Experience in one or more of the following areas of commercial lines insurance: underwriting, actuarial, audit, claims, marketing/distribution</li><li>Experience with R or SAS<br><br></li></ul><strong><u>Other Desired Experience<br></u></strong><ul><li>Experience with open source GIS software and libraries</li><li>MS SQL Server Integration Services</li><li>Mozenda</li><li>Python<br><br></li></ul><strong><u>Additional Information<br><br></u></strong>Verisk Analytics is an equal opportunity employer.<br><br>All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.<br><br>http://www.verisk.com/careers.html<br><br>Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.<br><br><strong>Consumer Privacy Notice<br><br></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Restaurants, Food & Beverages, Hospitality"
Data Engineer,"Boston, Massachusetts, United States",McGraw Hill,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-mcgraw-hill-2410233499?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=tKh1kKvYe79wrQocU7MG3g%3D%3D&position=4&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"We are looking for a Data Engineer to join our team in helping to support our modern data platform in Azure. This person will primarily be responsible for the development and support of our data pipelines, data lake, and our data warehouse solution along with finding ways to unlock value from our data to support our finance, marketing and operation teams.

Duties & Responsibilities

Acquire, ingest, and process data from multiple source systems into the data lake
Plan and execute data integration strategies and approaches for batch data
Create data integration strategies and approaches for real-time streaming data
Assist in the development and maintenance of the data lake and the data warehouse
Participate in architectural design and discussions
Work with business owners to identity new types of data that are of interest to be pulled into the data warehouse



Candidate Attributes



Strong and effective communication skills with an ability to engage business stakeholders in discussion or resolution of issues
Self-starter who can identify and develop data solutions with minimal direction and pivot based on dynamically changing business priorities
Demonstrated desire to continuously learn and evolve Cloud and programming skill sets within the Azure tech stack and elsewhere
Demonstrated ability to meet deadlines
Proven track-record of developing creative data solutions to solve complex business issues
Proven track-record of ownership of entire project lifecycle



Technical Qualifications

Proven experience developing data pipelines for acquisition, cleansing, and integration
Proven experience creating data movement solutions using Azure Data Factory (ADF)
Understanding of error handling best practices
Understanding of the benefits of data lakes
Working knowledge of dimensional data warehouse best practices and techniques
Working knowledge of scaling data solutions in the Azure stack
5+ years of experience developing SQL Server code, including stored procedures, views, CTEs etc.
3+ years of experience developing solutions using cloud technologies
Working knowledge of SQL Server optimization techniques and best practices
Exposure to developing solutions in Spark and/or Databricks and Python



Cooper's Hawk is an Equal Opportunity Employer
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are looking for a Data Engineer to join our team in helping to support our modern data platform in Azure. This person will primarily be responsible for the development and support of our data pipelines, data lake, and our data warehouse solution along with finding ways to unlock value from our data to support our finance, marketing and operation teams.<br><br><strong><u>Duties &amp; Responsibilities<br></u></strong><ul> <li>Acquire, ingest, and process data from multiple source systems into the data lake</li> <li>Plan and execute data integration strategies and approaches for batch data</li> <li>Create data integration strategies and approaches for real-time streaming data</li> <li>Assist in the development and maintenance of the data lake and the data warehouse</li> <li>Participate in architectural design and discussions</li> <li>Work with business owners to identity new types of data that are of interest to be pulled into the data warehouse</li> <br><br></ul><strong><u>Candidate Attributes<br><br><br></u></strong><ul> <li>Strong and effective communication skills with an ability to engage business stakeholders in discussion or resolution of issues</li> <li>Self-starter who can identify and develop data solutions with minimal direction and pivot based on dynamically changing business priorities</li> <li>Demonstrated desire to continuously learn and evolve Cloud and programming skill sets within the Azure tech stack and elsewhere</li> <li>Demonstrated ability to meet deadlines</li> <li> Proven track-record of developing creative data solutions to solve complex business issues</li> <li>Proven track-record of ownership of entire project lifecycle</li> <br><br></ul><strong><u>Technical Qualifications<br></u></strong><ul> <li>Proven experience developing data pipelines for acquisition, cleansing, and integration</li> <li>Proven experience creating data movement solutions using Azure Data Factory (ADF)</li> <li>Understanding of error handling best practices</li> <li> Understanding of the benefits of data lakes</li> <li>Working knowledge of dimensional data warehouse best practices and techniques</li> <li>Working knowledge of scaling data solutions in the Azure stack</li> <li>5+ years of experience developing SQL Server code, including stored procedures, views, CTEs etc.</li> <li>3+ years of experience developing solutions using cloud technologies</li> <li>Working knowledge of SQL Server optimization techniques and best practices</li> <li>Exposure to developing solutions in Spark and/or Databricks and Python</li> <br><br></ul>Cooper's Hawk is an Equal Opportunity Employer</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Restaurants, Food & Beverages, Hospitality"
Data Engineer,"Houston, Texas, United States",Neudesic,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-neudesic-2405702574?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=mf7X3B6NQCfuh0vhhN858g%3D%3D&position=5&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Build the Future

Do you enjoy testing the limits of possibility? At McGraw Hill, our Data Integration team drives progress and helps build the future of learning. If you have the passion and technical expertise to thrive in an innovative and agile environment, we want to learn more about you.

Your impact on the team

As a Data Engineer, you will help drive the design and development of highly scalable enterprise data processing and data warehouse use cases deployed on AWS for our core analytics and data science platform. You will create, own, manage, share support of, and drive best practices for a variety of existing and emerging data intensive applications.

The Data Integration team is part of our Digital Platform Group, which is responsible for building and supporting innovative digital platforms to power learning across K-12, Higher Education, International, and Professional segments. As part of this group, the Analytics and Reporting team is building best-in-class applications which leverage data and machine learning for advanced analytics and adaptive learning products. If you are interested in contributing to the future of digital and remote learning, join us on this mission!

What can you expect from the position?


Contribute to complex solution designs, hands-on software development goals, new tool and framework creation, and code reviews.
Identify gaps and proactively improve system service level agreements.
Provide technical knowledge sharing and coaching to engineers on the development team.
Work effectively with Technical Product Management and SCRUM masters to meaningfully contribute to our agile team.


What can you bring to the role?


At least 5 years of experience with ETL data processing concepts with full implementation cycle experience in enterprise data marts, including advanced SQL development skills.
At least 3 years of Architecture and Optimization experience for database systems technologies with a focus on data marts and data warehouses.
Having coding experience with a modern development language (Scala, Python, Java).
Experience with Apache Spark.
Strong understanding of data modeling concepts, including schema development, validation, and evolution (normalized and denormalized).
Experience with performance tuning and scaling production databases.
Experience with agile engineering practices.


As an education innovation company, we're proud to play our part by inspiring learners around the world. If you bring your curiosity, we'll help you grow in a collaborative environment where everyone shares a passion for success.

Are you ready for a new challenge? Apply for a career at McGraw Hill and together, we'll impact the world.

Other Locations

United States-New York-New York


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Build the Future<br><br></strong>Do you enjoy testing the limits of possibility? At McGraw Hill, our <strong>Data Integration team </strong>drives progress and helps build the future of learning. If you have the passion and technical expertise to thrive in an innovative and agile environment, we want to learn more about you.<br><br><strong>Your impact on the team<br><br></strong>As a <strong>Data Engineer, </strong>you will help drive the design and development of highly scalable enterprise data processing and data warehouse use cases deployed on AWS for our core analytics and data science platform. You will create, own, manage, share support of, and drive best practices for a variety of existing and emerging data intensive applications.<br><br>The Data Integration team is part of our Digital Platform Group, which is responsible for building and supporting innovative digital platforms to power learning across K-12, Higher Education, International, and Professional segments. As part of this group, the Analytics and Reporting team is building best-in-class applications which leverage data and machine learning for advanced analytics and adaptive learning products. If you are interested in contributing to the future of digital and remote learning, join us on this mission!<br><br><strong>What can you expect from the position?<br><br></strong><li>Contribute to complex solution designs, hands-on software development goals, new tool and framework creation, and code reviews.</li><li>Identify gaps and proactively improve system service level agreements.</li><li>Provide technical knowledge sharing and coaching to engineers on the development team.</li><li>Work effectively with Technical Product Management and SCRUM masters to meaningfully contribute to our agile team.<br><br></li><strong>What can you bring to the role?<br><br></strong><li>At least 5 years of experience with ETL data processing concepts with full implementation cycle experience in enterprise data marts, including advanced SQL development skills.</li><li>At least 3 years of Architecture and Optimization experience for database systems technologies with a focus on data marts and data warehouses.</li><li>Having coding experience with a modern development language (Scala, Python, Java).</li><li>Experience with Apache Spark.</li><li>Strong understanding of data modeling concepts, including schema development, validation, and evolution (normalized and denormalized).</li><li>Experience with performance tuning and scaling production databases.</li><li>Experience with agile engineering practices.<br><br></li>As an education innovation company, we're proud to play our part by inspiring learners around the world. If you bring your curiosity, we'll help you grow in a collaborative environment where everyone shares a passion for success.<br><br>Are you ready for a new challenge? Apply for a career at McGraw Hill and together, we'll impact the world.<br><br><strong>Other Locations<br><br></strong>United States-New York-New York<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Quality Assurance, Engineering",Full-time,"Education Management, E-Learning, Publishing"
Data Engineer,"Santa Clara, California, United States",Whiterabbit.ai,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-whiterabbit-ai-2427332331?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=c3ybwL48EdrFEZN6miEHmQ%3D%3D&position=6&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"About Neudesic

Passion for technology drives us, but it’s innovation that defines us. From design to development and support to management, Neudesic offers decades of experience, proven frameworks and a disciplined approach to quickly deliver reliable, quality solutions that help our customers go to market faster.

 

What sets us apart from the rest, is an amazing collection of people who live and lead with our core values. We believe that everyone should be Passionate about what they do, Disciplined to

the core, Innovative by nature, committed to a Team and conduct themselves with Integrity. If these attributes mean something to you - we'd like to hear from you.

 

Role Profile

Our Predictive Enterprise Capability is comprised of some of the most respected and well-known architects as well as brilliant new developers and designers. Together, our teams of professionals have delivered some of the most innovative and leading edge implementations of Business Intelligence, Data Warehousing and Big Data solutions for the business-to-business as well as business-to-consumer space.

 

Please note - this position is located in Houston, Texas.

 

Knowledge Foundation

Experience in Database development, Data Modeling, architecture, and storage
Strong understanding of data structures and algorithms
Solid understanding of concurrency and concurrent programming techniques
Knowledge of functional programing languages and techniques
Knowledge of object-oriented programming languages and techniques
Knowledge of Agile Software Development methodologies and Azure DevOps including Git and GitHub
Data Analysis Knowledge: Understanding how data is collected, analyzed and utilized

 

Foundation Technical Skills

Experience with database systems (SQL and/or NoSQL)
Data warehousing: experience in Microsoft traditional data warehousing and BI 
ETL tools: Azure Data Factory and Databricks a plus
Programming skills in Python, R, SQL and/or Scala a plus
Experience working with data API’s a plus
Exposure to Azure Cloud services and big data processing solutions a plus
Exposure to Azure Synapse a plus
Experience with Cloud Security a plus

 

Required and Preferred Technical and Professional Expertise

Bachelor’s degree (or higher) in Computer Science or related field with 3+ years’ experience required.
Desire to learn new technologies and languages required.
Excellent oral and written communication skills with a keen sense of customer service.
Able to convey information concisely and clearly with great technical documentation skills.
Excellent problem solving and troubleshooting skills.
Able to work closely and effectively with peer developers and work on several active projects simultaneously.
Knowledge of statistical analysis and machine learning is a plus.

 

 

Neudesic is an Equal Employment Opportunity Employer

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>About Neudesic</strong></p><p>Passion for technology drives us, but it’s innovation that defines us<em>.&nbsp;</em>From design to development and support to management, Neudesic offers decades of experience, proven frameworks and a disciplined approach to quickly deliver reliable, quality solutions that help our customers go to market faster.</p><p>&nbsp;</p><p>What sets us apart from the rest, is an amazing collection of people who live and lead with our core values. We believe that everyone should be&nbsp;<strong>Passionate</strong>&nbsp;about what they do,&nbsp;<strong>Disciplined&nbsp;</strong>to</p><p>the core,&nbsp;<strong>Innovative</strong>&nbsp;by nature, committed to a&nbsp;<strong>Team&nbsp;</strong>and conduct themselves with&nbsp;<strong>Integrity.</strong>&nbsp;If these attributes mean something to you - we'd like to hear from you.</p><p>&nbsp;</p><p><strong>Role Profile</strong></p><p>Our Predictive Enterprise Capability is comprised of some of the most respected and well-known architects as well as brilliant new developers and designers. Together, our teams of professionals have delivered some of the most innovative and leading edge implementations of Business Intelligence, Data Warehousing and Big Data solutions for the business-to-business as well as business-to-consumer space.</p><p>&nbsp;</p><p>Please note - this position is located in Houston, Texas.</p><p>&nbsp;</p><p><strong>Knowledge Foundation</strong></p><ul><li>Experience in&nbsp;Database development, Data Modeling, architecture, and storage</li><li>Strong understanding of data structures and algorithms</li><li>Solid understanding of concurrency and concurrent programming techniques</li><li>Knowledge of functional programing languages and techniques</li><li>Knowledge of object-oriented programming languages and techniques</li><li>Knowledge of Agile Software Development methodologies and Azure DevOps including Git and GitHub</li><li>Data Analysis Knowledge: Understanding how data is collected, analyzed and utilized</li></ul><p><strong>&nbsp;</strong></p><p><strong>Foundation Technical Skills</strong></p><ul><li>Experience with database systems (SQL and/or NoSQL)</li><li>Data warehousing: experience in Microsoft traditional data warehousing and BI&nbsp;</li><li>ETL tools: Azure Data Factory and Databricks a plus</li><li>Programming skills in Python, R, SQL and/or Scala a plus</li><li>Experience working with data API’s a plus</li><li>Exposure to Azure Cloud services and big data processing solutions a plus</li><li>Exposure to Azure Synapse a plus</li><li>Experience with Cloud Security a plus</li></ul><p>&nbsp;</p><p><strong>Required and Preferred Technical and Professional Expertise</strong></p><ul><li>Bachelor’s degree (or higher) in Computer Science or related field with 3+ years’ experience required.</li><li>Desire to learn new technologies and languages required.</li><li>Excellent oral and written communication skills with a keen sense of customer service.</li><li>Able to convey information concisely and clearly with great technical documentation skills.</li><li>Excellent problem solving and troubleshooting skills.</li><li>Able to work closely and effectively with peer developers and work on several active projects simultaneously.</li><li>Knowledge of statistical analysis and machine learning is a plus.</li></ul><p>&nbsp;</p><p>&nbsp;</p><p><strong>Neudesic is an Equal Employment Opportunity Employer</strong></p><p>All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Consulting",Full-time,Information Technology and Services
Data Engineer,"New York, New York, United States",Foot Locker,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-foot-locker-2422011351?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=U6dfJKCvdTjGwF79WE4JMg%3D%3D&position=7&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Who We Are

Our mission at Whiterabbit.ai is to save lives and eliminate suffering through the early detection of cancer with artificial intelligence. We collaborate closely with one of the top medical schools in the country and have exclusive access to one of the world’s largest cancer datasets with millions of images. We invent algorithms that make doctors more productive, more accurate, and more capable. We build products and services with a relentless focus on transforming the patient’s healthcare experience.

Purpose

We are looking for a Clinical Research Specialist to lead the ideation, design, and execution of clinical studies that evaluate the impact of our technology and products on breast cancer screening. You will leverage your own clinical expertise, work with professional societies, talk with healthcare professionals and patients, and coordinate a multidisciplinary effort that spans AI research, product, and marketing to publish landmark studies that seek to establish a higher standard of care for patients enabled by AI.

An excellent candidate has a background in breast imaging and can leverage her knowledge to understand the issues for the adoption of AI from academic, regulatory, and clinical perspectives. The ideal candidate could be a radiologist in training looking for a career in commercial research who has experience with mammography.

Responsibilities

Extract data from standard PACS servers.
Standardize, organize, normalize and augment data acquired from multiple sources.
Extract data from databases and join it with image data acquired from the PACS servers.
Extract non-standard data from multiple source using non-standard methods (i.e. write selenium robots).
Write and maintain applications for automating data acquisition and processing.
Help run studies on the existing data to reports stats.
De-identify data sets for specific purposes.
Generate standard datasets for specific purposes.

Generate non-standard datasets for specific purposes.

Must Have Experience

Python and object-oriented programming
SQL and Database knowledge
Amazon S3
Shell

Nice To Have Experience

DICOM
Javascript
Docker

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Who We Are <br><br></strong>Our mission at Whiterabbit.ai is to save lives and eliminate suffering through the early detection of cancer with artificial intelligence. We collaborate closely with one of the top medical schools in the country and have exclusive access to one of the world’s largest cancer datasets with millions of images. We invent algorithms that make doctors more productive, more accurate, and more capable. We build products and services with a relentless focus on transforming the patient’s healthcare experience.<br><br><strong> Purpose <br><br></strong>We are looking for a Clinical Research Specialist to lead the ideation, design, and execution of clinical studies that evaluate the impact of our technology and products on breast cancer screening. You will leverage your own clinical expertise, work with professional societies, talk with healthcare professionals and patients, and coordinate a multidisciplinary effort that spans AI research, product, and marketing to publish landmark studies that seek to establish a higher standard of care for patients enabled by AI.<br><br>An excellent candidate has a background in breast imaging and can leverage her knowledge to understand the issues for the adoption of AI from academic, regulatory, and clinical perspectives. The ideal candidate could be a radiologist in training looking for a career in commercial research who has experience with mammography.<br><br><strong> Responsibilities <br></strong><ul><li> Extract data from standard PACS servers.</li><li> Standardize, organize, normalize and augment data acquired from multiple sources.</li><li> Extract data from databases and join it with image data acquired from the PACS servers.</li><li> Extract non-standard data from multiple source using non-standard methods (i.e. write selenium robots).</li><li> Write and maintain applications for automating data acquisition and processing.</li><li> Help run studies on the existing data to reports stats.</li><li> De-identify data sets for specific purposes.</li><li> Generate standard datasets for specific purposes.<br></li></ul>Generate non-standard datasets for specific purposes.<br><br><strong> Must Have Experience <br></strong><ul><li> Python and object-oriented programming</li><li> SQL and Database knowledge</li><li> Amazon S3</li><li> Shell<br></li></ul><strong> Nice To Have Experience <br></strong><ul><li> DICOM</li><li> Javascript</li><li> Docker<br></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Medical Devices, Computer Software, Hospital & Health Care"
Data Analytics Engineer,"Atlanta, Georgia, United States",North Highland,2021-02-10,https://www.linkedin.com/jobs/view/data-analytics-engineer-at-north-highland-2398543596?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=HpDQBcgP9by1ayj3CsaN7Q%3D%3D&position=8&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Overview

Our global house-of-brands inspires and empowers youth culture. Relentlessly committed to fuel a shared passion for self-expression, we create unrivaled experiences at the heart of the sport and sneaker communities through the power of our people. If you want to be a part of something bigger than you can imagine, you’ve come to the right place. To learn more about the incredible impact we’re making on both our local and global communities, Click Here!

Foot Locker, Inc. is seeking an innovative individual who has a proven track record of building enterprise level platform components to support product development from multiple teams and lines of business. This role is expected to drive innovation through collaboration across our data science teams and business to help push Foot Locker, inc. to the next level. The team is embarking on a journey of building a brand new data lake platform built using cloud native concepts and the latest tech stacks.

Responsibilities

Build new data sets, and products helping support Foot Locker business initiatives.
Help grow our data catalog through ingestions of a variety of third party data sources, both internal and external
Must be able to contribute to self-organizing teams with minimal supervision working within the Agile / Scrum project methodology
Build production quality ingestion pipelines with automated quality checks to help enable the business to access all of our data sets in one place
Participate in the continuous evolution of our schema / data model as we find more data sources to pull into the platform
Support our Data Scientists by helping enhance their modeling jobs to be more scalable when modeling across the entire data set
Participate in a collaborative, peer review based environment fostering new ideas via cross team guilds / specialty groups
Maintain comprehensive documentation around our processes / decision making


Qualifications

Bachelors Degree in Computer science or related field, preferred
Experience with information technology and Big Data technologies
Experience with Spark, running on multiple platforms. Spark Certified Developer a plus
Knowledge of Hive, Hadoop, Parquet, HDFS, Python, Scala, Data Lake, NoSQL
Public cloud experience, preferably Azure or AWS
Understands proper executor / driver sizing, understands caching / object serialization, spark shuffle optimization, streaming
Demonstrated experience with agile scrum methodology
Strong desire to learn new technologies and keep up with the latest technologies in the big data space
Solid leadership and mentorship skills
Well-developed verbal and written communication skills.
Experience using CI / CD tools and project build automation, Git, Jenkins, Maven, PyPi, etc. preferred
Experience with enabling Data Science and Self Service product development with clean, reliable data sets a plus
Airflow, a plus
Industry recognized certifications, a plus


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong>Our global house-of-brands inspires and empowers youth culture. Relentlessly committed to fuel a shared passion for self-expression, we create unrivaled experiences at the heart of the sport and sneaker communities through the power of our people. If you want to be a part of something bigger than you can imagine, you’ve come to the right place. To learn more about the incredible impact we’re making on both our local and global communities, <u>Click Here!<br><br></u>Foot Locker, Inc. is seeking an innovative individual who has a proven track record of building enterprise level platform components to support product development from multiple teams and lines of business. This role is expected to drive innovation through collaboration across our data science teams and business to help push Foot Locker, inc. to the next level. The team is embarking on a journey of building a brand new data lake platform built using cloud native concepts and the latest tech stacks.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Build new data sets, and products helping support Foot Locker business initiatives.</li><li> Help grow our data catalog through ingestions of a variety of third party data sources, both internal and external</li><li> Must be able to contribute to self-organizing teams with minimal supervision working within the Agile / Scrum project methodology</li><li> Build production quality ingestion pipelines with automated quality checks to help enable the business to access all of our data sets in one place</li><li> Participate in the continuous evolution of our schema / data model as we find more data sources to pull into the platform</li><li> Support our Data Scientists by helping enhance their modeling jobs to be more scalable when modeling across the entire data set</li><li> Participate in a collaborative, peer review based environment fostering new ideas via cross team guilds / specialty groups</li><li> Maintain comprehensive documentation around our processes / decision making<br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>Bachelors Degree in Computer science or related field, preferred</li><li>Experience with information technology and Big Data technologies</li><li>Experience with Spark, running on multiple platforms. Spark Certified Developer a plus</li><li>Knowledge of Hive, Hadoop, Parquet, HDFS, Python, Scala, Data Lake, NoSQL</li><li>Public cloud experience, preferably Azure or AWS</li><li>Understands proper executor / driver sizing, understands caching / object serialization, spark shuffle optimization, streaming</li><li>Demonstrated experience with agile scrum methodology </li><li>Strong desire to learn new technologies and keep up with the latest technologies in the big data space</li><li>Solid leadership and mentorship skills </li><li>Well-developed verbal and written communication skills.</li><li>Experience using CI / CD tools and project build automation, Git, Jenkins, Maven, PyPi, etc. preferred</li><li>Experience with enabling Data Science and Self Service product development with clean, reliable data sets a plus</li><li>Airflow, a plus</li><li>Industry recognized certifications, a plus<br><br></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Apparel & Fashion, Retail, Luxury Goods & Jewelry"
"Data Engineer, Workspace","San Francisco, California, United States",MURAL,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-workspace-at-mural-2422968279?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=9nOF4ROiGm2LjhKXo60M4A%3D%3D&position=9&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"LEAVE YOUR MARK ON A BETTER WORLD.
COLLABORATE WITH AMAZING PEOPLE.
MAKE CHANGE HAPPEN.

At North Highland, we believe in doing great things together. With you. With our clients. With a perspective on actions today that shape tomorrow. As the world’s most innovative, collaborative consulting group, we’ve built a space to share ideas like never before. Do you have the skills, passion and commitment to transform industries for the better? Think you can bring your A-game every day? If so, join us. We like big thinkers with action on the brain…

Want to support fresh perspectives with all the right insights? Our Data & Analytics experts help clients realize their true potential. Through a combination of analytics, management, visualization and data engineering, we bring the best decisions to light across a number of key industries. As part of our team, you’ll be getting to the heart of trends, behaviors and worthwhile investments.

Why North Highland? Every choice you make will give you the opportunity to grow. It’s our employee ownership model - with plenty of coaching and personal development opportunities in the mix. For us, training doesn’t have an off switch. You’ll learn new things, both during and beyond traditional working hours. We want people who strive for the next level, then the next.

At North Highland, you’re never a number. Our firm is large enough to scale up, test your mettle and tackle big challenges, but small enough that clients won’t lose your face in a crowd. You’re recognized individually.

We started as three leaders and a kitchen table. Which means we know expectations are made to be broken. Want to surprise us? Do it. Experiment and stretch yourself. There’s room to grow as a budding entrepreneur.

Data Analytics Engineer, Analyst

Data & Analytics is North Highland’s leading growth area and we are looking for a Data Analytics Engineer to join our Data & Analytics capability, focusing on advanced analytics, data visualization, machine learning, data wrangling, and emerging cloud technologies. Most companies are storing more data than is contained in the United States Library of Congress, and according to Gartner, that will increase by 650% over the next five years. The capacity to create value from Big Data, now a game changer, is quickly becoming the price to play. We have executed more than 200 solutions for some of the world's largest healthcare, financial services, telecommunications and public sector enterprises. We work together with business owners and IT teams alike to create immediate value.

The Exciting Work You Will Do

Use knowledge of data analytics to increase client impact, develop your skill-sets and grow your career
Work with new and emerging technologies
Work on advanced analytical projects for clients under supervision of lead data scientist
Effectively communicating with internal teams and external clients to understand the business problem, work through solutioning, and present analytic findings to the client
Building effective visual presentations and analytical dashboards using PowerBI, Tableau and other tools to present analytical findings
Handling large volumes of data in a variety of formats for preparation of data insights
Rapid prototyping and exploratory analytical work in the North Highland Insight Lab using commercial, public and private data
Being a part of a collaborative team working to creatively solve complex technical and business problems that in the end drive real business value
Make your mark by working directly with clients as a visible and engaged member of the team
Collaborate across disciplines to deliver creative solutions to client challenges
Actively contribute to business development proposals and the identification of new opportunities
Establish positive relationships with clients and peers that build credibility, foster your support network and empower career development
Develop a deeper understanding of our firm’s shared vision to build our clients capabilities and unleash their potential



Qualifications

At least 3-7 years of hands-on data experience
Motivated self-starter enjoying the fast-paced world of analytics consulting
Bachelor's Degree in Information Systems, Computer Science or Computer Engineering or other related fields
Solid interpersonal and communication skills (written and verbal) to technical and non-technical audience of wide variety of levels including client-facing senior management
Analytical scripting language skills, such as Python, R, SAS
Data Visualization tools: Tableau, Qlikview, Power BI
Familiarity with the scripting data and machine learning ecosystems - (Jupyter Notebooks, scikit-learn, SciPy, NumPy, pandas, Matplotlib, TensorFlow, etc.)
Experience with wide array of analytical approaches (correlation analysis, predictive and explanatory modeling, data mining, unsupervised clustering, analysis of unstructured data)
Solid SQL skills via exposure to RDBMS’s such as Amazon Redshift, Google Cloud BigQuery, SQL Server, Oracle, Teradata, postgres, etc.
Familiarity with cloud technologies Data warehouse (BigQuery, RedShift) / cloud storage (GS, S3) / app engine (GCP App Engine, AWS Elastic Beanstalk)
Experience with ""Big Data"" environments
Working knowledge of data movement ETL technologies Stored procedures, SSIS, Informatica, Alteryx
Ability to gather and document business requirements and translate them to technical requirements
Understanding of business functions (sales, finance, marketing, operations) and how they relate to business intelligence solutions
Has the investigative mindset and related skills that can be used with any number of tools to explore available data
Ability to self-direct and manage priorities; ability to handle issues that are not well-defined and/or conflict with available information; ability to successfully navigate ambiguity to resolution
Willingness to travel to fulfill client requirements and project needs



Preferred Skills

Master's degree in MIS or Analytics
Professional certifications in data technologies (BI tools, cloud technologies, ETL, etc.)
Familiarity with dimensional modeling techniques (star schemas, facts, dimensions, etc.)
Ability to build and maintain relationships across the organization, and influence senior management, peers and staff through an inclusive style and recognition of their abilities to achieve results


Applicants must be authorized to work in the United States without the need for visa sponsorship by North Highland. Work visa sponsorship will not be provided, now or in the future, for this position.

Click HERE to apply

North Highland makes change happen for organizations who dare to be different. By melding workforce, customer and operational transformation, they are one of the world’s leading consulting groups, with 65+ offices around the globe. They break new ground today so tomorrow is easier to explore.

For more information, visit northhighland.com and connect with us on LinkedIn , Twitter and Facebook .

North Highland is an Equal Employment Opportunity (EEO)/Affirmative Action employer. All qualified applicants will receive fair and impartial consideration without regard to race, color, sex, gender identity, religion, national origin, age, sexual orientation, disability, veteran status, or any other characteristic protected by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>LEAVE YOUR MARK ON A BETTER WORLD. <br></strong><strong> COLLABORATE WITH AMAZING PEOPLE. <br></strong><strong> MAKE CHANGE HAPPEN. <br><br></strong>At North Highland, we believe in doing great things together. With you. With our clients. With a perspective on actions today that shape tomorrow. As the world’s most innovative, collaborative consulting group, we’ve built a space to share ideas like never before. Do you have the skills, passion and commitment to transform industries for the better? Think you can bring your A-game every day? If so, join us. We like big thinkers with action on the brain…<br><br>Want to support fresh perspectives with all the right insights? Our Data &amp; Analytics experts help clients realize their true potential. Through a combination of analytics, management, visualization and data engineering, we bring the best decisions to light across a number of key industries. As part of our team, you’ll be getting to the heart of trends, behaviors and worthwhile investments.<br><br><strong> Why North Highland? </strong> Every choice you make will give you the opportunity to grow. It’s our employee ownership model - with plenty of coaching and personal development opportunities in the mix. For us, training doesn’t have an off switch. You’ll learn new things, both during and beyond traditional working hours. We want people who strive for the next level, then the next.<br><br><strong> At North Highland, you’re never a number. </strong> Our firm is large enough to scale up, test your mettle and tackle big challenges, but small enough that clients won’t lose your face in a crowd. You’re recognized individually.<br><br><strong> We started as three leaders and a kitchen table. </strong> Which means we know expectations are made to be broken. Want to surprise us? Do it. Experiment and stretch yourself. There’s room to grow as a budding entrepreneur.<br><br><strong> Data Analytics Engineer, Analyst <br><br></strong>Data &amp; Analytics is North Highland’s leading growth area and we are looking for a Data Analytics Engineer to join our Data &amp; Analytics capability, focusing on advanced analytics, data visualization, machine learning, data wrangling, and emerging cloud technologies. Most companies are storing more data than is contained in the United States Library of Congress, and according to Gartner, that will increase by 650% over the next five years. The capacity to create value from Big Data, now a game changer, is quickly becoming the price to play. We have executed more than 200 solutions for some of the world's largest healthcare, financial services, telecommunications and public sector enterprises. We work together with business owners and IT teams alike to create immediate value.<br><br><strong><u>The Exciting Work You Will Do<br></u></strong><ul> <li> Use knowledge of data analytics to increase client impact, develop your skill-sets and grow your career </li> <li> Work with new and emerging technologies </li> <li> Work on advanced analytical projects for clients under supervision of lead data scientist </li> <li> Effectively communicating with internal teams and external clients to understand the business problem, work through solutioning, and present analytic findings to the client </li> <li> Building effective visual presentations and analytical dashboards using PowerBI, Tableau and other tools to present analytical findings </li> <li> Handling large volumes of data in a variety of formats for preparation of data insights </li> <li> Rapid prototyping and exploratory analytical work in the North Highland Insight Lab using commercial, public and private data </li> <li> Being a part of a collaborative team working to creatively solve complex technical and business problems that in the end drive real business value </li> <li> Make your mark by working directly with clients as a visible and engaged member of the team </li> <li> Collaborate across disciplines to deliver creative solutions to client challenges </li> <li> Actively contribute to business development proposals and the identification of new opportunities </li> <li> Establish positive relationships with clients and peers that build credibility, foster your support network and empower career development </li> <li> Develop a deeper understanding of our firm’s shared vision to build our clients capabilities and unleash their potential </li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li> At least 3-7 years of hands-on data experience </li> <li> Motivated self-starter enjoying the fast-paced world of analytics consulting </li> <li> Bachelor's Degree in Information Systems, Computer Science or Computer Engineering or other related fields </li> <li> Solid interpersonal and communication skills (written and verbal) to technical and non-technical audience of wide variety of levels including client-facing senior management </li> <li> Analytical scripting language skills, such as Python, R, SAS </li> <li> Data Visualization tools: Tableau, Qlikview, Power BI </li> <li> Familiarity with the scripting data and machine learning ecosystems - (Jupyter Notebooks, scikit-learn, SciPy, NumPy, pandas, Matplotlib, TensorFlow, etc.) </li> <li> Experience with wide array of analytical approaches (correlation analysis, predictive and explanatory modeling, data mining, unsupervised clustering, analysis of unstructured data) </li> <li> Solid SQL skills via exposure to RDBMS’s such as Amazon Redshift, Google Cloud BigQuery, SQL Server, Oracle, Teradata, postgres, etc. </li> <li> Familiarity with cloud technologies Data warehouse (BigQuery, RedShift) / cloud storage (GS, S3) / app engine (GCP App Engine, AWS Elastic Beanstalk) </li> <li> Experience with ""Big Data"" environments </li> <li> Working knowledge of data movement ETL technologies Stored procedures, SSIS, Informatica, Alteryx </li> <li> Ability to gather and document business requirements and translate them to technical requirements </li> <li> Understanding of business functions (sales, finance, marketing, operations) and how they relate to business intelligence solutions </li> <li> Has the investigative mindset and related skills that can be used with any number of tools to explore available data </li> <li> Ability to self-direct and manage priorities; ability to handle issues that are not well-defined and/or conflict with available information; ability to successfully navigate ambiguity to resolution </li> <li> Willingness to travel to fulfill client requirements and project needs </li> <br><br></ul><strong><u>Preferred Skills<br></u></strong><ul> <li> Master's degree in MIS or Analytics </li> <li> Professional certifications in data technologies (BI tools, cloud technologies, ETL, etc.) </li> <li> Familiarity with dimensional modeling techniques (star schemas, facts, dimensions, etc.) </li> <li> Ability to build and maintain relationships across the organization, and influence senior management, peers and staff through an inclusive style and recognition of their abilities to achieve results </li> <br></ul><strong> <li> Applicants must be authorized to work in the United States without the need for visa sponsorship by North Highland. Work visa sponsorship will not be provided, now or in the future, for this position. <br><br><strong> Click </strong> <strong> HERE </strong> <strong> to apply <br><br></strong>North Highland makes change happen for organizations who dare to be different. By melding workforce, customer and operational transformation, they are one of the world’s leading consulting groups, with 65+ offices around the globe. They break new ground today so tomorrow is easier to explore.<br><br>For more information, visit northhighland.com and connect with us on LinkedIn , Twitter and Facebook .<br><br>North Highland is an Equal Employment Opportunity (EEO)/Affirmative Action employer. All qualified applicants will receive fair and impartial consideration without regard to race, color, sex, gender identity, religion, national origin, age, sexual orientation, disability, veteran status, or any other characteristic protected by law.</li></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Management Consulting"
Data Engineer,"Austin, Texas, United States",REX,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-at-rex-2397947103?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=zbELgbBLu3gZy80Vnuundw%3D%3D&position=10&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"MURAL is on a mission to inspire and connect imagination workers globally.

MURAL is a digital workspace for visual collaboration that connects over 50 percent of the Fortune 100. Teams at global enterprises including IBM, USAA, E-Trade, Intuit, SAP, Atlassian, Autodesk, and GitHub embrace visual collaboration to run more productive meetings and workshops. This leads to a more creative, engaging, and fun way of working together, all in a welcoming, simple-to-use online space.

Headquartered in San Francisco, California, MURAL employs over 300 people around the world. In 2020, MURAL raised $118M in a series B round of financing and are working hard to take MURAL to the next level.

YOUR MISSION

We are looking for a Data Engineer capable of helping create and maintain a new data pipeline architecture at Mural, including the APIs and tools to help other teams use the data. You will be working in the Workspace engineering team and collaborating closely with other teams to help deliver features that are based on data.

This Data Engineer role is a software development role with knowledge of data architectures, APIs, and the delivery and transformation of data in a reliable way.

The ideal candidate is passionate about both developing software, working with data, and is capable of challenging and redesigning existing solutions. They must be a team player, always willing to collaborate with others.

In this role, you will:

Help create the platform, tools and APIs necessary to enable your team (and others) to build features based on data.
Help create a data platform and design optimal solutions.
Work closely with other Product teams to help create experimental data-driven features. You will build the tools and APIs necessary to support those features. A strong analytical mindset is important.
Efficiently handle vast amounts of data from multiple sources and destinations, including relational and NoSQL databases. This may include things like batch processing and real-time delivery.
Follow modern development best practices such as code reviews, unit testing, and continuous integration.
Work well as part of a team. We value team players who share their knowledge and enjoy collaborating with others.
Show initiative, completing your tasks and providing timely status updates to both the rest of your team and all of the stakeholders.
Take ownership of the solutions you build. This means analyzing requirements, building them, monitoring in production, and troubleshooting if problems arise.


YOUR PROFILE

We are looking for a Software Engineer with several years of experience in a development role, preferably with Data Engineering experience.

Strong technical skills and proficiency with any general purpose language (Java, Javascript/Typescript, Python, C#, C++, Go, etc.).
Experience designing and developing web services and REST APIs.
Advanced knowledge of relational databases such as PostgreSQL or MySQL, and capable of writing non-trivial SQL.
Some knowledge of message brokers and event streaming platforms such as Apache Kafka.
Experience with NoSQL databases such as MongoDB.
Experience with Data Lakes and Data Warehouses is a bonus.
Experience with Big Data tools such as Spark is a bonus.
You should be able to create an application from scratch following best practices such as writing clean code with unit tests and using continuous integration.



What We Offer

In addition to being part of our quest to help people empower their imagination, we offer:

Competitive salary and benefits
Flexible working hours
Ability to work remotely
Flexible time off
A phenomenal learning environment for you to develop


OUR VALUES

We bring people to our team that care about our mission to inspire and connect creative people globally, and who feel aligned with our values:

Make Others Successful
Adapt to Thrive
Show Up With a Smile
Generate Wows
Think Global
Play to Win and Have Fun


Practicing equality through imagination work.

MURAL is committed to creating diverse and inclusive workspaces where people can make a positive impact on the world and share their vision of how they achieve it. We are dedicated to working alongside multiple communities to help build this dream and bring it to life.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">MURAL is on a mission to inspire and connect imagination workers globally.<br><br>MURAL is a digital workspace for visual collaboration that <strong>connects over 50 percent of the Fortune 100</strong>. Teams at global enterprises including IBM, USAA, E-Trade, Intuit, SAP, Atlassian, Autodesk, and GitHub embrace visual collaboration to run more productive meetings and workshops. This leads to a more creative, engaging, and fun way of working together, all in a welcoming, simple-to-use online space.<br><br>Headquartered in San Francisco, California, MURAL employs over 300 people around the world. In 2020, MURAL raised $118M in a series B round of financing and are working hard to take MURAL to the next level.<br><br><strong>YOUR MISSION<br><br></strong>We are looking for a Data Engineer capable of helping create and maintain a new data pipeline architecture at Mural, including the APIs and tools to help other teams use the data. You will be working in the Workspace engineering team and collaborating closely with other teams to help deliver features that are based on data.<br><br>This Data Engineer role is a software development role with knowledge of data architectures, APIs, and the delivery and transformation of data in a reliable way.<br><br>The ideal candidate is passionate about both developing software, working with data, and is capable of challenging and redesigning existing solutions. They must be a team player, always willing to collaborate with others.<br><br>In this role, you will:<br><ul> <li>Help create the platform, tools and APIs necessary to enable your team (and others) to build features based on data.</li> <li>Help create a data platform and design optimal solutions.</li> <li>Work closely with other Product teams to help create experimental data-driven features. You will build the tools and APIs necessary to support those features. A strong analytical mindset is important.</li> <li>Efficiently handle vast amounts of data from multiple sources and destinations, including relational and NoSQL databases. This may include things like batch processing and real-time delivery.</li> <li>Follow modern development best practices such as code reviews, unit testing, and continuous integration.</li> <li>Work well as part of a team. We value team players who share their knowledge and enjoy collaborating with others.</li> <li>Show initiative, completing your tasks and providing timely status updates to both the rest of your team and all of the stakeholders.</li> <li>Take ownership of the solutions you build. This means analyzing requirements, building them, monitoring in production, and troubleshooting if problems arise.</li> <br></ul><strong>YOUR PROFILE<br><br></strong>We are looking for a Software Engineer with several years of experience in a development role, preferably with Data Engineering experience.<br><ul> <li>Strong technical skills and proficiency with any general purpose language (Java, Javascript/Typescript, Python, C#, C++, Go, etc.). </li> <li>Experience designing and developing web services and REST APIs.</li> <li>Advanced knowledge of relational databases such as PostgreSQL or MySQL, and capable of writing non-trivial SQL.</li> <li>Some knowledge of message brokers and event streaming platforms such as Apache Kafka.</li> <li>Experience with NoSQL databases such as MongoDB.</li> <li>Experience with Data Lakes and Data Warehouses is a bonus.</li> <li>Experience with Big Data tools such as Spark is a bonus.</li> <li>You should be able to create an application from scratch following best practices such as writing clean code with unit tests and using continuous integration.</li> <br><br></ul><strong><u>What We Offer<br><br></u></strong>In addition to being part of our quest to help people empower their imagination, we offer:<br><ul> <li>Competitive salary and benefits</li> <li>Flexible working hours</li> <li>Ability to work remotely</li> <li>Flexible time off</li> <li>A phenomenal learning environment for you to develop</li> <br></ul>OUR VALUES<br><br>We bring people to our team that care about our mission to inspire and connect creative people globally, and who feel aligned with our values:<br><ul> <li>Make Others Successful</li> <li>Adapt to Thrive</li> <li>Show Up With a Smile</li> <li>Generate Wows</li> <li>Think Global</li> <li>Play to Win and Have Fun</li> <br></ul>Practicing equality through imagination work.<br><br>MURAL is committed to creating diverse and inclusive workspaces where people can make a positive impact on the world and share their vision of how they achieve it. We are dedicated to working alongside multiple communities to help build this dream and bring it to life.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Austin, Texas, United States","ConsumerTrack, Inc.",2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-consumertrack-inc-2405795603?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=UlQmDVtozXXjYAOr3CcZRA%3D%3D&position=11&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"At REX, we are growing fast and hiring passionate, intelligent people to join us on our mission of becoming the BEST company in the world! We are changing the way people buy and sell homes by using technology to make the process more convenient and transparent. Come work with a company that is passionate about putting the consumer first as well as your career growth.



About REX



REX is a well-funded, game-changing real estate technology startup with offices in Austin, Los Angeles, and the Bay Area. With the goal of improving the lives of homebuyers and sellers, REX created a digital platform and real estate service that eliminates traditional agent commissions and shifts control away from agents over to those who matter most: consumers! REX saves homesellers thousands of dollars in fees by going around the MLS to target home-buyers directly with sophisticated marketing that has never been used in real estate. Since its launch in Southern California, REX has expanded to 17 states and over 250 employees. Throughout the years, REX has represented homes cumulatively valued at over $1 billion and in the process, saved customers over $20 million in fees they otherwise would have paid traditional brokers.



About the Position



As a DevOps Engineer, you’ll work on solving scalability, performance, and automation problems, and helping us to grow our business. You’ll be responsible for both customer-facing and internal systems. You’ll also be responsible for working with, helping, or teaching other engineers about how to run systems that are reliable, performant, scalable, and automated. You’ll be flexible and open-minded about using a wide variety of tools and will focus on getting the job done right, not on processes and rules. You’ll add, create or enforce formal processes only when it helps us to move faster.



As a Data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.



As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.



Experience & Qualifications



Our ideal candidate brings the following:



Significant experience with multiple data platforms, including SQL and NoSQL systems.
Experience with ETL pipelines
Comfortable coding in backend languages such as Java, Python, and Go
AWS experience
Experience with distributed batch data-processing techniques and tools

Bonus Points:



Experience with web-scale architectures
Kafka
Spark
Map-Reduce, Hive or any big data technology
DRUID
Java proficiency
Python proficiency 

Social Mission:



REX sets aside a portion of all income from selling homes to fund homes for families in dire need. It is our mission to contribute one home for every 50 homes we sell. We started in Sihanoukville, Cambodia, where we partnered with World Housing and the Cambodian Children's Fund to help homeless families get back on their feet.



Perks and Benefits



At REX, we appreciate diverse perspectives and want each person to feel valued and impactful in their work. We believe in nurturing your career growth at a fast pace and giving recognition where it's due! 



Listed below are just some of the awesome perks available when joining REX:



Competitive base & bonus packages plus stock options
Open and flexible PTO plan
Benefits, including medical, dental & vision insurance, as well as 401(k)
Career growth opportunities 
Cell phone & Internet reimbursement for some roles
Parental leave 
Employer discounts on select home services
Some perks do not apply to contract workers or interns

Additional Information



As a pioneer in our industry, REX is setting new standards in the marketplace – for quality, innovation, integrity, professionalism, drive, consumer happiness, and social good. Our culture, together with our business vision and goals, serve as an orientation for leadership and a guide for how we conduct ourselves in day-to-day business. They also form the foundation for hiring, encouraging and rewarding great people. In addition, REX has been committed to doing good things for real estate consumers and to providing homes for those in the greatest need, wherever they may be. For every 50 homes we sell, we provide a home for a family in need. We started by funding the construction of a home for a family in Cambodia at the end of 2015. In addition to funding homes, the REX team regularly provides hands-on support to local nonprofits that provide shelter to families.



Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>At REX, we are growing fast and hiring passionate, intelligent people to join us on our mission of becoming the BEST company in the world! We are changing the way people buy and sell homes by using technology to make the process more convenient and transparent. Come work with a company that is passionate about putting the consumer first as well as your career growth.<br><br></p><p><strong>About REX<br><br></strong></p><p>REX is a well-funded, game-changing real estate technology startup with offices in Austin, Los Angeles, and the Bay Area. With the goal of improving the lives of homebuyers and sellers, REX created a digital platform and real estate service that eliminates traditional agent commissions and shifts control away from agents over to those who matter most: consumers! REX saves homesellers thousands of dollars in fees by going around the MLS to target home-buyers directly with sophisticated marketing that has never been used in real estate. Since its launch in Southern California, REX has expanded to 17 states and over 250 employees. Throughout the years, REX has represented homes cumulatively valued at over $1 billion and in the process, saved customers over $20 million in fees they otherwise would have paid traditional brokers.<br><br></p><p><strong>About the Position<br><br></strong></p><p>As a DevOps Engineer, you’ll work on solving scalability, performance, and automation problems, and helping us to grow our business. You’ll be responsible for both customer-facing and internal systems. You’ll also be responsible for working with, helping, or teaching other engineers about how to run systems that are reliable, performant, scalable, and automated. You’ll be flexible and open-minded about using a wide variety of tools and will focus on getting the job done right, not on processes and rules. You’ll add, create or enforce formal processes only when it helps us to move faster.<br><br></p><p>As a Data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.<br><br></p><p>As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.<br><br></p><p><strong>Experience &amp; Qualifications<br><br></strong></p><p>Our ideal candidate brings the following:<br><br></p><ul><li>Significant experience with multiple data platforms, including SQL and NoSQL systems.</li><li>Experience with ETL pipelines</li><li>Comfortable coding in backend languages such as Java, Python, and Go</li><li>AWS experience</li><li>Experience with distributed batch data-processing techniques and tools</li></ul><p><strong>Bonus Points:<br><br></strong></p><ul><li>Experience with web-scale architectures</li><li>Kafka</li><li>Spark</li><li>Map-Reduce, Hive or any big data technology</li><li>DRUID</li><li>Java proficiency</li><li>Python proficiency&nbsp;</li></ul><p><strong>Social Mission:<br><br></strong></p><p>REX sets aside a portion of all income from selling homes to fund homes for families in dire need. It is our mission to contribute one home for every 50 homes we sell. We started in Sihanoukville, Cambodia, where we partnered with World Housing and the Cambodian Children's Fund to help homeless families get back on their feet.<br><br></p><p>Perks and Benefits<br><br></p><p>At REX, we appreciate diverse perspectives and want each person to feel valued and impactful in their work. We believe in nurturing your career growth at a fast pace and giving recognition where it's due!&nbsp;<br><br></p><p>Listed below are just some of the awesome perks available when joining REX:<br><br></p><ul><li>Competitive base &amp; bonus packages plus stock options</li><li>Open and flexible PTO plan</li><li>Benefits, including medical, dental &amp; vision insurance, as well as 401(k)</li><li>Career growth opportunities&nbsp;</li><li>Cell phone &amp; Internet reimbursement for some roles</li><li>Parental leave&nbsp;</li><li>Employer discounts on select home services</li><li>Some perks do not apply to contract workers or interns</li></ul><p><strong>Additional Information<br><br></strong></p><p>As a pioneer in our industry, REX is setting new standards in the marketplace – for quality, innovation, integrity, professionalism, drive, consumer happiness, and social good. Our culture, together with our business vision and goals, serve as an orientation for leadership and a guide for how we conduct ourselves in day-to-day business. They also form the foundation for hiring, encouraging and rewarding great people. In addition, REX has been committed to doing good things for real estate consumers and to providing homes for those in the greatest need, wherever they may be. For every 50 homes we sell, we provide a home for a family in need. We started by funding the construction of a home for a family in Cambodia at the end of 2015. In addition to funding homes, the REX team regularly provides hands-on support to local nonprofits that provide shelter to families.<br><br></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Internet, Financial Services, Real Estate"
Business Intelligence (BI) Engineer,"Portland, Oregon, United States",Columbia Sportswear Company,2021-02-09,https://www.linkedin.com/jobs/view/business-intelligence-bi-engineer-at-columbia-sportswear-company-2402767230?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=gNEUgzbZl5PL84RwY40p7A%3D%3D&position=12&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Description

ConsumerTrack™ is unique in the digital marketing and media industry - we combine marketing, digital, content and fintech. Our performance based approach increases brand awareness and generates targeted audience engagement on our internal web properties and partner sites.

Learn More About What We Do

The ConsumerTrack has big growth plans ahead and is looking for a rockstar Data Engineer experienced in Data warehousing and Python to join our Data Engineering team. The CTI Data Engineering team is responsible for designing and developing the Data lake, enterprise database, data warehouse, reporting solutions, and pipelines for data processing. If you are a critical thinker with a solid track record of developing data solutions and solving complex problems with SQL and Python, we want you to join our team! You will play a vital role in designing and developing our next generation data pipelines and data platform. Join the team and prototype new data product ideas and concepts!

Functions/Responsibilities

Build and maintain multiple data pipelines to ingest new data sources (API and file-based) and support products used by both external users and internal teams.
Optimize by building tools to evaluate and automatically monitor data quality, develop automated scheduling, testing, and distribution of feeds.
Work with our data science and product management teams to design, rapid prototype, and productize new data product ideas and capabilities.
Work with the data engineering team to migrate and enhance our existing Pentaho-based ETL pipeline to a new ELT-based/SaaS Integration system.
Conquer complex problems by finding new ways to solve with simple, efficient approaches with a focus on reliability, scalability, quality, and cost of our platforms.
Build processes supporting data transformation, data structures metadata, and workload management.
Collaborate with the team to perform root cause analysis and audit internal and external data and processes to help answer specific business questions.



Requirements

Basic Qualifications:

Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field.
3+ years of professional Dimensional Data Warehousing/Data Modeling and ‘Big Data’ Experience.
Strong skills to write complex, highly-optimized SQL queries across large volumes of data.
Comfortable working directly with data analytics to bridge business requirements with data engineering.
Experience with AWS infrastructure.
Must have excellent troubleshooting and problem-solving skills.
Ability to operate in an agile, entrepreneurial start-up environment, and prioritize.
Excellent communication and teamwork, and a passion for learning.
Curiosity and passion for data, visualization, and solving problems.
Willingness to question the validity, accuracy of data and assumptions.



Preferred Qualifications

Experience with Redshift, Snowflake, or other MPP databases is a plus.
Knowledge for ETL/ELT tools like Informatica, IBM DataStage, or SaaS ETL tools is a plus.
Experience with Tableau or other reporting tools is a plus.



Benefits

Competitive salary with excellent growth opportunity; we pride ourselves in having a team that exudes leadership, high initiative, creativity and passion.
Awesome medical, dental and vision plans with heavy employer contribution.
Paid maternity leave and paternity leave programs.
Paid vacation, sick days and holidays.
Company funding for outside classes and conferences to help you improve your skills.
Contribution to student loan debt payments after the first year of employment.
401(k) -- employees can start contributing immediately. After the first year, CTI matches your contribution up to 4% of your salary.


A note about our response to COVID -19 and our new norm: The world has changed and we know it’s important to adapt and to do our part to take care of our teams in this global pandemic. Our number one priority is to have our ConsumerTrackers feel safe, balanced and connected. We’re committed to providing our teams with the best resources and tools to navigate this new virtual world that we’re living in. We've also reinvented the ways in which we recognize, celebrate, and engage with each other to keep our culture strong!

Here’s a peek into our world at ConsumerTrack -

Our teams are working remotely 100% for the foreseeable future and have flex time. We’re in the digital media space so we’re mobile and flexible!

*Option to work from an office (if you need to get away!)
Tools & resources are available to keep our team connected across North America. (JIRA, Trello, Airtable, Slack, Zoom and so much more!)
To keep our community of ConsumerTrackers engaged and connected, virtual team building events are held weekly and monthly.
For wellness and balance, weekly virtual fitness classes such as yoga are available.
To care for the local communities that we’re a part of across the U.S our team members host socially distanced philanthropic events every quarter.
And most importantly, we’ve committed to consistent and transparent communication to help us all stay informed, engaged and to keep us on our path to success and #greatness.


We are an equal-opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>ConsumerTrack™ is unique in the digital marketing and media industry - we combine marketing, digital, content and fintech. Our performance based approach increases brand awareness and generates targeted audience engagement on our internal web properties and partner sites.<br><br><strong><u>Learn More About What We Do<br><br></u></strong>The ConsumerTrack has big growth plans ahead and is looking for a rockstar Data Engineer experienced in Data warehousing and Python to join our Data Engineering team. The CTI Data Engineering team is responsible for designing and developing the Data lake, enterprise database, data warehouse, reporting solutions, and pipelines for data processing. If you are a critical thinker with a solid track record of developing data solutions and solving complex problems with SQL and Python, we want you to join our team! You will play a vital role in designing and developing our next generation data pipelines and data platform. Join the team and prototype new data product ideas and concepts!<br><br><strong><u>Functions/Responsibilities<br></u></strong><ul> <li>Build and maintain multiple data pipelines to ingest new data sources (API and file-based) and support products used by both external users and internal teams.</li> <li>Optimize by building tools to evaluate and automatically monitor data quality, develop automated scheduling, testing, and distribution of feeds.</li> <li>Work with our data science and product management teams to design, rapid prototype, and productize new data product ideas and capabilities.</li> <li> Work with the data engineering team to migrate and enhance our existing Pentaho-based ETL pipeline to a new ELT-based/SaaS Integration system.</li> <li>Conquer complex problems by finding new ways to solve with simple, efficient approaches with a focus on reliability, scalability, quality, and cost of our platforms.</li> <li>Build processes supporting data transformation, data structures metadata, and workload management.</li> <li>Collaborate with the team to perform root cause analysis and audit internal and external data and processes to help answer specific business questions.</li> <br><br></ul><strong><u>Requirements<br><br></u></strong><strong>Basic Qualifications:<br></strong><ul> <li>Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field.</li> <li>3+ years of professional Dimensional Data Warehousing/Data Modeling and ‘Big Data’ Experience.</li> <li>Strong skills to write complex, highly-optimized SQL queries across large volumes of data.</li> <li>Comfortable working directly with data analytics to bridge business requirements with data engineering.</li> <li>Experience with AWS infrastructure.</li> <li>Must have excellent troubleshooting and problem-solving skills.</li> <li>Ability to operate in an agile, entrepreneurial start-up environment, and prioritize.</li> <li>Excellent communication and teamwork, and a passion for learning.</li> <li>Curiosity and passion for data, visualization, and solving problems.</li> <li>Willingness to question the validity, accuracy of data and assumptions.</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Experience with Redshift, Snowflake, or other MPP databases is a plus.</li> <li>Knowledge for ETL/ELT tools like Informatica, IBM DataStage, or SaaS ETL tools is a plus.</li> <li>Experience with Tableau or other reporting tools is a plus.</li> <br><br></ul><strong><u>Benefits<br></u></strong><ul> <li>Competitive salary with excellent growth opportunity; we pride ourselves in having a team that exudes leadership, high initiative, creativity and passion.</li> <li>Awesome medical, dental and vision plans with heavy employer contribution.</li> <li>Paid maternity leave and paternity leave programs.</li> <li>Paid vacation, sick days and holidays.</li> <li>Company funding for outside classes and conferences to help you improve your skills.</li> <li>Contribution to student loan debt payments after the first year of employment.</li> <li>401(k) -- employees can start contributing immediately. After the first year, CTI matches your contribution up to 4% of your salary.</li> <br></ul>A note about our response to COVID -19 and our new norm: The world has changed and we know it’s important to adapt and to do our part to take care of our teams in this global pandemic. Our number one priority is to have our ConsumerTrackers feel safe, balanced and connected. We’re committed to providing our teams with the best resources and tools to navigate this new virtual world that we’re living in. We've also reinvented the ways in which we recognize, celebrate, and engage with each other to keep our culture strong!<br><br>Here’s a peek into our world at ConsumerTrack -<br><ul> <li>Our teams are working remotely 100% for the foreseeable future and have flex time. We’re in the digital media space so we’re mobile and flexible!<br><ul><li>*Option to work from an office (if you need to get away!)</li></ul> </li> <li>Tools &amp; resources are available to keep our team connected across North America. (JIRA, Trello, Airtable, Slack, Zoom and so much more!)</li> <li>To keep our community of ConsumerTrackers engaged and connected, virtual team building events are held weekly and monthly.</li> <li>For wellness and balance, weekly virtual fitness classes such as yoga are available.</li> <li>To care for the local communities that we’re a part of across the U.S our team members host socially distanced philanthropic events every quarter.</li> <li>And most importantly, we’ve committed to consistent and transparent communication to help us all stay informed, engaged and to keep us on our path to success and #greatness.</li> <br></ul><em>We are an equal-opportunity employer, and all qualified applicants will receive consideration for </em><em>employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Online Media, Internet"
Data Engineer,"Redmond, Washington, United States",Apex Systems,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-apex-systems-2417276618?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=valekl6wXjpc%2FWYDxaxE5g%3D%3D&position=13&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"The Business Intelligence (BI) Engineer position within the Enterprise Information Management organization has a passion for telling stories with data, developing insight through visualization, and enabling self-service, data exploration, and discovery. The BI Engineer will participate in the strategic design, development, implementation, and support of data and technology components to further mature Columbia Sportswear’s data access needs. This is a full-time employment position with limited travel requirements.







OUTGROWN YOUR OWN BACKYARD? COME PLAY IN OURS.


At Columbia, we’re as passionate about the outdoors as you are. And while our gear is available worldwide, we’re proud to be based in the Pacific Northwest, where natural wonders are our playground.  





Every product we make and every task we undertake is inspired by the famous words of our founder Gert Boyle: “It’s perfect. Now make it better.” As pioneers of relentless improvement, we are constantly evolving. 





We believe the outdoors is ours to protect and strive to keep our planet healthy. We believe in empowering people to experience the outdoors to the fullest.  





And we believe in you.  





ABOUT THE POSITION 


Although we're an apparel and footwear focused company, technology is central to everything we do.  Columbia Sportswear’s Global Information Services (GIS) teams enable an IT infrastructure across four global brands, a global supply chain, and 500+ geographically dispersed stores.  These teams support in-store, mobile, and data platforms to enhance customer interface and service in an ever-evolving industry.





The Business Intelligence (BI) Engineer position within the Enterprise Information Management organization has a passion for telling stories with data, developing insight through visualization, and enabling self-service, data exploration, and discovery. The BI Engineer will participate in the strategic design, development, implementation, and support of data and technology components to further mature Columbia Sportswear’s data access needs. 





HOW YOU’LL MAKE A DIFFERENCE 



Working closely with other EIM and other Global Information Systems team members to apply advanced technical experience and knowledge to develop, maintain, and monitor complex and critical BI data sources and integration processes.


Facilitate, enable, and expand self-service capabilities with interactive dashboards, reports, and other visualizations.


Provide support and issue resolution by analyzing issues, discovering root-cause, and providing alternative long-term solutions.


Partner with other BI Team members to design, develop, and support semantic layers.


Identify and implement solutions to enhance existing BI infrastructure, processes, and technology. 


Collaborate with subject matter experts to establish the technical vision and requirements to support the business solution.


Participate in the full development lifecycle, from developing business requirements to change management processes and ensuring changes are correctly tested and migrated to production.


Write and maintain technical documentation to describe program development, logic, coding, testing, changes, and corrections as needed as well as create and provide training to business users on Business Intelligence tools ranging from beginner to advanced users





YOU ARE 



Passionate about delivering business value by aligning enterprise analytic systems to the organization's strategic objectives


A skilled communicator able to facilitate discussion at all levels of the organization and develop a sound business understanding to help derive meaningful insights from the data


A Critical thinker with sound judgment and decision-making abilities


A relationship builder, flexible in your approach to designing to solutions that solve business problems.





YOU HAVE 



Minimum 4 years’ of hands-on experience with BI delivery initiatives for data warehouses and related applications using industry standards



Minimum 3 years’ experience in the SQL Server and Azure SQL environment and services


Implementation, development, and support experience with Data Visualization tool - Microsoft Power BI


Knowledge and experience building and designing business intelligence solutions from a technical or business perspective


Experience with installation, configuration, and stabilization of medium to large scale BI/Enterprise Reporting implementations.



Knowledge and experience of relational and dimensional modeling, data warehousing concepts, and methodologies.



Expert in writing T-SQL, DAX as well experience with scripting languages such as PowerShell or Python





To learn more about our hiring process during COVID-19, click here.

















Columbia Sportswear Company and our portfolio of brands, including Columbia, SOREL, Mountain Hardwear and prAna, know a thing or two about adventures. After all, we've been on one since 1938, working to perfect the art of enjoying the outdoors. Behind everything we make is an employee who's found that the greatest adventure starts with joining a company that strives to do the right thing.








This job description is not meant to be an all-inclusive list of duties and responsibilities, but constitutes a general definition of the position's scope and function in the company. 








At Columbia Sportswear Company (CSC), we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, military and veteran status, and any other characteristic protected by applicable law. CSC believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. All employment is decided on the basis of qualifications, merit, and business need.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The Business Intelligence (BI) Engineer position within the Enterprise Information Management organization has a passion for telling stories with data, developing insight through visualization, and enabling self-service, data exploration, and discovery. The BI Engineer will participate in the strategic design, development, implementation, and support of data and technology components to further mature Columbia Sportswear’s data access needs.  This is a full-time employment position with limited travel requirements.<p><br></p><p><br></p><p><strong>OUTGROWN YOUR OWN BACKYARD? COME PLAY IN OURS.<br></strong></p><p>At Columbia, we’re as passionate about the outdoors as you are. And while our gear is available worldwide, we’re proud to be based in the Pacific Northwest, where natural wonders are our playground.&nbsp;&nbsp;<br></p><p><br></p><p>Every product we make and every task we undertake is inspired by the famous words of our founder Gert Boyle: “It’s perfect. Now make it better.” As pioneers of relentless improvement, we are constantly evolving.&nbsp;<br></p><p><br></p><p>We believe the outdoors is ours to protect and strive to keep our planet healthy. We believe in empowering people to experience the outdoors to the fullest.&nbsp;&nbsp;<br></p><p><br></p><p>And we believe in you.&nbsp;&nbsp;<br></p><p><br></p><p><strong>ABOUT THE POSITION&nbsp;<br></strong></p><p>Although we're an apparel and footwear focused company, technology is central to everything we do.&nbsp; Columbia Sportswear’s Global Information Services (GIS) teams enable an IT infrastructure across four global brands, a global supply chain, and 500+ geographically dispersed stores.&nbsp; These teams support in-store, mobile, and data platforms to enhance customer interface and service in an ever-evolving industry.<br></p><p><br></p><p>The Business Intelligence (BI) Engineer position within the Enterprise Information Management organization has a passion for telling stories with data, developing insight through visualization, and enabling self-service, data exploration, and discovery. The BI Engineer will participate in the strategic design, development, implementation, and support of data and technology components to further mature Columbia Sportswear’s data access needs.&nbsp;<br></p><p><br></p><p><strong>HOW&nbsp;YOU’LL&nbsp;MAKE A DIFFERENCE&nbsp;<br><br></strong></p><ul><li><p>Working closely with other EIM and other Global Information Systems team members to apply advanced technical experience and knowledge to develop, maintain, and monitor complex and critical BI data sources and integration processes.<br></p></li><li><p>Facilitate, enable, and expand self-service capabilities with interactive dashboards, reports, and other visualizations.<br></p></li><li><p>Provide support and issue resolution by analyzing issues, discovering root-cause, and providing alternative long-term solutions.<br></p></li><li><p>Partner with other BI Team members to design, develop, and support semantic layers.<br></p></li><li><p>Identify and implement solutions to enhance existing BI infrastructure, processes, and technology.&nbsp;<br></p></li><li><p>Collaborate with subject matter experts to establish the technical vision and requirements to support the business solution.<br></p></li><li><p>Participate in the full development lifecycle, from developing business requirements to change management processes and ensuring changes are correctly tested and migrated to production.<br></p></li><li><p>Write and maintain technical documentation to describe program development, logic, coding, testing, changes, and corrections as needed as well as create and provide training to business users on Business Intelligence tools ranging from beginner to advanced users<br></p></li></ul><p><br></p><p><strong>YOU ARE&nbsp;<br><br></strong></p><ul><li><p>Passionate about delivering business value by aligning enterprise analytic systems to the organization's strategic objectives<br></p></li><li><p>A skilled communicator able to facilitate discussion at all levels of the organization and develop a sound business understanding to help derive meaningful insights from the data<br></p></li><li><p>A Critical thinker with sound judgment and decision-making abilities<br></p></li><li><p>A relationship builder, flexible in your approach to designing to solutions that solve business problems.<br></p></li></ul><p><br></p><p><strong>YOU&nbsp;HAVE&nbsp;<br><br></strong></p><ul><li><p>Minimum 4 years’ of hands-on experience with BI delivery initiatives for data warehouses and related applications using industry standards<br><br></p></li></ul><ul><li><p>Minimum 3 years’ experience in the SQL Server and Azure SQL environment and services<br></p></li><li><p>Implementation, development, and support experience with Data Visualization tool - Microsoft Power BI<br></p></li><li><p>Knowledge and experience building and designing business intelligence solutions from a technical or business perspective<br></p></li><li><p>Experience with installation, configuration, and stabilization of medium to large scale BI/Enterprise Reporting implementations.<br><br></p></li></ul><ul><li><p>Knowledge and experience of relational and dimensional modeling, data warehousing concepts, and methodologies.<br><br></p></li></ul><ul><li><p>Expert in writing T-SQL, DAX as well experience with scripting languages such as PowerShell or Python<br></p></li></ul><p><br></p><p>To learn more about our hiring process during COVID-19, click here.<br></p><p><br></p><p><br></p><p></p><span><br></span><p><br></p><p><br></p><p>Columbia Sportswear Company and our portfolio of brands, including Columbia, SOREL, Mountain Hardwear and prAna, know a thing or two about adventures. After all, we've been on one since 1938, working to perfect the art of enjoying the outdoors. Behind everything we make is an employee who's found that the greatest adventure starts with joining a company that strives to do the right thing.<br></p><p><br></p><p><br></p><p><em><span>This job description is not meant to be an all-inclusive list of duties and responsibilities, but constitutes a general definition of the position's scope and function in the company.&nbsp;<br></span></em></p><p><br></p><p><br></p>At Columbia Sportswear Company (CSC), we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, military and veteran status, and any other characteristic protected by applicable law. CSC believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. All employment is decided on the basis of qualifications, merit, and business need.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Business Development, Sales",Full-time,"Staffing and Recruiting, Consumer Goods, Retail"
Analytics Engineer II,"Austin, Texas, United States",The Zebra,2021-02-09,https://www.linkedin.com/jobs/view/analytics-engineer-ii-at-the-zebra-2415501722?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=2q69ElA%2FAkZvdEOyqT80bA%3D%3D&position=14&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Apex Systems is partnering with a AAA Game Studio in Redmond, WA and looking for a Data Engineer to join the Data Pipeline team.

Logistics

This is an 18 month contract. For the foreseeable future in 2021 it will be 100% remote. However, when it’s safe to go back on campus we’d like employees to be willing and able to go on site in Redmond Town Center. Therefore, non-local candidates are welcome to apply if you’re willing to relocate to Seattle when the pandemic is over.

As a member of the team, you will get to live on the front edge of modern technology by building on things like Azure Data Explorer and Azure Data Lake while building ETLs and process in Databricks and Data Factory. You will help build state of the art pipelines and data models that are at the heart of the studio decision-making process. Your large-scale warehouses will be multi-source environments that present data feeds to real-time production systems. Your customers will be the business, design, test and development teams and they will look to you to help shape how we capture data to improve our test-driven methodologies and build a culture around data driven development.

The successful candidate will bring an attention to detail along with modern engineering practices and help us build a high quality, modern data architecture at scale. ?

Qualifications

5+ years’ experience with SQL Server. Expert level TSQL knowledge required.
5+ years’ experience designing and implementing scalable ETL processes including data movement (SSIS, replication, etc.) and quality tools.
2+ years’ experience building cloud hosted data systems. Azure preferred.
2+ years’ experience with OOP language (C#, Python)
Strong communication and collaboration skills



Preferred

Building pipelines in Azure Data Factory.
Working with data in and from Azure Data Explorer/Kusto.
Modern Big Data Analytics using Data Lake, Spark and formats like Parquet.



EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Apex Systems is partnering with a AAA Game Studio in Redmond, WA and looking for a Data Engineer to join the Data Pipeline team.<br><br><strong><u>Logistics<br><br></u></strong>This is an 18 month contract. For the foreseeable future in 2021 it will be 100% remote. However, when it’s safe to go back on campus we’d like employees to be willing and able to go on site in Redmond Town Center. Therefore, non-local candidates are welcome to apply if you’re willing to relocate to Seattle when the pandemic is over.<br><br>As a member of the team, you will get to live on the front edge of modern technology by building on things like Azure Data Explorer and Azure Data Lake while building ETLs and process in Databricks and Data Factory. You will help build state of the art pipelines and data models that are at the heart of the studio decision-making process. Your large-scale warehouses will be multi-source environments that present data feeds to real-time production systems. Your customers will be the business, design, test and development teams and they will look to you to help shape how we capture data to improve our test-driven methodologies and build a culture around data driven development.<br><br>The successful candidate will bring an attention to detail along with modern engineering practices and help us build a high quality, modern data architecture at scale. ?<br><br><strong><u>Qualifications<br></u></strong><ul> <li>5+ years’ experience with SQL Server. Expert level TSQL knowledge required.</li> <li>5+ years’ experience designing and implementing scalable ETL processes including data movement (SSIS, replication, etc.) and quality tools.</li> <li>2+ years’ experience building cloud hosted data systems. Azure preferred.</li> <li>2+ years’ experience with OOP language (C#, Python)</li> <li>Strong communication and collaboration skills</li> <br><br></ul><strong><u>Preferred<br></u></strong><ul> <li>Building pipelines in Azure Data Factory.</li> <li>Working with data in and from Azure Data Explorer/Kusto.</li> <li>Modern Big Data Analytics using Data Lake, Spark and formats like Parquet.</li> <br><br></ul>EEO Employer<br><br>Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Remote, Oregon, United States",Rhino,2021-02-06,https://www.linkedin.com/jobs/view/data-engineer-at-rhino-2412024026?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=rHctbnlA0rTmF%2BNYQB%2FgWQ%3D%3D&position=15&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"The Zebra is expanding our engineering team and we’re seeking an Analytics Engineer to cleanse and model data to empower end users to answer their own questions. In addition to analyzing data, you will transform, test, deploy, and document. You will apply software engineering best practices like version control, test scripts and continuous integration to the analytics code base.

Our team is passionate about working together to solve interesting problems with technical solutions--and having fun doing it. With a team split between Austin and Africa, we know from experience the importance of diversity within Engineering teams, and we work constantly to ensure everyone has a voice and feels valued. Collaboration is key to our success.

Please note - all new hires must be able to relocate to Austin, Texas by the time of their start date.

This position is not currently eligible for visa sponsorship

What You'll Do

Ensure data is modeled properly so that others can develop dashboards and data solutions to support key initiatives within the organization
Have a significant role in the design and development of our master data models
Provide input on how to integrate additional data sets from independent sources that we can use to leverage our existing data
Work closely with other engineers, analysts and stakeholders across the company to identify data needs across the organization
Document our data models and transformations to provide transparency
Write tests around our data sets
REQUIREMENTS / QUALIFICATIONS:

3+ years of professional (or comparable) analyst experience
Experience with SQL and relational databases
Experience with Data Warehouses such as Snowflake
Experience with BI platforms such as Looker and Tableau
Technical expertise in designing and creating data models
Strong attention to detail
A passion for problem solving with strong analytical capabilities
A desire to follow exceptional software engineering processes, and familiarity with common engineering process tools like Github and Gitlab
Ability to communicate complex information to non-technical audiences


Experience That Will Impress The Heck Out Of Us

Experience with Snowflake, Redshift, or BigQuery
Programming experience in Python
Experience creating data visualizations using Javascript
Github profile or public code portfolio
Advanced STEM degree
BENEFITS + PERKS:

Competitive Compensation & Stock Option Offering
Health, Dental, Vision & Disability Coverages
HSA offering + employer contribution
401k with match
Unlimited PTO + flexibility to enjoy it
Paid Parental Leave Program
Wellness perk ($100/month)
Pet Adoption Reimbursement ($300/year)
Learning & Development Stipends
Bi-Monthly Wednesday Catered Lunch
Zeal Care - Monthly wellness subscriptions ($35/month)
Curated monthly snack box - sent to your house
Opportunity to join Employee Resource Groups (ERGs) or drive our diversity & inclusion stance by creating your own
Join a team that truly lives their values, and values their lives (outside of the office. Cliche, we know… but we really mean it)
ABOUT THE ZEBRA

The Zebra is the nation's leading, independent insurance comparison site. With its dynamic, real-time quote comparison tool, consumers can identify insurance companies with the coverage, service level, and pricing to suit their unique needs. The Zebra compares multiple insurance companies and provides agent support and educational resources to ensure consumers are equipped to make the most informed decisions about their home and auto insurance. Headquartered in Austin, Texas, The Zebra has sought to bring transparency and simplicity to insurance shopping since 2012 — it's ""insurance in black and white.""

The Zebra has garnered the attention and investment of some of the nation’s top venture capitalists, and the company’s success has been profiled in publications like Inc., The New York Times, Forbes, and TechCrunch. Local and national publications have named The Zebra as a Best Place to Work, including Austin Business Journal in 2015, 2016, 2017, 2018, 2020, The Austin American-Statesman in 2016, 2017, 2018, and 2020 and Inc. Magazine on their nationally-recognized list from 2018-2020.

The Zebra is aiming to grow our fantastic team to add to our dynamic culture and continue building on our success. Working at The Zebra means never being bored, always being challenged, and supporting one another. We’re a happy, hardworking group, and we’re eager to add “new stripes” who share those values.

The Zebra is an equal opportunity employer and “at will” company.

As part of our dedication to maintaining an inclusive and diverse workforce, The Zebra provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, The Zebra complies with applicable state and local laws governing nondiscrimination in employment. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

The Zebra expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of The Zebra's employees to perform their job duties may result in discipline up to and including discharge.

**No external recruiters or agents, please.**
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The Zebra is expanding our engineering team and we’re seeking an Analytics Engineer to cleanse and model data to empower end users to answer their own questions. In addition to analyzing data, you will transform, test, deploy, and document. You will apply software engineering best practices like version control, test scripts and continuous integration to the analytics code base.<br><br>Our team is passionate about working together to solve interesting problems with technical solutions--and having fun doing it. With a team split between Austin and Africa, we know from experience the importance of diversity within Engineering teams, and we work constantly to ensure everyone has a voice and feels valued. Collaboration is key to our success.<br><br>Please note - all new hires must be able to relocate to Austin, Texas by the time of their start date.<br><br>This position is not currently eligible for visa sponsorship<br><br><strong> What You'll Do <br></strong><ul><li>Ensure data is modeled properly so that others can develop dashboards and data solutions to support key initiatives within the organization</li><li>Have a significant role in the design and development of our master data models</li><li>Provide input on how to integrate additional data sets from independent sources that we can use to leverage our existing data</li><li>Work closely with other engineers, analysts and stakeholders across the company to identify data needs across the organization</li><li>Document our data models and transformations to provide transparency</li><li>Write tests around our data sets</li></ul>REQUIREMENTS / QUALIFICATIONS:<br><ul><li>3+ years of professional (or comparable) analyst experience</li><li>Experience with SQL and relational databases</li><li>Experience with Data Warehouses such as Snowflake</li><li>Experience with BI platforms such as Looker and Tableau</li><li>Technical expertise in designing and creating data models</li><li>Strong attention to detail</li><li>A passion for problem solving with strong analytical capabilities</li><li>A desire to follow exceptional software engineering processes, and familiarity with common engineering process tools like Github and Gitlab</li><li>Ability to communicate complex information to non-technical audiences<br><br></li></ul><strong> Experience That Will Impress The Heck Out Of Us <br></strong><ul><li>Experience with Snowflake, Redshift, or BigQuery</li><li>Programming experience in Python</li><li>Experience creating data visualizations using Javascript</li><li>Github profile or public code portfolio</li><li>Advanced STEM degree</li></ul>BENEFITS + PERKS:<br><ul><li>Competitive Compensation &amp; Stock Option Offering</li><li>Health, Dental, Vision &amp; Disability Coverages</li><li>HSA offering + employer contribution</li><li>401k with match</li><li>Unlimited PTO + flexibility to enjoy it</li><li>Paid Parental Leave Program</li><li>Wellness perk ($100/month)</li><li>Pet Adoption Reimbursement ($300/year)</li><li>Learning &amp; Development Stipends</li><li>Bi-Monthly Wednesday Catered Lunch</li><li>Zeal Care - Monthly wellness subscriptions ($35/month)</li><li>Curated monthly snack box - sent to your house</li><li>Opportunity to join Employee Resource Groups (ERGs) or drive our diversity &amp; inclusion stance by creating your own</li><li>Join a team that truly lives their values, and values their lives (outside of the office. Cliche, we know… but we really mean it)</li></ul>ABOUT THE ZEBRA<br><br>The Zebra is the nation's leading, independent insurance comparison site. With its dynamic, real-time quote comparison tool, consumers can identify insurance companies with the coverage, service level, and pricing to suit their unique needs. The Zebra compares multiple insurance companies and provides agent support and educational resources to ensure consumers are equipped to make the most informed decisions about their home and auto insurance. Headquartered in Austin, Texas, The Zebra has sought to bring transparency and simplicity to insurance shopping since 2012 — it's ""insurance in black and white.""<br><br>The Zebra has garnered the attention and investment of some of the nation’s top venture capitalists, and the company’s success has been profiled in publications like Inc., The New York Times, Forbes, and TechCrunch. Local and national publications have named The Zebra as a Best Place to Work, including Austin Business Journal in 2015, 2016, 2017, 2018, 2020, The Austin American-Statesman in 2016, 2017, 2018, and 2020 and Inc. Magazine on their nationally-recognized list from 2018-2020.<br><br>The Zebra is aiming to grow our fantastic team to add to our dynamic culture and continue building on our success. Working at The Zebra means never being bored, always being challenged, and supporting one another. We’re a happy, hardworking group, and we’re eager to add “new stripes” who share those values.<br><br>The Zebra is an equal opportunity employer and “at will” company.<br><br>As part of our dedication to maintaining an inclusive and diverse workforce, The Zebra provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, The Zebra complies with applicable state and local laws governing nondiscrimination in employment. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.<br><br>The Zebra expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of The Zebra's employees to perform their job duties may result in discipline up to and including discharge.<br><br>**No external recruiters or agents, please.**</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"Austin, Texas, United States",W2O Group,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-w2o-group-2405210972?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=D70DZeVDtuIBwfGAwJRz8g%3D%3D&position=16&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Our mission is to give renters everywhere greater financial freedom to plan and enjoy their lives.

Our first product eliminates cash security deposits and puts more money back in renters’ pockets. With over $45 billion tied up in security deposits for 110 million renters in the United States alone, it’s time for security deposits to officially become a thing of the past. Tying up money at one of life’s biggest and most expensive moments just isn’t fair.

So we threw out the antiquated “way of doing things” and built a technology-driven insurance product to help bring renting into the 21st century. With Rhino, millions of renters across the country now have the opportunity to save with our award-winning deposit insurance. We’ve already saved hundreds of millions of dollars for renters and are trusted in over 1 million homes nationwide, and most importantly, we’re just getting started...

As a Data Engineer at Rhino, you will build data infrastructure to enable data driven decision making for the whole company.

In This Role You Will

Build scalable data pipelines and API integrations to support continuing increase in data volume and complexity.
Design and build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Create data tools for data science and BI teams to assist them in building and optimizing our product into an innovative industry leader.
Evaluate and integrate open source and vendor tools for various parts of data infrastructure.
Participate in code reviews, standups, and planning sessions, while listening to feedback and commenting on others’ approaches.
Work with stakeholders including the Executive, Product, Data Science and BI teams to assist with data-related technical issues and support their data infrastructure needs.
We’re ideally seeking:

Interest in learning cutting edge technologies such as serverless computing and distributed systems.
Knowledge of object-oriented programming.
Knowledge of SQL.
Strong problem solving skills.
Someone who is excited to quickly ship features in a collaborative, rigorous, and fast-paced environment.
Experience with building ETL pipelines, data warehousing and data modeling.
Experience with Python.
Experience with Google BigQuery and Postgres.
Experience with data pipeline and workflow management tools such as Airflow or Luigi.
Experience with Google Cloud Platform or another cloud platform.
Benefits:

Competitive compensation and 401k
Unlimited PTO to give our employees a little extra R&R when they need it
Stock option plan to give our employees a direct stake in Rhino’s success
Comprehensive health coverage (medical, dental, vision)
Remote Work Program to allow for flexibility between home and the office
Generous Parental Leave to create a family-friendly culture
Wellness Perks (Gym, Classpass, & Citibike Memberships)
Commuter Benefits through a Flexible Spending Account
Fintech Equality Coalition Founding member



Rhino is committed to the principle of equal employment opportunity for all employees, and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Rhino are without regard to race, color, age, religion or belief, sexual orientation, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Rhino has a zero-tolerance policy against discrimination or harassment based on any of these characteristics. This includes recruitment, hiring, promotions, transfers, discipline, terminations, wage and salary administration, benefits, and training.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Our mission is to give renters everywhere greater financial freedom to plan and enjoy their lives.<br><br>Our first product eliminates cash security deposits and puts more money back in renters’ pockets. With over $45 billion tied up in security deposits for 110 million renters in the United States alone, it’s time for security deposits to officially become a thing of the past. Tying up money at one of life’s biggest and most expensive moments just isn’t fair.<br><br>So we threw out the antiquated “way of doing things” and built a technology-driven insurance product to help bring renting into the 21st century. With Rhino, millions of renters across the country now have the opportunity to save with our award-winning deposit insurance. We’ve already saved hundreds of millions of dollars for renters and are trusted in over 1 million homes nationwide, and most importantly, we’re just getting started...<br><br>As a Data Engineer at Rhino, you will build data infrastructure to enable data driven decision making for the whole company.<br><br><strong><u>In This Role You Will<br></u></strong><ul> <li> Build scalable data pipelines and API integrations to support continuing increase in data volume and complexity. </li> <li> Design and build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. </li> <li> Create data tools for data science and BI teams to assist them in building and optimizing our product into an innovative industry leader. </li> <li> Evaluate and integrate open source and vendor tools for various parts of data infrastructure. </li> <li> Participate in code reviews, standups, and planning sessions, while listening to feedback and commenting on others’ approaches. </li> <li> Work with stakeholders including the Executive, Product, Data Science and BI teams to assist with data-related technical issues and support their data infrastructure needs. </li> </ul> <strong>We’re ideally seeking:<br></strong><ul> <li> Interest in learning cutting edge technologies such as serverless computing and distributed systems. </li> <li> Knowledge of object-oriented programming. </li> <li> Knowledge of SQL. </li> <li> Strong problem solving skills. </li> <li> Someone who is excited to quickly ship features in a collaborative, rigorous, and fast-paced environment. </li> <li> Experience with building ETL pipelines, data warehousing and data modeling. </li> <li> Experience with Python. </li> <li> Experience with Google BigQuery and Postgres. </li> <li> Experience with data pipeline and workflow management tools such as Airflow or Luigi. </li> <li> Experience with Google Cloud Platform or another cloud platform. </li> </ul> <strong>Benefits:<br></strong><ul> <li>Competitive compensation and 401k</li> <li>Unlimited PTO to give our employees a little extra R&amp;R when they need it</li> <li>Stock option plan to give our employees a direct stake in Rhino’s success</li> <li>Comprehensive health coverage (medical, dental, vision)</li> <li>Remote Work Program to allow for flexibility between home and the office</li> <li>Generous Parental Leave to create a family-friendly culture</li> <li>Wellness Perks (Gym, Classpass, &amp; Citibike Memberships)</li> <li>Commuter Benefits through a Flexible Spending Account</li> <li>Fintech Equality Coalition Founding member</li> <br><br></ul>Rhino is committed to the principle of equal employment opportunity for all employees, and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Rhino are without regard to race, color, age, religion or belief, sexual orientation, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Rhino has a zero-tolerance policy against discrimination or harassment based on any of these characteristics. This includes recruitment, hiring, promotions, transfers, discipline, terminations, wage and salary administration, benefits, and training.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Big Data Engineer,"Remote, Oregon, United States",Bankers Healthcare Group,2021-02-18,https://www.linkedin.com/jobs/view/big-data-engineer-at-bankers-healthcare-group-2418214814?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=qWgb8iqpaZwGgT85PF18uA%3D%3D&position=17&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Recently named Best Place to Work by MM&M, The Holmes Report, PR News, PRWeek, and AdAge, W2O is an integrated marketing and communications firm powered by analytics and specializing in healthcare. We are currently looking to add talented professionals to our growing team. This is a great opportunity to join a dynamic, fast-growing global agency.

Data Engineer

Recently named Best Place to Work by MM&M, The Holmes Report, PR News, PRWeek, and AdAge, W2O is an integrated marketing and communications firm powered by analytics and specializing in healthcare. We are currently seeking a talented Data Engineer to join our growing team of pharmaceutical advertising, technology and data professionals. This is a great opportunity to join a dynamic, fast-growing global agency.

Role

As a Data Engineer on the technology team, you’ll be responsible for building and maintaining our data warehouse environment, maintaining our internal data processes, and implementing and supporting business intelligence capabilities across multiple business divisions. You will play a key role in helping design our enterprise data architecture to support overarching data governance and related initiatives such as data architecture management, data security management, and data quality management.

This role will be that of an over-arching Data Engineering guru. The ideal candidate will connect and work closely with Data Warehousing, Data Analytics, SW Engineering and Data Sciences as well as Product and Project Management. They will be responsible for solving some of the most complex and high scale data Engineering challenges in our industry while impacting the lives of healthcare professionals and their patients. The ideal candidate must be technologically curious, driven to work with some of newest data engineering technologies on the marketplace today. They will be a visionary and a key driver in the rapid adoption and scalability of crucial data engineering, warehousing and cloud-based technologies.

This Data Engineer will collaborate with executive level internal and external stakeholders. They will lead the development, delivery and implement of AI, IOT, data engineering and data analytics projects which will leverage data to develop industry leading business insights. This person will focus on solutions such as machine learning, IoT, batch/real-time data processing, data and business intelligence while ensuring enterprise wide data security and integrity.

Responsibilities

Design and implement data ingestion solutions on GCP using GCP native services
Demonstrated experience with distributed computing
Design and optimize data models on GCP cloud using GCP data stores such as BigQuery
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Delivery of cloud architecture to support new distributed computing solutions that often span the full array of cloud services. This will include migration of existing applications and development of new applications using cloud services.
Own the Insights gleaned by the creation of advanced technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value.
Innovate and engage with key technology stakeholders to create a compelling vision of a data-driven enterprise environment and the impact it will have on their teams, their projects and their outcomes.Requirements


5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Extensive, demonstrated expertise with Python. should be generally comfortable in different categories (machine learning, development, scripting, etc.)
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Dataflow or Apache (Apex Flink, or Spark) or Kafka in an analytics or data science use case
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Strong analytic skills related to working with unstructured datasets.
Hands on experience leading enterprise-wide data engineering, warehousing and analytics projects
Experience with data pipeline and workflow management tools: Airflow, Oozie etc.
Ability to think strategically about business, product, and technical challenges in an enterprise environment
Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, PostgreSQL, BI reporting and Dashboard development
Demonstrated industry efficiency in the fields of database, data warehousing or data sciences
Customer facing skills with the ability to drive discussions with senior leadership regarding trade-offs, best practices and risk mitigation
Desire and ability to interact with all levels of the organization

W2O Group offers a comprehensive benefit program and perks, including flexible PTO, expanded paid leave for new parents including a 4th Trimester program that helps new parents transition back to work, and a five-week sabbatical program. Other perks include Income Protection, Retirement plans/401(k) match, and cell phone savings plans. Learn more about our great benefits and perks at: http://www.w2ogroup.com/

W2O Group is an Equal Opportunity Employer. We foster an environment that embraces diversity. We are stronger with a wider range of opinions, strengths, and backgrounds to achieve our goals.

W2O Group offers a comprehensive benefit program and perks, including flexible PTO, expanded paid leave for new parents including a 4th Trimester program that helps new parents transition back to work, and a five-week sabbatical program. Other perks include Income Protection, Retirement plans/401(k) match, and cell phone savings plans. Learn more about our great benefits and perks at: http://www.w2ogroup.com/

W2O Group is committed to being an Equal Opportunity employer. As such, we seek motivated and qualified applicants without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where W2O operates. We strive to employ, motivate, advance and reasonably accommodate any qualified employees and applicants. We believe diversity of persons and ideas forms the most comprehensive, forward-looking company.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Recently named Best Place to Work by MM&amp;M, The Holmes Report, PR News, PRWeek, and AdAge, W2O is an integrated marketing and communications firm powered by analytics and specializing in healthcare. We are currently looking to add talented professionals to our growing team. This is a great opportunity to join a dynamic, fast-growing global agency.<br><br>Data Engineer<br><br>Recently named Best Place to Work by MM&amp;M, The Holmes Report, PR News, PRWeek, and AdAge, W2O is an integrated marketing and communications firm powered by analytics and specializing in healthcare. We are currently seeking a talented Data Engineer to join our growing team of pharmaceutical advertising, technology and data professionals. This is a great opportunity to join a dynamic, fast-growing global agency.<br><br><strong><u>Role<br><br></u></strong>As a Data Engineer on the technology team, you’ll be responsible for building and maintaining our data warehouse environment, maintaining our internal data processes, and implementing and supporting business intelligence capabilities across multiple business divisions. You will play a key role in helping design our enterprise data architecture to support overarching data governance and related initiatives such as data architecture management, data security management, and data quality management.<br><br>This role will be that of an over-arching Data Engineering guru. The ideal candidate will connect and work closely with Data Warehousing, Data Analytics, SW Engineering and Data Sciences as well as Product and Project Management. They will be responsible for solving some of the most complex and high scale data Engineering challenges in our industry while impacting the lives of healthcare professionals and their patients. The ideal candidate must be technologically curious, driven to work with some of newest data engineering technologies on the marketplace today. They will be a visionary and a key driver in the rapid adoption and scalability of crucial data engineering, warehousing and cloud-based technologies.<br><br>This Data Engineer will collaborate with executive level internal and external stakeholders. They will lead the development, delivery and implement of AI, IOT, data engineering and data analytics projects which will leverage data to develop industry leading business insights. This person will focus on solutions such as machine learning, IoT, batch/real-time data processing, data and business intelligence while ensuring enterprise wide data security and integrity.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Design and implement data ingestion solutions on GCP using GCP native services </li><li>Demonstrated experience with distributed computing</li><li>Design and optimize data models on GCP cloud using GCP data stores such as BigQuery</li><li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li><li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.</li><li>Delivery of cloud architecture to support new distributed computing solutions that often span the full array of cloud services. This will include migration of existing applications and development of new applications using cloud services.</li><li>Own the Insights gleaned by the creation of advanced technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value.</li></ul><strong><li>Innovate and engage with key technology stakeholders to create a compelling vision of a data-driven enterprise environment and the impact it will have on their teams, their projects and their outcomes.<strong><strong>Requirements<br><br></strong></strong><ul><li>5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field</li><li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li>Extensive, demonstrated expertise with Python. should be generally comfortable in different categories (machine learning, development, scripting, etc.)</li><li>Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Dataflow or Apache (Apex Flink, or Spark) or Kafka in an analytics or data science use case</li><li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li><li>Strong analytic skills related to working with unstructured datasets.</li><li>Hands on experience leading enterprise-wide data engineering, warehousing and analytics projects</li><li>Experience with data pipeline and workflow management tools: Airflow, Oozie etc.</li><li>Ability to think strategically about business, product, and technical challenges in an enterprise environment</li><li>Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, PostgreSQL, BI reporting and Dashboard development</li><li>Demonstrated industry efficiency in the fields of database, data warehousing or data sciences</li><li>Customer facing skills with the ability to drive discussions with senior leadership regarding trade-offs, best practices and risk mitigation</li><li>Desire and ability to interact with all levels of the organization<br></li></ul>W2O Group offers a comprehensive benefit program and perks, including flexible PTO, expanded paid leave for new parents including a <em>4th Trimester</em> program that helps new parents transition back to work, and a five-week sabbatical program. Other perks include Income Protection, Retirement plans/401(k) match, and cell phone savings plans. Learn more about our great benefits and perks at: http://www.w2ogroup.com/<br><br>W2O Group is an Equal Opportunity Employer. We foster an environment that embraces diversity. We are stronger with a wider range of opinions, strengths, and backgrounds to achieve our goals.<br><br>W2O Group offers a comprehensive benefit program and perks, including flexible PTO, expanded paid leave for new parents including a 4th Trimester program that helps new parents transition back to work, and a five-week sabbatical program. Other perks include Income Protection, Retirement plans/401(k) match, and cell phone savings plans. Learn more about our great benefits and perks at: http://www.w2ogroup.com/<br><br>W2O Group is committed to being an Equal Opportunity employer. As such, we seek motivated and qualified applicants without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where W2O operates. We strive to employ, motivate, advance and reasonably accommodate any qualified employees and applicants. We believe diversity of persons and ideas forms the most comprehensive, forward-looking company.</li></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Data Engineer,"Austin, Texas, United States",REEF,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-reef-2323974911?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=pT4UA5a3pfI2xBC1aKsCog%3D%3D&position=18&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Are you ready to join a growing team that puts a premium on productivity and has an award-winning culture, centered around transforming talented employees into effective business leaders?

Then Bankers Healthcare Group is the place for you. We offer innovative financial solutions to licensed and highly-skilled professionals, representing the best of both traditional lending and fintech, and are looking for passionate, impact players to help take our company to the next level.

At BHG, you’ll become immersed in the finance industry—with a variety of loan solutions, credit cards, patient financing, bank programs, and collections services, which have helped BHG become one of the leading providers of finance solutions.

With over 18 years in business, we have the stability of an established company with the speed and agility of a startup, where ingenuity and risk-taking are encouraged, and every employee has the opportunity to learn, grow and thrive.

Who You Are

You are a motivated Data Engineer professional who is passionate about data. You excel at architecting data solution, and have experience building out the next generation of data tools. You are articulate, and thrive in a fast-paced environment where you can change the data infrastructure of the company.

What You’ll Do

Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource 
Enabling real-time analytics and event driven architecture 
Develop pipelines real-time streaming from different sources like FTP, Windows Blob Storage, SQL Server, Cosmos or Mongo DB and scheduling the pipelines as per requirement using Kafka and Databricks 
Work with cross functional teams such as IT and Marketing 


What You’ll Need 

2+ years’ experience in data engineering and custom coding using Python, Java, or Scala utilizing tools such as Databricks.  
Experience working with NoSQL databases such as MongoDB or Cosmos DB 
Experience with real-time analytics and event driven architecture 
Ability to build Python scripts for scheduling, monitoring, & management 
Experience managing Spark and/or Kafka clusters on-prem or in the cloud 
Experience with Data lake or Delta Lake 
Understanding of big data pipelines 
Familiarity with docker 


Life at BHG

At BHG, we work hard and aren’t afraid to take risks. Since the beginning, our core values of PMA (positive mental attitude), team player and loyalty have been the driving force behind every interaction we have between each other and our customers. We have a healthy respect for the daily grind, yet we value work/life balance. We believe that all employees should have the opportunity to lead and that good ideas can come from anyone. From the top-down, our leaders are actively involved not only in strategic oversight and running the business, but also in the wellbeing and growth of all employees. We consider people our #1 asset, and help employees realize their full potential, set and exceed their goals, and explore new opportunities for personal and professional development.

Why You Should Join BHG

Benefits

Some of the benefits you can expect when you join BHG include

We strive to offer amenities, opportunities, events, and programming that support the interests of our teams, while furthering the culture that makes us Great Place to Work® certified.


100% coverage of monthly health insurance premiums
Competitive PTO and vacation policies
Company 401(k) plan with employer contributions after one year
On-site gym access and memberships, with personal trainers, and certified nutritionists on staff
Company-sponsored training and certification opportunities
Monthly award ceremonies where top achievers are celebrated and receive additional bonuses
Ongoing volunteer opportunities to give back to the community through our BHG Cares program


If you’re ready for a career where you can exercise your passions, be surrounded by co-workers who are relentlessly committed to service, and have a team-player mindset, apply today!

Bankers Healthcare Group is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Bankers Healthcare Group is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Are you ready to join a growing team that puts a premium on productivity and has an award-winning culture, centered around transforming talented employees into effective business leaders?<br><br>Then Bankers Healthcare Group is the place for you. We offer innovative financial solutions to licensed and highly-skilled professionals, representing the best of both traditional lending and fintech, and are looking for passionate, impact players to help take our company to the next level.<br><br>At BHG, you’ll become immersed in the finance industry—with a variety of loan solutions, credit cards, patient financing, bank programs, and collections services, which have helped BHG become one of the leading providers of finance solutions.<br><br>With over 18 years in business, we have the stability of an established company with the speed and agility of a startup, where ingenuity and risk-taking are encouraged, and every employee has the opportunity to learn, grow and thrive.<br><br><strong><u>Who You Are<br><br></u></strong>You are a motivated Data Engineer professional who is passionate about data. You excel at architecting data solution, and have experience building out the next generation of data tools. You are articulate, and thrive in a fast-paced environment where you can change the data infrastructure of the company.<br><br><strong><u>What You’ll Do<br></u></strong><ul><ul><li>Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource  </li><li>Enabling real-time analytics and event driven architecture  </li><li>Develop pipelines real-time streaming from different sources like FTP, Windows Blob Storage, SQL Server, Cosmos or Mongo DB and scheduling the pipelines as per requirement using Kafka and Databricks  </li><li>Work with cross functional teams such as IT and Marketing  <br><br></li></ul></ul><strong><u>What You’ll Need <br></u></strong><ul><ul><li>2+ years’ experience in data engineering and custom coding using Python, Java, or Scala utilizing tools such as Databricks.   </li><li>Experience working with NoSQL databases such as MongoDB or Cosmos DB  </li><li>Experience with real-time analytics and event driven architecture  </li><li>Ability to build Python scripts for scheduling, monitoring, &amp; management  </li><li>Experience managing Spark and/or Kafka clusters on-prem or in the cloud  </li><li>Experience with Data lake or Delta Lake  </li><li>Understanding of big data pipelines  </li><li>Familiarity with docker  <br><br></li></ul></ul><strong>Life at BHG<br><br></strong>At BHG, we work hard and aren’t afraid to take risks. Since the beginning, our core values of PMA (positive mental attitude), team player and loyalty have been the driving force behind every interaction we have between each other and our customers. We have a healthy respect for the daily grind, yet we value work/life balance. We believe that all employees should have the opportunity to lead and that good ideas can come from anyone. From the top-down, our leaders are actively involved not only in strategic oversight and running the business, but also in the wellbeing and growth of all employees. We consider people our #1 asset, and help employees realize their full potential, set and exceed their goals, and explore new opportunities for personal and professional development.<br><br><strong>Why You Should Join BHG<br><br></strong><strong><u>Benefits<br><br></u></strong>Some of the benefits you can expect when you join BHG include<br><br>We strive to offer amenities, opportunities, events, and programming that support the interests of our teams, while furthering the culture that makes us Great Place to Work® certified.<br><br><li> 100% coverage of monthly health insurance premiums</li><li> Competitive PTO and vacation policies</li><li> Company 401(k) plan with employer contributions after one year</li><li> On-site gym access and memberships, with personal trainers, and certified nutritionists on staff</li><li> Company-sponsored training and certification opportunities</li><li> Monthly award ceremonies where top achievers are celebrated and receive additional bonuses</li><li> Ongoing volunteer opportunities to give back to the community through our BHG Cares program<br><br></li>If you’re ready for a career where you can exercise your passions, be surrounded by co-workers who are relentlessly committed to service, and have a team-player mindset, apply today!<br><br><em>Bankers Healthcare Group is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Bankers Healthcare Group is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.<br><br></em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Finance, Consulting",Full-time,"Financial Services, Hospital & Health Care"
Data Engineer,"Salem, Massachusetts, United States",Titan Advanced Energy Solutions,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-titan-advanced-energy-solutions-2416699969?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=dEVqpKNVcb7FFTd77Ulvhg%3D%3D&position=19&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"REEF’s mission is to connect the world to your block.

We transform underutilized urban spaces into neighborhood hubs that connect people to locally curated goods, services, and experiences.

With an ecosystem of 4,500 locations and a team of 15,000 people, REEF is the largest operator of mobility, logistics hubs, and neighborhood kitchens in North America.
Together we are leveraging the power of proximity to keep our communities moving forward in a sustainable and thoughtful way.

What You’ll Do

Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ingestion technics and AWS technologies.
In-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.
Work with stakeholders including internal and external to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.



What We Want From You

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience with big data tools: Hadoop, Hdfs, Spark, Hive, Sqoop, Kafka, Yarn, Zookeeper etc.
Experience in Scala, Python, pySpark, Java, Rest API, Microservices etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structure and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a very fast dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science or another quantitative field. They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases, including redshift, Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, ECS
Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc.
Familiar with data platform like Cloudera, Hortonworks



What We’ll Provide

Medical
Dental
Vision
Life and Disability
401K
Paid Time Off (PTO)

Physical Demands
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.

Frequently operate small office equipment such as a computer, tablet, and copier/printer, telephone.
Work is performed in a professional office environment.



Working Conditions
Work is performed indoors for extended periods of time including up to the entire duration of shift.

REEF Technology is an equal opportunity employer, and we value diversity at our company. REEF does not discriminate on the basis of race, religion, color, sex, national origin, gender identity, gender expression, sexual orientation, age, marital status, veteran status, or disability status. REEF complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">REEF’s mission is to connect the world to your block.<br><br>We transform underutilized urban spaces into neighborhood hubs that connect people to locally curated goods, services, and experiences.<br><br>With an ecosystem of 4,500 locations and a team of 15,000 people, REEF is the largest operator of mobility, logistics hubs, and neighborhood kitchens in North America.<br>Together we are leveraging the power of proximity to keep our communities moving forward in a sustainable and thoughtful way.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Create and maintain optimal data pipeline architecture.</li> <li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li> <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li> <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ingestion technics and AWS technologies.</li> <li>In-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.</li> <li>Work with stakeholders including internal and external to assist with data-related technical issues and support their data infrastructure needs.</li> <li>Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.</li> <li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li> <li>Work with data and analytics experts to strive for greater functionality in our data systems.</li> <br><br></ul><strong><u>What We Want From You<br></u></strong><ul> <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li> <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li> <li>Experience with big data tools: Hadoop, Hdfs, Spark, Hive, Sqoop, Kafka, Yarn, Zookeeper etc.</li> <li>Experience in Scala, Python, pySpark, Java, Rest API, Microservices etc.</li> <li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li> <li>Strong analytic skills related to working with structure and unstructured datasets.</li> <li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li> <li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li> <li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li> <li>Strong project management and organizational skills.</li> <li>Experience supporting and working with cross-functional teams in a very fast dynamic environment.</li> <li>We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science or another quantitative field. They should also have experience using the following software/tools:</li> <li>Experience with relational SQL and NoSQL databases, including redshift, Postgres and Cassandra.</li> <li>Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.</li> <li>Experience with AWS cloud services: EC2, EMR, RDS, Redshift, ECS</li> <li>Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc.</li> <li>Familiar with data platform like Cloudera, Hortonworks</li> <br><br></ul><strong><u>What We’ll Provide<br><br></u></strong>Medical<br>Dental<br>Vision<br>Life and Disability<br>401K<br>Paid Time Off (PTO)<br><br><strong>Physical Demands<br></strong>The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.<br><ul> <li>Frequently operate small office equipment such as a computer, tablet, and copier/printer, telephone.</li> <li>Work is performed in a professional office environment.</li> <br><br></ul><strong>Working Conditions<br></strong>Work is performed indoors for extended periods of time including up to the entire duration of shift.<br><br>REEF Technology is an equal opportunity employer, and we value diversity at our company. REEF does not discriminate on the basis of race, religion, color, sex, national origin, gender identity, gender expression, sexual orientation, age, marital status, veteran status, or disability status. REEF complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Food & Beverages, Financial Services"
Data Engineer,"Remote, Oregon, United States",OODA Health,2021-01-31,https://www.linkedin.com/jobs/view/data-engineer-at-ooda-health-2402624378?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=RAy%2FOUs5lsgRy8ILEzWrrw%3D%3D&position=20&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Are you a Data Engineer with 2+ years of progressive experience looking to join an innovative and dynamic team and the thought of enabling higher adoption of renewable energy and zero emission mobility globally gets you excited?




Located in Salem, MA, Titan Advanced Energy Solutions (Titan) is developing and producing ultrasound-based battery management diagnostic systems for lithium ion batteries (LiBs) for the consumer electronics, automotive, storage, and Second Life markets. Our patented technology provides accurate and practically instantaneous measures of state of charge (SoC) and state of health (SoH). By measuring the battery with this improved accuracy, we provide significant benefits to the whole value chain, including an increase in daily usable charge capacity, longer battery life, unprecedented safety monitoring and control, and real-time cell level monitoring and control. Titan’s value to the LiB is multi-fold, providing net benefits to manufacturers, integrators, producers, and consumers.




Titan’s innovative strides have been recognized with numerous awards and funding from top clean energy programs and institutions, including Greentown Labs, the Massachusetts Clean Energy Center (MassCEC) and the Department of Energy. Growing and poised to continue on their positive momentum, this is an exciting time to join the Titan team!




Reporting to the Head of Algorithm Development, the Data Engineer will work with our multi-disciplined, fast-pace team on a variety of interesting projects. We are looking for an independent thinker who is highly self-motivated, driven to achieve, goal and team-oriented, and passionate about clean technology.




Core Responsibilities

Receive data from the laboratory on daily basis
Use in-house software tools to assess data quality and report issues
Conduct preliminary analyses of data including plotting and simple statistics
Use in-house software to conduct data and signal preprocessing
Merge related data sets and validate
Document and communicate processes to larger team

Required Experience & Skills:

BS/BA in data science, computer science, engineering, statistics, physics, math, or similar
2+ years of experience in data engineer / analyst role, or similar
Passion for managing large multi-dimensional data sets
Basic understanding of electrical systems and signals (voltage, current, etc.)
Basic programming in Python (including Numpy, Pandas, Matplotlib)
Basic knowledge in statistics including hypothesis testing (t-test, ANOVA, etc.)

Preferred Skills & Experience:

Expert programming in Python
Experience with time-domain signal processing
Experience working with non-relational databases
Expert knowledge in statistics and hypothesis testing
Experience with expert-level statistical software (R, or similar)
Agile Methodologies and/or Lean Practices
Start-up experience a plus
Technology development and commercialization
Clear oral and written communication and leadership skills

Personal Values:

·      Bias to action, self-motivated and entrepreneurial spirit

·      Attention to detail, effective time management, and pride in work

·      Dependable, trustworthy, empathetic & full of integrity

·      Strong collaborative communication skills; able to build consensus internally and externally

 

Learn more at www.titanaes.com




Titan welcomes applicants from every background – our diversity helps us thrive and serve our customers and each other. All employment decisions are based on qualifications, merit and business needs, without discrimination or bias. We are proud to be an equal opportunity employer. If you need assistance or an accommodation due to a disability, please let us know.




Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Are you a Data Engineer with 2+ years of progressive experience looking to join an innovative and dynamic team and the thought of enabling higher adoption of renewable energy and zero emission mobility globally gets you excited?</p><p><br></p><p>Located in Salem, MA, Titan Advanced Energy Solutions (Titan) is developing and producing ultrasound-based battery management diagnostic systems for lithium ion batteries (LiBs) for the consumer electronics, automotive, storage, and Second Life markets. Our patented technology provides accurate and practically instantaneous measures of state of charge (SoC) and state of health (SoH). By measuring the battery with this improved accuracy, we provide significant benefits to the whole value chain, including an increase in daily usable charge capacity, longer battery life, unprecedented safety monitoring and control, and real-time cell level monitoring and control. Titan’s value to the LiB is multi-fold, providing net benefits to manufacturers, integrators, producers, and consumers.</p><p><br></p><p>Titan’s innovative strides have been recognized with numerous awards and funding from top clean energy programs and institutions, including Greentown Labs, the Massachusetts Clean Energy Center (MassCEC) and the Department of Energy. Growing and poised to continue on their positive momentum, this is an exciting time to join the Titan team!</p><p><br></p><p>Reporting to the Head of Algorithm Development, the Data Engineer will work with our multi-disciplined, fast-pace team on a variety of interesting projects. We are looking for an independent thinker who is highly self-motivated, driven to achieve, goal and team-oriented, and passionate about clean technology.</p><p><br></p><p><strong>Core Responsibilities</strong></p><ul><li>Receive data from the laboratory on daily basis</li><li>Use in-house software tools to assess data quality and report issues</li><li>Conduct preliminary analyses of data including plotting and simple statistics</li><li>Use in-house software to conduct data and signal preprocessing</li><li>Merge related data sets and validate</li><li>Document and communicate processes to larger team</li></ul><p><strong>Required Experience &amp; Skills</strong>:</p><ul><li>BS/BA in data science, computer science, engineering, statistics, physics, math, or similar</li><li>2+ years of experience in data engineer / analyst role, or similar</li><li>Passion for managing large multi-dimensional data sets</li><li>Basic understanding of electrical systems and signals (voltage, current, etc.)</li><li>Basic programming in Python (including Numpy, Pandas, Matplotlib)</li><li>Basic knowledge in statistics including hypothesis testing (t-test, ANOVA, etc.)</li></ul><p><strong>Preferred</strong> <strong>Skills &amp; Experience:</strong></p><ul><li>Expert programming in Python</li><li>Experience with time-domain signal processing</li><li>Experience working with non-relational databases</li><li>Expert knowledge in statistics and hypothesis testing</li><li>Experience with expert-level statistical software (R, or similar)</li><li>Agile Methodologies and/or Lean Practices</li><li>Start-up experience a plus</li><li>Technology development and commercialization</li><li>Clear oral and written communication and leadership skills</li></ul><p><strong>Personal Values:</strong></p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bias to action, self-motivated and entrepreneurial spirit</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Attention to detail, effective time management, and pride in work</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dependable, trustworthy, empathetic &amp; full of integrity</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Strong collaborative communication skills; able to build consensus internally and externally</p><p><strong>&nbsp;</strong></p><p>Learn more at www.titanaes.com</p><p><br></p><p>Titan welcomes applicants from every background – our diversity helps us thrive and serve our customers and each other. All employment decisions are based on qualifications, merit and business needs, without discrimination or bias. We are proud to be an equal opportunity employer. If you need assistance or an accommodation due to a disability, please let us know.</p><p><br></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Electrical/Electronic Manufacturing
Data Engineer,"New York, New York, United States",HelloFresh,2021-02-03,https://www.linkedin.com/jobs/view/data-engineer-at-hellofresh-2386939750?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=bJI%2F9mrqxs7YBMQlmkFBfQ%3D%3D&position=21&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"OODA Health is a new, mission-driven organization founded by seasoned entrepreneurs who are committed to transforming our healthcare system. OODA is building a revolutionary technology platform through which payers, providers, and patients achieve real-time payment, maximize appropriate care, and reduce unnecessary friction and confusion for all parties. Founded in 2017 with substantial financial backing, we are a passionate, growing team looking for dedicated teammates to make a major impact on the healthcare system. We are committed to living our company values to provide a positive and dynamic working environment for our team members. Based on the principle of Colonel John Boyd’s OODA Loop, we know we must move quickly and with purpose to effect meaningful change in healthcare.

Join a team of data scientists and engineers that leverages diverse healthcare datasets to enhance collaborative, real-time interactions between care providers, payers, and members. We are looking for an experienced data engineer to help us discover and extract information from data in claims, EHRs, and other healthcare-related data sets. Your work will support data-driven insights and discovery, and you will help create data pipelines, real-time reporting, and automation products.

Responsibilities

Build tools and processes to facilitate rapid delivery of accurate, clear, and useful reports
Partner with colleagues in product, engineering, and other teams to gather data well and to interpret and use analytics appropriately
Processing, cleansing, and verifying the integrity of data used for analysis
Building programmatic analysis methods using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Creating automated anomaly detection systems to monitor and improve quality of data flows.


Skills And Qualifications

High proficiency in using query languages (e.g. SQL) and experience working with databases (e.g. AWS MariaDB, Redshift)
Excellent scripting and programming skills especially in Python
Experience with data visualization and reporting tools, such as D3.js, GGplot, Tableau, Qlik
Strong communication skills, including the ability to tell compelling stories with data


Preferred Skills And Experience

Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.
Experience in using API calls and scripting languages to gather data through multiple sources
Familiarity with Healthcare datasets and business models a plus, especially experience or understanding of healthcare billing/claims/Revenue-Cycle-Management
Experience with NLP/Text Analytics and generally leveraging unstructured data sets
Proficiency in using additional query languages beyond SQL such as Hive and experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Familiarity with Healthcare datasets and business models a plus
We offer all employees competitive, data-driven compensation, stock options and generous benefits (which begin on your first day of employment).

OODA Health is an Equal Opportunity Employer. This means we believe:


Discrimination and harassment have no place at OODA, including in our hiring practices or in opportunities you could have while working here. At all, but particularly when based on race, color, religion, gender, gender identity, sexual orientation, pregnancy, family status, religion, national origin, age, disability, genetics, or any other basis forbidden under federal, state or local law.
Equal pay for equal work is a given.
All people, especially BIPOC, deserve a fair chance. So we consider all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.
Diverse teams produce better outcomes, and diverse companies provide richer employee experiences. So we encourage people from all backgrounds to apply.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">OODA Health is a new, mission-driven organization founded by seasoned entrepreneurs who are committed to transforming our healthcare system. OODA is building a revolutionary technology platform through which payers, providers, and patients achieve real-time payment, maximize appropriate care, and reduce unnecessary friction and confusion for all parties. Founded in 2017 with substantial financial backing, we are a passionate, growing team looking for dedicated teammates to make a major impact on the healthcare system. We are committed to living our company values to provide a positive and dynamic working environment for our team members. Based on the principle of Colonel John Boyd’s OODA Loop, we know we must move quickly and with purpose to effect meaningful change in healthcare.<br><br>Join a team of data scientists and engineers that leverages diverse healthcare datasets to enhance collaborative, real-time interactions between care providers, payers, and members. We are looking for an experienced data engineer to help us discover and extract information from data in claims, EHRs, and other healthcare-related data sets. Your work will support data-driven insights and discovery, and you will help create data pipelines, real-time reporting, and automation products.<br><br><strong> Responsibilities <br></strong><ul><li>Build tools and processes to facilitate rapid delivery of accurate, clear, and useful reports</li><li>Partner with colleagues in product, engineering, and other teams to gather data well and to interpret and use analytics appropriately</li><li>Processing, cleansing, and verifying the integrity of data used for analysis</li><li>Building programmatic analysis methods using state-of-the-art methods</li><li>Extending company’s data with third party sources of information when needed</li><li>Creating automated anomaly detection systems to monitor and improve quality of data flows.<br><br></li></ul><strong> Skills And Qualifications <br></strong><ul><li>High proficiency in using query languages (e.g. SQL) and experience working with databases (e.g. AWS MariaDB, Redshift)</li><li>Excellent scripting and programming skills especially in Python </li><li>Experience with data visualization and reporting tools, such as D3.js, GGplot, Tableau, Qlik</li><li>Strong communication skills, including the ability to tell compelling stories with data<br><br></li></ul><strong> Preferred Skills And Experience <br></strong><ul><li>Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.</li><li>Experience in using API calls and scripting languages to gather data through multiple sources </li><li>Familiarity with Healthcare datasets and business models a plus, especially experience or understanding of healthcare billing/claims/Revenue-Cycle-Management</li><li>Experience with NLP/Text Analytics and generally leveraging unstructured data sets</li><li>Proficiency in using additional query languages beyond SQL such as Hive and experience with NoSQL databases, such as MongoDB, Cassandra, HBase</li><li>Familiarity with Healthcare datasets and business models a plus</li></ul>We offer all employees competitive, data-driven compensation, stock options and generous benefits (which begin on your first day of employment).<br><br>OODA Health is an Equal Opportunity Employer. This means we believe:<br><br><li> Discrimination and harassment have no place at OODA, including in our hiring practices or in opportunities you could have while working here. At all, but particularly when based on race, color, religion, gender, gender identity, sexual orientation, pregnancy, family status, religion, national origin, age, disability, genetics, or any other basis forbidden under federal, state or local law.</li><li> Equal pay for equal work is a given.</li><li> All people, especially BIPOC, deserve a fair chance. So we consider all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.</li><li> Diverse teams produce better outcomes, and diverse companies provide richer employee experiences. So we encourage people from all backgrounds to apply.</li></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Financial Services, Hospital & Health Care"
"Data Scientist, Analytics & Inference - New York or Remote","Remote, Oregon, United States",Codecademy,2021-02-14,https://www.linkedin.com/jobs/view/data-scientist-analytics-inference-new-york-or-remote-at-codecademy-2410298488?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=FmU%2B1v%2FOJh0kF71DkcXk6g%3D%3D&position=22&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Come see what’s cookin’ at HelloFresh!

At HelloFresh, we want to revolutionize the way we eat by making it more convenient and exciting to cook meals from scratch. We have offices all over the world and we deliver delicious meals to millions of people.

We are the industry leader in meal-kit subscription services and we’re growing all the time. We have distinct meal-kit services that cater to everyone with the most menu variety in the market, which allows us to reach an incredibly wide population of people.

The HelloFresh team is diverse, high-performing, and international, and our work environment is an inspiring space where you can thrive as a result.

Job Description

We are growing our Data Engineering team to take our data modeling and automation to the next level. The Data Engineering team is part of the broader Growth Organization (Data Science, Digital Product, Marketing) and works closely with Data Scientists to build and maintain best-in-class data products to improve HelloFresh’s user-experience and marketing effectiveness. The Data Engineering department is focused on designing scalable and automated data flows using a variety of big data tools and platforms (AWS Glue, Airflow, Spark, Databricks Cloud etc..)

We are hiring a Data Engineer to play a key role in HelloFresh’s Data Infrastructure & Automation workstreams within the Data Engineering team.

Our vision is to maintain a best-in-class automated data platform directing our marketing initiatives on delivering the right food box at the desired price point to the front door of all our customers. We are looking for someone who can help us with some of our key engineering projects.

You will do ...

Design and deploy cloud-based Data infrastructure (AWS, Databricks)
Implement ETLs monitoring automation
Help design, update and extend HelloFresh's data model (create new schemas, fact tables, mat views, joins, etc.)
Data cleaning/enrichment: keeping data clean and consistent with production systems (e.g. bug fixes, backfills …)
Design and implement end-to-end data products and marketing automation flows: from data ingestions for data science modeling to creation of automated pipelines to external software (Salesforce, etc.)
Data Transformations: implement the logic of the data pipeline (aggregations, projections, selections, etc …)



You are ...

An active, solution-oriented member of autonomous, cross-functional agile teams collaborating with Product Owners, Data Scientists, and Business Intelligence teams
Able to develop an in-depth understanding of HelloFresh’s core product and architecture, and act as an ambassador for state of the art software solutions and industry best practices



At a minimum, you have ...

BSc in a STEM discipline
2+ years’ data engineering experience is required
Proficient in Python (with knowledge of OOP) and SQL (DDL, DML, CTEs, query optimization, ...).
Past experience working with Apache Spark required
Experience with end-to-end testing and general DevOps practices for data pipelines
The ability to design, implement and deliver maintainable and high-quality code using best practices (e.g. git/github, secrets, configurations, yaml/json)
Knowledge of data structures (DataFrames, RDDs, Dataclasses) and data formats (CSV, JSON, Parquet, Avro, ORC)
Experience with software design patterns, and building highly scalable solutions preferred
Experience with job orchestration tools like Airflow, Luigi or similar preferred



You’ll get …

Competitive Salary & 401k company match that vests immediately upon participation
Generous parental leave of 16 weeks & PTO policy
$0 monthly premium and other flexible health plans effective first day of employment
75% discount on your subscription to HelloFresh (as well as other product initiatives)
Snacks, cold brew on tap & monthly catered lunches
Company sponsored outings & Employee Resource Groups
Collaborative, dynamic work environment within a fast-paced, mission-driven company



It is the policy of HelloFresh not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because they are a protected veteran. #zr
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Come see what’s cookin’ at HelloFresh!<br><br></strong>At HelloFresh, we want to revolutionize the way we eat by making it more convenient and exciting to cook meals from scratch. We have offices all over the world and we deliver delicious meals to millions of people.<br><br>We are the industry leader in meal-kit subscription services and we’re growing all the time. We have distinct meal-kit services that cater to everyone with the most menu variety in the market, which allows us to reach an incredibly wide population of people.<br><br>The HelloFresh team is diverse, high-performing, and international, and our work environment is an inspiring space where you can thrive as a result.<br><br><strong><u>Job Description<br><br></u></strong>We are growing our Data Engineering team to take our data modeling and automation to the next level. The Data Engineering team is part of the broader Growth Organization (Data Science, Digital Product, Marketing) and works closely with Data Scientists to build and maintain best-in-class data products to improve HelloFresh’s user-experience and marketing effectiveness. The Data Engineering department is focused on designing scalable and automated data flows using a variety of big data tools and platforms (AWS Glue, Airflow, Spark, Databricks Cloud etc..)<br><br>We are hiring a Data Engineer to play a key role in HelloFresh’s Data Infrastructure &amp; Automation workstreams within the Data Engineering team.<br><br>Our vision is to maintain a best-in-class automated data platform directing our marketing initiatives on delivering the right food box at the desired price point to the front door of all our customers. We are looking for someone who can help us with some of our key engineering projects.<br><br><strong>You will do ...<br></strong><ul> <li>Design and deploy cloud-based Data infrastructure (AWS, Databricks)</li> <li>Implement ETLs monitoring automation</li> <li>Help design, update and extend HelloFresh's data model (create new schemas, fact tables, mat views, joins, etc.)</li> <li>Data cleaning/enrichment: keeping data clean and consistent with production systems (e.g. bug fixes, backfills …)</li> <li>Design and implement end-to-end data products and marketing automation flows: from data ingestions for data science modeling to creation of automated pipelines to external software (Salesforce, etc.)</li> <li>Data Transformations: implement the logic of the data pipeline (aggregations, projections, selections, etc …)</li> <br><br></ul><strong>You are ...<br></strong><ul> <li>An active, solution-oriented member of autonomous, cross-functional agile teams collaborating with Product Owners, Data Scientists, and Business Intelligence teams</li> <li>Able to develop an in-depth understanding of HelloFresh’s core product and architecture, and act as an ambassador for state of the art software solutions and industry best practices</li> <br><br></ul><strong>At a minimum, you have ...<br></strong><ul> <li>BSc in a STEM discipline</li> <li>2+ years’ data engineering experience is required</li> <li>Proficient in Python (with knowledge of OOP) and SQL (DDL, DML, CTEs, query optimization, ...). </li> <li>Past experience working with Apache Spark required</li> <li>Experience with end-to-end testing and general DevOps practices for data pipelines</li> <li>The ability to design, implement and deliver maintainable and high-quality code using best practices (e.g. git/github, secrets, configurations, yaml/json)</li> <li>Knowledge of data structures (DataFrames, RDDs, Dataclasses) and data formats (CSV, JSON, Parquet, Avro, ORC)</li> <li>Experience with software design patterns, and building highly scalable solutions preferred</li> <li>Experience with job orchestration tools like Airflow, Luigi or similar preferred</li> <br><br></ul><strong>You’ll get …<br></strong><ul> <li>Competitive Salary &amp; 401k company match that vests immediately upon participation</li> <li>Generous parental leave of 16 weeks &amp; PTO policy</li> <li>$0 monthly premium and other flexible health plans effective first day of employment</li> <li>75% discount on your subscription to HelloFresh (as well as other product initiatives)</li> <li>Snacks, cold brew on tap &amp; monthly catered lunches</li> <li>Company sponsored outings &amp; Employee Resource Groups</li> <li>Collaborative, dynamic work environment within a fast-paced, mission-driven company</li> <br><br></ul>It is the policy of HelloFresh not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because they are a protected veteran. #zr</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Food & Beverages, Internet"
Data Engineer,"San Francisco, California, United States",Shippo,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-at-shippo-2410476089?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=tPCI2BYVn72KC2rKtbzj0A%3D%3D&position=24&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Before you read on, take a look around you. Chances are, pretty much everything you see has been shipped, often multiple times, in order to get there. E-commerce is exploding, and with it, parcel shipping is becoming a meaningful factor in a business' ability to succeed. Creating a compelling shipping experience for customers is hard but necessary.

At Shippo, our goal is to level the playing field by providing businesses access to shipping tools and terms that would not be available to them otherwise.

Shippo lowers the barriers to shipping for businesses around the world. As free and fast shipping becomes the norm, better access to shipping is a competitive advantage for businesses. Through Shippo, e-commerce businesses, marketplaces, and platforms are able to connect to multiple shipping carriers around the world from one API and dashboard. Businesses can get shipping rates, print labels, automate international documents, track shipments, and facilitate returns.

Internally, we think of Shippo as the building blocks of shipping. Shippos are a diverse set of individuals. We look for cultural and skill fit in every new person. Join us to build the foundations of something great, roll up your sleeves, and get important work done everyday. Founded in 2013, we are a proud team based out of San Francisco. Shippo’s investors include D1 Capital Partners, Bessemer Venture Partners, Union Square Ventures, Uncork Capital, VersionOne Ventures, FundersClub, and others.

We are seeking a new Data Engineer! You will be responsible for building systems to collect and process events of massive scale to gain operational and business insight into the performance and optimization of shipping services.

The data engineer will work closely with product, engineering, and business leads in generating customer-facing and internal dashboards, ad hoc reports, and models to provide insights and affect platform behavior. This will also include building and maintaining the infrastructure to collect and transform raw data.

Responsibilities and Impact

Design, build, scale, and evolve our large scale data infrastructure and processing workflows to support running our business intelligence, data analytics and data science processes
Build robust, efficient and reliable data pipelines and data integration consisting of diverse data sources and transformation techniques, and ensure consistency and availability of data insights
Collaborates with product, engineering and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-informed decision making across the organization
Articulate and present findings and recommendations at different levels, with a clear bias towards impactful learning and results
Develop clean, well-designed, reusable, scalable code following TDD practices Champion engineering organization’s adoption and ongoing use of the data infrastructure
Embody Shippo’s cultural values in your everyday work and interactions
Requirements

3+ years of experience in software development
Experience designing, building, and maintaining data pipeline systemsCoding experience in server-side programming languages (e.g. Python, Scala, Go, Java) as well as database languages (SQL)
Experience with data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, RDBMS, NoSQL, and Columnar databases
Exceptional verbal, written, and interpersonal communication skills
Deep understanding of customer needs and passion for customer success
Exhibit core behaviors focused on craftsmanship, continuous improvement, and team success
BS or MS degree in Computer Science or equivalent experience
Bonus Points

Experience with implementing ETL process
Experience with Big Data frameworks such as Hadoop, MapReduce and associated tools
Experience building stream-processing systems, using solutions such as Kinesis Stream, Kafka or Spark-Streaming
Experience integrating with APIs that use REST, gRPC, SOAP and other technologies
Experience with cloud environments and DevOps tools; working experience with AWS and its associated products a plus Experience with machine learning a plus
Benefits, Perks, and More

Medical, dental, and vision healthcare coverage for you and your dependents. Pets coverage is also available!
Flexible policy for PTO and work arrangement
3 VTO days for ShippoCares volunteering events$2,500 annual learning stipend for your personal and professional growth
Charity donation match up to $100Free daily catered lunch, drinks, and snacks
Fun team events outside of work hours - happy hours, “escape room” adventures, hikes, and more!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Before you read on, take a look around you. Chances are, pretty much everything you see has been shipped, often multiple times, in order to get there. E-commerce is exploding, and with it, parcel shipping is becoming a meaningful factor in a business' ability to succeed. Creating a compelling shipping experience for customers is hard but necessary.<br><br>At Shippo, our goal is to level the playing field by providing businesses access to shipping tools and terms that would not be available to them otherwise.<br><br>Shippo lowers the barriers to shipping for businesses around the world. As free and fast shipping becomes the norm, better access to shipping is a competitive advantage for businesses. Through Shippo, e-commerce businesses, marketplaces, and platforms are able to connect to multiple shipping carriers around the world from one API and dashboard. Businesses can get shipping rates, print labels, automate international documents, track shipments, and facilitate returns.<br><br>Internally, we think of Shippo as the building blocks of shipping. Shippos are a diverse set of individuals. We look for cultural and skill fit in every new person. Join us to build the foundations of something great, roll up your sleeves, and get important work done everyday. Founded in 2013, we are a proud team based out of San Francisco. Shippo’s investors include D1 Capital Partners, Bessemer Venture Partners, Union Square Ventures, Uncork Capital, VersionOne Ventures, FundersClub, and others.<br><br>We are seeking a new Data Engineer! You will be responsible for building systems to collect and process events of massive scale to gain operational and business insight into the performance and optimization of shipping services.<br><br>The data engineer will work closely with product, engineering, and business leads in generating customer-facing and internal dashboards, ad hoc reports, and models to provide insights and affect platform behavior. This will also include building and maintaining the infrastructure to collect and transform raw data.<br><br>Responsibilities and Impact<br><ul><li>Design, build, scale, and evolve our large scale data infrastructure and processing workflows to support running our business intelligence, data analytics and data science processes</li><li>Build robust, efficient and reliable data pipelines and data integration consisting of diverse data sources and transformation techniques, and ensure consistency and availability of data insights </li><li>Collaborates with product, engineering and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-informed decision making across the organization </li><li>Articulate and present findings and recommendations at different levels, with a clear bias towards impactful learning and results </li><li>Develop clean, well-designed, reusable, scalable code following TDD practices Champion engineering organization’s adoption and ongoing use of the data infrastructure </li><li>Embody Shippo’s cultural values in your everyday work and interactions</li></ul>Requirements<br><ul><li> 3+ years of experience in software development</li><li>Experience designing, building, and maintaining data pipeline systemsCoding experience in server-side programming languages (e.g. Python, Scala, Go, Java) as well as database languages (SQL)</li><li>Experience with data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, RDBMS, NoSQL, and Columnar databases</li><li>Exceptional verbal, written, and interpersonal communication skills</li><li>Deep understanding of customer needs and passion for customer success</li><li>Exhibit core behaviors focused on craftsmanship, continuous improvement, and team success</li><li>BS or MS degree in Computer Science or equivalent experience</li></ul>Bonus Points<br><ul><li>Experience with implementing ETL process</li><li>Experience with Big Data frameworks such as Hadoop, MapReduce and associated tools</li><li>Experience building stream-processing systems, using solutions such as Kinesis Stream, Kafka or Spark-Streaming</li><li>Experience integrating with APIs that use REST, gRPC, SOAP and other technologies</li><li>Experience with cloud environments and DevOps tools; working experience with AWS and its associated products a plus Experience with machine learning a plus </li></ul>Benefits, Perks, and More<br><ul><li>Medical, dental, and vision healthcare coverage for you and your dependents. Pets coverage is also available!</li><li>Flexible policy for PTO and work arrangement</li><li>3 VTO days for ShippoCares volunteering events$2,500 annual learning stipend for your personal and professional growth</li><li>Charity donation match up to $100Free daily catered lunch, drinks, and snacks</li><li>Fun team events outside of work hours - happy hours, “escape room” adventures, hikes, and more!</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Entry Level Data Engineer,"Boston, Massachusetts, United States",SPECTRUM Talent Delivery,2021-02-19,https://www.linkedin.com/jobs/view/entry-level-data-engineer-at-spectrum-talent-delivery-2430436916?refId=08b4d902-e5b8-4aae-85c9-ebe756a2d75f&trackingId=fOfe4k8c6sKo1GZmrSSYrg%3D%3D&position=25&pageNum=5&trk=public_jobs_job-result-card_result-card_full-click,"Before you read on, take a look around you. Chances are, pretty much everything you see has been shipped, often multiple times, in order to get there. E-commerce is exploding, and with it, parcel shipping is becoming a meaningful factor in a business' ability to succeed. Creating a compelling shipping experience for customers is hard but necessary.

At Shippo, our goal is to level the playing field by providing businesses access to shipping tools and terms that would not be available to them otherwise.

Shippo lowers the barriers to shipping for businesses around the world. As free and fast shipping becomes the norm, better access to shipping is a competitive advantage for businesses. Through Shippo, e-commerce businesses, marketplaces, and platforms are able to connect to multiple shipping carriers around the world from one API and dashboard. Businesses can get shipping rates, print labels, automate international documents, track shipments, and facilitate returns.

Internally, we think of Shippo as the building blocks of shipping. Shippos are a diverse set of individuals. We look for cultural and skill fit in every new person. Join us to build the foundations of something great, roll up your sleeves, and get important work done everyday. Founded in 2013, we are a proud team based out of San Francisco. Shippo’s investors include D1 Capital Partners, Bessemer Venture Partners, Union Square Ventures, Uncork Capital, VersionOne Ventures, FundersClub, and others.

We are seeking a new Data Engineer! You will be responsible for building systems to collect and process events of massive scale to gain operational and business insight into the performance and optimization of shipping services.

The data engineer will work closely with product, engineering, and business leads in generating customer-facing and internal dashboards, ad hoc reports, and models to provide insights and affect platform behavior. This will also include building and maintaining the infrastructure to collect and transform raw data.

Responsibilities and Impact

Design, build, scale, and evolve our large scale data infrastructure and processing workflows to support running our business intelligence, data analytics and data science processes
Build robust, efficient and reliable data pipelines and data integration consisting of diverse data sources and transformation techniques, and ensure consistency and availability of data insights
Collaborates with product, engineering and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-informed decision making across the organization
Articulate and present findings and recommendations at different levels, with a clear bias towards impactful learning and results
Develop clean, well-designed, reusable, scalable code following TDD practices Champion engineering organization’s adoption and ongoing use of the data infrastructure
Embody Shippo’s cultural values in your everyday work and interactions
Requirements

3+ years of experience in software development
Experience designing, building, and maintaining data pipeline systemsCoding experience in server-side programming languages (e.g. Python, Scala, Go, Java) as well as database languages (SQL)
Experience with data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, RDBMS, NoSQL, and Columnar databases
Exceptional verbal, written, and interpersonal communication skills
Deep understanding of customer needs and passion for customer success
Exhibit core behaviors focused on craftsmanship, continuous improvement, and team success
BS or MS degree in Computer Science or equivalent experience
Bonus Points

Experience with implementing ETL process
Experience with Big Data frameworks such as Hadoop, MapReduce and associated tools
Experience building stream-processing systems, using solutions such as Kinesis Stream, Kafka or Spark-Streaming
Experience integrating with APIs that use REST, gRPC, SOAP and other technologies
Experience with cloud environments and DevOps tools; working experience with AWS and its associated products a plus Experience with machine learning a plus
Benefits, Perks, and More

Medical, dental, and vision healthcare coverage for you and your dependents. Pets coverage is also available!
Flexible policy for PTO and work arrangement
3 VTO days for ShippoCares volunteering events$2,500 annual learning stipend for your personal and professional growth
Charity donation match up to $100Free daily catered lunch, drinks, and snacks
Fun team events outside of work hours - happy hours, “escape room” adventures, hikes, and more!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Before you read on, take a look around you. Chances are, pretty much everything you see has been shipped, often multiple times, in order to get there. E-commerce is exploding, and with it, parcel shipping is becoming a meaningful factor in a business' ability to succeed. Creating a compelling shipping experience for customers is hard but necessary.<br><br>At Shippo, our goal is to level the playing field by providing businesses access to shipping tools and terms that would not be available to them otherwise.<br><br>Shippo lowers the barriers to shipping for businesses around the world. As free and fast shipping becomes the norm, better access to shipping is a competitive advantage for businesses. Through Shippo, e-commerce businesses, marketplaces, and platforms are able to connect to multiple shipping carriers around the world from one API and dashboard. Businesses can get shipping rates, print labels, automate international documents, track shipments, and facilitate returns.<br><br>Internally, we think of Shippo as the building blocks of shipping. Shippos are a diverse set of individuals. We look for cultural and skill fit in every new person. Join us to build the foundations of something great, roll up your sleeves, and get important work done everyday. Founded in 2013, we are a proud team based out of San Francisco. Shippo’s investors include D1 Capital Partners, Bessemer Venture Partners, Union Square Ventures, Uncork Capital, VersionOne Ventures, FundersClub, and others.<br><br>We are seeking a new Data Engineer! You will be responsible for building systems to collect and process events of massive scale to gain operational and business insight into the performance and optimization of shipping services.<br><br>The data engineer will work closely with product, engineering, and business leads in generating customer-facing and internal dashboards, ad hoc reports, and models to provide insights and affect platform behavior. This will also include building and maintaining the infrastructure to collect and transform raw data.<br><br>Responsibilities and Impact<br><ul><li>Design, build, scale, and evolve our large scale data infrastructure and processing workflows to support running our business intelligence, data analytics and data science processes</li><li>Build robust, efficient and reliable data pipelines and data integration consisting of diverse data sources and transformation techniques, and ensure consistency and availability of data insights </li><li>Collaborates with product, engineering and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-informed decision making across the organization </li><li>Articulate and present findings and recommendations at different levels, with a clear bias towards impactful learning and results </li><li>Develop clean, well-designed, reusable, scalable code following TDD practices Champion engineering organization’s adoption and ongoing use of the data infrastructure </li><li>Embody Shippo’s cultural values in your everyday work and interactions</li></ul>Requirements<br><ul><li> 3+ years of experience in software development</li><li>Experience designing, building, and maintaining data pipeline systemsCoding experience in server-side programming languages (e.g. Python, Scala, Go, Java) as well as database languages (SQL)</li><li>Experience with data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, RDBMS, NoSQL, and Columnar databases</li><li>Exceptional verbal, written, and interpersonal communication skills</li><li>Deep understanding of customer needs and passion for customer success</li><li>Exhibit core behaviors focused on craftsmanship, continuous improvement, and team success</li><li>BS or MS degree in Computer Science or equivalent experience</li></ul>Bonus Points<br><ul><li>Experience with implementing ETL process</li><li>Experience with Big Data frameworks such as Hadoop, MapReduce and associated tools</li><li>Experience building stream-processing systems, using solutions such as Kinesis Stream, Kafka or Spark-Streaming</li><li>Experience integrating with APIs that use REST, gRPC, SOAP and other technologies</li><li>Experience with cloud environments and DevOps tools; working experience with AWS and its associated products a plus Experience with machine learning a plus </li></ul>Benefits, Perks, and More<br><ul><li>Medical, dental, and vision healthcare coverage for you and your dependents. Pets coverage is also available!</li><li>Flexible policy for PTO and work arrangement</li><li>3 VTO days for ShippoCares volunteering events$2,500 annual learning stipend for your personal and professional growth</li><li>Charity donation match up to $100Free daily catered lunch, drinks, and snacks</li><li>Fun team events outside of work hours - happy hours, “escape room” adventures, hikes, and more!</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
"Data Engineer - Python, Data Science, Machine Learning","Hazelwood, Missouri, United States",CyberCoders,2021-02-15,https://www.linkedin.com/jobs/view/data-engineer-python-data-science-machine-learning-at-cybercoders-2411971499?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=odnlzztqYnBiOvLF6QWw%2FA%3D%3D&position=1&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Want to be a Data Engineering but seem unable to get your chance? Want to be paid and mentored while learning an in-demand skill? If these resonate with you, we should talk! Spectrum Talent Delivery is expanding and hiring our newest entry level Data Engineers in Boston. We are not an agency. You will be a fulltime employee of Spectrum, get a salary, benefits and PTO. We will pay for any required training you need to be a great engineer! Diverse candidates are encouraged to apply.

We need a Data Engineer to work within an AWS cloud platform. The primary focus of this role is to work alongside and be mentored by senior engineers to design, build & deliver multiple applications and data solutions. This is a hands-on position with 80% focus towards data engineering and 20% towards best practice, unit testing and reviewing code.

Responsibilities

Develop new Platforms and Tools.
Develop new AWS services using S3, Lambda, SNS, Kafka etc.
Build high performing and scalable data ingestion patterns to support multiple batch processing and real-time data streaming.
Develop scalable data engineering platform using cloud infrastructure.
Build processes for supporting data transformation, data structures, metadata, dependency, and workload management.
Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.


Technical Skills Required

Bachelor’s degree in data engineering, business analytics, applied mathematics, computer science, IT, computer applications, engineering or related field is required.
Self-learner and networking skills Experience with AWS cloud services
Strong analytic skills related to working with unstructured datasets.
Understanding of different types of data ingestion like JSON, XML, Parquet file
Understanding of servers, storage, and networking roles Experience with serverless services like Lambda
Understanding of Lean, Agile and iterative delivery frameworks, metrics and methodologies.
Understanding of big data tools: Hadoop, Spark, Kafka, etc.
Understanding of object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Understanding of relational SQL and NoSQL databases, including Postgres and Cassandra.
Understanding of data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Understanding of stream-processing systems: Storm, Spark-Streaming, etc.
Must be able to provide proof of US work authorization without requiring sponsorship now or at any point in the future. We are not able to provide any form of current or future sponsorship.
Able to provide proof of US work authorization without requiring sponsorship now or at any point in the future. We are not able to provide any form of current or future sponsorship.


Eeo Statement

Spectrum values diversity in the workplace and among our customers. The company provides equal opportunity for employment and promotion to all qualified employees and applicants on the basis of experience, training, education, and ability to do the available work without regard to race, religion, color, age, sex/gender, sexual orientation, national origin, gender identity, disability, marital status, veteran status, genetic information, ancestry or any other status protected by law.

Furthermore, Spectrum is committed to providing an equal opportunity workplace that is free of discrimination and harassment based on national origin, race, color, religion, gender, ancestry, age, sexual orientation, gender identity, disability, marital status, veteran status, genetic information or any other status protected by law.

Spectrum Talent Delivery is bridging the ‘Skills Gap’ for STEM graduates. We curate technical professionals by assessing and developing the skills. Do you have a bachelor’s or master’s degree or about to receive one? Excellent! Would you finally like to land that elusive first tech job? Perfect! We’ll hire you into a role and provide fully paid training that is customized to meet your needs and the requirements of the role you’re training for. Real world, on-the-job experience coupled with targeted technical training is just the tip of the iceberg.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Want to be a Data Engineering but seem unable to get your chance? Want to be paid and mentored while learning an in-demand skill? If these resonate with you, we should talk! Spectrum Talent Delivery is expanding and hiring our newest entry level Data Engineers in Boston. We are <strong>not an agency. </strong>You will be a fulltime employee of Spectrum, get a salary, benefits and PTO. We <strong>will pay</strong> for any required training you need to be a great engineer! Diverse candidates are encouraged to apply.<br><br>We need a Data Engineer to work within an AWS cloud platform. The primary focus of this role is to work alongside and be mentored by senior engineers to design, build &amp; deliver multiple applications and data solutions. This is a hands-on position with 80% focus towards data engineering and 20% towards best practice, unit testing and reviewing code.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Develop new Platforms and Tools.</li><li>Develop new AWS services using S3, Lambda, SNS, Kafka etc.</li><li>Build high performing and scalable data ingestion patterns to support multiple batch processing and real-time data streaming.</li><li>Develop scalable data engineering platform using cloud infrastructure.</li><li>Build processes for supporting data transformation, data structures, metadata, dependency, and workload management.</li><li>Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.<br><br></li></ul><strong><u>Technical Skills Required<br></u></strong><ul><li>Bachelor’s degree in data engineering, business analytics, applied mathematics, computer science, IT, computer applications, engineering or related field is required.</li><li>Self-learner and networking skills Experience with AWS cloud services</li><li>Strong analytic skills related to working with unstructured datasets.</li><li>Understanding of different types of data ingestion like JSON, XML, Parquet file</li><li>Understanding of servers, storage, and networking roles Experience with serverless services like Lambda</li><li>Understanding of Lean, Agile and iterative delivery frameworks, metrics and methodologies.</li><li>Understanding of big data tools: Hadoop, Spark, Kafka, etc.</li><li>Understanding of object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.</li><li>Understanding of relational SQL and NoSQL databases, including Postgres and Cassandra.</li><li>Understanding of data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.</li><li>Understanding of stream-processing systems: Storm, Spark-Streaming, etc.</li><li>Must be able to provide proof of US work authorization without requiring sponsorship now or at any point in the future. We are not able to provide any form of current or future sponsorship.</li><li>Able to provide proof of US work authorization without requiring sponsorship now or at any point in the future. We are not able to provide any form of current or future sponsorship.<br><br></li></ul><strong><u>Eeo Statement<br><br></u></strong>Spectrum values diversity in the workplace and among our customers. The company provides equal opportunity for employment and promotion to all qualified employees and applicants on the basis of experience, training, education, and ability to do the available work without regard to race, religion, color, age, sex/gender, sexual orientation, national origin, gender identity, disability, marital status, veteran status, genetic information, ancestry or any other status protected by law.<br><br>Furthermore, Spectrum is committed to providing an equal opportunity workplace that is free of discrimination and harassment based on national origin, race, color, religion, gender, ancestry, age, sexual orientation, gender identity, disability, marital status, veteran status, genetic information or any other status protected by law.<br><br>Spectrum Talent Delivery is bridging the ‘Skills Gap’ for STEM graduates. We curate technical professionals by assessing and developing the skills. Do you have a bachelor’s or master’s degree or about to receive one? Excellent! Would you finally like to land that elusive first tech job? Perfect! We’ll hire you into a role and provide fully paid training that is customized to meet your needs and the requirements of the role you’re training for. Real world, on-the-job experience coupled with targeted technical training is just the tip of the iceberg.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Software Engineer - Data,"San Francisco, California, United States",Blend,2021-02-19,https://www.linkedin.com/jobs/view/software-engineer-data-at-blend-1983863645?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=dtUzaqmySo6BB2uIGlTkCg%3D%3D&position=2&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Title: Data Engineer
Location: Hazelwood, MO 63044
Salary: $70,000 - $90,000/year
Requirements: Bachelors in Computer Science, Python, data science expeirence etc

Founded in 1946, we are one of the global leaders in automotive service equipment, offering cutting edge wheel alignment systems, wheel balancers, tire changers, vehicle inspection equipment, brake lathes and more. We have over 350 patents and foster an environment that encourages creativity and out of the box thinking. For this postion we are targeting to hire a degreed Data Engineer with Pyton & data science background to join our growing team!

Top Reasons to Work with Us

Been around since 1940s
Good market share
strong benefits
ability to be a lead in this position

What You Will Be Doing

Data Acquisition and Manipulation

Create & use PowerShell / Python scripts to acquire and organize data
Create & use VBA scripts in Excel as part of data evaluation
Create & use Python programs to clean and evaluate data
Work w/ source control tools like Microsoft TFS and GIT to save and control data
Annotate data used for training an ML model
Work w/ Azure team to get data from our equipment
Update infrastructure to accommodate the changing needs of data from our equipment

Machine Learning Models

Work with an AI platform like TensorFlow or PyTorch
Configure & use a Linux PC to shorten ML model training times
Test & evaluate ML models
Work w/ Azure team to deploy a trained model

Software

Modify existing software to fix bugs, make improvements and add functionality
Use container software such as Docker to package up results for deployment
Create test programs for a variety of supporting projects

What You Need for this Position

Bachelors in Computer Science, Computer Engineering or Electrical Engineering
Experience in data science (or at least a proven interest in the topic)
Programming experience in Python
3+ years of experience

What's In It for You

Full benefits (Medical / dental / vision / 401k and more)! We have a very strong benefits package and can pay relocation for this role!

So, if you are a Data Engineer with experience...

Apply directly to this link w/ an updated resume & answer all skills questions

OR

Email me an updated resume, salary requirements and interview availability to josh.reifman@cybercoders.com

Email Your Resume In Word To

Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:

Josh.Reifman@CyberCoders.com

Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JR12-1618601 -- in the email subject line for your application to be considered.***

Josh Reifman - Lead Recruiter - CyberCoders

Applicants must be authorized to work in the U.S.

CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Title:</strong> Data Engineer<br><strong>Location:</strong> Hazelwood, MO 63044<br><strong>Salary:</strong> $70,000 - $90,000/year<br><strong>Requirements:</strong> Bachelors in Computer Science, Python, data science expeirence etc<br><br>Founded in 1946, we are one of the global leaders in automotive service equipment, offering cutting edge wheel alignment systems, wheel balancers, tire changers, vehicle inspection equipment, brake lathes and more. We have over 350 patents and foster an environment that encourages creativity and out of the box thinking. For this postion we are targeting to hire a degreed Data Engineer with Pyton &amp; data science background to join our growing team!<br><br>Top Reasons to Work with Us<br><ul><li> Been around since 1940s</li><li> Good market share</li><li> strong benefits</li><li> ability to be a lead in this position<br></li></ul>What You Will Be Doing<br><br>Data Acquisition and Manipulation<br><ul><li> Create &amp; use PowerShell / Python scripts to acquire and organize data</li><li> Create &amp; use VBA scripts in Excel as part of data evaluation</li><li> Create &amp; use Python programs to clean and evaluate data</li><li> Work w/ source control tools like Microsoft TFS and GIT to save and control data</li><li> Annotate data used for training an ML model</li><li> Work w/ Azure team to get data from our equipment</li><li> Update infrastructure to accommodate the changing needs of data from our equipment<br></li></ul>Machine Learning Models<br><ul><li> Work with an AI platform like TensorFlow or PyTorch</li><li> Configure &amp; use a Linux PC to shorten ML model training times</li><li> Test &amp; evaluate ML models</li><li> Work w/ Azure team to deploy a trained model<br></li></ul>Software<br><ul><li> Modify existing software to fix bugs, make improvements and add functionality</li><li> Use container software such as Docker to package up results for deployment</li><li> Create test programs for a variety of supporting projects<br></li></ul>What You Need for this Position<br><ul><li> Bachelors in Computer Science, Computer Engineering or Electrical Engineering</li><li> Experience in data science (or at least a proven interest in the topic)</li><li> Programming experience in Python</li><li> 3+ years of experience<br></li></ul>What's In It for You<br><br>Full benefits (Medical / dental / vision / 401k and more)! We have a very strong benefits package and can pay relocation for this role!<br><br>So, if you are a Data Engineer with experience...<br><ul><li> Apply directly to this link w/ an updated resume &amp; answer all skills questions<br></li></ul>OR<br><ul><li> Email me an updated resume, salary requirements and interview availability to josh.reifman@cybercoders.com<br></li></ul><strong><u>Email Your Resume In Word To<br><br></u></strong>Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:<br><br>Josh.Reifman@CyberCoders.com<br><ul><li>Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JR12-1618601 -- in the email subject line for your application to be considered.***<br></li></ul>Josh Reifman - Lead Recruiter - CyberCoders<br><br>Applicants must be authorized to work in the U.S.<br><br><strong>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br><strong>Your Right to Work</strong> - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Information Technology and Services, Financial Services"
Data Engineer,"Portland, Oregon, United States",Skillz Inc.,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-skillz-inc-2410256562?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=lLud%2BdjzJJLbFk8QM2dm5Q%3D%3D&position=3&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Blend helps lenders maximize their digital agility. Our digital lending platform is used by Wells Fargo, U.S. Bank, and other leading financial institutions to increase customer acquisition, improve productivity, and accelerate the delivery of any banking product across every channel. We process more than $3.5 billion in mortgages and consumer loans daily, helping millions of consumers get into homes and gain access to the capital they need to lead better lives.

We're looking for a Data Engineer who is driven to solve hard problems— the harder, the better. We’re motivated by the fact that our product won’t just affect the lives of a few people in the Bay Area— it affects people all over the U.S., not to mention a foundational part of the U.S. economy. As a Data Engineer, you can define how we instrument our data infrastructure to influence the entire industry. Your contributions to Blend’s data architecture and infrastructure will shape the company’s ability to innovate in the consumer finance space.

Our ideal Data Engineer has hands-on experience building and architecting data pipelines and distributed systems. Using this expertise, you will work both independently and collaboratively with Engineers, Product Managers, and Analysts to appropriately prioritize, execute, and innovate on the organization’s data needs.

Who You Are

At least 2+ years of relevant industry experience
Shipped several large scale projects with multiple dependencies across teams
Recent accomplishments working with relational as well as NoSQL data stores, methods, and approaches (logging, columnar, star and snowflake, dimensional modeling)
Experience in ETL development strongly preferred
Experience working with highly-sensitive data a plus
Experience and interest in working with state-of-the-art data technologies: Hive, Redshift, Snowflake, or other data warehouses strongly preferred
Spark, Presto, Hadoop or other query engines a plus
Kafka, Logstash, Spark Streaming or other stream processing technologies a plus
Experience with Python or Go, Docker, and SQL required; Typescript a plus
Experience with AWS or GCP devops a plusDeep understanding of the infrastructure that powers large scale analytics and machine learning systems a plus
Ability to communicate effectively within and across teams


How You'll Contribute

Design, build, and maintain data pipelines from the ground up that instrument new functionality such as automatic metrics generation, pipeline auditing, and data repopulation
Develop and scale out reporting solutions, delivering actionable insights in an intelligent manner to enable a data-driven decision-making culture for internal and external clients
Drive and lead complex, large projects independently, partnering with product managers and other stakeholders to understand business requirements and craft technical solutions
Ensure accuracy, completeness, and consistency of data
Maximize the impact of our infrastructure
Partner with other engineers, analysts, and product managers to build systems for effective data exploration and consumption
Ensure that all data components are designed and implemented in compliance with our information security requirements
Working in a fast-paced environment where people are valued


Benefits And Perks

Meaningful equity and a 401(k) plan
Comprehensive health benefits
Wellness benefits covering a variety of wellness activities, gym memberships, fitness classes and more
Daily meal stipend for non-regularly remote employees during COVID-19 (and lunch, dinner,snacks, and Pizza Fridays provided in offices outside of COVID-19)
Diversity and inclusion training
Weekly mindfulness meditation class
Weekly remote company all-hands
4 months of paid parental or personal leave
Flexible work schedule, with open vacation policy and companywide mental health days during COVID-19
Work from home office set up stipend and internet stipend during COVID-19


Blend is an equal opportunity employer that values diversity, inclusion and belonging. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity or expression, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by law. We will consider for employment all qualified applicants with arrest and conviction records in a manner consistent with applicable law, including the San Francisco Fair Chance Ordinance.

Blend is an equal opportunity employer that values diversity, inclusion and belonging. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity or expression, sexual orientation, age, marital status, veteran status disability status, or any other characteristic protected by law. We will consider for employment all qualified applicants with arrest and conviction records in a manner consistent with applicable law, including the San Francisco Fair Chance Ordinance.

Notice at Collection for California Applicants
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Blend helps lenders maximize their digital agility. Our digital lending platform is used by Wells Fargo, U.S. Bank, and other leading financial institutions to increase customer acquisition, improve productivity, and accelerate the delivery of any banking product across every channel. We process more than $3.5 billion in mortgages and consumer loans daily, helping millions of consumers get into homes and gain access to the capital they need to lead better lives.<br><br>We're looking for a Data Engineer who is driven to solve hard problems— the harder, the better. We’re motivated by the fact that our product won’t just affect the lives of a few people in the Bay Area— it affects people all over the U.S., not to mention a foundational part of the U.S. economy. As a Data Engineer, you can define how we instrument our data infrastructure to influence the entire industry. Your contributions to Blend’s data architecture and infrastructure will shape the company’s ability to innovate in the consumer finance space.<br><br>Our ideal Data Engineer has hands-on experience building and architecting data pipelines and distributed systems. Using this expertise, you will work both independently and collaboratively with Engineers, Product Managers, and Analysts to appropriately prioritize, execute, and innovate on the organization’s data needs.<br><br><strong><u>Who You Are<br></u></strong><ul><ul><li>At least 2+ years of relevant industry experience</li><li>Shipped several large scale projects with multiple dependencies across teams</li><li>Recent accomplishments working with relational as well as NoSQL data stores, methods, and approaches (logging, columnar, star and snowflake, dimensional modeling)</li><li>Experience in ETL development strongly preferred</li><li>Experience working with highly-sensitive data a plus</li><li>Experience and interest in working with state-of-the-art data technologies: Hive, Redshift, Snowflake, or other data warehouses strongly preferred</li><li>Spark, Presto, Hadoop or other query engines a plus</li><li>Kafka, Logstash, Spark Streaming or other stream processing technologies a plus</li><li>Experience with Python or Go, Docker, and SQL required; Typescript a plus</li><li>Experience with AWS or GCP devops a plusDeep understanding of the infrastructure that powers large scale analytics and machine learning systems a plus</li><li>Ability to communicate effectively within and across teams<br><br></li></ul></ul><strong><u>How You'll Contribute<br></u></strong><ul><ul><li>Design, build, and maintain data pipelines from the ground up that instrument new functionality such as automatic metrics generation, pipeline auditing, and data repopulation</li><li>Develop and scale out reporting solutions, delivering actionable insights in an intelligent manner to enable a data-driven decision-making culture for internal and external clients</li><li>Drive and lead complex, large projects independently, partnering with product managers and other stakeholders to understand business requirements and craft technical solutions</li><li>Ensure accuracy, completeness, and consistency of data</li><li>Maximize the impact of our infrastructure</li><li>Partner with other engineers, analysts, and product managers to build systems for effective data exploration and consumption</li><li>Ensure that all data components are designed and implemented in compliance with our information security requirements</li><li>Working in a fast-paced environment where people are valued<br><br></li></ul></ul><strong><u>Benefits And Perks<br></u></strong><ul><ul><li>Meaningful equity and a 401(k) plan</li><li>Comprehensive health benefits</li><li>Wellness benefits covering a variety of wellness activities, gym memberships, fitness classes and more</li><li>Daily meal stipend for non-regularly remote employees during COVID-19 (and lunch, dinner,snacks, and Pizza Fridays provided in offices outside of COVID-19)</li><li>Diversity and inclusion training </li><li>Weekly mindfulness meditation class</li><li>Weekly remote company all-hands </li><li>4 months of paid parental or personal leave</li><li>Flexible work schedule, with open vacation policy and companywide mental health days during COVID-19</li><li>Work from home office set up stipend and internet stipend during COVID-19<br><br></li></ul></ul>Blend is an equal opportunity employer that values diversity, inclusion and belonging. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity or expression, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by law. We will consider for employment all qualified applicants with arrest and conviction records in a manner consistent with applicable law, including the San Francisco Fair Chance Ordinance.<br><br>Blend is an equal opportunity employer that values diversity, inclusion and belonging. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity or expression, sexual orientation, age, marital status, veteran status disability status, or any other characteristic protected by law. We will consider for employment all qualified applicants with arrest and conviction records in a manner consistent with applicable law, including the San Francisco Fair Chance Ordinance.<br><br>Notice at Collection for California Applicants</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Software, Internet, Financial Services"
Data Science Engineer,"Baltimore, Maryland, United States",Fearless,2021-02-02,https://www.linkedin.com/jobs/view/data-science-engineer-at-fearless-2404988931?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=8NTpDycwJC4LJYKKSd8zfA%3D%3D&position=4&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"About Skillz

Skillz is the leading mobile games platform connecting players in fair, fun, and meaningful competition.

The gaming industry is larger than movies, music, and books, with more than 2.7 billion gamers playing monthly and 10 million developers worldwide. Mobile is the fastest-growing segment of the gaming market, expected to increase from $68 billion in 2019 to $150 billion in 2025.

As the first publicly-traded mobile esports platform, Skillz has pioneered the future of the gaming industry. The Skillz platform helps developers build multi-million dollar franchises by enabling social competition in their games. Leveraging its patented technology, Skillz hosts billions of casual esports tournaments for millions of mobile players worldwide, and distributes millions in prizes each month.

Through its philanthropic initiatives, Skillz has harnessed the power of its platform to transform the way nonprofits engage with donors, enabling anyone with a mobile device to support causes such as the American Red Cross, Susan G. Komen, American Cancer Society, and NAACP by playing in Skillz tournaments.

Skillz has also earned recognition as one of Fast Company’s Most Innovative Companies, a two-time winner of CNBC’s Disruptor 50, one of Forbes’ Next Billion-Dollar Startups, and the #1 fastest-growing company in America on the Inc. 5000.

Who We’re Looking For

You’re ready to take the next step in your Data Engineering career - to a fast-moving, successful company building out their next-generation streaming analytics infrastructure! You love data consistency and integrity. You consider yourself scrappy and a technologist, passionate about data infrastructure... with your attention to detail and insistence on doing things correctly, you know you can make a big impact on a small team! You’re an excellent communicator and know that you grow faster from being able to mentor others.

What You’ll Do

Build new systems to provide real-time streaming analytics and event processing pipeline based on fast data architecture
Build enterprise grade data lake to support both business analytical needs and next generation data infrastructure
Building data integration toolkit for backend services
Support our data science team in deploying new algorithms for matchmaking, fraud and cheat detection
Find better ways to move massive amounts of data from a variety of sources to formats consumable by reporting systems and people
Improve monitoring and alarms that impact data integrity replication lag
Support our product development team in creating new events to measure/track



Basic Qualifications

Your Skillz:

At least 1+ years of experience in Scala/Java or Python programming
AWS data products (Data pipelines, Athena, Pinpoint, S3, etc)
Experience deploying data infrastructure
Experience with recognized industry patterns, methodologies, and techniques



Bonus

Familiarity with Agile engineering practices
1+ years experience on Kubernete, Helm chart
1+ years of experience with Spark, Scala and/or Akka
1+ years of experience with Spark Streaming, Storm, Flink, or other Stream Processing technologies
1+ years of experience working with Kafka or similar data pipeline backbone
1+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python
1+ years’ experience with NoSQL implementation (ElasticSearch, Cassandra, etc. a plus)
At least 1 year of experience with Unix/Linux systems with scripting experience
Familiarity with Alooma, Snowflakes
Familiarity with Kinesis, Lamda
Prior experience in gaming
Prior experience in finance


Skillz embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Skillz<br><br></u></strong>Skillz is the leading mobile games platform connecting players in fair, fun, and meaningful competition.<br><br>The gaming industry is larger than movies, music, and books, with more than 2.7 billion gamers playing monthly and 10 million developers worldwide. Mobile is the fastest-growing segment of the gaming market, expected to increase from $68 billion in 2019 to $150 billion in 2025.<br><br>As the first publicly-traded mobile esports platform, Skillz has pioneered the future of the gaming industry. The Skillz platform helps developers build multi-million dollar franchises by enabling social competition in their games. Leveraging its patented technology, Skillz hosts billions of casual esports tournaments for millions of mobile players worldwide, and distributes millions in prizes each month.<br><br>Through its philanthropic initiatives, Skillz has harnessed the power of its platform to transform the way nonprofits engage with donors, enabling anyone with a mobile device to support causes such as the American Red Cross, Susan G. Komen, American Cancer Society, and NAACP by playing in Skillz tournaments.<br><br>Skillz has also earned recognition as one of Fast Company’s Most Innovative Companies, a two-time winner of CNBC’s Disruptor 50, one of Forbes’ Next Billion-Dollar Startups, and the #1 fastest-growing company in America on the Inc. 5000.<br><br><strong><u>Who We’re Looking For<br><br></u></strong>You’re ready to take the next step in your Data Engineering career - to a fast-moving, successful company building out their next-generation streaming analytics infrastructure! You love data consistency and integrity. You consider yourself scrappy and a technologist, passionate about data infrastructure... with your attention to detail and insistence on doing things correctly, you know you can make a big impact on a small team! You’re an excellent communicator and know that you grow faster from being able to mentor others.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Build new systems to provide real-time streaming analytics and event processing pipeline based on fast data architecture</li> <li>Build enterprise grade data lake to support both business analytical needs and next generation data infrastructure</li> <li>Building data integration toolkit for backend services</li> <li>Support our data science team in deploying new algorithms for matchmaking, fraud and cheat detection</li> <li>Find better ways to move massive amounts of data from a variety of sources to formats consumable by reporting systems and people</li> <li>Improve monitoring and alarms that impact data integrity replication lag</li> <li>Support our product development team in creating new events to measure/track</li> <br><br></ul><strong><u>Basic Qualifications<br><br></u></strong><strong>Your Skillz:<br></strong><ul> <li>At least 1+ years of experience in Scala/Java or Python programming</li> <li>AWS data products (Data pipelines, Athena, Pinpoint, S3, etc)</li> <li>Experience deploying data infrastructure</li> <li>Experience with recognized industry patterns, methodologies, and techniques</li> <br><br></ul><strong><u>Bonus<br></u></strong><ul> <li>Familiarity with Agile engineering practices</li> <li>1+ years experience on Kubernete, Helm chart</li> <li>1+ years of experience with Spark, Scala and/or Akka</li> <li>1+ years of experience with Spark Streaming, Storm, Flink, or other Stream Processing technologies</li> <li>1+ years of experience working with Kafka or similar data pipeline backbone</li> <li>1+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python</li> <li>1+ years’ experience with NoSQL implementation (ElasticSearch, Cassandra, etc. a plus)</li> <li>At least 1 year of experience with Unix/Linux systems with scripting experience</li> <li>Familiarity with Alooma, Snowflakes</li> <li>Familiarity with Kinesis, Lamda</li> <li>Prior experience in gaming</li> <li>Prior experience in finance</li> <br></ul>Skillz embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Science & Analytics Development Program 2021b,"Moline, Illinois, United States",John Deere,2021-02-18,https://www.linkedin.com/jobs/view/data-science-analytics-development-program-2021b-at-john-deere-2428960385?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=30WVu32Erkx%2Frj5HJW0N%2Fg%3D%3D&position=5&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Fearless is looking for a Data Science Engineer to add to our diverse team of 130+ employees (and counting!).

What you'll be doing:

We're looking to change the world by building software with a soul, and we want your help.

The Data Science Engineer works with a variety of data sources and stakeholders to design and implement solutions that solve business problems. The Data Science Engineer drives the data formatting, analysis, and optimization to build solutions using tools like statistical analysis and machine learning models. They are experts in algorithms, data modeling, and asking good questions.

They help build the data pipelines used to manage and analyze data. They work with the team to support product innovation and implementation.

What you should know:

This position is 100% remote until after COVID-19.
Once COVID-19 is over, this position is located in the Downtown Baltimore office and will have the flexibility to support some remote work/telecommuting.



Why we're excited about you:

We need your data science engineering skills!

What other skills will help you succeed at Fearless? Glad you asked! We're excited about candidates who have the following skills:

Required:

Develop custom data models, algorithms, and predictive models to perform multifaceted analysis
Strong understanding of Python with the ability to quickly pick up new libraries. Optional: react, cypher
Build and maintain predictive models and machine learning algorithms from the ground up to solve real-world business challenges
Understands how to ETL new data sources along with mining for insights
Familiarity with Machine Learning and Deep Learning Tools
Strongly Proficient in statistics, data processing, or data annotation
Experience with various types of databases such as relational, key-value, document, graph
Experience with OLAP data storage technologies like data lakes, and data warehouses
Experience working with at least one data analysis tool like Hadoop, Apache Spark, or cloud-provider equivalents
Understand, monitor QA, translate and collaborate with teams to ensure ongoing data quality.
Stitch, calibrate, and optimize sparse and noisy data across various data sources
Partner with various stakeholders and teams of stakeholders to understand business problems, help define them into KPIs and then deliver insightful analysis in reports or visualizations



Good to have:

Strong analytical and problem-solving skills with attention to detail
Understand, monitor QA, translate and collaborate with teams to ensure ongoing data quality.
View data through the lens of what questions to ask, what assumptions to make, what algorithms to use and how to get the biggest impact from it
Support regular ad-hoc data and analysis needs to better understand customer behaviors.
Support teams in running growth programs and A/B tests through analyzing results and communicating findings and insights.
Effective organizational and time management skills with the ability to work independently, as well as with remote teams, under strict project deadlines



At Fearless, we believe in sharing knowledge, fresh perspectives, and unique interests as individuals and as a company, so we're also interested to know what makes you tick. We want to know where your interests and passions lie so we can all grow together.

Compensation:

We believe in paying people fairly, so we've established a compensation model that ensures everyone at Fearless — regardless of race, ethnicity, gender, sexual orientation, disability, religion, age, nationality, or negotiation skills — is given equal pay for equal work.

So, what's next?

Over the years, we've honed a 3-step interview process that helps ensure that every employee we hire is the right fit for us and that we're the right fit for them. If we think you're a good fit, we'll get in touch and start scheduling your interviews!

Cultural Interview - We're a people-first company, so we always start off by getting to know more about you, how you work, what your career goals are, and what you're passionate about. This is your opportunity to ask questions and get a feel for Fearless, so don't be shy!
Technical Interview - This is where we get into the nitty gritty of the project. During the Technical Interview, you'll be interviewed by our Passion Coaches and/or the team's Project Lead to make sure your skills align with the project requirements.
Business Interview - At this point, you've made it to the final frontier! The Business Interview is when you'll meet with Fearless leadership to dot the i's, cross the t's, and determine whether or not we'll be moving forward with the hiring process.



Why Fearless?

Our people make us who we are. We believe that every member of the Fearless team has something to share, and we value the unique viewpoint you'll bring to our community. But we value your community, too, so we offer fulfilling work that stays in balance with the rest of life. Because everyone has different needs, desires, and goals, our benefits offer the choices and flexibility that our team members need to live well and succeed. Here are a few highlights of our benefits package:

Flexible schedule
Family-friendly workplace
3 weeks accrued PTO + 1 week sick leave + 10 federal holidays + your birthday off
100% coverage of the employee-only premium for HSA, HMO, or PPO plan and Employee Wellness Plan
Tech, education / training, and snack allowances
[Free parking in downtown Baltimore / public transit coverage]
Safe Harbor 401(k) plan with employer contributions



About Fearless

Fearless is a full-stack digital services firm in Baltimore that delivers sleek, modern, and user-friendly software designed to push the boundaries of possibility. It's our mission to build software with a soul — tools that empower communities and make a difference — so we can create a world where good software powers the things that matter.

That's not our only goal, though. We also strive to create a purple culture that makes our employees excited to come to work every day. That's why we encourage our employees to pursue their passions, both in and out of the office. With built-in company mentoring, continuing education support, flexible schedules, and a family-friendly work environment, we've created a culture that allows our team to thrive professionally and personally.

Fearless believes in equal opportunity employment. We won't discriminate against any employee or applicant on the basis of race, gender, nationality, age, religion, disability, military status, or sexual orientation. As a company and as individuals, we're committed to providing an inclusive and welcoming environment for our team, our family members, our clients, our subcontractors, and our vendors.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Fearless is looking for a Data Science Engineer to add to our diverse team of 130+ employees (and counting!).<br><br><strong>What you'll be doing:<br><br></strong>We're looking to change the world by building software with a soul, and we want your help.<br><br>The Data Science Engineer works with a variety of data sources and stakeholders to design and implement solutions that solve business problems. The Data Science Engineer drives the data formatting, analysis, and optimization to build solutions using tools like statistical analysis and machine learning models. They are experts in algorithms, data modeling, and asking good questions.<br><br>They help build the data pipelines used to manage and analyze data. They work with the team to support product innovation and implementation.<br><br><strong>What you should know:<br></strong><ul> <li>This position is 100% remote until after COVID-19. </li> <li>Once COVID-19 is over, this position is located in the Downtown Baltimore office and will have the flexibility to support some remote work/telecommuting.</li> <br><br></ul><strong>Why we're excited about you:<br><br></strong>We need your data science engineering skills!<br><br>What other skills will help you succeed at Fearless? Glad you asked! We're excited about candidates who have the following skills:<br><br>Required:<br><ul> <li>Develop custom data models, algorithms, and predictive models to perform multifaceted analysis</li> <li>Strong understanding of Python with the ability to quickly pick up new libraries. Optional: react, cypher</li> <li>Build and maintain predictive models and machine learning algorithms from the ground up to solve real-world business challenges</li> <li>Understands how to ETL new data sources along with mining for insights</li> <li>Familiarity with Machine Learning and Deep Learning Tools</li> <li>Strongly Proficient in statistics, data processing, or data annotation</li> <li>Experience with various types of databases such as relational, key-value, document, graph</li> <li>Experience with OLAP data storage technologies like data lakes, and data warehouses</li> <li>Experience working with at least one data analysis tool like Hadoop, Apache Spark, or cloud-provider equivalents</li> <li>Understand, monitor QA, translate and collaborate with teams to ensure ongoing data quality.</li> <li>Stitch, calibrate, and optimize sparse and noisy data across various data sources</li> <li>Partner with various stakeholders and teams of stakeholders to understand business problems, help define them into KPIs and then deliver insightful analysis in reports or visualizations</li> <br><br></ul>Good to have:<br><ul> <li>Strong analytical and problem-solving skills with attention to detail</li> <li>Understand, monitor QA, translate and collaborate with teams to ensure ongoing data quality.</li> <li>View data through the lens of what questions to ask, what assumptions to make, what algorithms to use and how to get the biggest impact from it</li> <li>Support regular ad-hoc data and analysis needs to better understand customer behaviors. </li> <li>Support teams in running growth programs and A/B tests through analyzing results and communicating findings and insights.</li> <li>Effective organizational and time management skills with the ability to work independently, as well as with remote teams, under strict project deadlines</li> <br><br></ul>At Fearless, we believe in sharing knowledge, fresh perspectives, and unique interests as individuals and as a company, so we're also interested to know what makes you tick. We want to know where your interests and passions lie so we can all grow together.<br><br><strong>Compensation:<br><br></strong>We believe in paying people fairly, so we've established a compensation model that ensures everyone at Fearless — regardless of race, ethnicity, gender, sexual orientation, disability, religion, age, nationality, or negotiation skills — is given equal pay for equal work.<br><br><strong>So, what's next?<br><br></strong>Over the years, we've honed a 3-step interview process that helps ensure that every employee we hire is the right fit for us and that we're the right fit for them. If we think you're a good fit, we'll get in touch and start scheduling your interviews!<br><ul> <li>Cultural Interview - We're a people-first company, so we always start off by getting to know more about you, how you work, what your career goals are, and what you're passionate about. This is your opportunity to ask questions and get a feel for Fearless, so don't be shy!</li> <li>Technical Interview - This is where we get into the nitty gritty of the project. During the Technical Interview, you'll be interviewed by our Passion Coaches and/or the team's Project Lead to make sure your skills align with the project requirements.</li> <li>Business Interview - At this point, you've made it to the final frontier! The Business Interview is when you'll meet with Fearless leadership to dot the i's, cross the t's, and determine whether or not we'll be moving forward with the hiring process. </li> <br><br></ul><strong>Why Fearless?<br><br></strong>Our people make us who we are. We believe that every member of the Fearless team has something to share, and we value the unique viewpoint you'll bring to our community. But we value your community, too, so we offer fulfilling work that stays in balance with the rest of life. Because everyone has different needs, desires, and goals, our benefits offer the choices and flexibility that our team members need to live well and succeed. Here are a few highlights of our benefits package:<br><ul> <li>Flexible schedule</li> <li>Family-friendly workplace </li> <li>3 weeks accrued PTO + 1 week sick leave + 10 federal holidays + your birthday off </li> <li>100% coverage of the employee-only premium for HSA, HMO, or PPO plan and Employee Wellness Plan</li> <li>Tech, education / training, and snack allowances </li> <li>[Free parking in downtown Baltimore / public transit coverage]</li> <li>Safe Harbor 401(k) plan with employer contributions</li> <br><br></ul><strong><u>About Fearless<br><br></u></strong>Fearless is a full-stack digital services firm in Baltimore that delivers sleek, modern, and user-friendly software designed to push the boundaries of possibility. It's our mission to build software with a soul — tools that empower communities and make a difference — so we can create a world where good software powers the things that matter.<br><br>That's not our only goal, though. We also strive to create a purple culture that makes our employees excited to come to work every day. That's why we encourage our employees to pursue their passions, both in and out of the office. With built-in company mentoring, continuing education support, flexible schedules, and a family-friendly work environment, we've created a culture that allows our team to thrive professionally and personally.<br><br>Fearless believes in equal opportunity employment. We won't discriminate against any employee or applicant on the basis of race, gender, nationality, age, religion, disability, military status, or sexual orientation. As a company and as individuals, we're committed to providing an inclusive and welcoming environment for our team, our family members, our clients, our subcontractors, and our vendors.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Big Data Engineer - AWS,"Herndon, Virginia, United States",Fannie Mae,2021-02-17,https://www.linkedin.com/jobs/view/big-data-engineer-aws-at-fannie-mae-2415331050?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=vhNWhupKoYC%2FxiraEgMlHA%3D%3D&position=6&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"There are 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we’re all about at John Deere. And it’s why we’re investing in our people and our technology like never before in our 175-year history. Here the world’s brightest minds are tackling the world’s biggest challenges. If you believe one person can make the world a better place, we’ll put you to work. RIGHT NOW.

Primary Location: United States (US) - Moline, IL & Des Moines, IA
Function: Data Science & Analytics
Title: Data Science & Analytics Development Program 2021b - 70322

The Data Science & Analytics Development Program is a full-time, permanent position for new or recent graduates interested in working as a Data Scientist or Data Engineer. This provides an accelerated development experience during the first 3 years of employment in the company, through 3 one-year-long work assignments. Employees rotate across varied functional areas such as Financial Services, IT, Precision Agriculture, Customer & Product Support, Sales & Marketing, Engineering, etc.

What will you do?

Build a network of contacts across 3 different areas of John Deere’s business
Gaining expertise using the latest analytics technology & tools
Integrate large and diverse data sets together
Learn and apply appropriate data science techniques to solve business problems


Do you have what it takes?

Bachelor’s , Master’s, or PhD Degree in Data Science, Analytics, Statistics, Mathematics, Computer Science, Engineering or related quantitative discipline
Desired cumulative GPA of 3.0 on a 4.0 scale
Knowledge of applied statistical analysis, modeling techniques, and data visualization methods
Ability to demonstrate algorithm development and predictive modeling to solve problems
Proficiency in programming languages SQL, R, Python, and/or SAS


We have development program locations across the United States so you must be willing to relocate and travel domestically. Work Statement: US Visa sponsorship is not available for this position.

What You'll Get

At John Deere, you are empowered to create a career that will take you to where you want to go. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. We offer comprehensive relocation and reward packages to help you get started on your new career path.

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">There are 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we’re all about at John Deere. And it’s why we’re investing in our people and our technology like never before in our 175-year history. Here the world’s brightest minds are tackling the world’s biggest challenges. If you believe one person can make the world a better place, we’ll put you to work. RIGHT NOW.<br><br>Primary Location: United States (US) - Moline, IL &amp; Des Moines, IA<br>Function: Data Science &amp; Analytics<br>Title: Data Science &amp; Analytics Development Program 2021b - 70322<br><br>The <strong>Data Science &amp;</strong> <strong>Analytics Development Program</strong> is a full-time, permanent position for new or recent graduates interested in working as a Data Scientist or Data Engineer. This provides an accelerated development experience during the first 3 years of employment in the company, through 3 one-year-long work assignments. Employees rotate across varied functional areas such as Financial Services, IT, Precision Agriculture, Customer &amp; Product Support, Sales &amp; Marketing, Engineering, etc.<br><br><strong>What will you do? <br></strong><ul> <li> Build a network of contacts across 3 different areas of John Deere’s business </li> <li> Gaining expertise using the latest analytics technology &amp; tools </li> <li> Integrate large and diverse data sets together </li> <li> Learn and apply appropriate data science techniques to solve business problems </li> <br></ul><strong> Do you have what it takes? <br></strong><ul> <li> Bachelor’s , Master’s, or PhD Degree in Data Science, Analytics, Statistics, Mathematics, Computer Science, Engineering or related quantitative discipline </li> <li> Desired cumulative GPA of 3.0 on a 4.0 scale </li> <li> Knowledge of applied statistical analysis, modeling techniques, and data visualization methods </li> <li> Ability to demonstrate algorithm development and predictive modeling to solve problems </li> <li> Proficiency in programming languages SQL, R, Python, and/or SAS </li> <br></ul><strong> We have development program locations across the United States so you must be willing to relocate and travel domestically. <strong>Work Statement: US Visa sponsorship is not available for this position.</strong> <br><br></strong><strong><u>What You'll Get<br><br></u></strong>At John Deere, you are empowered to create a career that will take you to where you want to go. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. We offer comprehensive relocation and reward packages to help you get started on your new career path.<br><br>The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.<br><br>John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Human Resources, Financial Services"
Data Engineer,"Rochester, New York, United States",AVANGRID,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-at-avangrid-2425355588?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=q8yFRaUnDyDWbMDNHcgOgA%3D%3D&position=7&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Company Description

THE COMPANY

Fannie Mae provides reliable, large-scale access to affordable mortgage credit in communities across our nation. We are the leading source of funding for housing in America, which means more people can buy or rent a home. We are focused on sustaining the housing recovery, improving our company, and leading change to make housing better.

Join our diverse, high-performing team and make a difference as we work together to enable access to a good home.

Job Description

Use modern tools, techniques, and methods to develop, modify, or update applications used by business units or infrastructure units. Lead, or play lead technical role in development teams' efforts to determine unit needs and business processes that are automated by the application. Participate in or review all of the steps in the software development life cycle to create and modify the software.

Key Job Functions

Work with product owners and other development team members to determine new features and user stories needed in new/revised applications or large/complex development projects.
Create or Update documentation in support of development efforts. Documents may include detailed specifications, implementation guides, architecture diagrams or design documents.
Participate in code reviews with peers and managers to ensure that each increment adheres to original vision as described in the user story and all standard resource libraries and architecture patterns as appropriate.
Respond to trouble/support calls for applications in production in order to make quick repair to keep application in production.
Serve as a technical lead for an Agile team and actively participate in all Agile ceremonies.
Participate in all team ceremonies including planning, grooming, product demonstration and team retrospectives.
Mentor less experienced technical staff; may use high end development tools to assist or facilitate development process.
Leverage Fannie Mae DevOps tool stack to build, inspect, deploy, test and promote new or updated features.
Set up and configure a continuous integration environment.
Advanced proficiency in unit testing as well as coding in 1-2 languages (e.g. Java, etc).
Advanced proficiency in Object Oriented Design (OOD) and analysis.
Advanced proficiency in application of analysis/design engineering functions.
Advanced proficiency in application of non-functional software qualities such as resiliency, maintainability, etc.
Advanced proficiency in advanced behavior-driven testing techniques.


Qualifications

Education Level Required

Bachelor Degree or Equivalent


Area Of Study Preferred

Business or Computer Science


Certifications Preferred

Specialized training in specific platforms, enterprise


Minimum Experience

4-6 years of related experience; Experienced with Agile practices/ methodologies (e.g. Scrum, TDD, BDD, etc).


Required Skills

2+ years with Big Data Hadoop cluster (HDFS, Yarn, Hive, MapReduce frameworks), Spark
2+ years of recent experience with building and deploying applications in AWS (S3, Hive, Glue, EMR, AWS Batch, Dynamo DB, Redshift, Cloudwatch, RDS, Lambda, SNS, SQS etc.)
4+ years of Java/Python, SQL, SparkSQL, PySpark
Excellent problem-solving skills, strong verbal & written communication skills
Ability to work independently as well as part of a team


Desired Skills

Familiar with Hadoop information architecture, data modeling, machine learning, Talend
Knowledge of Spark streaming technologies, Graph Database will be a nice to have
Knowledge of Financial Products, Risk Management, Portfolio Management is preferred but not mandatory. Training will be provided to help you gain ground


Additional Information

The future is what you make it to be. Discover compelling opportunities at careers.fanniemae.com.

Fannie Mae is an Equal Opportunity Employer, which means we are committed to fostering a diverse and inclusive workplace. All qualified applicants will receive consideration for employment without regard to race, religion, national origin, gender, gender identity, sexual orientation, personal appearance, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation in the application process, email us at [email protected]

REF1571P
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company Description<br><br></u></strong><strong>THE COMPANY<br><br></strong>Fannie Mae provides reliable, large-scale access to affordable mortgage credit in communities across our nation. We are the leading source of funding for housing in America, which means more people can buy or rent a home. We are focused on sustaining the housing recovery, improving our company, and leading change to make housing better.<br><br>Join our diverse, high-performing team and make a difference as we work together to enable access to a good home.<br><br><strong><u>Job Description<br><br></u></strong>Use modern tools, techniques, and methods to develop, modify, or update applications used by business units or infrastructure units. Lead, or play lead technical role in development teams' efforts to determine unit needs and business processes that are automated by the application. Participate in or review all of the steps in the software development life cycle to create and modify the software.<br><br><strong><u>Key Job Functions<br></u></strong><ul><li>Work with product owners and other development team members to determine new features and user stories needed in new/revised applications or large/complex development projects.</li><li>Create or Update documentation in support of development efforts. Documents may include detailed specifications, implementation guides, architecture diagrams or design documents.</li><li>Participate in code reviews with peers and managers to ensure that each increment adheres to original vision as described in the user story and all standard resource libraries and architecture patterns as appropriate.</li><li>Respond to trouble/support calls for applications in production in order to make quick repair to keep application in production.</li><li>Serve as a technical lead for an Agile team and actively participate in all Agile ceremonies. </li><li>Participate in all team ceremonies including planning, grooming, product demonstration and team retrospectives.</li><li>Mentor less experienced technical staff; may use high end development tools to assist or facilitate development process.</li><li>Leverage Fannie Mae DevOps tool stack to build, inspect, deploy, test and promote new or updated features.</li><li>Set up and configure a continuous integration environment.</li><li>Advanced proficiency in unit testing as well as coding in 1-2 languages (e.g. Java, etc).</li><li>Advanced proficiency in Object Oriented Design (OOD) and analysis. </li><li>Advanced proficiency in application of analysis/design engineering functions. </li><li>Advanced proficiency in application of non-functional software qualities such as resiliency, maintainability, etc. </li><li>Advanced proficiency in advanced behavior-driven testing techniques.<br><br></li></ul><strong><u>Qualifications<br><br></u></strong><strong>Education Level Required <br></strong><ul><li>Bachelor Degree or Equivalent<br><br></li></ul><strong><u>Area Of Study Preferred<br></u></strong><ul><li>Business or Computer Science<br><br></li></ul><strong><u>Certifications Preferred<br></u></strong><ul><li>Specialized training in specific platforms, enterprise<br><br></li></ul><strong><u>Minimum Experience<br></u></strong><ul><li>4-6 years of related experience; Experienced with Agile practices/ methodologies (e.g. Scrum, TDD, BDD, etc).<br><br></li></ul><strong><u>Required Skills<br></u></strong><ul><li>2+ years with Big Data Hadoop cluster (HDFS, Yarn, Hive, MapReduce frameworks), Spark</li><li>2+ years of recent experience with building and deploying applications in AWS (S3, Hive, Glue, EMR, AWS Batch, Dynamo DB, Redshift, Cloudwatch, RDS, Lambda, SNS, SQS etc.)</li><li>4+ years of Java/Python, SQL, SparkSQL, PySpark</li><li>Excellent problem-solving skills, strong verbal &amp; written communication skills</li><li>Ability to work independently as well as part of a team<br><br></li></ul><strong><u>Desired Skills<br></u></strong><ul><li>Familiar with Hadoop information architecture, data modeling, machine learning, Talend</li><li>Knowledge of Spark streaming technologies, Graph Database will be a nice to have</li><li>Knowledge of Financial Products, Risk Management, Portfolio Management is preferred but not mandatory. Training will be provided to help you gain ground<br><br></li></ul>Additional Information<br><br>The future is what you make it to be. Discover compelling opportunities at careers.fanniemae.com.<br><br>Fannie Mae is an Equal Opportunity Employer, which means we are committed to fostering a diverse and inclusive workplace. All qualified applicants will receive consideration for employment without regard to race, religion, national origin, gender, gender identity, sexual orientation, personal appearance, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation in the application process, email us at [email protected]<br><br>REF1571P</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Financial Services
"Software Engineer, Data Science","Boston, Massachusetts, United States",Fairmarkit,2021-02-02,https://www.linkedin.com/jobs/view/software-engineer-data-science-at-fairmarkit-2405683159?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=egvLpk6VwGJgWY%2B%2Fbja8DQ%3D%3D&position=8&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Job Summary

The Operational Performance group works to develop management tools to support electric operations and provides strategic direction for reliability improvements across all the AVANGRID Networks electric operating companies. Our team executes projects analyzing large sets of data and providing solutions primarily for but not limited to the distribution system, while driving operational performance using
KPIs and dashboards.

MAJOR ROLES AND RESPONSIBILITIES (Scope of work - range of responsibilities):

Work with interdepartmental, internal stakeholders to understand their needs and provide data analytical tools and solutions.
Design and build data pipelines and workflows from the ground up.
Perform the transformation, filtering, and aggregation of raw data into concise, accurate and focused data models.
Develop coding and testing tools, and assets to provide to internal stakeholders to help improve and drive electric operations.
Use internal software capabilities to acquire, ingest, and transform big datasets.
Create and manage data environments in both cloud environments and local networks.
Ensure information security standards are maintained at all time.
Perform complex assessments and manipulation of reliability data, as well as further development of the company’s data retention capabilities, historic reporting capabilities, and data mining capabilities to complete complex analysis and reporting.
Assist in the development of Reliability Engineering and Reliability Reporting processes, tools, and projects to support the goals and objectives of the Operational Performance organization.
Provide technical advice and support to other departments as it pertains to Big Data and Analytics.
Coordinate with internal stakeholders across the organization to ensure implementation of strategies and process improvements.

Job Requirements

Education & Experience Required:

Bachelor’s degree in engineering, computer science, or equivalent area
3-6 years previous experience in the field of application development, database development, and data analysis domains with SQL knowledge
Hands-on coding and application development experience with multiple programming languages such as Python, Shell, Java, or similar scripting languages – certification is a plus
Experience in agile development methodologies required
Understanding of data modeling, data warehousing, data lakes, and big-data concepts
Experience building data pipelines in production and ability to work across structured, semi-structured, and unstructured data
Experience preparing data for analytics and following a data science workflow
Knowledge of the electric distribution system and its challenges with a focus on implementing Big Data and analytical tools to monitor effectiveness of strategies
Project management or process improvement implementation experience required

Skills/Abilities

Strong written and verbal skills; must be able to communicate effectively with internal and external stakeholders

Behavioral Competencies

Develop self & others
Empower to grow
Collaborate and share
Be a role model
Focus to achieve results
Be agile

Avangrid employees may be assigned a system emergency role and in the event of a system emergency, may be required to work outside of their regular schedule/job duties. This is applicable to employees that will work in Connecticut, Maine, Massachusetts, and New York within AVANGRD Network and Corporate functions. This does not include those that will work for Avangrid Renewables


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Summary<br><br></u></strong>The Operational Performance group works to develop management tools to support electric operations and provides strategic direction for reliability improvements across all the AVANGRID Networks electric operating companies. Our team executes projects analyzing large sets of data and providing solutions primarily for but not limited to the distribution system, while driving operational performance using<br>KPIs and dashboards.<br><br>MAJOR ROLES AND RESPONSIBILITIES (Scope of work - range of responsibilities):<br><ul><li> Work with interdepartmental, internal stakeholders to understand their needs and provide data analytical tools and solutions.</li><li> Design and build data pipelines and workflows from the ground up.</li><li> Perform the transformation, filtering, and aggregation of raw data into concise, accurate and focused data models.</li><li> Develop coding and testing tools, and assets to provide to internal stakeholders to help improve and drive electric operations.</li><li> Use internal software capabilities to acquire, ingest, and transform big datasets.</li><li> Create and manage data environments in both cloud environments and local networks.</li><li> Ensure information security standards are maintained at all time.</li><li> Perform complex assessments and manipulation of reliability data, as well as further development of the company’s data retention capabilities, historic reporting capabilities, and data mining capabilities to complete complex analysis and reporting.</li><li> Assist in the development of Reliability Engineering and Reliability Reporting processes, tools, and projects to support the goals and objectives of the Operational Performance organization.</li><li> Provide technical advice and support to other departments as it pertains to Big Data and Analytics.</li><li> Coordinate with internal stakeholders across the organization to ensure implementation of strategies and process improvements.<br></li></ul><strong><u>Job Requirements<br><br></u></strong>Education &amp; Experience Required:<br><ul><li> Bachelor’s degree in engineering, computer science, or equivalent area</li><li> 3-6 years previous experience in the field of application development, database development, and data analysis domains with SQL knowledge</li><li> Hands-on coding and application development experience with multiple programming languages such as Python, Shell, Java, or similar scripting languages – certification is a plus</li><li> Experience in agile development methodologies required</li><li> Understanding of data modeling, data warehousing, data lakes, and big-data concepts</li><li> Experience building data pipelines in production and ability to work across structured, semi-structured, and unstructured data</li><li> Experience preparing data for analytics and following a data science workflow</li><li> Knowledge of the electric distribution system and its challenges with a focus on implementing Big Data and analytical tools to monitor effectiveness of strategies</li><li> Project management or process improvement implementation experience required<br></li></ul><strong><u>Skills/Abilities<br></u></strong><ul><li> Strong written and verbal skills; must be able to communicate effectively with internal and external stakeholders<br></li></ul><strong><u>Behavioral Competencies<br></u></strong><ul><li> Develop self &amp; others</li><li> Empower to grow</li><li> Collaborate and share</li><li> Be a role model</li><li> Focus to achieve results</li><li> Be agile<br></li></ul>Avangrid employees may be assigned a system emergency role and in the event of a system emergency, may be required to work outside of their regular schedule/job duties. This is applicable to employees that will work in Connecticut, Maine, Massachusetts, and New York within AVANGRD Network and Corporate functions. This does not include those that will work for Avangrid Renewables<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Oil & Energy, Financial Services"
Data Engineer,"Nashville, Tennessee, United States",Built Technologies,2021-02-03,https://www.linkedin.com/jobs/view/data-engineer-at-built-technologies-2316134521?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=fVHRjyKum5waafP0aiqVqQ%3D%3D&position=9&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Fairmarkit is the intelligent sourcing platform that empowers organizations to more efficiently purchase the goods and services they need. By equipping procurement and supply-chain teams with automation and data, Fairmarkit promotes competitive bidding while reducing manual work within existing processes. Fairmarkit has been recognized with awards by organizations such as Gartner and IDC, and is backed by strategic investors like GGV Capital, Insight Partners, 1984.VC, and Newfund.

We are looking for a Software Engineer with experience in data analysis tools & techniques to join us as we seek to evolve our offerings and improve our ability to use data to serve our customers. The ideal candidate will have proven from prior projects and roles that they are able to both analyze data sets to answer business questions as well as write code to automate jobs or processes.

This role reports into the VP of Engineering and will act as a bridge between our engineering teams focused on customer data integrations and our machine learning team focused on powering our recommendation engine.

In Your First 30 Days You Will

Learn about the procurement process and the types of data emitted from this trillion dollar B2B market
Leverage Python to conduct analysis of our customers’ or prospects’ procurement data
Improve our anomaly detection algorithms that ensure that we have visibility into the smooth flow of data between systems
Leverage Looker to make or extend BI dashboards to inform on the operations of our integrations team and answer questions about prospect's and customer's onboarding


In Your First 90 Days You Will

Research the best practices in data science for financial data and natural language processing in order to run proof of concepts that leverage those techniques
Make updates to our suite of Python data processing scripts to more reliably process procurement data from specific enterprise resource programs
Find, refine and analyze open government data and other external data sources to fill in gaps in Fairmarkit’s vendor recommendation data as we tackle new territories and categories of goods
Work with our Machine Learning and DevOps teams to automate loading data from upstream ERP systems into the Fairmarkit platform


In Your First Year You Will Have

Helped dozens of Fairmarkit customers onboard to our platform
Shaved hours of manual work off of our onboarding schedule by automating routine data processing and analytical steps
Gained extreme proficiency with Python and with statistical packages such as PandasContributed to our Machine Learning code base by committing tooling and reusable components to our vendor recommendation engine
Key Qualifications

1+ years hands on experience with statistical and analytical tools such as R, SPSS, Excel, Pandas, Matlab, etc. acquired during coursework, independent study or prior work experience
Curiosity and passion for the business side and customer success. Every Fairmarkit customer is unique and their data has a story to tell.
Familiarity with programming/scripting languages such as Python. Although we do not expect you to be an expert on day 1 we believe everyone should be able to use programming to automate tasks
Engineering, Math, Computer Science, or other technical degree, or substantial technical experience
Demonstrated ability to acquire new skills and thrive in a fast-paced startup environment
Headquartered in Boston, and backed by a $30M Series B co-led by GGV Capital and Insight Partners, we are looking for exceptional candidates who want to help grow our company into a global enterprise and make their mark on the B2B tech industry. Come soar to new heights with us!

Fairmarkit is an equal opportunity employer, and selects individuals best matched for the job based upon job-related qualifications regardless of race, religion, color, creed, sex, sexual orientation, age, ancestry, national origin, gender identity, genetic information, disability, pregnancy, veteran or military status or any other status or characteristic protected by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Fairmarkit is the intelligent sourcing platform that empowers organizations to more efficiently purchase the goods and services they need. By equipping procurement and supply-chain teams with automation and data, Fairmarkit promotes competitive bidding while reducing manual work within existing processes. Fairmarkit has been recognized with awards by organizations such as Gartner and IDC, and is backed by strategic investors like GGV Capital, Insight Partners, 1984.VC, and Newfund.<br><br>We are looking for a Software Engineer with experience in data analysis tools &amp; techniques to join us as we seek to evolve our offerings and improve our ability to use data to serve our customers. The ideal candidate will have proven from prior projects and roles that they are able to both analyze data sets to answer business questions as well as write code to automate jobs or processes.<br><br>This role reports into the VP of Engineering and will act as a bridge between our engineering teams focused on customer data integrations and our machine learning team focused on powering our recommendation engine.<br><br><strong> In Your First 30 Days You Will <br></strong><ul><li>Learn about the procurement process and the types of data emitted from this trillion dollar B2B market</li><li>Leverage Python to conduct analysis of our customers’ or prospects’ procurement data</li><li>Improve our anomaly detection algorithms that ensure that we have visibility into the smooth flow of data between systems</li><li>Leverage Looker to make or extend BI dashboards to inform on the operations of our integrations team and answer questions about prospect's and customer's onboarding <br><br></li></ul><strong> In Your First 90 Days You Will <br></strong><ul><li>Research the best practices in data science for financial data and natural language processing in order to run proof of concepts that leverage those techniques</li><li>Make updates to our suite of Python data processing scripts to more reliably process procurement data from specific enterprise resource programs</li><li>Find, refine and analyze open government data and other external data sources to fill in gaps in Fairmarkit’s vendor recommendation data as we tackle new territories and categories of goods </li><li>Work with our Machine Learning and DevOps teams to automate loading data from upstream ERP systems into the Fairmarkit platform<br><br></li></ul><strong> In Your First Year You Will Have <br></strong><ul><li>Helped dozens of Fairmarkit customers onboard to our platform</li><li>Shaved hours of manual work off of our onboarding schedule by automating routine data processing and analytical steps</li><li>Gained extreme proficiency with Python and with statistical packages such as PandasContributed to our Machine Learning code base by committing tooling and reusable components to our vendor recommendation engine</li></ul>Key Qualifications<br><ul><li>1+ years hands on experience with statistical and analytical tools such as R, SPSS, Excel, Pandas, Matlab, etc. acquired during coursework, independent study or prior work experience</li><li>Curiosity and passion for the business side and customer success. Every Fairmarkit customer is unique and their data has a story to tell.</li><li>Familiarity with programming/scripting languages such as Python. Although we do not expect you to be an expert on day 1 we believe everyone should be able to use programming to automate tasks</li><li>Engineering, Math, Computer Science, or other technical degree, or substantial technical experience</li><li>Demonstrated ability to acquire new skills and thrive in a fast-paced startup environment</li></ul>Headquartered in Boston, and backed by a $30M Series B co-led by GGV Capital and Insight Partners, we are looking for exceptional candidates who want to help grow our company into a global enterprise and make their mark on the B2B tech industry. Come soar to new heights with us!<br><br>Fairmarkit is an equal opportunity employer, and selects individuals best matched for the job based upon job-related qualifications regardless of race, religion, color, creed, sex, sexual orientation, age, ancestry, national origin, gender identity, genetic information, disability, pregnancy, veteran or military status or any other status or characteristic protected by law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Scientist,"Brazil, Indiana, United States",CI&T,2021-02-11,https://www.linkedin.com/jobs/view/data-scientist-at-ci-t-2401613783?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=2kcxtmuugO8l%2FH%2FvqgxkBA%3D%3D&position=10&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Built is a growth-stage company at the intersection of FinTech and PropTech. We are on a mission to change the way the world gets built with technology and services that streamline the $1.2T U.S. construction industry. We strive to empower lenders, owners, builders, and vendors with innovative software, payments products & services that enable participants to manage risk, maximize productivity / collaboration and ensure better cost management as capital flows into and throughout the construction industry. Founded in 2015, Built now serves more than 110 of the top financial institutions in the US and Canada, including 25+ of the top 100 US construction lenders. In 2019, we completed our Series B raise led by Goldman Sachs bringing our total funding to $55M. Bringing on the “best talent in the world” is at the forefront of our continued growth trajectory.

Built’s Insights team is hard at work on the product features that enable our clients and customers to get the most out of their data within Built. This includes data warehousing, in-app reporting, secure scheduled report delivery, and ad-hoc report generation where necessary. In addition to client needs, the Insights team is also instrumental in helping Built make sense of all of its internal data, allowing internal stakeholders to make informed, data-driven product decisions.

As a member of this team, you will...

Help build the foundation for the future of reporting at Built
Ship features that enable clients and internal stakeholders to get the most out of their data
Provide data that helps drive product decisions
Participate in design and architectural conversations around data warehousing and report generation/building
Encourage and build up your teammates


Success in this role will be defined by...

Delivering the right solution at the right time with integrity
Participating in driving our data warehousing and report generation architecture forward
Communicating and collaborating with both technical and non-technical team members to arrive at negotiated decisions.
Working across languages, environments, and teams to create the best solution from the information currently available


Experience with these technologies will be helpful:

MySQL
Python (3.6+), JavaScript, and/or PHP
ETL processes
Looker or similar Business Intelligence platform (Power BI, Tableau, etc)
Rundeck
GoCD


In addition to tech skills, it's important to:

Be a good communicator
Possess a strong focus on customers, both internal and external
Be able to work across teams to accomplish goals
Have a dedication to the quality and ownership of your work product
Have empathy and support for your teammates


Perks:

The rare opportunity to change the world and radically disrupt an industry

Competitive benefits including Unmetered Vacation; Health, Dental & Vision Insurance; and 401k

Flexible Hours

Weekly Team Lunches

Kitchen loaded with all the essentials to keep you productive


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Built is a growth-stage company at the intersection of FinTech and PropTech. We are on a mission to change the way the world gets built with technology and services that streamline the $1.2T U.S. construction industry. We strive to empower lenders, owners, builders, and vendors with innovative software, payments products &amp; services that enable participants to manage risk, maximize productivity / collaboration and ensure better cost management as capital flows into and throughout the construction industry. Founded in 2015, Built now serves more than 110 of the top financial institutions in the US and Canada, including 25+ of the top 100 US construction lenders. In 2019, we completed our Series B raise led by Goldman Sachs bringing our total funding to $55M. Bringing on the “best talent in the world” is at the forefront of our continued growth trajectory.<br><br>Built’s <em>Insights</em> team is hard at work on the product features that enable our clients and customers to get the most out of their data within Built. This includes data warehousing, in-app reporting, secure scheduled report delivery, and ad-hoc report generation where necessary. In addition to client needs, the Insights team is also instrumental in helping Built make sense of all of its internal data, allowing internal stakeholders to make informed, data-driven product decisions.<br><br><strong>As a member of this team, you will...<br></strong><ul><ul><li>Help build the foundation for the future of reporting at Built</li><li>Ship features that enable clients and internal stakeholders to get the most out of their data</li><li>Provide data that helps drive product decisions</li><li>Participate in design and architectural conversations around data warehousing and report generation/building</li><li>Encourage and build up your teammates<br><br></li></ul></ul><strong>Success in this role will be defined by...<br></strong><ul><ul><li>Delivering the right solution at the right time with integrity</li><li>Participating in driving our data warehousing and report generation architecture forward</li><li>Communicating and collaborating with both technical and non-technical team members to arrive at negotiated decisions.</li><li>Working across languages, environments, and teams to create the best solution from the information currently available<br><br></li></ul></ul><strong>Experience with these technologies will be helpful:<br></strong><ul><ul><li>MySQL</li><li>Python (3.6+), JavaScript, and/or PHP</li><li>ETL processes</li><li>Looker or similar Business Intelligence platform (Power BI, Tableau, etc)</li><li>Rundeck</li><li>GoCD<br><br></li></ul></ul><strong>In addition to tech skills, it's important to:<br></strong><ul><ul><li>Be a good communicator</li><li>Possess a strong focus on customers, both internal and external</li><li>Be able to work across teams to accomplish goals</li><li>Have a dedication to the quality and ownership of your work product</li><li>Have empathy and support for your teammates<br><br></li></ul></ul><strong>Perks:<br><br></strong>The rare opportunity to change the world and radically disrupt an industry<br><br>Competitive benefits including Unmetered Vacation; Health, Dental &amp; Vision Insurance; and 401k<br><br>Flexible Hours<br><br>Weekly Team Lunches<br><br>Kitchen loaded with all the essentials to keep you productive<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Technology and Services
Data Scientist,"Austin, Texas, United States",SAM Companies,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-sam-companies-2417232577?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=Bwf1Pxw5X3zZsXPLAEOnfg%3D%3D&position=11&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"CI&T is your end-to-end digital transformation partner. As a digital native, we bring a 25-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of more than 3,300 professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience and drive operational efficiency.

Buscamos um Cientista de Dados que tenha formação em áreas como Matemática Aplicada, Estatística, Física, Computação, Engenharia ou Economia, para trabalhar em desafios aplicando o método científico usando modelos estatísticos e estratégias de machine learning para testar e validar hipóteses de negócio em ordem de entender/solucionar problemas de nossos clientes.

Essa pessoa vai utilizar dados estruturados e não-estruturados (documentos, imagens, vídeos) e neles, empregar técnicas multivariadas, modelos preditivos e análises exploratórias, podendo adotar heurísticas e modelos de otimização em união com machine learning classificando, mapeando e detectando automaticamente business insights.

Essa pessoa trabalhará com uma empresa líder do seu segmento nos Estados Unidos , portanto, se comunicando primariamente em inglês. Uma excelente oportunidade para entender mercados e estratégias globais de negócio, não é mesmo?

Sua Missão

Identificar oportunidades de negócio e propor soluções baseadas em dados.

Explorar grandes volumes de dados com e sem um problema específico definido, a fim de apresentar as perguntas certas e fornecer insights interessantes;

Propor, implementar e validar modelos de Machine Learning para diversos fins, como segmentação de clientes, recomendação de produtos, retargeting de clientes, modelagem de recorrência de clientes e de next-best action, otimização de sortimento de produtos, entre outros;

Criar visualizações de dados para explicar suas análises e conclusões para uma audiência não-técnica, assim como contextualizar a narrativa (data storytelling);

Focar em experimentação e em gerar valor para o cliente final;

Você Precisa Ter Prática Com

Você precisa ser fluente em inglês!

Utilizar da estatística para analizar problemas complexos;

Programação, manipulação e modelagem de dados em Python ou R e SQL;

Ter experiência prática em projetos com Machine Learning e Data Mining;

Análise Exploratória de Dados: criar narrativas baseadas em dados para apresentar o resultado das análises, treinar e avaliar de modelos preditivos;

Negócios e postura consultiva para identificar e analisar problemas, definir e testar hipóteses;

Engenharia de dados, ETL, ferramentas de Big Data (como Spark), Data Science em Cloud Data Viz (Power Bi ou Tableau).(diferencial);

Ter conhecimento em estratégias e algoritmos de otimização( diferencial).

Causal Inference (diferencial);

Buscamos pessoas que são conectadas com a transformação digital, que gostam de compartilhar e aprender novas tecnologias contribuindo com a CI&T e comunidade externa. Além disso, que tenham match cultural conosco, respeitando as diferenças, trabalhando com colaboração e teamwork.

Eai? Se animou?!

Então conclua a sua inscrição e boa sorte =D

CI&T is an Equal Opportunity Employer

We are actively seeking to diversify our team and build an inclusive environment where everyone feels like they belong.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">CI&amp;T is your end-to-end digital transformation partner. As a digital native, we bring a 25-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of more than 3,300 professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience and drive operational efficiency.<br><br>Buscamos um Cientista de Dados que tenha formação em áreas como Matemática Aplicada, Estatística, Física, Computação, Engenharia ou Economia, para trabalhar em desafios aplicando o método científico usando modelos estatísticos e estratégias de machine learning para testar e validar hipóteses de negócio em ordem de entender/solucionar problemas de nossos clientes.<br><br>Essa pessoa vai utilizar dados estruturados e não-estruturados (documentos, imagens, vídeos) e neles, empregar técnicas multivariadas, modelos preditivos e análises exploratórias, podendo adotar heurísticas e modelos de otimização em união com machine learning classificando, mapeando e detectando automaticamente business insights.<br><br>Essa pessoa trabalhará com uma empresa líder do seu segmento nos Estados Unidos , portanto, se comunicando primariamente em inglês. Uma excelente oportunidade para entender mercados e estratégias globais de negócio, não é mesmo?<br><br><strong> Sua Missão <br><br></strong>Identificar oportunidades de negócio e propor soluções baseadas em dados.<br><br>Explorar grandes volumes de dados com e sem um problema específico definido, a fim de apresentar as perguntas certas e fornecer insights interessantes;<br><br>Propor, implementar e validar modelos de Machine Learning para diversos fins, como segmentação de clientes, recomendação de produtos, retargeting de clientes, modelagem de recorrência de clientes e de next-best action, otimização de sortimento de produtos, entre outros;<br><br>Criar visualizações de dados para explicar suas análises e conclusões para uma audiência não-técnica, assim como contextualizar a narrativa (data storytelling);<br><br>Focar em experimentação e em gerar valor para o cliente final;<br><br><strong> Você Precisa Ter Prática Com <br><br></strong>Você precisa ser fluente em inglês!<br><br>Utilizar da estatística para analizar problemas complexos;<br><br>Programação, manipulação e modelagem de dados em Python ou R e SQL;<br><br>Ter experiência prática em projetos com Machine Learning e Data Mining;<br><br>Análise Exploratória de Dados: criar narrativas baseadas em dados para apresentar o resultado das análises, treinar e avaliar de modelos preditivos;<br><br>Negócios e postura consultiva para identificar e analisar problemas, definir e testar hipóteses;<br><br>Engenharia de dados, ETL, ferramentas de Big Data (como Spark), Data Science em Cloud Data Viz (Power Bi ou Tableau).(diferencial);<br><br>Ter conhecimento em estratégias e algoritmos de otimização( diferencial).<br><br>Causal Inference (diferencial);<br><br>Buscamos pessoas que são conectadas com a transformação digital, que gostam de compartilhar e aprender novas tecnologias contribuindo com a CI&amp;T e comunidade externa. Além disso, que tenham match cultural conosco, respeitando as diferenças, trabalhando com colaboração e teamwork.<br><br>Eai? Se animou?!<br><br>Então conclua a sua inscrição e boa sorte =D<br><br>CI&amp;T is an Equal Opportunity Employer<br><br>We are actively seeking to diversify our team and build an inclusive environment where everyone feels like they belong.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"New York, New York, United States",Via,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-via-2416711319?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=E5XxEU7IrMGa82d71LSATw%3D%3D&position=12&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Who We Are

SAM Companies is recognized as the industry’s technology leader in providing geospatial solutions and construction services on a national scale. Our staff encompasses 1,000+ individuals from diverse backgrounds who are deploying the latest industry technology and changing the way data is collected and delivered in our industry.

Our Culture
Our entrepreneurial culture is a key factor in SAM being recognized as a Top Workplace for nine consecutive years, and we make it our mission to ensure every one of our employees learns how to build and manage a business, not just be the subject matter expert on the team. At SAM, our employee’s development is instrumental to our success. Your learning will be supported by specialized in-house training programs and mentoring by the industry’s leading experts, who just happen to be on our staff! We make SAM a GREAT place to work, but it all starts with YOU!

Your Impact at SAM

The Data Scientist will be joining a small group within the team that develops and deploys Machine Learning solutions to advance the products that we build. We are using Machine Learning to increase the quality and efficiency of our products on remotely sensed and business data. The team adapts or develops custom architecture to business needs and assembles large in-house datasets with tens of thousands of training examples. We are only scratching the surface with what we can achieve, and you will have a front-row seat in advancing our efforts.

Develop infrastructure and tools to productionize new models in a reproducible manner
Implement machine learning lifecycle to iterate on current models to improve predictive and runtime performance
Prototype new ML approaches and design experiments for evaluation
Identify opportunities to apply machine learning methodologies to solve new problems
Participate in design discussions about new features and approaches to implementing new services


What You Bring To SAM

3+ years of experience in building software professionally
Experience contributing high quality code to large codebases; Python and .net preferred
Experience with data preparation for model training including collation, normalization, transformation, and annotation
Experience with Machine Learning APIs and libraries; TensorFlow, PyTorch, Keras
Knowledge of databases (relational and NoSQL alternatives)
Experience with Apache Spark and/or Databricks for dataset preparation
Experience with cloud ML infrastructure (e.g., Azure ML)
Experience building Machine Learning systems at scale would be a plus
Successful implementation of defect detection and other ML algorithms (CNN, GAN, kNN, salience, etc)
Real-time object detection using YOLOv3, opencv
Data science background (math/statistical) and Master’s degree+ preferred

Our Perks!

In Addition, We Offer

We offer a best-in-class benefits package that includes company paid premiums for medical, vision, dental and life insurance. SAM’s 401 (k) program offers a 100% employer match up to 3% of your contribution, along with a 401(k) profit sharing and performance-based bonuses.


Generous paid time off
Tuition reimbursement
No glass ceiling! Truly a place to spread your wings
Work/life balance with flexible work hours – priority is getting the job done
Trainings every Tuesday – Specialized in-house trainings programs designed to assist you in advancing in your career
Office snacks, free food and fun-themed, employee events provided throughout the year
Passion for our Community – You have endless opportunities to volunteer alongside your peers with our Corporate Social Responsibility Program


EEO
SAM is an EOE/Affirmative Action Employer M/F/D/V. SAM also participates in the federal E-Verify Program.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Who We Are<br><br></u></strong>SAM Companies is recognized as the industry’s technology leader in providing geospatial solutions and construction services on a national scale. Our staff encompasses 1,000+ individuals from diverse backgrounds who are deploying the latest industry technology and changing the way data is collected and delivered in our industry.<br><br><strong>Our Culture<br></strong>Our entrepreneurial culture is a key factor in SAM being recognized as a Top Workplace for nine consecutive years, and we make it our mission to ensure every one of our employees learns how to build and manage a business, not just be the subject matter expert on the team. At SAM, our employee’s development is instrumental to our success. Your learning will be supported by specialized in-house training programs and mentoring by the industry’s leading experts, who just happen to be on our staff! We make SAM a GREAT place to work, but it all starts with YOU!<br><br><strong> Your Impact at SAM <br><br></strong>The Data Scientist will be joining a small group within the team that develops and deploys Machine Learning solutions to advance the products that we build. We are using Machine Learning to increase the quality and efficiency of our products on remotely sensed and business data. The team adapts or develops custom architecture to business needs and assembles large in-house datasets with tens of thousands of training examples. We are only scratching the surface with what we can achieve, and you will have a front-row seat in advancing our efforts.<br><ul><li> Develop infrastructure and tools to productionize new models in a reproducible manner </li><li> Implement machine learning lifecycle to iterate on current models to improve predictive and runtime performance </li><li> Prototype new ML approaches and design experiments for evaluation </li><li> Identify opportunities to apply machine learning methodologies to solve new problems </li><li> Participate in design discussions about new features and approaches to implementing new services <br><br></li></ul><strong><u>What You Bring To SAM<br></u></strong><ul><li> 3+ years of experience in building software professionally </li><li> Experience contributing high quality code to large codebases; Python and .net preferred </li><li> Experience with data preparation for model training including collation, normalization, transformation, and annotation </li><li> Experience with Machine Learning APIs and libraries; TensorFlow, PyTorch, Keras </li><li> Knowledge of databases (relational and NoSQL alternatives) </li><li> Experience with Apache Spark and/or Databricks for dataset preparation </li><li> Experience with cloud ML infrastructure (e.g., Azure ML) </li><li> Experience building Machine Learning systems at scale would be a plus </li><li> Successful implementation of defect detection and other ML algorithms (CNN, GAN, kNN, salience, etc) </li><li> Real-time object detection using YOLOv3, opencv </li><li> Data science background (math/statistical) and Master’s degree+ preferred <br></li></ul><strong>Our Perks!<br><br></strong><strong><u>In Addition, We Offer<br><br></u></strong>We offer a best-in-class benefits package that includes company paid premiums for medical, vision, dental and life insurance. SAM’s 401 (k) program offers a 100% employer match up to 3% of your contribution, along with a 401(k) profit sharing and performance-based bonuses.<br><br><li> Generous paid time off</li><li> Tuition reimbursement</li><li> No glass ceiling! Truly a place to spread your wings</li><li> Work/life balance with flexible work hours – priority is getting the job done</li><li> Trainings every Tuesday – Specialized in-house trainings programs designed to assist you in advancing in your career</li><li> Office snacks, free food and fun-themed, employee events provided throughout the year</li><li> Passion for our Community – You have endless opportunities to volunteer alongside your peers with our Corporate Social Responsibility Program<br><br></li><strong>EEO<br></strong>SAM is an EOE/Affirmative Action Employer M/F/D/V. SAM also participates in the federal E-Verify Program.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Civil Engineering, Telecommunications"
Data Scientist - REMOTE,"Raleigh, North Carolina, United States","Medable, Inc",2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-remote-at-medable-inc-2416748242?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=lNX3%2BpM0xrS3tBZL8pSh8g%3D%3D&position=13&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"As a Data Scientist , you’ll utilize advanced quantitative & statistical analysis techniques to drive business model innovation for Via, and work closely with our senior management to help drive decisions.

What You’ll Do

Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses & insights, and present these insights to the different stakeholders
Use sophisticated statistical methods to solve problems, leveraging up-to-date academic research and tools
Quantitatively test hypotheses about customer and driver behavior using large sets of proprietary data; leverage results to increase conversion and retention at every touch point
Design and implement novel experiments to better understand current operation as well as expansion to new markets



Who You Are

A natural relationship builder that values camaraderie, comes with a sense of humor, and doesn’t take themselves too seriously
Obtained a Master’s degree in statistics, math, computer science, operations research, or other highly quantitative fields with 2+ years of industry experience in a Data Scientist or equivalent role, or a PhD degree with 3+ years of highly quantitative graduate-level research experience.
Mastery in some or all of the following: SQL, Python, R, and Tableau
Obsessed with data; analytical and rigorous, with a thorough understanding of statistics and machine learning
Extraordinary communicator with demonstrated writing and editing skills.
Passionate about elegant visualization; you understand the importance of graphic techniques in communicating a quantitative idea effectively
Deep understanding of business concepts within strategy, operations, and marketing



What Catches Our Eye

Experience with the transportation industry is a plus
Prior role at a startup or similar high-growth environment


We’re Via, and we build technology that changes the way the world moves. We pioneered the TransitTech category to ensure that the future of transportation is shared, dynamic public mobility — the kind that reduces carbon emissions across congested cities, minimizes reliance on private cars, and provides everyone with accessible, efficient, and affordable ways of getting around.

Via was founded with the guiding principle that we go further when we go together. We’re committed to building and nurturing a team as diverse as the communities we serve. Bringing transportation equity to the world begins with championing equal opportunity in our own offices. All backgrounds, identities, and voices are welcomed and celebrated here.

We’re proud to be leading a worldwide transportation revolution and modernizing mobility for all. Through intelligently-designed systems and sophisticated algorithms, we craft localized solutions for each one of our global partners. Ready to join the ride?

Via is an equal opportunity employer.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">As a <strong>Data Scientist</strong> , you’ll utilize advanced quantitative &amp; statistical analysis techniques to drive business model innovation for Via, and work closely with our senior management to help drive decisions.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li> Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses &amp; insights, and present these insights to the different stakeholders </li> <li> Use sophisticated statistical methods to solve problems, leveraging up-to-date academic research and tools </li> <li> Quantitatively test hypotheses about customer and driver behavior using large sets of proprietary data; leverage results to increase conversion and retention at every touch point </li> <li> Design and implement novel experiments to better understand current operation as well as expansion to new markets </li> <br><br></ul><strong><u>Who You Are<br></u></strong><ul> <li> A natural relationship builder that values camaraderie, comes with a sense of humor, and doesn’t take themselves too seriously </li> <li> Obtained a Master’s degree in statistics, math, computer science, operations research, or other highly quantitative fields with 2+ years of industry experience in a Data Scientist or equivalent role, or a PhD degree with 3+ years of highly quantitative graduate-level research experience. </li> <li> Mastery in some or all of the following: SQL, Python, R, and Tableau </li> <li> Obsessed with data; analytical and rigorous, with a thorough understanding of statistics and machine learning </li> <li> Extraordinary communicator with demonstrated writing and editing skills. </li> <li> Passionate about elegant visualization; you understand the importance of graphic techniques in communicating a quantitative idea effectively </li> <li> Deep understanding of business concepts within strategy, operations, and marketing </li> <br><br></ul><strong><u>What Catches Our Eye<br></u></strong><ul> <li> Experience with the transportation industry is a plus </li> <li> Prior role at a startup or similar high-growth environment </li> <br></ul>We’re Via, and we build technology that changes the way the world moves. We pioneered the TransitTech category to ensure that the future of transportation is shared, dynamic public mobility — the kind that reduces carbon emissions across congested cities, minimizes reliance on private cars, and provides everyone with accessible, efficient, and affordable ways of getting around.<br><br>Via was founded with the guiding principle that we go further when we go together. We’re committed to building and nurturing a team as diverse as the communities we serve. Bringing transportation equity to the world begins with championing equal opportunity in our own offices. All backgrounds, identities, and voices are welcomed and celebrated here.<br><br>We’re proud to be leading a worldwide transportation revolution and modernizing mobility for all. Through intelligently-designed systems and sophisticated algorithms, we craft localized solutions for each one of our global partners. Ready to join the ride?<br><br>Via is an equal opportunity employer.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer - USA,Oklahoma City Metropolitan Area,InterWorks,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-usa-at-interworks-2426551167?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=4Q0kijg%2BLUA34EulwAthrg%3D%3D&position=14&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Company Description

Medable's mission is to get effective therapies to patients faster. We provide an end-to-end, cloud-based platform with a flexible suite of tools that allows patients, healthcare providers, clinical research organizations and pharmaceutical sponsors to work together as a team in clinical trials. Our solutions enable more efficient clinical research, more effective healthcare delivery, and more accurate precision and predictive medicine. Our target audiences are patients, providers, principal investigators, and innovators who work in healthcare and life sciences.

Our vision is to accelerate the path to human discovery and medical cures. We are passionate about driving innovation and empowering consumers. We are proactive, collaborative, self-motivated learners, committed, bold and tenacious. We are dedicated to making this world a healthier place.

Job Description

Explore machine learning opportunities
Investigate and compile new sources of medical data
Provide clinical input to refine existing machine learning architecture
Develop and integrate machine learning algorithms for data processing and analysis
Building models to address business problems
Presenting information using data visualization techniques
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Other duties as assigned


Qualifications

0-3 years working in Computer Science or a combination of education and experience (3+ preferred)
Bachelor’s degree in Computer Science, Artificial Intelligence, Engineering or relevant field
Experiece with R programming language, C++, Python, Java, Node.JS


Additional Information

Highly analytical with a knack for analysis, math and statistics
Critical thinking and problem-solving skills
Passion for machine-learning and research
Experience in data mining
Analytical mind and business acumen
Problem-solving aptitude
Excellent communication and presentation skills
Experience working in machine learning (preferred)

All information will be kept confidential according to EEO guidelines.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company Description<br><br></u></strong>Medable's mission is to get effective therapies to patients faster. We provide an end-to-end, cloud-based platform with a flexible suite of tools that allows patients, healthcare providers, clinical research organizations and pharmaceutical sponsors to work together as a team in clinical trials. Our solutions enable more efficient clinical research, more effective healthcare delivery, and more accurate precision and predictive medicine. Our target audiences are patients, providers, principal investigators, and innovators who work in healthcare and life sciences.<br><br>Our vision is to accelerate the path to human discovery and medical cures. We are passionate about driving innovation and empowering consumers. We are proactive, collaborative, self-motivated learners, committed, bold and tenacious. We are dedicated to making this world a healthier place.<br><br><strong><u>Job Description<br></u></strong><ul><li>Explore machine learning opportunities</li><li>Investigate and compile new sources of medical data</li><li>Provide clinical input to refine existing machine learning architecture</li><li>Develop and integrate machine learning algorithms for data processing and analysis</li><li>Building models to address business problems</li><li>Presenting information using data visualization techniques</li><li>Undertake preprocessing of structured and unstructured data</li><li>Analyze large amounts of information to discover trends and patterns</li><li>Build predictive models and machine-learning algorithms</li><li>Propose solutions and strategies to business challenges</li><li>Collaborate with engineering and product development teams</li><li>Other duties as assigned<br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>0-3 years working in Computer Science or a combination of education and experience (3+ preferred)</li><li>Bachelor’s degree in Computer Science, Artificial Intelligence, Engineering or relevant field </li><li>Experiece with R programming language, C++, Python, Java, Node.JS<br><br></li></ul>Additional Information<br><ul><li>Highly analytical with a knack for analysis, math and statistics</li><li>Critical thinking and problem-solving skills</li><li>Passion for machine-learning and research</li><li>Experience in data mining</li><li>Analytical mind and business acumen</li><li>Problem-solving aptitude</li><li>Excellent communication and presentation skills</li><li>Experience working in machine learning (preferred)<br></li></ul>All information will be kept confidential according to EEO guidelines.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Internet
Data Engineer,"Dallas, Texas, United States",Pegasys Information Technologies,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-pegasys-information-technologies-2430509220?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=A4mWL4rq7cwpwkh9m5CiQQ%3D%3D&position=15&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Do you want a job that throws a different challenge at you every day? Have you got an unquenchable passion for data and problem solving? Are you aching to jump into a fast-paced work environment that will keep you on your toes? We’ve got one you might like.

At InterWorks, we like our work with a hefty side of play. Our team of high achievers is looking for an eager learner who doesn’t shy away from hard work. We need someone whose overall data and programming savvy outweighs niche experience with a certain database platform. Whether you’ve worked primarily in SQL Server, Postgres or something else, all we really care about is that you have a strong understanding of building data pipelines and are ready to hit the ground running. It also wouldn’t hurt for you to be wicked smart and make one heck of a coworker, but we’re pretty sure you’ve got that covered already. Otherwise, you wouldn’t still be reading.

What You’ll Do

Tackle diverse projects that range in duration from a few days to a few months for clients ranging from local businesses to the Fortune 500
Work with disparate data sources (relational databases, flat files, Excel, HDFS/Big Data systems, high-performance analytical databases, etc.) to unify client data
Collaborate closely with users to understand their unique needs and support them with the best solutions
Solve data-acquisition, integration and management problems
Create ETL processes based on client needs while managing client expectations


What You’ll Need

Must-Haves

Excellent SQL fluency
Programming (Python, Java, C#, PHP, etc.)
Strong ETL proficiency using GUI-based tools or code-based patterns
Understanding of data-modeling principles
Excellent verbal and written communication
Business acumen
Strong problem-solving skills
Adaptability and flexibility in changing situations
Passion for delivering compelling solutions that exceed client expectations

What We’d Like You to Have

Experience with software engineering practices
Experience with modern data-engineering practices and frameworks
Experience with integration from API sources
Matillion, Fivetran, Airflow, DBT or other ETL tools
AWS / Microsoft Azure
Snowflake / Amazon Redshift / Google BigQuery / Azure Synapse


Why InterWorks

InterWorks is a people-focused tech consultancy that empowers clients with customized, collaborative solutions, and we love pursuing innovation alongside people who inspire us. Our approach to work and community is unique and unconventional—just like us—and that’s the way we want it. The only thing missing is you.

Click here for the InterWorks Privacy Policy
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Do you want a job that throws a different challenge at you every day? Have you got an unquenchable passion for data and problem solving? Are you aching to jump into a fast-paced work environment that will keep you on your toes? We’ve got one you might like.<br><br>At InterWorks, we like our work with a hefty side of play. Our team of high achievers is looking for an eager learner who doesn’t shy away from hard work. We need someone whose overall data and programming savvy outweighs niche experience with a certain database platform. Whether you’ve worked primarily in SQL Server, Postgres or something else, all we really care about is that you have a strong understanding of building data pipelines and are ready to hit the ground running. It also wouldn’t hurt for you to be wicked smart and make one heck of a coworker, but we’re pretty sure you’ve got that covered already. Otherwise, you wouldn’t still be reading.<br><br><strong><u>What You’ll Do<br></u></strong><ul><li>Tackle diverse projects that range in duration from a few days to a few months for clients ranging from local businesses to the Fortune 500</li><li>Work with disparate data sources (relational databases, flat files, Excel, HDFS/Big Data systems, high-performance analytical databases, etc.) to unify client data</li><li>Collaborate closely with users to understand their unique needs and support them with the best solutions</li><li>Solve data-acquisition, integration and management problems</li><li>Create ETL processes based on client needs while managing client expectations<br><br></li></ul><strong><u>What You’ll Need<br><br></u></strong><u>Must-Haves<br></u><ul><li>Excellent SQL fluency</li><li>Programming (Python, Java, C#, PHP, etc.)</li><li>Strong ETL proficiency using GUI-based tools or code-based patterns</li><li>Understanding of data-modeling principles</li><li>Excellent verbal and written communication</li><li>Business acumen</li><li>Strong problem-solving skills</li><li>Adaptability and flexibility in changing situations</li><li>Passion for delivering compelling solutions that exceed client expectations<br></li></ul><u>What We’d Like You to Have<br></u><ul><li>Experience with software engineering practices</li><li>Experience with modern data-engineering practices and frameworks</li><li>Experience with integration from API sources</li><li>Matillion, Fivetran, Airflow, DBT or other ETL tools</li><li>AWS / Microsoft Azure</li><li>Snowflake / Amazon Redshift / Google BigQuery / Azure Synapse <br><br></li></ul><strong>Why InterWorks<br><br></strong>InterWorks is a people-focused tech consultancy that empowers clients with customized, collaborative solutions, and we love pursuing innovation alongside people who inspire us. Our approach to work and community is unique and unconventional—just like us—and that’s the way we want it. The only thing missing is you.<br><br>Click here for the InterWorks Privacy Policy</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Management Consulting"
"Data Engineer - Python, Spark, SQL","Beaverton, Oregon, United States",Dice,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-python-spark-sql-at-dice-2427534017?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=qn%2F42fY8fitDWi9pyuVJpw%3D%3D&position=16&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Experience with object orientedscripting language PySpark or Spark Scala Hands on experience with Python is must. Hands on experience in Azure Cloud components such as Azure Data Factory, Azure Logic apps service, Data Bricks Experience with integration of different data sources (Files, DBs, APIs)

Experience in working with huge data sets perform data ingestion, Load transformation

Data aggregation

Data optimization.

Knowledge of various ETL techniques Strong SQL skills Strong analytic skill to work with unstructured data Experience with data pipeline and workflow management tools Azure DevOps Ability to work directly with customers Experience with object orientedscripting language PySpark or Spark Scala

Experience working with Agile teams scrums. Azure DevOps skill would be an added advantage.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Experience with object orientedscripting language PySpark or Spark Scala Hands on experience with Python is must. Hands on experience in Azure Cloud components such as Azure Data Factory, Azure Logic apps service, Data Bricks Experience with integration of different data sources (Files, DBs, APIs)<br><br>Experience in working with huge data sets perform data ingestion, Load transformation<br><br>Data aggregation<br><br>Data optimization.<br><br>Knowledge of various ETL techniques Strong SQL skills Strong analytic skill to work with unstructured data Experience with data pipeline and workflow management tools Azure DevOps Ability to work directly with customers Experience with object orientedscripting language PySpark or Spark Scala<br><br>Experience working with Agile teams scrums. Azure DevOps skill would be an added advantage.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Automotive"
AWS Data Engineer,"Lafayette, Louisiana, United States",CGI,2021-02-11,https://www.linkedin.com/jobs/view/aws-data-engineer-at-cgi-2406631238?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=poch4VJNauqKPrM3zZKCjg%3D%3D&position=17&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, KSN Technologies, Inc., is seeking the following. Apply via Dice today!

Data Engineer - Python, Spark, SQL Beaverton, Oregon Long term Contract Looking for the candidates who can work on our W2. As a Data Engineer within the North America Supply Chain Analytics team, you will be a key member of a growing and passionate group focused on collaborating across business and technology resources to drive forward key programs and projects building enterprise data analytics capabilities across Nike. Primary Responsibilities bull Good understanding and application of modern data processing technology stacks. For example, Snowflake, SQL, Spark, Hadoop ecosystem technologies, and others bull Design and build product features in collaboration with business and IT bull Design reusable components, frameworks, libraries like User Defined Functions bull Build continuous integration and test-driven development environment bull Performancescalability tuning, algorithms and computational complexity bull Develop architecture and design patterns to process and store high volume data sets bull Participate in an Agile Scrum methodology to deliver high - quality software releases every 2 weeks through Sprints bull Troubleshoot production support issues post - deployment and come up with solutions as required bull A Bachelor's degree in Business, Information Technology or related field bull 2+ yearsrsquo experience in a professional organization collaborating across multiple functions bull Familiarity with Agile project delivery methods bull Experience with AWS components and services (E.G. EMR, S3, and Lambda) bull Experience with Jenkins, BitbucketGitHub and scheduling tools like Airflow bull Strong programming, Python, shell scripting and SQL bull Good understanding of file formats including JSON, Parquet, Avro, and others bull Experience with data warehousesRDBMS like Oracle, Teradata, Snowflake bull Experience with data warehousing, dimensional modeling and ETL development bull Demonstrable ability to quickly learn new tools and technologies bull Machine learning frameworks statistical analysis with Python, R or similar bull Exceptional interpersonal and communication skills (written and verbal) bull Passion for data with demonstrated ability to use data to tell a story and influence decision making bull Detail oriented with strong information seeking skills Competencies bull Effective Communicator bull Broad Business Process and Systems Understanding bull Analytical and Focused bull Strategic Thinking and Tactical Execution bull Continuous Learner
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Dice is the leading career destination for tech experts at every stage of their careers. Our client, KSN Technologies, Inc., is seeking the following. Apply via Dice today!<br><br>Data Engineer - Python, Spark, SQL Beaverton, Oregon Long term Contract Looking for the candidates who can work on our W2. As a Data Engineer within the North America Supply Chain Analytics team, you will be a key member of a growing and passionate group focused on collaborating across business and technology resources to drive forward key programs and projects building enterprise data analytics capabilities across Nike. Primary Responsibilities bull Good understanding and application of modern data processing technology stacks. For example, Snowflake, SQL, Spark, Hadoop ecosystem technologies, and others bull Design and build product features in collaboration with business and IT bull Design reusable components, frameworks, libraries like User Defined Functions bull Build continuous integration and test-driven development environment bull Performancescalability tuning, algorithms and computational complexity bull Develop architecture and design patterns to process and store high volume data sets bull Participate in an Agile Scrum methodology to deliver high - quality software releases every 2 weeks through Sprints bull Troubleshoot production support issues post - deployment and come up with solutions as required bull A Bachelor's degree in Business, Information Technology or related field bull 2+ yearsrsquo experience in a professional organization collaborating across multiple functions bull Familiarity with Agile project delivery methods bull Experience with AWS components and services (E.G. EMR, S3, and Lambda) bull Experience with Jenkins, BitbucketGitHub and scheduling tools like Airflow bull Strong programming, Python, shell scripting and SQL bull Good understanding of file formats including JSON, Parquet, Avro, and others bull Experience with data warehousesRDBMS like Oracle, Teradata, Snowflake bull Experience with data warehousing, dimensional modeling and ETL development bull Demonstrable ability to quickly learn new tools and technologies bull Machine learning frameworks statistical analysis with Python, R or similar bull Exceptional interpersonal and communication skills (written and verbal) bull Passion for data with demonstrated ability to use data to tell a story and influence decision making bull Detail oriented with strong information seeking skills Competencies bull Effective Communicator bull Broad Business Process and Systems Understanding bull Analytical and Focused bull Strategic Thinking and Tactical Execution bull Continuous Learner</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Banking"
Data Engineer/Software Engineer - Data,"Mountain View, California, United States",Confluent,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-software-engineer-data-at-confluent-2368009092?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=N50g7HtVfMS6Sy7S4456Bg%3D%3D&position=18&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Job Description AWS Data Engineer

Position Description

Position Description

CGI is looking for an AWS Data Engineer who can join in our emerging technology group in the digital insight practice. The AWS Data Engineer with 2-5 years of experience will be responsible for designing & developing data ingestion and data transformation framework for modern data lake solutions.
Design and build production data pipelines from ingestion to consumption within a big data architecture, using, Python, Scala, GLUE. Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming. Code & Unit test, and design continuous integration/development.
Automate testing.

Responsibilities


Candidates with the skills (not all but some) AWS Step Functions, S3, Glue, EMR, Redshift, Dynamo DB, Aurora, Athena, Big data on AWS.
AWS data services, Hadoop, Pyspark,
Secondary Skill: Glue, Data Pipe Line, Databricks, Virtual Machine
Role Description: Design & develop solution on AWS Cloud for data lake/integration using PaaS services like Glue, data pipe line etc Hadoop, Pyspark platform.


Required Skills


7+ years of work experience with ETL, and business intelligence AWS data architectures.
3+ years of hands-on Spark/Scala/Python development experience.
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Experience with core competencies in Data Structures, Rest/SOAP APIs, JSON, etc.
Strong experience in massively parallel processing & columnar databases.
Expert in writing SQL.
Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.
Experience with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)
Ability to manage numerous requests concurrently and strategically, prioritizing when necessary.
Good communication and presentation skills.
Dynamic team player.


Your future duties and responsibilities

Required Qualifications To Be Successful In This Role

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com .

No unsolicited agency referrals please.

CGI is an equal opportunity employer.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.

Skills

SQL
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Job Description AWS Data Engineer<br><br>Position Description<br><br><strong><u>Position Description<br><br></u></strong>CGI is looking for an AWS Data Engineer who can join in our emerging technology group in the digital insight practice. The AWS Data Engineer with 2-5 years of experience will be responsible for designing &amp; developing data ingestion and data transformation framework for modern data lake solutions.<br>Design and build production data pipelines from ingestion to consumption within a big data architecture, using, Python, Scala, GLUE. Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming. Code &amp; Unit test, and design continuous integration/development.<br>Automate testing.<br><br><strong><u>Responsibilities<br><br></u></strong><li> Candidates with the skills (not all but some) AWS Step Functions, S3, Glue, EMR, Redshift, Dynamo DB, Aurora, Athena, Big data on AWS.</li><li> AWS data services, Hadoop, Pyspark,</li><li> Secondary Skill: Glue, Data Pipe Line, Databricks, Virtual Machine</li><li> Role Description: Design &amp; develop solution on AWS Cloud for data lake/integration using PaaS services like Glue, data pipe line etc Hadoop, Pyspark platform.<br><br></li><strong><u>Required Skills<br><br></u></strong><li> 7+ years of work experience with ETL, and business intelligence AWS data architectures.</li><li> 3+ years of hands-on Spark/Scala/Python development experience.</li><li> Experience developing and managing data warehouses on a terabyte or petabyte scale.</li><li> Experience with core competencies in Data Structures, Rest/SOAP APIs, JSON, etc.</li><li> Strong experience in massively parallel processing &amp; columnar databases.</li><li> Expert in writing SQL.</li><li> Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.</li><li> Experience with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)</li><li> Ability to manage numerous requests concurrently and strategically, prioritizing when necessary.</li><li> Good communication and presentation skills.</li><li> Dynamic team player.<br><br></li>Your future duties and responsibilities<br><br><strong><u>Required Qualifications To Be Successful In This Role<br><br></u></strong><strong>Build your career with us.<br><br></strong>It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.<br><br>At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.<br><br>Be part of building one of the largest independent technology and business services firms in the world.<br><br>Learn more about CGI at www.cgi.com .<br><br>No unsolicited agency referrals please.<br><br>CGI is an equal opportunity employer.<br><br>Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.<br><br>CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. <strong>Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned</strong>.<br><br>We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.<br><br>All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held.<br><br>CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.<br><br><strong><u>Skills<br></u></strong><ul><li> SQL</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Machine Learning Engineer,"Reston, Virginia, United States",Leading Path Consulting,2021-02-19,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-leading-path-consulting-2415656871?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=zMQOS2Jbl%2Fn04NuU62G%2BLA%3D%3D&position=19&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"At Confluent, we’re creating a category that transforms how every company manages and streams data. Have you ever found a new favorite series on Netflix, picked up groceries curbside at Walmart, or paid for something using Square? That’s Confluent in action—giving our customers instant access to massive amounts of real-time data, enabling them to thrive in an ever-changing digital world. As one of the fastest-growing enterprise companies in history, and with Fortune 100 customers across major industries, we have a tremendous opportunity in front of us. We also have experience on our side. Our leaders have taken companies of our size to major success before and include some of the original creators of Apache Kafka®.

We’re looking for self-motivated team members who crave a challenge and feel energized to roll up their sleeves and help realize Confluent’s unlimited potential. Chart your own path and take healthy risks with the backing and support of our #OneTeam culture. Be part of inclusive initiatives like Employee Resource Groups and development programs, and take advantage of benefits that support our diverse global teams. Grow as we grow—whether you’re just starting out or managing a large team, you’ll be amazed at the magnitude of your impact.

About The Team

The mission of the Data team at Confluent is to serve as the central nervous system of all things data for the company: we build analytics infrastructure, insights, models and tools, to empower data-driven thinking, and optimize every part of the business. This position offers limitless opportunities for an ambitious data engineer to make an immediate and meaningful impact within a hyper growth start-up, and contribute to a highly engaged open source community.

About The Role

This role will help improve our streaming ETL and analytics infrastructure using Kafka to provide real-time visibility and insights into business operations. By doing so, it will also help form a strong feedback loop with the Product team to help inform Confluent’s product direction and market growth.

In this role you will have the opportunity to work with the Kafka and the Product team at Confluent and help influence the product direction and take Kafka’s Cloud Native journey to the next level.

You are encouraged to think out of the box and play with the latest technologies while exploring their limits. Success

Responsibilities

Design and build a highly available and durable event streaming infrastructure which provides end-to-end latency guarantee
Develop strong subject matter expertise and manage the SLAs for those data pipelines
Partner with Data Scientists and business partners to onboard more use cases to this streaming platform to empower every aspect of our business


What We're Looking For

Bachelor or advanced degree in Computer Science, Engineering, or related technical discipline
3+ years of experience in a Software Engineering or Data Engineering role, with a focus on building event streaming applications.
Strong knowledge of streaming data architectures and data infrastructure ecosystem.
Experience with Kafka in a production environment.
Excellent programming skills in Java or Scala (Required) and Python (nice to have)
An innate desire to deliver and a strong sense of accountability for your work
The ability to communicate cross-functionally, derive requirements and architect; ability to synthesize, simplify and explain complex problems to different types of audiences, including executives
The ability to thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful.


What Gives You An Edge

Experience with other Kafka components such as Connect and ksqlDB.
Working knowledge of SQL and data analytics at scale.
Application deployment and management using Docker and Kubernetes.
Familiarity with AWS, GCP or Azure cloud environments and technologies.
Experience with enterprise business systems such as Salesforce, Marketo, Zendesk, etc.
Product mindset to understand business needs, and come up with scalable engineering solutions


#LI- MT1

Come As You Are

At Confluent, equality is a core tenet of our culture. We are committed to building an inclusive global team that represents a variety of backgrounds, perspectives, beliefs, and experiences. The more diverse we are, the richer our community and the broader our impact.

Click here to review our California Candidate Privacy Notice , which describes how and when Confluent, Inc., and its group companies, collects, uses, and shares certain personal information of California job applicants and prospective employees.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Confluent, we’re creating a category that transforms how every company manages and streams data. Have you ever found a new favorite series on Netflix, picked up groceries curbside at Walmart, or paid for something using Square? That’s Confluent in action—giving our customers instant access to massive amounts of real-time data, enabling them to thrive in an ever-changing digital world. As one of the fastest-growing enterprise companies in history, and with Fortune 100 customers across major industries, we have a tremendous opportunity in front of us. We also have experience on our side. Our leaders have taken companies of our size to major success before and include some of the original creators of Apache Kafka®.<br><br>We’re looking for self-motivated team members who crave a challenge and feel energized to roll up their sleeves and help realize Confluent’s unlimited potential. Chart your own path and take healthy risks with the backing and support of our #OneTeam culture. Be part of inclusive initiatives like Employee Resource Groups and development programs, and take advantage of benefits that support our diverse global teams. Grow as we grow—whether you’re just starting out or managing a large team, you’ll be amazed at the magnitude of your impact.<br><br><strong><u>About The Team<br><br></u></strong>The mission of the Data team at Confluent is to serve as the central nervous system of all things data for the company: we build analytics infrastructure, insights, models and tools, to empower data-driven thinking, and optimize every part of the business. This position offers limitless opportunities for an ambitious data engineer to make an immediate and meaningful impact within a hyper growth start-up, and contribute to a highly engaged open source community.<br><br><strong><u>About The Role<br><br></u></strong>This role will help improve our streaming ETL and analytics infrastructure using Kafka to provide real-time visibility and insights into business operations. By doing so, it will also help form a strong feedback loop with the Product team to help inform Confluent’s product direction and market growth.<br><br>In this role you will have the opportunity to work with the Kafka and the Product team at Confluent and help influence the product direction and take Kafka’s Cloud Native journey to the next level.<br><br>You are encouraged to think out of the box and play with the latest technologies while exploring their limits. Success<br><br><strong><u>Responsibilities<br></u></strong><ul><ul><li>Design and build a highly available and durable event streaming infrastructure which provides end-to-end latency guarantee</li><li>Develop strong subject matter expertise and manage the SLAs for those data pipelines</li><li>Partner with Data Scientists and business partners to onboard more use cases to this streaming platform to empower every aspect of our business<br><br></li></ul></ul><strong><u>What We're Looking For<br></u></strong><ul><ul><li>Bachelor or advanced degree in Computer Science, Engineering, or related technical discipline</li><li>3+ years of experience in a Software Engineering or Data Engineering role, with a focus on building event streaming applications.</li><li>Strong knowledge of streaming data architectures and data infrastructure ecosystem.</li><li>Experience with Kafka in a production environment.</li><li>Excellent programming skills in Java or Scala (Required) and Python (nice to have)</li><li>An innate desire to deliver and a strong sense of accountability for your work</li><li>The ability to communicate cross-functionally, derive requirements and architect; ability to synthesize, simplify and explain complex problems to different types of audiences, including executives</li><li>The ability to thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful.<br><br></li></ul></ul><strong><u>What Gives You An Edge<br></u></strong><ul><ul><li>Experience with other Kafka components such as Connect and ksqlDB.</li><li>Working knowledge of SQL and data analytics at scale.</li><li>Application deployment and management using Docker and Kubernetes.</li><li>Familiarity with AWS, GCP or Azure cloud environments and technologies.</li><li>Experience with enterprise business systems such as Salesforce, Marketo, Zendesk, etc.</li><li>Product mindset to understand business needs, and come up with scalable engineering solutions<br><br></li></ul></ul>#LI- MT1<br><br><strong>Come As You Are<br><br></strong>At Confluent, equality is a core tenet of our culture. We are committed to building an inclusive global team that represents a variety of backgrounds, perspectives, beliefs, and experiences. The more diverse we are, the richer our community and the broader our impact.<br><br>Click here to review our <em>California Candidate Privacy Notice</em> , which describes how and when Confluent, Inc., and its group companies, collects, uses, and shares certain personal information of California job applicants and prospective employees.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Computer Networking, Information Technology and Services"
Data Engineer,"New York, New York, United States",1010data,2021-01-31,https://www.linkedin.com/jobs/view/data-engineer-at-1010data-2388191836?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=ln%2FkjRrO8UZFmeoJaI3WZQ%3D%3D&position=21&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"1010data values

Integrity: Doing the right things for the right reasons
Agility: Adapting and thriving in a dynamic environment
Teamwork: Combining our strengths to do amazing things
Passion: Channeling enthusiasm to drive excellence
Creativity: Unleashing curiosity to defy the norm



About The Role

As a Data Engineer at 1010data, you will be responsible for designing, maintaining, and optimizing large-scale automated ELT processes. Working actively with analysts and customer teams specializing in enterprise data warehousing, you will leverage industry-standard data orchestration tools as well as in-house proprietary scheduling and automation tools to create efficient and reliable ELT jobs which support 1010data’s product offerings and data warehousing needs for our customers. As we incorporate more cloud technologies into our processes, you will be at the forefront of exploring and defining best practices and helping us transition our products to be more scalable.

As part of the onboarding process, you will learn about 1010data’s proprietary technology stack. Our query engine, query language, database, and data storage layer were all developed and fine-tuned in-house over the lifetime of the company. ELT processes heavily rely on these components, whether they are written in Python and Airflow, or our proprietary data orchestration tools. You will be formally trained in the latter as a new 1010data employee. The concepts should be familiar to anyone with exposure to database techniques like normalization/indexing/partitioning, MapReduce, columnar database architecture and distributed systems.

This role is not sponsorable    

What You Will Take On

Taking end-to-end ownership of data pipelines and custom solutions for our clients
Coordinating with the systems, core, CX, and analytics teams to build and maintain data products and custom solutions for our clients
Designing and writing automated scripts to preprocess terabytes of data from our partners/clients
Designing and writing new enterprise-scale ELT/ETL workflows from scratch in Python using Airflow, Docker, AWS, etc.
Modifying/redesigning legacy ELT/ETL processes to leverage cutting-edge open source and proprietary technologies
Ensuring quality, reliability and uptime for critical automated processes
Migrating our products and processes into the cloud while drastically reducing our in-house data center footprint



Required Skills

What you already have:

At least 1-2 years of professional experience programming in Python
Exposure to ETL/ELT pipeline automation
Exposure to basic database concepts



Preferred Skills

Good understanding of Data Engineering, NoSQL databases and database design, distributed systems and/or information retrieval
Work with Saas products
Knowledge of Apache Airflow
DBA experience
Ability to plan and collect requirements for projects, and interact with the analyst and data science teams



Education

STEM Bachelor’s required, graduate degree is a big plus



About 1010data

For more than 20 years, 1010data has helped financial, retail and consumer goods customers monitor shifts in consumer demand and market conditions and rapidly respond with highly targeted strategies. The 1010data Insights Platform combines market intelligence, data management, granular enterprise analytics, and collaboration capabilities to empower better business outcomes. More than 900 of the world’s foremost companies partner with 1010data to power smarter decisions.

You can find this on the Company page of 1010data at https://1010data.com/company/

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. 
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>1010data values<br></u></strong><ul> <li>Integrity: Doing the right things for the right reasons </li> <li>Agility: Adapting and thriving in a dynamic environment </li> <li>Teamwork: Combining our strengths to do amazing things </li> <li>Passion: Channeling enthusiasm to drive excellence </li> <li>Creativity: Unleashing curiosity to defy the norm </li> <br><br></ul><strong><u>About The Role<br><br></u></strong>As a Data Engineer at 1010data, you will be responsible for designing, maintaining, and optimizing large-scale automated ELT processes. Working actively with analysts and customer teams specializing in enterprise data warehousing, you will leverage industry-standard data orchestration tools as well as in-house proprietary scheduling and automation tools to create efficient and reliable ELT jobs which support 1010data’s product offerings and data warehousing needs for our customers. As we incorporate more cloud technologies into our processes, you will be at the forefront of exploring and defining best practices and helping us transition our products to be more scalable.<br><br>As part of the onboarding process, you will learn about 1010data’s proprietary technology stack. Our query engine, query language, database, and data storage layer were all developed and fine-tuned in-house over the lifetime of the company. ELT processes heavily rely on these components, whether they are written in Python and Airflow, or our proprietary data orchestration tools. You will be formally trained in the latter as a new 1010data employee. The concepts should be familiar to anyone with exposure to database techniques like normalization/indexing/partitioning, MapReduce, columnar database architecture and distributed systems.<br><br><strong>This role is not sponsorable     <br><br></strong><strong><u>What You Will Take On<br></u></strong><ul> <li>Taking end-to-end ownership of data pipelines and custom solutions for our clients </li> <li>Coordinating with the systems, core, CX, and analytics teams to build and maintain data products and custom solutions for our clients </li> <li>Designing and writing automated scripts to preprocess terabytes of data from our partners/clients </li> <li>Designing and writing new enterprise-scale ELT/ETL workflows from scratch in Python using Airflow, Docker, AWS, etc. </li> <li>Modifying/redesigning legacy ELT/ETL processes to leverage cutting-edge open source and proprietary technologies </li> <li>Ensuring quality, reliability and uptime for critical automated processes </li> <li>Migrating our products and processes into the cloud while drastically reducing our in-house data center footprint </li> <br><br></ul><strong><u>Required Skills<br><br></u></strong><strong>What you already have:<br></strong><ul> <li>At least 1-2 years of professional experience programming in Python </li> <li>Exposure to ETL/ELT pipeline automation </li> <li>Exposure to basic database concepts </li> <br><br></ul><strong><u>Preferred Skills<br></u></strong><ul> <li>Good understanding of Data Engineering, NoSQL databases and database design, distributed systems and/or information retrieval </li> <li>Work with Saas products </li> <li>Knowledge of Apache Airflow </li> <li>DBA experience </li> <li>Ability to plan and collect requirements for projects, and interact with the analyst and data science teams </li> <br><br></ul><strong><u>Education<br></u></strong><ul> <li>STEM Bachelor’s required, graduate degree is a big plus </li> <br><br></ul><strong><u>About 1010data<br><br></u></strong>For more than 20 years, 1010data has helped financial, retail and consumer goods customers monitor shifts in consumer demand and market conditions and rapidly respond with highly targeted strategies. The 1010data Insights Platform combines market intelligence, data management, granular enterprise analytics, and collaboration capabilities to empower better business outcomes. More than 900 of the world’s foremost companies partner with 1010data to power smarter decisions.<br><br>You can find this on the Company page of 1010data at https://1010data.com/company/<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. </div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Internet
Data Scientist,"Austin, Texas, United States",Zynga,2021-01-28,https://www.linkedin.com/jobs/view/data-scientist-at-zynga-2398248334?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=DZLpRHbAN4BeHdAKCxy8Dg%3D%3D&position=22&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"1010data values

Integrity: Doing the right things for the right reasons
Agility: Adapting and thriving in a dynamic environment
Teamwork: Combining our strengths to do amazing things
Passion: Channeling enthusiasm to drive excellence
Creativity: Unleashing curiosity to defy the norm



About The Role

As a Data Engineer at 1010data, you will be responsible for designing, maintaining, and optimizing large-scale automated ELT processes. Working actively with analysts and customer teams specializing in enterprise data warehousing, you will leverage industry-standard data orchestration tools as well as in-house proprietary scheduling and automation tools to create efficient and reliable ELT jobs which support 1010data’s product offerings and data warehousing needs for our customers. As we incorporate more cloud technologies into our processes, you will be at the forefront of exploring and defining best practices and helping us transition our products to be more scalable.

As part of the onboarding process, you will learn about 1010data’s proprietary technology stack. Our query engine, query language, database, and data storage layer were all developed and fine-tuned in-house over the lifetime of the company. ELT processes heavily rely on these components, whether they are written in Python and Airflow, or our proprietary data orchestration tools. You will be formally trained in the latter as a new 1010data employee. The concepts should be familiar to anyone with exposure to database techniques like normalization/indexing/partitioning, MapReduce, columnar database architecture and distributed systems.

This role is not sponsorable    

What You Will Take On

Taking end-to-end ownership of data pipelines and custom solutions for our clients
Coordinating with the systems, core, CX, and analytics teams to build and maintain data products and custom solutions for our clients
Designing and writing automated scripts to preprocess terabytes of data from our partners/clients
Designing and writing new enterprise-scale ELT/ETL workflows from scratch in Python using Airflow, Docker, AWS, etc.
Modifying/redesigning legacy ELT/ETL processes to leverage cutting-edge open source and proprietary technologies
Ensuring quality, reliability and uptime for critical automated processes
Migrating our products and processes into the cloud while drastically reducing our in-house data center footprint



Required Skills

What you already have:

At least 1-2 years of professional experience programming in Python
Exposure to ETL/ELT pipeline automation
Exposure to basic database concepts



Preferred Skills

Good understanding of Data Engineering, NoSQL databases and database design, distributed systems and/or information retrieval
Work with Saas products
Knowledge of Apache Airflow
DBA experience
Ability to plan and collect requirements for projects, and interact with the analyst and data science teams



Education

STEM Bachelor’s required, graduate degree is a big plus



About 1010data

For more than 20 years, 1010data has helped financial, retail and consumer goods customers monitor shifts in consumer demand and market conditions and rapidly respond with highly targeted strategies. The 1010data Insights Platform combines market intelligence, data management, granular enterprise analytics, and collaboration capabilities to empower better business outcomes. More than 900 of the world’s foremost companies partner with 1010data to power smarter decisions.

You can find this on the Company page of 1010data at https://1010data.com/company/

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. 
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>1010data values<br></u></strong><ul> <li>Integrity: Doing the right things for the right reasons </li> <li>Agility: Adapting and thriving in a dynamic environment </li> <li>Teamwork: Combining our strengths to do amazing things </li> <li>Passion: Channeling enthusiasm to drive excellence </li> <li>Creativity: Unleashing curiosity to defy the norm </li> <br><br></ul><strong><u>About The Role<br><br></u></strong>As a Data Engineer at 1010data, you will be responsible for designing, maintaining, and optimizing large-scale automated ELT processes. Working actively with analysts and customer teams specializing in enterprise data warehousing, you will leverage industry-standard data orchestration tools as well as in-house proprietary scheduling and automation tools to create efficient and reliable ELT jobs which support 1010data’s product offerings and data warehousing needs for our customers. As we incorporate more cloud technologies into our processes, you will be at the forefront of exploring and defining best practices and helping us transition our products to be more scalable.<br><br>As part of the onboarding process, you will learn about 1010data’s proprietary technology stack. Our query engine, query language, database, and data storage layer were all developed and fine-tuned in-house over the lifetime of the company. ELT processes heavily rely on these components, whether they are written in Python and Airflow, or our proprietary data orchestration tools. You will be formally trained in the latter as a new 1010data employee. The concepts should be familiar to anyone with exposure to database techniques like normalization/indexing/partitioning, MapReduce, columnar database architecture and distributed systems.<br><br><strong>This role is not sponsorable     <br><br></strong><strong><u>What You Will Take On<br></u></strong><ul> <li>Taking end-to-end ownership of data pipelines and custom solutions for our clients </li> <li>Coordinating with the systems, core, CX, and analytics teams to build and maintain data products and custom solutions for our clients </li> <li>Designing and writing automated scripts to preprocess terabytes of data from our partners/clients </li> <li>Designing and writing new enterprise-scale ELT/ETL workflows from scratch in Python using Airflow, Docker, AWS, etc. </li> <li>Modifying/redesigning legacy ELT/ETL processes to leverage cutting-edge open source and proprietary technologies </li> <li>Ensuring quality, reliability and uptime for critical automated processes </li> <li>Migrating our products and processes into the cloud while drastically reducing our in-house data center footprint </li> <br><br></ul><strong><u>Required Skills<br><br></u></strong><strong>What you already have:<br></strong><ul> <li>At least 1-2 years of professional experience programming in Python </li> <li>Exposure to ETL/ELT pipeline automation </li> <li>Exposure to basic database concepts </li> <br><br></ul><strong><u>Preferred Skills<br></u></strong><ul> <li>Good understanding of Data Engineering, NoSQL databases and database design, distributed systems and/or information retrieval </li> <li>Work with Saas products </li> <li>Knowledge of Apache Airflow </li> <li>DBA experience </li> <li>Ability to plan and collect requirements for projects, and interact with the analyst and data science teams </li> <br><br></ul><strong><u>Education<br></u></strong><ul> <li>STEM Bachelor’s required, graduate degree is a big plus </li> <br><br></ul><strong><u>About 1010data<br><br></u></strong>For more than 20 years, 1010data has helped financial, retail and consumer goods customers monitor shifts in consumer demand and market conditions and rapidly respond with highly targeted strategies. The 1010data Insights Platform combines market intelligence, data management, granular enterprise analytics, and collaboration capabilities to empower better business outcomes. More than 900 of the world’s foremost companies partner with 1010data to power smarter decisions.<br><br>You can find this on the Company page of 1010data at https://1010data.com/company/<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. </div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Games, Computer Software, Entertainment"
Data Visualization Engineer,"Chicago, Illinois, United States",GHX,2021-02-13,https://www.linkedin.com/jobs/view/data-visualization-engineer-at-ghx-2408983866?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=ipv%2FfzZ91d%2B8zbN5qpR%2Bww%3D%3D&position=23&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"Description

Position at Zynga

Zynga is a leading developer of the world’s most popular social games, played by tens of millions of people around the world each day. To-date, more than 1 billion people have played our games across Web and mobile, including FarmVille, Zynga Poker, Words With Friends, Harry Potter: Puzzles & Spells, Merge Dragons!, Empires & Puzzles, Hit it Rich! Slots, Toy and Toon Blast, and CSR Racing.

The Marketing Analytics team has been charged with supporting audience growth functions across our portfolio. We utilize the vast amount of internal and third-party data available to provide reporting, tooling, and automation solutions that elevate the various functions in Zynga’s Marketing organization. Our roadmap has one purpose: to expand Zynga's ability to reach new audiences.

As a data scientist, you will use your machine-learning expertise to capitalize on some of our most ambitious opportunities. Predicting LTV’s, optimizing spend allocation across titles and networks, building publisher recommendation engines, and automating ad sentiment evaluation through computer vision and AI are only a small sample of possible projects for which you could be asked to design and implement solutions. The demands on this team are constantly evolving with the needs of Zynga’s dynamic marketing teams, so it is important that you be able to adapt and utilize your time efficiently.

Responsibilities

Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools
Work closely with marketing teams to craft, test, verify and implement machine learning models to optimize Zynga audience growth
Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives
Design and develop using standard practices within a GitHub environment
Required Skills and Experience:

BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred
3+ years of work experience in data science, machine learning or analytics role
Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization
Proficient in Python, SQL, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks
Strong written and oral communication skills
What we offer you:

Zynga Stock RSUs and Bonus Plan
Full medical, dental, vision benefits as well as life insurance
Generous Paid Maternity/Paternity leave
Open vacation policy for all full time employees
Flexible working hours on many teams
Work alongside driven individuals towards a common goal
Zynga is an equal opportunity employer. We are proud of our diverse community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome candidates, players, employees, and partners from all backgrounds. Join us!

Zynga will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><em>Position at Zynga<br><br></em>Zynga is a leading developer of the world’s most popular social games, played by tens of millions of people around the world each day. To-date, more than 1 billion people have played our games across Web and mobile, including FarmVille, Zynga Poker, Words With Friends, Harry Potter: Puzzles &amp; Spells, Merge Dragons!, Empires &amp; Puzzles, Hit it Rich! Slots, Toy and Toon Blast, and CSR Racing.<br><br>The Marketing Analytics team has been charged with supporting audience growth functions across our portfolio. We utilize the vast amount of internal and third-party data available to provide reporting, tooling, and automation solutions that elevate the various functions in Zynga’s Marketing organization. Our roadmap has one purpose: to expand Zynga's ability to reach new audiences.<br><br>As a data scientist, you will use your machine-learning expertise to capitalize on some of our most ambitious opportunities. Predicting LTV’s, optimizing spend allocation across titles and networks, building publisher recommendation engines, and automating ad sentiment evaluation through computer vision and AI are only a small sample of possible projects for which you could be asked to design and implement solutions. The demands on this team are constantly evolving with the needs of Zynga’s dynamic marketing teams, so it is important that you be able to adapt and utilize your time efficiently.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Use our modern tech stack, AWS (Redshift &amp; Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools</li><li>Work closely with marketing teams to craft, test, verify and implement machine learning models to optimize Zynga audience growth</li><li>Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives</li><li>Design and develop using standard practices within a GitHub environment</li></ul><strong>Required Skills and Experience:<br></strong><ul><li>BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred</li><li>3+ years of work experience in data science, machine learning or analytics role</li><li>Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization</li><li>Proficient in Python, SQL, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks</li><li>Strong written and oral communication skills</li></ul><strong>What we offer you:<br></strong><ul><li>Zynga Stock RSUs and Bonus Plan</li><li>Full medical, dental, vision benefits as well as life insurance</li><li>Generous Paid Maternity/Paternity leave</li><li>Open vacation policy for all full time employees</li><li>Flexible working hours on many teams</li><li>Work alongside driven individuals towards a common goal</li></ul>Zynga is an equal opportunity employer. We are proud of our diverse community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome candidates, players, employees, and partners from all backgrounds. Join us!<br><br>Zynga will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.<br><br>We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Games, Computer Software, Entertainment"
Data Engineer/Machine Learning Engineer,"Houston, Texas, United States",Genuent,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-machine-learning-engineer-at-genuent-2418200725?refId=61ff9e7e-c5be-426f-8580-50c86fea8feb&trackingId=sAyvH651jpTe4BsjVVS13w%3D%3D&position=24&pageNum=6&trk=public_jobs_job-result-card_result-card_full-click,"What is Lumere?

Lumere, a GHX company, is at the forefront of clinical decision making for medical devices, offering evidence-based solutions and services that empower physicians and health systems to reduce costly, unwarranted variation. The company works with more than 700 facilities across the U.S.

What is the data visualization team?

The data visualization team develops scalable, automated analyses and data-driven interpretations of those analyses. These empower our healthcare system customers to make strategic decisions backed by scientific research and their own data in order to provide high-value care for their patients. We are passionate about using data visualization to improve the value derived from healthcare. Our team values diverse perspectives and backgrounds. We value creativity and build up our toolset in a collaborative, consensus-based manner.

As a Data Visualization Engineer, you’ll provide the technical leadership for advancing our component-based visualization library. Whether it’s looking to provide advanced interactivity in our visualizations or working to scale commonly used visualization techniques, you’ll have the opportunity to work on our most impactful data problems.

Results from the analyses you’ll support will guide hospital administrators to make evidence-based decisions when working with clinicians and doctors to select medical devices. This allows health systems to reduce costs and improve care for patients. You can help our customers understand which data points are significant enough to make decisions with and which are simply noise.

You will thrive if you love exploring datasets, applying novel data manipulation and communication techniques, identifying and implementing performance improvements, supporting health systems to interpret their utilization and patient data, improving healthcare value for patients, and solving front-end engineering problems.

What You'll Do

Develop and maintain Lumere’s data visualization component library while adhering to data visualization and engineering best practices
Execute against the ‘technical vision’ for data visualization, ensuring that all data visualization efforts are building toward long-term success
Work closely with Product Management and UX/UI designers to deliver data visualizations to our customers
Foster our pair-programming and team-wide knowledge sharing efforts
Review pull requests, troubleshoot tough development issues
Help to develop code standards that lead to strong performance and long-term maintainability
Scale new analytical features while improving usability and performance



Necessary Requirements To Hit The Ground Running

Professional experience in front end development with a high level of proficiency in HTML, CSS, JavaScript, and JavaScript frameworks and technologies (Vue.js, React, or Angular)
Enough knowledge to be dangerous when it comes to visualizing data with open-source technologies and libraries such as JavaScript (d3.js, Vega), R (ggplot2), or Python (Matplotlib)
SQL and strong understanding of relational databases
Experience with Vue.js or Vega a plus



Estimated Salary range for this position: $90,000- $110,000.

The base salary range represents the anticipated low and high end of the GHX’s salary range for this position. Actual salaries will vary and will be based on various factors, such as candidate’s qualifications, skills, competencies and proficiency for the role. The base salary is one component of GHX’s total compensation package for employees. Other rewards and benefits include: health, vision, and dental insurance, accident and life insurance, 401k matching, paid-time off, and education reimbursement, to name a few. To view more details of our benefits, visit us here: https://www.ghx.com/about/careers/

GHX provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. GHX complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.

GHX expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. Improper interference with the ability of GHX’s employees to perform their expected job duties is absolutely not tolerated.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>What is Lumere?<br><br></strong>Lumere, a GHX company, is at the forefront of clinical decision making for medical devices, offering evidence-based solutions and services that empower physicians and health systems to reduce costly, unwarranted variation. The company works with more than 700 facilities across the U.S.<br><br><strong>What is the data visualization team?<br><br></strong>The data visualization team develops scalable, automated analyses and data-driven interpretations of those analyses. These empower our healthcare system customers to make strategic decisions backed by scientific research and their own data in order to provide high-value care for their patients. We are passionate about using data visualization to improve the value derived from healthcare. Our team values diverse perspectives and backgrounds. We value creativity and build up our toolset in a collaborative, consensus-based manner.<br><br>As a Data Visualization Engineer, you’ll provide the technical leadership for advancing our component-based visualization library. Whether it’s looking to provide advanced interactivity in our visualizations or working to scale commonly used visualization techniques, you’ll have the opportunity to work on our most impactful data problems.<br><br>Results from the analyses you’ll support will guide hospital administrators to make evidence-based decisions when working with clinicians and doctors to select medical devices. This allows health systems to reduce costs and improve care for patients. You can help our customers understand which data points are significant enough to make decisions with and which are simply noise.<br><br>You will thrive if you love exploring datasets, applying novel data manipulation and communication techniques, identifying and implementing performance improvements, supporting health systems to interpret their utilization and patient data, improving healthcare value for patients, and solving front-end engineering problems.<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>Develop and maintain Lumere’s data visualization component library while adhering to data visualization and engineering best practices</li> <li>Execute against the ‘technical vision’ for data visualization, ensuring that all data visualization efforts are building toward long-term success</li> <li>Work closely with Product Management and UX/UI designers to deliver data visualizations to our customers</li> <li>Foster our pair-programming and team-wide knowledge sharing efforts</li> <li>Review pull requests, troubleshoot tough development issues</li> <li>Help to develop code standards that lead to strong performance and long-term maintainability</li> <li>Scale new analytical features while improving usability and performance</li> <br><br></ul><strong><u>Necessary Requirements To Hit The Ground Running<br></u></strong><ul> <li>Professional experience in front end development with a high level of proficiency in HTML, CSS, JavaScript, and JavaScript frameworks and technologies (Vue.js, React, or Angular)</li> <li>Enough knowledge to be dangerous when it comes to visualizing data with open-source technologies and libraries such as JavaScript (d3.js, Vega), R (ggplot2), or Python (Matplotlib)</li> <li>SQL and strong understanding of relational databases</li> <li>Experience with Vue.js or Vega a plus</li> <br><br></ul>Estimated Salary range for this position: $90,000- $110,000.<br><br><em>The base salary range represents the anticipated low and high end of the GHX’s salary range for this position. Actual salaries will vary and will be based on various factors, such as candidate’s qualifications, skills, competencies and proficiency for the role. The base salary is one component of GHX’s total compensation package for employees. Other rewards and benefits include: health, vision, and dental insurance, accident and life insurance, 401k matching, paid-time off, and education reimbursement, to name a few. To view more details of our benefits, visit us here: https://www.ghx.com/about/careers/<br><br></em><em>GHX provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. GHX complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.<br><br></em><em>GHX expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. Improper interference with the ability of GHX’s employees to perform their expected job duties is absolutely not tolerated.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Data Scientist,"Austin, Texas, United States",Zynga,2021-01-28,https://www.linkedin.com/jobs/view/data-scientist-at-zynga-2398248334?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=wYKOReKOpSCXFP%2B%2FrYMehw%3D%3D&position=1&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Description

Position at Zynga

Zynga is a leading developer of the world’s most popular social games, played by tens of millions of people around the world each day. To-date, more than 1 billion people have played our games across Web and mobile, including FarmVille, Zynga Poker, Words With Friends, Harry Potter: Puzzles & Spells, Merge Dragons!, Empires & Puzzles, Hit it Rich! Slots, Toy and Toon Blast, and CSR Racing.

The Marketing Analytics team has been charged with supporting audience growth functions across our portfolio. We utilize the vast amount of internal and third-party data available to provide reporting, tooling, and automation solutions that elevate the various functions in Zynga’s Marketing organization. Our roadmap has one purpose: to expand Zynga's ability to reach new audiences.

As a data scientist, you will use your machine-learning expertise to capitalize on some of our most ambitious opportunities. Predicting LTV’s, optimizing spend allocation across titles and networks, building publisher recommendation engines, and automating ad sentiment evaluation through computer vision and AI are only a small sample of possible projects for which you could be asked to design and implement solutions. The demands on this team are constantly evolving with the needs of Zynga’s dynamic marketing teams, so it is important that you be able to adapt and utilize your time efficiently.

Responsibilities

Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools
Work closely with marketing teams to craft, test, verify and implement machine learning models to optimize Zynga audience growth
Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives
Design and develop using standard practices within a GitHub environment
Required Skills and Experience:

BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred
3+ years of work experience in data science, machine learning or analytics role
Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization
Proficient in Python, SQL, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks
Strong written and oral communication skills
What we offer you:

Zynga Stock RSUs and Bonus Plan
Full medical, dental, vision benefits as well as life insurance
Generous Paid Maternity/Paternity leave
Open vacation policy for all full time employees
Flexible working hours on many teams
Work alongside driven individuals towards a common goal
Zynga is an equal opportunity employer. We are proud of our diverse community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome candidates, players, employees, and partners from all backgrounds. Join us!

Zynga will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><em>Position at Zynga<br><br></em>Zynga is a leading developer of the world’s most popular social games, played by tens of millions of people around the world each day. To-date, more than 1 billion people have played our games across Web and mobile, including FarmVille, Zynga Poker, Words With Friends, Harry Potter: Puzzles &amp; Spells, Merge Dragons!, Empires &amp; Puzzles, Hit it Rich! Slots, Toy and Toon Blast, and CSR Racing.<br><br>The Marketing Analytics team has been charged with supporting audience growth functions across our portfolio. We utilize the vast amount of internal and third-party data available to provide reporting, tooling, and automation solutions that elevate the various functions in Zynga’s Marketing organization. Our roadmap has one purpose: to expand Zynga's ability to reach new audiences.<br><br>As a data scientist, you will use your machine-learning expertise to capitalize on some of our most ambitious opportunities. Predicting LTV’s, optimizing spend allocation across titles and networks, building publisher recommendation engines, and automating ad sentiment evaluation through computer vision and AI are only a small sample of possible projects for which you could be asked to design and implement solutions. The demands on this team are constantly evolving with the needs of Zynga’s dynamic marketing teams, so it is important that you be able to adapt and utilize your time efficiently.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Use our modern tech stack, AWS (Redshift &amp; Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools</li><li>Work closely with marketing teams to craft, test, verify and implement machine learning models to optimize Zynga audience growth</li><li>Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives</li><li>Design and develop using standard practices within a GitHub environment</li></ul><strong>Required Skills and Experience:<br></strong><ul><li>BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred</li><li>3+ years of work experience in data science, machine learning or analytics role</li><li>Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization</li><li>Proficient in Python, SQL, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks</li><li>Strong written and oral communication skills</li></ul><strong>What we offer you:<br></strong><ul><li>Zynga Stock RSUs and Bonus Plan</li><li>Full medical, dental, vision benefits as well as life insurance</li><li>Generous Paid Maternity/Paternity leave</li><li>Open vacation policy for all full time employees</li><li>Flexible working hours on many teams</li><li>Work alongside driven individuals towards a common goal</li></ul>Zynga is an equal opportunity employer. We are proud of our diverse community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome candidates, players, employees, and partners from all backgrounds. Join us!<br><br>Zynga will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.<br><br>We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Games, Computer Software, Entertainment"
Data Visualization Engineer,"Chicago, Illinois, United States",GHX,2021-02-13,https://www.linkedin.com/jobs/view/data-visualization-engineer-at-ghx-2408983866?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=0%2FT0gnUT7g%2FcEJAcm8sB0w%3D%3D&position=2&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"What is Lumere?

Lumere, a GHX company, is at the forefront of clinical decision making for medical devices, offering evidence-based solutions and services that empower physicians and health systems to reduce costly, unwarranted variation. The company works with more than 700 facilities across the U.S.

What is the data visualization team?

The data visualization team develops scalable, automated analyses and data-driven interpretations of those analyses. These empower our healthcare system customers to make strategic decisions backed by scientific research and their own data in order to provide high-value care for their patients. We are passionate about using data visualization to improve the value derived from healthcare. Our team values diverse perspectives and backgrounds. We value creativity and build up our toolset in a collaborative, consensus-based manner.

As a Data Visualization Engineer, you’ll provide the technical leadership for advancing our component-based visualization library. Whether it’s looking to provide advanced interactivity in our visualizations or working to scale commonly used visualization techniques, you’ll have the opportunity to work on our most impactful data problems.

Results from the analyses you’ll support will guide hospital administrators to make evidence-based decisions when working with clinicians and doctors to select medical devices. This allows health systems to reduce costs and improve care for patients. You can help our customers understand which data points are significant enough to make decisions with and which are simply noise.

You will thrive if you love exploring datasets, applying novel data manipulation and communication techniques, identifying and implementing performance improvements, supporting health systems to interpret their utilization and patient data, improving healthcare value for patients, and solving front-end engineering problems.

What You'll Do

Develop and maintain Lumere’s data visualization component library while adhering to data visualization and engineering best practices
Execute against the ‘technical vision’ for data visualization, ensuring that all data visualization efforts are building toward long-term success
Work closely with Product Management and UX/UI designers to deliver data visualizations to our customers
Foster our pair-programming and team-wide knowledge sharing efforts
Review pull requests, troubleshoot tough development issues
Help to develop code standards that lead to strong performance and long-term maintainability
Scale new analytical features while improving usability and performance



Necessary Requirements To Hit The Ground Running

Professional experience in front end development with a high level of proficiency in HTML, CSS, JavaScript, and JavaScript frameworks and technologies (Vue.js, React, or Angular)
Enough knowledge to be dangerous when it comes to visualizing data with open-source technologies and libraries such as JavaScript (d3.js, Vega), R (ggplot2), or Python (Matplotlib)
SQL and strong understanding of relational databases
Experience with Vue.js or Vega a plus



Estimated Salary range for this position: $90,000- $110,000.

The base salary range represents the anticipated low and high end of the GHX’s salary range for this position. Actual salaries will vary and will be based on various factors, such as candidate’s qualifications, skills, competencies and proficiency for the role. The base salary is one component of GHX’s total compensation package for employees. Other rewards and benefits include: health, vision, and dental insurance, accident and life insurance, 401k matching, paid-time off, and education reimbursement, to name a few. To view more details of our benefits, visit us here: https://www.ghx.com/about/careers/

GHX provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. GHX complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.

GHX expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. Improper interference with the ability of GHX’s employees to perform their expected job duties is absolutely not tolerated.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>What is Lumere?<br><br></strong>Lumere, a GHX company, is at the forefront of clinical decision making for medical devices, offering evidence-based solutions and services that empower physicians and health systems to reduce costly, unwarranted variation. The company works with more than 700 facilities across the U.S.<br><br><strong>What is the data visualization team?<br><br></strong>The data visualization team develops scalable, automated analyses and data-driven interpretations of those analyses. These empower our healthcare system customers to make strategic decisions backed by scientific research and their own data in order to provide high-value care for their patients. We are passionate about using data visualization to improve the value derived from healthcare. Our team values diverse perspectives and backgrounds. We value creativity and build up our toolset in a collaborative, consensus-based manner.<br><br>As a Data Visualization Engineer, you’ll provide the technical leadership for advancing our component-based visualization library. Whether it’s looking to provide advanced interactivity in our visualizations or working to scale commonly used visualization techniques, you’ll have the opportunity to work on our most impactful data problems.<br><br>Results from the analyses you’ll support will guide hospital administrators to make evidence-based decisions when working with clinicians and doctors to select medical devices. This allows health systems to reduce costs and improve care for patients. You can help our customers understand which data points are significant enough to make decisions with and which are simply noise.<br><br>You will thrive if you love exploring datasets, applying novel data manipulation and communication techniques, identifying and implementing performance improvements, supporting health systems to interpret their utilization and patient data, improving healthcare value for patients, and solving front-end engineering problems.<br><br><strong><u>What You'll Do<br></u></strong><ul> <li>Develop and maintain Lumere’s data visualization component library while adhering to data visualization and engineering best practices</li> <li>Execute against the ‘technical vision’ for data visualization, ensuring that all data visualization efforts are building toward long-term success</li> <li>Work closely with Product Management and UX/UI designers to deliver data visualizations to our customers</li> <li>Foster our pair-programming and team-wide knowledge sharing efforts</li> <li>Review pull requests, troubleshoot tough development issues</li> <li>Help to develop code standards that lead to strong performance and long-term maintainability</li> <li>Scale new analytical features while improving usability and performance</li> <br><br></ul><strong><u>Necessary Requirements To Hit The Ground Running<br></u></strong><ul> <li>Professional experience in front end development with a high level of proficiency in HTML, CSS, JavaScript, and JavaScript frameworks and technologies (Vue.js, React, or Angular)</li> <li>Enough knowledge to be dangerous when it comes to visualizing data with open-source technologies and libraries such as JavaScript (d3.js, Vega), R (ggplot2), or Python (Matplotlib)</li> <li>SQL and strong understanding of relational databases</li> <li>Experience with Vue.js or Vega a plus</li> <br><br></ul>Estimated Salary range for this position: $90,000- $110,000.<br><br><em>The base salary range represents the anticipated low and high end of the GHX’s salary range for this position. Actual salaries will vary and will be based on various factors, such as candidate’s qualifications, skills, competencies and proficiency for the role. The base salary is one component of GHX’s total compensation package for employees. Other rewards and benefits include: health, vision, and dental insurance, accident and life insurance, 401k matching, paid-time off, and education reimbursement, to name a few. To view more details of our benefits, visit us here: https://www.ghx.com/about/careers/<br><br></em><em>GHX provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. GHX complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.<br><br></em><em>GHX expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. Improper interference with the ability of GHX’s employees to perform their expected job duties is absolutely not tolerated.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Hospital & Health Care"
Data Engineer/Machine Learning Engineer,"Houston, Texas, United States",Genuent,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-machine-learning-engineer-at-genuent-2418200725?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=N5VYKPOJFfxc%2ByVmIkj7Fg%3D%3D&position=3&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Genuent is hiring a Data Engineer / Machine Learning Engineer for our direct client located in the Houston, TX area. This is a 6 month contract opportunity that must be worked ONSITE. Qualified candidates should send an updated, Word version of their resume to Cara Mason at CMason@Genuent.com.

Data Engineer/Machine Learning Engineer
6 Month Contract - Onsite in Houston, TX

Must Have Skills

Python
SQL
Business Analysis and Requirements Gathering
Software Development practices such as Design Principles & Patterns, Testing, CI/CD, and Version Control
Statistical Analysis
ETL/ELT
Knowledgeable of Machine Learning
Proficient in working with time-series data and IOT solutions
Containerization such as Docker and Kubernetes
Responsibilities:

Architect end to end data solutions including data collection and storage, data modeling, data processing, and data consumption
Work independently on analytic projects for multiple business functions
Implement data flows connecting operational systems, BI systems, and the big data platform
Automate manual data flows for repeated use and scalability
Develop data-intensive applications with API's and streaming data pipelines
Prepare and transform data into a usable state for analytics
Productionize mathematical models and machine learning models
Assists data analysts and data scientists with query optimization, performance tuning, and data processing
Identify opportunities for data improvements and presents recommendations to management
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Genuent is hiring a Data Engineer / Machine Learning Engineer for our direct client located in the Houston, TX area. This is a 6 month contract opportunity that must be worked ONSITE. Qualified candidates should send an updated, Word version of their resume to Cara Mason at CMason@Genuent.com.<br><br><strong>Data Engineer/Machine Learning Engineer<br>6 Month Contract - Onsite in Houston, TX<br><br></strong><strong><u>Must Have Skills<br></u></strong><ul> <li>Python</li> <li>SQL</li> <li>Business Analysis and Requirements Gathering</li> <li>Software Development practices such as Design Principles &amp; Patterns, Testing, CI/CD, and Version Control</li> <li>Statistical Analysis</li> <li>ETL/ELT</li> <li>Knowledgeable of Machine Learning</li> <li>Proficient in working with time-series data and IOT solutions</li> <li>Containerization such as Docker and Kubernetes</li> </ul> <strong>Responsibilities:<br></strong><ul> <li>Architect end to end data solutions including data collection and storage, data modeling, data processing, and data consumption</li> <li>Work independently on analytic projects for multiple business functions</li> <li>Implement data flows connecting operational systems, BI systems, and the big data platform</li> <li>Automate manual data flows for repeated use and scalability</li> <li>Develop data-intensive applications with API's and streaming data pipelines</li> <li>Prepare and transform data into a usable state for analytics</li> <li>Productionize mathematical models and machine learning models</li> <li>Assists data analysts and data scientists with query optimization, performance tuning, and data processing</li> <li>Identify opportunities for data improvements and presents recommendations to management</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Software Engineer- Data Engineering,"Menlo Park, California, United States",Robinhood,2021-01-21,https://www.linkedin.com/jobs/view/software-engineer-data-engineering-at-robinhood-2374936800?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=CdcjKEFsDFf9hXJ06iYmdg%3D%3D&position=4&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Join a leading fintech company that’s democratizing finance for all.

Robinhood was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood is lowering barriers, removing fees, and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in.

We Are Proud Of The World Class Products And Company Culture We Continue To Build And Have Been Recognized As

Just as we focus on our customers, we also strive to create an inclusive environment where our employees can thrive and do impactful work.

A Great Place to Work
A CNBC Disruptor 50 in 2019 and 2020
A LinkedIn Top Startup in 2017, 2018, 2019 and 2020


Robinhood is backed by leading investors that include DST Global, Index Ventures, NEA, Ribbit Capital, Thrive Capital, and Sequoia.

Check out life at Robinhood on The Muse!

About The Role

Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for Senior Data Engineers to build and maintain the foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data analysts, and data scientists across the company to power analytics, experimentation, and machine learning use cases. Robinhood is a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.

Your Day-to-day Will Involve

Help define, build, and own key datasets and the quality and evolution of these datasets as use cases grow
Build scalable data pipelines (using Spark and Airflow) to move data from different applications into our data warehouse
Partner with upstream engineering teams to enhance data logging patterns
Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models
Ideate and contribute to shared data engineering tooling and standards
Evangelize data engineering best practices across the organization



Some Things We Consider Critical For This Role

CS background or any other relevant fields of study
Strong product mindset and 5+ years of experience building high-quality data solutions
Strong analytical and problem solving skills
Expertise building data pipelines using open source frameworks (Hadoop, Spark, etc)
Expertise in one or more programming languages (ideally Python)
Strong SQL (Presto, Spark SQL, etc) skills
Familiarity with data visualization tools (Looker, Tableau, etc)
Strong communication skills


We’re looking for more growth-minded and collaborative people to be a part our journey in democratizing finance for all. If you’re ready to give 100% in helping us achieve our mission—we’d love to have you apply even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we're looking for people invigorated by our mission, values, and drive to change the world, not just those who simply check off all the boxes.

Robinhood promotes diversity and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. To review Robinhood's Privacy Policy please click here.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Join a leading fintech company that’s democratizing finance for all. <br><br></strong>Robinhood was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood is lowering barriers, removing fees, and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in.<br><br><strong><u>We Are Proud Of The World Class Products And Company Culture We Continue To Build And Have Been Recognized As<br><br></u></strong>Just as we focus on our customers, we also strive to create an inclusive environment where our employees can thrive and do impactful work.<br><ul> <li>A Great Place to Work</li> <li>A CNBC Disruptor 50 in 2019 and 2020</li> <li>A LinkedIn Top Startup in 2017, 2018, 2019 and 2020</li> <br></ul>Robinhood is backed by leading investors that include DST Global, Index Ventures, NEA, Ribbit Capital, Thrive Capital, and Sequoia.<br><br>Check out life at Robinhood on The Muse!<br><br><strong><u>About The Role<br><br></u></strong>Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for Senior Data Engineers to build and maintain the foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data analysts, and data scientists across the company to power analytics, experimentation, and machine learning use cases. Robinhood is a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.<br><br><strong><u>Your Day-to-day Will Involve<br></u></strong><ul> <li>Help define, build, and own key datasets and the quality and evolution of these datasets as use cases grow</li> <li>Build scalable data pipelines (using Spark and Airflow) to move data from different applications into our data warehouse</li> <li>Partner with upstream engineering teams to enhance data logging patterns</li> <li>Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models</li> <li>Ideate and contribute to shared data engineering tooling and standards</li> <li>Evangelize data engineering best practices across the organization</li> <br><br></ul><strong><u>Some Things We Consider Critical For This Role<br></u></strong><ul> <li>CS background or any other relevant fields of study</li> <li>Strong product mindset and 5+ years of experience building high-quality data solutions</li> <li>Strong analytical and problem solving skills</li> <li>Expertise building data pipelines using open source frameworks (Hadoop, Spark, etc)</li> <li>Expertise in one or more programming languages (ideally Python)</li> <li>Strong SQL (Presto, Spark SQL, etc) skills</li> <li>Familiarity with data visualization tools (Looker, Tableau, etc)</li> <li>Strong communication skills</li> <br></ul>We’re looking for more growth-minded and collaborative people to be a part our journey in democratizing finance for all. If you’re ready to give 100% in helping us achieve our mission—we’d love to have you apply even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we're looking for people invigorated by our mission, values, and drive to change the world, not just those who simply check off all the boxes.<br><br>Robinhood promotes diversity and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. To review Robinhood's Privacy Policy please click here.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Python Data Engineer,"Hillsboro, Oregon, United States","LanceSoft, Inc.",2021-02-05,https://www.linkedin.com/jobs/view/python-data-engineer-at-lancesoft-inc-2398167669?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=wtHCQ%2FQAfsWdj3JGMDjDTA%3D%3D&position=5&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Join a leading fintech company that’s democratizing finance for all.

Robinhood was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood is lowering barriers, removing fees, and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in.

We Are Proud Of The World Class Products And Company Culture We Continue To Build And Have Been Recognized As

Just as we focus on our customers, we also strive to create an inclusive environment where our employees can thrive and do impactful work.

A Great Place to Work
A CNBC Disruptor 50 in 2019 and 2020
A LinkedIn Top Startup in 2017, 2018, 2019 and 2020


Robinhood is backed by leading investors that include DST Global, Index Ventures, NEA, Ribbit Capital, Thrive Capital, and Sequoia.

Check out life at Robinhood on The Muse!

About The Role

Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for Senior Data Engineers to build and maintain the foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data analysts, and data scientists across the company to power analytics, experimentation, and machine learning use cases. Robinhood is a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.

Your Day-to-day Will Involve

Help define, build, and own key datasets and the quality and evolution of these datasets as use cases grow
Build scalable data pipelines (using Spark and Airflow) to move data from different applications into our data warehouse
Partner with upstream engineering teams to enhance data logging patterns
Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models
Ideate and contribute to shared data engineering tooling and standards
Evangelize data engineering best practices across the organization



Some Things We Consider Critical For This Role

CS background or any other relevant fields of study
Strong product mindset and 5+ years of experience building high-quality data solutions
Strong analytical and problem solving skills
Expertise building data pipelines using open source frameworks (Hadoop, Spark, etc)
Expertise in one or more programming languages (ideally Python)
Strong SQL (Presto, Spark SQL, etc) skills
Familiarity with data visualization tools (Looker, Tableau, etc)
Strong communication skills


We’re looking for more growth-minded and collaborative people to be a part our journey in democratizing finance for all. If you’re ready to give 100% in helping us achieve our mission—we’d love to have you apply even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we're looking for people invigorated by our mission, values, and drive to change the world, not just those who simply check off all the boxes.

Robinhood promotes diversity and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. To review Robinhood's Privacy Policy please click here.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Join a leading fintech company that’s democratizing finance for all. <br><br></strong>Robinhood was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood is lowering barriers, removing fees, and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in.<br><br><strong><u>We Are Proud Of The World Class Products And Company Culture We Continue To Build And Have Been Recognized As<br><br></u></strong>Just as we focus on our customers, we also strive to create an inclusive environment where our employees can thrive and do impactful work.<br><ul> <li>A Great Place to Work</li> <li>A CNBC Disruptor 50 in 2019 and 2020</li> <li>A LinkedIn Top Startup in 2017, 2018, 2019 and 2020</li> <br></ul>Robinhood is backed by leading investors that include DST Global, Index Ventures, NEA, Ribbit Capital, Thrive Capital, and Sequoia.<br><br>Check out life at Robinhood on The Muse!<br><br><strong><u>About The Role<br><br></u></strong>Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for Senior Data Engineers to build and maintain the foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data analysts, and data scientists across the company to power analytics, experimentation, and machine learning use cases. Robinhood is a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.<br><br><strong><u>Your Day-to-day Will Involve<br></u></strong><ul> <li>Help define, build, and own key datasets and the quality and evolution of these datasets as use cases grow</li> <li>Build scalable data pipelines (using Spark and Airflow) to move data from different applications into our data warehouse</li> <li>Partner with upstream engineering teams to enhance data logging patterns</li> <li>Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models</li> <li>Ideate and contribute to shared data engineering tooling and standards</li> <li>Evangelize data engineering best practices across the organization</li> <br><br></ul><strong><u>Some Things We Consider Critical For This Role<br></u></strong><ul> <li>CS background or any other relevant fields of study</li> <li>Strong product mindset and 5+ years of experience building high-quality data solutions</li> <li>Strong analytical and problem solving skills</li> <li>Expertise building data pipelines using open source frameworks (Hadoop, Spark, etc)</li> <li>Expertise in one or more programming languages (ideally Python)</li> <li>Strong SQL (Presto, Spark SQL, etc) skills</li> <li>Familiarity with data visualization tools (Looker, Tableau, etc)</li> <li>Strong communication skills</li> <br></ul>We’re looking for more growth-minded and collaborative people to be a part our journey in democratizing finance for all. If you’re ready to give 100% in helping us achieve our mission—we’d love to have you apply even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we're looking for people invigorated by our mission, values, and drive to change the world, not just those who simply check off all the boxes.<br><br>Robinhood promotes diversity and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. To review Robinhood's Privacy Policy please click here.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer-Java,"Cincinnati, Ohio, United States",Kroger,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-java-at-kroger-2427296334?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=bP5uyVdafGW1EosldjVbrw%3D%3D&position=6&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Duration: 12 months.

Must Have Skills

Expert Python Data Engineer
Experience in AWS and related services 3. Data analytics and high volume data processing
Good communication skills
Experience with CICD tools like Jenkins Terraforms



Detailed Job Description

Expert Python Data Engineer
Provide engineering on modern, cloud-based data processing technology stack
Build data pipelines, data validation frameworks, job schedules with emphasis on automation and scale
Contribute to overall architecture, framework, and design patterns to store and process high data volumes
Ensure product and technical features are delivered to spec and on-time
Design and implement features in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology
Proactively support product health by building solutions that are automated, scalable, and sustainable be relentlessly focused on minimizing defects and technical debt
Should be a good communicator, excellent team player, able to collaborate with remote team members over zoom, demonstrating great flexibility
Masters or Bachelors degree in Computer Science or a related field
6+ years of experience in data engineering development
4+ years of experience implementing scalable data architectures
3+ years of experience in large-scale software development with emphasis on data analytics and high-volume data processing
3+ years of experience with AWS and related services (e.g., EC2, S3, DynamoDB, ElasticSearch, DSL Queries, Kibana, SQS, SNS, Lambda, Snowflake, Apache Spark, Airflow.)
Expert Experience in python is a hard requirement. Experience in other data-centric programming languages is a plus.
5+ years of experience in database development using relational and non-relational database is preferred. SQL and PL/SQL experience is preferred.
Automating jobs using Autosys, shell scripting etc
Experience with CI/CD tools like Jenkins / Terraforms
//

EEO Employer
Minorities/ Females/ Disabled/ Veterans/ Gender Identity/ Sexual Orient
//*
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong><strong>Duration: 12 months.<br><br><strong><u>Must Have Skills<br></u></strong><ul> <li>Expert Python Data Engineer</li> <li>Experience in AWS and related services 3. Data analytics and high volume data processing</li> <li>Good communication skills</li> <li>Experience with CICD tools like Jenkins Terraforms</li> <br><br></ul><strong><u>Detailed Job Description<br></u></strong><ul> <li>Expert Python Data Engineer</li> <li>Provide engineering on modern, cloud-based data processing technology stack</li> <li>Build data pipelines, data validation frameworks, job schedules with emphasis on automation and scale</li> <li>Contribute to overall architecture, framework, and design patterns to store and process high data volumes</li> <li>Ensure product and technical features are delivered to spec and on-time</li> <li>Design and implement features in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology</li> <li>Proactively support product health by building solutions that are automated, scalable, and sustainable be relentlessly focused on minimizing defects and technical debt</li> <li>Should be a good communicator, excellent team player, able to collaborate with remote team members over zoom, demonstrating great flexibility</li> <li>Masters or Bachelors degree in Computer Science or a related field</li> <li>6+ years of experience in data engineering development</li> <li>4+ years of experience implementing scalable data architectures</li> <li>3+ years of experience in large-scale software development with emphasis on data analytics and high-volume data processing</li> <li>3+ years of experience with AWS and related services (e.g., EC2, S3, DynamoDB, ElasticSearch, DSL Queries, Kibana, SQS, SNS, Lambda, Snowflake, Apache Spark, Airflow.)</li> <li>Expert Experience in python is a hard requirement. Experience in other data-centric programming languages is a plus.</li> <li>5+ years of experience in database development using relational and non-relational database is preferred. SQL and PL/SQL experience is preferred.</li> <li>Automating jobs using Autosys, shell scripting etc</li> <li>Experience with CI/CD tools like Jenkins / Terraforms</li> </ul><li>//<br></li>EEO Employer<br>Minorities/ Females/ Disabled/ Veterans/ Gender Identity/ Sexual Orient<br>//*</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Retail, Financial Services, Hospital & Health Care"
Data Engineer,"Chicago, Illinois, United States",GoHealth,2021-02-07,https://www.linkedin.com/jobs/view/data-engineer-at-gohealth-2357740767?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=WP4VwNTV8uNCLm5Y1fS5iA%3D%3D&position=7&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Company Name: Kroger General Office
Position Type: Employee
FLSA Status: 87

Position Summary

Accountable for developing and delivering technological responses to targeted business outcomes. Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for the enterprise. Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with 84.51, where needed. Demonstrate the company's core values of respect, honesty, integrity, diversity, inclusion and safety.

Essential Job Functions

Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses
Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with 84.51
Leverage innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms
Define high-level migration plans to address the gaps between the current and future state
Contribute to the development of cost/benefit analysis for leadership to shape sound architectural decisions
Analyze technology environments to detect critical deficiencies and recommend solutions for improvement
Promote the reuse of data assets, including the management of the data catalog for reference
Draft architectural diagrams, interface specifications and other design documents
Must be able to perform the essential job functions of this position with or without reasonable accommodation

Minimum Position Qualifications

Bachelor's Degree in computer science, software engineering, or related field
4+ years experience in the data development and principles including end-to-end design patterns
4+ years proven track record of delivering large scale, high quality operational or analytical data systems
4+ years successful and applicable experience building complex data solutions that have been successfully delivered to customers
Any experience in a minimum of two of the following technical disciplines: data warehousing, big data management, analytics development, data science, application programming interfaces (APIs), data integration, cloud, servers and storage, and database mgmt
Excellent oral/written communication skills

Desired Previous Experience/Education

Any experience with SSAS Tabular models, Power BI, Dataflows and DAX
Any experience with Azure Data Platform stack: Azure Data Lake, Data Factory and Databricks
Any experience with Python, Spark and SQL
Any experience with streaming technologies like Kafka, IBM MQ and EventHub
Any experience with data science solutions or platforms
Any experience with a variety of SQL, NoSQL and Big Data Platforms
Any experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform)

Education Level: Bachelor's Required
Required Travel: Up to 25%
Required Certifications/Licenses: None
Position Type: Full-Time
Regions: Any; General Office- Cincinnati

States: Alabama; Arizona; Arkansas; California; Colorado; Florida; Georgia; Illinois; Indiana; Kansas; Kentucky; Michigan; New York; North Carolina; Ohio; Oregon; South Carolina; Tennessee; Texas; Virginia; Washington

Keywords

Jobs at Kroger: At Kroger, we hire people who have a passion for helping others and who want to build a relationship with our Customers. No matter what stage of your career, you can build your future at Kroger. We look for people who want more, aspire to be more and work hard to achieve their goals. Our focus on keeping the Customer first is what makes us successful. As the largest traditional grocery chain in the U.S. and one of the world's largest retailers, we employee more nearly half a million Associates across 35 states. We offer many opportunities not only in our stores, but in Manufacturing, Logistics, Marketing, Finance, Human Resources, and many other fields.

Company Overview: Kroger Family of Companies employs nearly half a million associates who serve over 11 million customers daily through a seamless shopping experience under a variety of banner names . At The Kroger Co., we are Fresh for Everyone™ and dedicated to our Purpose: To Feed the Human Spirit®. We are committed to creating #ZeroHungerZeroWaste communities by 2025. Careers with The Kroger Co. and our family of companies offer competitive wages, flexible schedules, benefits and room for advancement.

Posting Notes: OH || Blue Ash || 11450 Grooms Road || 45242 || Kroger General Office || [[mfield2]] || Kroger Technology || Employee || Exempt || Full-Time || None
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Company Name:</strong> Kroger General Office<br><strong>Position Type:</strong> Employee<br><strong>FLSA Status: </strong>87<br><br><strong><u>Position Summary<br><br></u></strong>Accountable for developing and delivering technological responses to targeted business outcomes. Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for the enterprise. Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with 84.51, where needed. Demonstrate the company's core values of respect, honesty, integrity, diversity, inclusion and safety.<br><br><strong><u>Essential Job Functions<br></u></strong><ul><li>Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses</li><li>Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with 84.51</li><li>Leverage innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms</li><li>Define high-level migration plans to address the gaps between the current and future state</li><li>Contribute to the development of cost/benefit analysis for leadership to shape sound architectural decisions</li><li>Analyze technology environments to detect critical deficiencies and recommend solutions for improvement</li><li>Promote the reuse of data assets, including the management of the data catalog for reference</li><li>Draft architectural diagrams, interface specifications and other design documents</li><li>Must be able to perform the essential job functions of this position with or without reasonable accommodation<br></li></ul><strong><u>Minimum Position Qualifications<br></u></strong><ul><li> Bachelor's Degree in computer science, software engineering, or related field</li><li>4+ years experience in the data development and principles including end-to-end design patterns</li><li>4+ years proven track record of delivering large scale, high quality operational or analytical data systems</li><li>4+ years successful and applicable experience building complex data solutions that have been successfully delivered to customers</li><li>Any experience in a minimum of two of the following technical disciplines: data warehousing, big data management, analytics development, data science, application programming interfaces (APIs), data integration, cloud, servers and storage, and database mgmt</li><li>Excellent oral/written communication skills<br></li></ul><strong><u>Desired Previous Experience/Education<br></u></strong><ul><li>Any experience with SSAS Tabular models, Power BI, Dataflows and DAX</li><li>Any experience with Azure Data Platform stack: Azure Data Lake, Data Factory and Databricks</li><li>Any experience with Python, Spark and SQL</li><li>Any experience with streaming technologies like Kafka, IBM MQ and EventHub</li><li>Any experience with data science solutions or platforms</li><li>Any experience with a variety of SQL, NoSQL and Big Data Platforms</li><li>Any experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform)<br></li></ul><strong>Education Level:</strong> Bachelor's Required<br><strong>Required Travel:</strong> Up to 25%<br><strong>Required Certifications/Licenses:</strong> None<br><strong>Position Type:</strong> Full-Time<br><strong>Regions:</strong> Any; General Office- Cincinnati<br><br>States: Alabama; Arizona; Arkansas; California; Colorado; Florida; Georgia; Illinois; Indiana; Kansas; Kentucky; Michigan; New York; North Carolina; Ohio; Oregon; South Carolina; Tennessee; Texas; Virginia; Washington<br><br><strong><u>Keywords<br><br></u></strong><strong> Jobs at Kroger: </strong> At Kroger, we hire people who have a passion for helping others and who want to build a relationship with our Customers. No matter what stage of your career, you can build your future at Kroger. We look for people who want more, aspire to be more and work hard to achieve their goals. Our focus on keeping the Customer first is what makes us successful. As the largest traditional grocery chain in the U.S. and one of the world's largest retailers, we employee more nearly half a million Associates across 35 states. We offer many opportunities not only in our stores, but in Manufacturing, Logistics, Marketing, Finance, Human Resources, and many other fields.<br><br><strong>Company Overview: </strong> Kroger Family of Companies employs nearly half a million associates who serve over 11 million customers daily through a seamless shopping experience under a variety of <u> banner names </u> . At The Kroger Co., we are Fresh for Everyone™ and dedicated to our Purpose: To Feed the Human Spirit®. We are committed to creating #ZeroHungerZeroWaste communities by 2025. Careers with The Kroger Co. and our family of companies offer competitive wages, flexible schedules, benefits and room for advancement.<br><br>Posting Notes: OH || Blue Ash || 11450 Grooms Road || 45242 || Kroger General Office || [[mfield2]] || Kroger Technology || Employee || Exempt || Full-Time || None</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Retail, Financial Services, Hospital & Health Care"
Data Scientist / Process Engineer,"Mobile, Alabama, United States",Evonik,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-process-engineer-at-evonik-2415380021?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=79nQ2OMtFMVYfKJ7byUmJg%3D%3D&position=8&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of its various batch and streaming data pipelines. We are seeking candidates who have experience in building large batch pipelines, as well as experiencing building stable, high throughput streaming systems. In this role, you will work with other members of Engineering, Product and Project Management, and various business groups to ensure timely availability of usable data to all parts of the business that need it.

Frequently cited statistics show that women and underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application.

Responsibilities

Design, develop and deploy batch and streaming data pipelines.
Monitor and ensure operational stability of data pipelines.
Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipelines.
Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.
Collaborate with the rest of the Engineering Team, subject matter experts and department leaders to understand, analyze, build and deliver new data-related processes and/or reports.



Skills And Experience

Bachelor’s Degree in computer science or equivalent experience required.
2+ years of experience in the design and development of data pipelines and tasks.
Strong analytical and problem solving ability with strong attention to detail and accuracy.
Understanding of data warehousing concepts and dimensional data modeling.
Hands-on experience with troubleshooting performance issues and fine tuning queries.
Experience extracting data from relational and document databases.
Experience consuming data over HTTP and in formats such as HTML, XML, and JSON.
Knowledge of and experience with a version control system (such as Git, Mercurial, SVN, etc).
Proficiency in Java or Python programming languages.
Familiarity with data warehousing platforms, such as Redshift, Snowflake, SQL Server, etc.



Benefits And Perks

Open vacation policy because work life balance is important
401k program with company match
Employee Stock Purchase Program
Medical, dental, vision, and life insurance benefits
Paid maternity and paternity leave
Professional growth opportunities
Generous employee referral bonuses
Employee Resource Groups
Work from Home Stipend
GoHealth is an Equal Opportunity Employer


Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities and the CDC.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of its various batch and streaming data pipelines. We are seeking candidates who have experience in building large batch pipelines, as well as experiencing building stable, high throughput streaming systems. In this role, you will work with other members of Engineering, Product and Project Management, and various business groups to ensure timely availability of usable data to all parts of the business that need it.<br><br><strong>Frequently cited statistics show that women and underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application.<br><br></strong><strong><u>Responsibilities<br></u></strong><ul> <li>Design, develop and deploy batch and streaming data pipelines.</li> <li>Monitor and ensure operational stability of data pipelines.</li> <li>Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipelines.</li> <li>Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.</li> <li>Collaborate with the rest of the Engineering Team, subject matter experts and department leaders to understand, analyze, build and deliver new data-related processes and/or reports.</li> <br><br></ul><strong><u>Skills And Experience<br></u></strong><ul> <li>Bachelor’s Degree in computer science or equivalent experience required.</li> <li>2+ years of experience in the design and development of data pipelines and tasks.</li> <li>Strong analytical and problem solving ability with strong attention to detail and accuracy.</li> <li>Understanding of data warehousing concepts and dimensional data modeling.</li> <li>Hands-on experience with troubleshooting performance issues and fine tuning queries.</li> <li>Experience extracting data from relational and document databases.</li> <li>Experience consuming data over HTTP and in formats such as HTML, XML, and JSON.</li> <li>Knowledge of and experience with a version control system (such as Git, Mercurial, SVN, etc).</li> <li>Proficiency in Java or Python programming languages.</li> <li>Familiarity with data warehousing platforms, such as Redshift, Snowflake, SQL Server, etc.</li> <br><br></ul><strong><u>Benefits And Perks<br></u></strong><ul> <li>Open vacation policy because work life balance is important</li> <li>401k program with company match</li> <li>Employee Stock Purchase Program</li> <li>Medical, dental, vision, and life insurance benefits</li> <li>Paid maternity and paternity leave</li> <li>Professional growth opportunities</li> <li>Generous employee referral bonuses</li> <li>Employee Resource Groups</li> <li>Work from Home Stipend</li> <li>GoHealth is an Equal Opportunity Employer</li> <br></ul><strong><em>Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities and the CDC.<br><br></em></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Machinery, Staffing and Recruiting"
Data Engineer (SQL Developer),"York, Illinois, United States","Tempus Labs, Inc.",2021-02-11,https://www.linkedin.com/jobs/view/data-engineer-sql-developer-at-tempus-labs-inc-2301301717?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=RuY5arXTP28R43vYgXkIEQ%3D%3D&position=9&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Discover a world of opportunities. #HumanChemistry

See what chemistry can do for your career: careers.evonik.com

Exploring opportunities. Growing together.

VACANCY REFERENCE NUMBER 129435

Data Scientist / Process Engineer

The term of employment is limited to months.

Location: United States : Mobile, AL

Function: Engineering

Career Level: Experienced professionals (2-5 years)

Legal Entity: Evonik Corporation

Business Line: Process Technology & Engineering

What We Offer

You will work on exciting and challenging topics together with a team in an ultra-modern, innovative and creative environment. Intensive on-the-job training with expert colleagues guarantees you will quickly become familiar with your duties and perform them independently. Performance related pay and the opportunity for personal and professional development are of course part of the package. Since 2009 Evonik Industries AG has been certified as a family-friendly company by the German Hertie Foundation.

Click here to learn more about Evonik from our employees

Evonik has an immediate opening at our Mobile, AL, location. This position leads and supports continuous improvement processes for the North America region, predominantly through the application of data science and machine learning methodologies. The support is given through consulting, mathematical data analysis, machine learning model selection and deployment, visualization, improvement tracking and project leadership & participation. The incumbent is perceived to be significantly adding to the overall deployment of data science and machine learning within the company for the North America region and even globally.

Responsibilities


Initiating and execution of data analysis, data science and machine learning projects
Consulting of the Evonik chemical segments in the area of data analysis, data science and machine learning project
End-to-end deployment of data science solution including machine learning model selection, data pipelining, and visualization
Project leader with full responsibility on methodologies, quality, cost, time-frame and know how protection for development projects
Developing new applications of data science and machine learning principles to asset maintenance, plant quality/cost/yield optimization, product development and business intelligence
Performing analysis on cost reduction and turnover increase potential
Providing industry best practices and standardization of data science methodologies
Implementation and methodology transfer to/from other in-house sites
Close cooperation and networking with operative units, internal and external development units and global competence centers
Support on building and maintaining internal customer contacts as well as cooperation with external solution providers, universities and research institutes
Support on marketing the methodology
Support the development of data science and machine learning into a growing service for the region
Consult Evonik Venture Capital on investments in the area of data science
Serve as a key contact point in the region



Requirements


BS Degree in Chemical Engineering or related field
General understanding of manufacturing or chemical production processes
2+ years’ Work experience within manufacturing industry
2+ years’ background in mathematical and statistical methods
Significant hands-on experience with data science and machine learning methods (Supervised and unsupervised learning, time-series analysis/forecasting, anomaly detection, prediction modeling, etc.)
Experience with R, Python or other statistical/machine learning software
Strong problem-solving ability
Improvisation, coordination, and organization skills
Proactive, flexible and good sense of responsibility
Strong written and spoken English
Excellent communication skills and ability to work in a team
Willingness to travel on a regular basis at 25% (mainly domestic, sometimes international)


Your Application

To ensure the fastest process of your application and to protect the environment, please apply online via our careers portal at https://careers.evonik.com.

Only applications that are submitted via our online application tool can be considered.

Please address your application to Woody B Burke . If you have any questions regarding the application process, please contact Mr. Antonio Bello ( antonio.bello@evonik.com ).

VACANCY REFERENCE NUMBER 129435

Please note that Evonik will not accept any unsolicited application documents sent by staffing firms. Evonik works in conjunction with preferred service providers and will not pay any fee to staffing firms in the absence of an appropriate framework agreement. Should Evonik receive a candidate profile from a staffing firm with which it has no framework agreement, and should this candidate subsequently be considered in the recruitment process or offered employment, no claims from the staffing firm will be entertained in this regard.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Discover a world of opportunities. <strong>#HumanChemistry<br><br></strong>See what chemistry can do for your career: <strong>careers.evonik.com<br><br></strong><strong>Exploring opportunities. Growing together.<br><br></strong><strong> VACANCY REFERENCE NUMBER 129435 <br><br></strong><strong>Data Scientist / Process Engineer<br><br></strong>The term of employment is limited to months.<br><br><strong>Location:</strong> United States : Mobile, AL<br><br><strong>Function:</strong> Engineering<br><br><strong>Career Level:</strong> Experienced professionals (2-5 years)<br><br><strong>Legal Entity:</strong> Evonik Corporation<br><br><strong>Business Line:</strong> Process Technology &amp; Engineering<br><br><strong>What We Offer<br><br></strong>You will work on exciting and challenging topics together with a team in an ultra-modern, innovative and creative environment. Intensive on-the-job training with expert colleagues guarantees you will quickly become familiar with your duties and perform them independently. Performance related pay and the opportunity for personal and professional development are of course part of the package. Since 2009 Evonik Industries AG has been certified as a family-friendly company by the German Hertie Foundation.<br><br><strong> Click here to learn more about Evonik from our employees <br><br></strong>Evonik has an immediate opening at our Mobile, AL, location. This position leads and supports continuous improvement processes for the North America region, predominantly through the application of data science and machine learning methodologies. The support is given through consulting, mathematical data analysis, machine learning model selection and deployment, visualization, improvement tracking and project leadership &amp; participation. The incumbent is perceived to be significantly adding to the overall deployment of data science and machine learning within the company for the North America region and even globally.<br><br><strong>Responsibilities<br><br></strong><ul><li>Initiating and execution of data analysis, data science and machine learning projects</li> <li>Consulting of the Evonik chemical segments in the area of data analysis, data science and machine learning project</li> <li>End-to-end deployment of data science solution including machine learning model selection, data pipelining, and visualization</li> <li>Project leader with full responsibility on methodologies, quality, cost, time-frame and know how protection for development projects </li> <li>Developing new applications of data science and machine learning principles to asset maintenance, plant quality/cost/yield optimization, product development and business intelligence</li> <li>Performing analysis on cost reduction and turnover increase potential </li> <li>Providing industry best practices and standardization of data science methodologies</li> <li>Implementation and methodology transfer to/from other in-house sites</li> <li>Close cooperation and networking with operative units, internal and external development units and global competence centers</li> <li>Support on building and maintaining internal customer contacts as well as cooperation with external solution providers, universities and research institutes</li> <li>Support on marketing the methodology</li> <li>Support the development of data science and machine learning into a growing service for the region</li> <li>Consult Evonik Venture Capital on investments in the area of data science</li> <li>Serve as a key contact point in the region<br><br><br></li></ul><strong>Requirements<br><br></strong><ul><li>BS Degree in Chemical Engineering or related field</li> <li>General understanding of manufacturing or chemical production processes</li> <li>2+ years’ Work experience within manufacturing industry </li> <li>2+ years’ background in mathematical and statistical methods</li> <li>Significant hands-on experience with data science and machine learning methods (Supervised and unsupervised learning, time-series analysis/forecasting, anomaly detection, prediction modeling, etc.)</li> <li>Experience with R, Python or other statistical/machine learning software</li> <li>Strong problem-solving ability</li> <li>Improvisation, coordination, and organization skills</li> <li>Proactive, flexible and good sense of responsibility</li> <li>Strong written and spoken English</li> <li>Excellent communication skills and ability to work in a team</li> <li>Willingness to travel on a regular basis at 25% (mainly domestic, sometimes international)<br><br></li></ul><strong> Your Application <br><br></strong>To ensure the fastest process of your application and to protect the environment, please apply online via our careers portal at https://careers.evonik.com.<br><br><strong>Only applications that are submitted via our online application tool can be considered.<br><br></strong>Please address your application to Woody B Burke . If you have any questions regarding the application process, please contact Mr. Antonio Bello ( antonio.bello@evonik.com ).<br><br><strong>VACANCY REFERENCE NUMBER 129435<br><br></strong>Please note that Evonik will not accept any unsolicited application documents sent by staffing firms. Evonik works in conjunction with preferred service providers and will not pay any fee to staffing firms in the absence of an appropriate framework agreement. Should Evonik receive a candidate profile from a staffing firm with which it has no framework agreement, and should this candidate subsequently be considered in the recruitment process or offered employment, no claims from the staffing firm will be entertained in this regard.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Machinery, Staffing and Recruiting"
Data Engineer,"Houston, Texas, United States",LyondellBasell,2021-01-26,https://www.linkedin.com/jobs/view/data-engineer-at-lyondellbasell-2380399799?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=YJrJInVDmZKAYuMERookgw%3D%3D&position=10&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"LyondellBasell (NYSE: LYB) is one of the largest plastics, chemicals and refining companies in the world. Driven by its employees around the globe, LyondellBasell produces materials and products that are key to advancing solutions to modern challenges like enhancing food safety through lightweight and flexible packaging, protecting the purity of water supplies through stronger and more versatile pipes, improving the safety, comfort and fuel efficiency of many of the cars and trucks on the road, and ensuring the safe and effective functionality in electronics and appliances. LyondellBasell sells products into more than 100 countries and is the world's largest producer of polypropylene compounds and the largest licensor of polyolefin technologies. In 2020, LyondellBasell was named to Fortune Magazine's list of the ""World's Most Admired Companies"" for the third consecutive year.

Basic Function

LyondellBasell has embarked upon a strategic digital transformation journey, to provide value focused and scalable digital and advanced analytics solutions across LyondellBasell’s enterprise. Through working closely with other Data Engineers, Data Scientists, business domain experts, and IT, the Data Engineer will have the opportunity to provide significant tangible business value through developing and deploying scalable Data Engineering capabilities on high value problems. This requires a team of innovative, energetic, productive, software development minded, and humble individuals who demonstrate LyondellBasell’s core values in the application of Data Engineering pipelines and workflows on each project.

Roles & Responsibilities

Place emphasis on delivering value through data engineering pipelines and solutions, through excellent problem solving, development, and implementation of scalable solutions
Work collaboratively with Data Scientists and business SMEs (Process Engineers, Automation Engineers, Reliability Engineers, other business domain experts) in providing data pipelines and workflows which are critical to delivering data driven solutions on high impact problems
Work collaboratively with IT to ensure proper architecture, security, exception handling, testing, and code development standards are adhered to
Develop data workflows and pipelines necessary for algorithm and ML solution deployment and maintenance for chemical manufacturing domains including predictive maintenance, reliability, preventing downtime, industrial automation and optimization, demand forecasting, and improving health and safety
Leverage deep data engineering, architecture, advanced technologies, software development expertise, and code development standards to enable the delivery of advanced analytics projects
Develop technical platforms, frameworks, and applications, to provide data, business intelligence, and information
Network internally and externally to build relationships that foster technology transfer and collaboration



Min. Qualifications

BS degree in Computer Science, Software Engineering, Computer Engineering, or related technical field.
3 years professional hands on technical experience in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications. A higher degree (Master's or PhD) with less experience is also acceptable.
Demonstrated ability to work under the direction of others and in a team
High level of enthusiasm and a love of data, software development, and data engineering
Strong quantitative and problem-solving skills, including strong data, technical, and mathematical knowledge and skills
Strong Python, JavaScript, and/or SQL programming and scripting skills
Experience in Real Time historian data, SQL, NoSQL, and/or NewSQL database technologies
Experience working with large structured and/or unstructured data and technologies
Experience with modern Data Engineering, ML and Data Science libraries such as Pandas, NumPy, Scikit-Learn, NLTK, Seaborn, Dplyr
Experience in large scale computing, cluster computing, and/or cloud computing (Azure preferably)
Experience with Linux, Unix, Git, and software development testing frameworks
Experience in providing data engineering solutions in various Data Science domains, such as Predictive Maintenance, Forecasting, Real Time streaming analytics, Image Analysis leveraging deep learning methodologies, and optimization



Preferred Qualifications

MS strongly preferred or PhD
3+ years professional hands on technical experience when combined with advanced education, in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications, with additional experience required in the place of advanced education
Strong programming and scripting skills in other languages, such as C#, C++, Java, Julia, or Scala
Experience with Azure DevOps, Jupyter Notebooks, or VS Code
Experience with stream-processing systems, Big Data querying tools, MapReduce, MongoDB, Cassandra, integration of data from multiple data sources, ETL techniques and frameworks, and/or messaging systems
Experienced working with Data Scientists on architecting and delivering scalable, end to end advanced analytics solutions
Knowledge of ML techniques & algorithms, such as ANNs, SVM, GBM, Decision Forests, Clustering algorithms
Experience with GPU technology, NVIDIA data science development stacks, and CUDA programming
Experience with C3.ai is highly favorable, but is not expected



Competencies

Builds effective teams

Collaborates

Cultivates innovation

Customer focus

Demonstrates courage

Drives results

Ensures accountability

Instills trust and exemplifies integrity

Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.

LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.

LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here .
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">LyondellBasell (NYSE: LYB) is one of the largest plastics, chemicals and refining companies in the world. Driven by its employees around the globe, LyondellBasell produces materials and products that are key to advancing solutions to modern challenges like enhancing food safety through lightweight and flexible packaging, protecting the purity of water supplies through stronger and more versatile pipes, improving the safety, comfort and fuel efficiency of many of the cars and trucks on the road, and ensuring the safe and effective functionality in electronics and appliances. LyondellBasell sells products into more than 100 countries and is the world's largest producer of polypropylene compounds and the largest licensor of polyolefin technologies. In 2020, LyondellBasell was named to Fortune Magazine's list of the ""World's Most Admired Companies"" for the third consecutive year.<br><br><strong><strong>Basic Function<br><br></strong></strong>LyondellBasell has embarked upon a strategic digital transformation journey, to provide value focused and scalable digital and advanced analytics solutions across LyondellBasell’s enterprise. Through working closely with other Data Engineers, Data Scientists, business domain experts, and IT, the Data Engineer will have the opportunity to provide significant tangible business value through developing and deploying scalable Data Engineering capabilities on high value problems. This requires a team of innovative, energetic, productive, software development minded, and humble individuals who demonstrate LyondellBasell’s core values in the application of Data Engineering pipelines and workflows on each project.<br><br><strong><strong>Roles &amp; Responsibilities<br></strong></strong><ul> <li>Place emphasis on delivering value through data engineering pipelines and solutions, through excellent problem solving, development, and implementation of scalable solutions</li> <li>Work collaboratively with Data Scientists and business SMEs (Process Engineers, Automation Engineers, Reliability Engineers, other business domain experts) in providing data pipelines and workflows which are critical to delivering data driven solutions on high impact problems</li> <li>Work collaboratively with IT to ensure proper architecture, security, exception handling, testing, and code development standards are adhered to</li> <li>Develop data workflows and pipelines necessary for algorithm and ML solution deployment and maintenance for chemical manufacturing domains including predictive maintenance, reliability, preventing downtime, industrial automation and optimization, demand forecasting, and improving health and safety</li> <li>Leverage deep data engineering, architecture, advanced technologies, software development expertise, and code development standards to enable the delivery of advanced analytics projects</li> <li>Develop technical platforms, frameworks, and applications, to provide data, business intelligence, and information</li> <li>Network internally and externally to build relationships that foster technology transfer and collaboration</li> <br><br></ul><strong><u>Min. Qualifications<br></u></strong><ul> <li>BS degree in Computer Science, Software Engineering, Computer Engineering, or related technical field.</li> <li>3 years professional hands on technical experience in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications. A higher degree (Master's or PhD) with less experience is also acceptable.</li> <li>Demonstrated ability to work under the direction of others and in a team</li> <li>High level of enthusiasm and a love of data, software development, and data engineering</li> <li>Strong quantitative and problem-solving skills, including strong data, technical, and mathematical knowledge and skills</li> <li>Strong Python, JavaScript, and/or SQL programming and scripting skills</li> <li>Experience in Real Time historian data, SQL, NoSQL, and/or NewSQL database technologies</li> <li>Experience working with large structured and/or unstructured data and technologies</li> <li>Experience with modern Data Engineering, ML and Data Science libraries such as Pandas, NumPy, Scikit-Learn, NLTK, Seaborn, Dplyr</li> <li>Experience in large scale computing, cluster computing, and/or cloud computing (Azure preferably)</li> <li>Experience with Linux, Unix, Git, and software development testing frameworks</li> <li>Experience in providing data engineering solutions in various Data Science domains, such as Predictive Maintenance, Forecasting, Real Time streaming analytics, Image Analysis leveraging deep learning methodologies, and optimization</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>MS strongly preferred or PhD</li> <li>3+ years professional hands on technical experience when combined with advanced education, in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications, with additional experience required in the place of advanced education</li> <li>Strong programming and scripting skills in other languages, such as C#, C++, Java, Julia, or Scala</li> <li>Experience with Azure DevOps, Jupyter Notebooks, or VS Code</li> <li>Experience with stream-processing systems, Big Data querying tools, MapReduce, MongoDB, Cassandra, integration of data from multiple data sources, ETL techniques and frameworks, and/or messaging systems</li> <li>Experienced working with Data Scientists on architecting and delivering scalable, end to end advanced analytics solutions</li> <li>Knowledge of ML techniques &amp; algorithms, such as ANNs, SVM, GBM, Decision Forests, Clustering algorithms</li> <li>Experience with GPU technology, NVIDIA data science development stacks, and CUDA programming</li> <li>Experience with C3.ai is highly favorable, but is not expected</li> <br><br></ul><strong><strong>Competencies<br><br></strong></strong>Builds effective teams<br><br>Collaborates<br><br>Cultivates innovation<br><br>Customer focus<br><br>Demonstrates courage<br><br>Drives results<br><br>Ensures accountability<br><br>Instills trust and exemplifies integrity<br><br>Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.<br><br>LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.<br><br>LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here .</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Chemicals, Machinery, Mechanical or Industrial Engineering"
Data Engineer,"Nashville, Tennessee, United States",Eventbrite,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-at-eventbrite-2396998516?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=%2Fnw6fnJzRQVbP4VxxFWFDQ%3D%3D&position=11&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"LyondellBasell (NYSE: LYB) is one of the largest plastics, chemicals and refining companies in the world. Driven by its employees around the globe, LyondellBasell produces materials and products that are key to advancing solutions to modern challenges like enhancing food safety through lightweight and flexible packaging, protecting the purity of water supplies through stronger and more versatile pipes, improving the safety, comfort and fuel efficiency of many of the cars and trucks on the road, and ensuring the safe and effective functionality in electronics and appliances. LyondellBasell sells products into more than 100 countries and is the world's largest producer of polypropylene compounds and the largest licensor of polyolefin technologies. In 2020, LyondellBasell was named to Fortune Magazine's list of the ""World's Most Admired Companies"" for the third consecutive year.

Basic Function

LyondellBasell has embarked upon a strategic digital transformation journey, to provide value focused and scalable digital and advanced analytics solutions across LyondellBasell’s enterprise. Through working closely with other Data Engineers, Data Scientists, business domain experts, and IT, the Data Engineer will have the opportunity to provide significant tangible business value through developing and deploying scalable Data Engineering capabilities on high value problems. This requires a team of innovative, energetic, productive, software development minded, and humble individuals who demonstrate LyondellBasell’s core values in the application of Data Engineering pipelines and workflows on each project.

Roles & Responsibilities

Place emphasis on delivering value through data engineering pipelines and solutions, through excellent problem solving, development, and implementation of scalable solutions
Work collaboratively with Data Scientists and business SMEs (Process Engineers, Automation Engineers, Reliability Engineers, other business domain experts) in providing data pipelines and workflows which are critical to delivering data driven solutions on high impact problems
Work collaboratively with IT to ensure proper architecture, security, exception handling, testing, and code development standards are adhered to
Develop data workflows and pipelines necessary for algorithm and ML solution deployment and maintenance for chemical manufacturing domains including predictive maintenance, reliability, preventing downtime, industrial automation and optimization, demand forecasting, and improving health and safety
Leverage deep data engineering, architecture, advanced technologies, software development expertise, and code development standards to enable the delivery of advanced analytics projects
Develop technical platforms, frameworks, and applications, to provide data, business intelligence, and information
Network internally and externally to build relationships that foster technology transfer and collaboration



Min. Qualifications

BS degree in Computer Science, Software Engineering, Computer Engineering, or related technical field.
3 years professional hands on technical experience in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications. A higher degree (Master's or PhD) with less experience is also acceptable.
Demonstrated ability to work under the direction of others and in a team
High level of enthusiasm and a love of data, software development, and data engineering
Strong quantitative and problem-solving skills, including strong data, technical, and mathematical knowledge and skills
Strong Python, JavaScript, and/or SQL programming and scripting skills
Experience in Real Time historian data, SQL, NoSQL, and/or NewSQL database technologies
Experience working with large structured and/or unstructured data and technologies
Experience with modern Data Engineering, ML and Data Science libraries such as Pandas, NumPy, Scikit-Learn, NLTK, Seaborn, Dplyr
Experience in large scale computing, cluster computing, and/or cloud computing (Azure preferably)
Experience with Linux, Unix, Git, and software development testing frameworks
Experience in providing data engineering solutions in various Data Science domains, such as Predictive Maintenance, Forecasting, Real Time streaming analytics, Image Analysis leveraging deep learning methodologies, and optimization



Preferred Qualifications

MS strongly preferred or PhD
3+ years professional hands on technical experience when combined with advanced education, in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications, with additional experience required in the place of advanced education
Strong programming and scripting skills in other languages, such as C#, C++, Java, Julia, or Scala
Experience with Azure DevOps, Jupyter Notebooks, or VS Code
Experience with stream-processing systems, Big Data querying tools, MapReduce, MongoDB, Cassandra, integration of data from multiple data sources, ETL techniques and frameworks, and/or messaging systems
Experienced working with Data Scientists on architecting and delivering scalable, end to end advanced analytics solutions
Knowledge of ML techniques & algorithms, such as ANNs, SVM, GBM, Decision Forests, Clustering algorithms
Experience with GPU technology, NVIDIA data science development stacks, and CUDA programming
Experience with C3.ai is highly favorable, but is not expected



Competencies

Builds effective teams

Collaborates

Cultivates innovation

Customer focus

Demonstrates courage

Drives results

Ensures accountability

Instills trust and exemplifies integrity

Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.

LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.

LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here .
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">LyondellBasell (NYSE: LYB) is one of the largest plastics, chemicals and refining companies in the world. Driven by its employees around the globe, LyondellBasell produces materials and products that are key to advancing solutions to modern challenges like enhancing food safety through lightweight and flexible packaging, protecting the purity of water supplies through stronger and more versatile pipes, improving the safety, comfort and fuel efficiency of many of the cars and trucks on the road, and ensuring the safe and effective functionality in electronics and appliances. LyondellBasell sells products into more than 100 countries and is the world's largest producer of polypropylene compounds and the largest licensor of polyolefin technologies. In 2020, LyondellBasell was named to Fortune Magazine's list of the ""World's Most Admired Companies"" for the third consecutive year.<br><br><strong><strong>Basic Function<br><br></strong></strong>LyondellBasell has embarked upon a strategic digital transformation journey, to provide value focused and scalable digital and advanced analytics solutions across LyondellBasell’s enterprise. Through working closely with other Data Engineers, Data Scientists, business domain experts, and IT, the Data Engineer will have the opportunity to provide significant tangible business value through developing and deploying scalable Data Engineering capabilities on high value problems. This requires a team of innovative, energetic, productive, software development minded, and humble individuals who demonstrate LyondellBasell’s core values in the application of Data Engineering pipelines and workflows on each project.<br><br><strong><strong>Roles &amp; Responsibilities<br></strong></strong><ul> <li>Place emphasis on delivering value through data engineering pipelines and solutions, through excellent problem solving, development, and implementation of scalable solutions</li> <li>Work collaboratively with Data Scientists and business SMEs (Process Engineers, Automation Engineers, Reliability Engineers, other business domain experts) in providing data pipelines and workflows which are critical to delivering data driven solutions on high impact problems</li> <li>Work collaboratively with IT to ensure proper architecture, security, exception handling, testing, and code development standards are adhered to</li> <li>Develop data workflows and pipelines necessary for algorithm and ML solution deployment and maintenance for chemical manufacturing domains including predictive maintenance, reliability, preventing downtime, industrial automation and optimization, demand forecasting, and improving health and safety</li> <li>Leverage deep data engineering, architecture, advanced technologies, software development expertise, and code development standards to enable the delivery of advanced analytics projects</li> <li>Develop technical platforms, frameworks, and applications, to provide data, business intelligence, and information</li> <li>Network internally and externally to build relationships that foster technology transfer and collaboration</li> <br><br></ul><strong><u>Min. Qualifications<br></u></strong><ul> <li>BS degree in Computer Science, Software Engineering, Computer Engineering, or related technical field.</li> <li>3 years professional hands on technical experience in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications. A higher degree (Master's or PhD) with less experience is also acceptable.</li> <li>Demonstrated ability to work under the direction of others and in a team</li> <li>High level of enthusiasm and a love of data, software development, and data engineering</li> <li>Strong quantitative and problem-solving skills, including strong data, technical, and mathematical knowledge and skills</li> <li>Strong Python, JavaScript, and/or SQL programming and scripting skills</li> <li>Experience in Real Time historian data, SQL, NoSQL, and/or NewSQL database technologies</li> <li>Experience working with large structured and/or unstructured data and technologies</li> <li>Experience with modern Data Engineering, ML and Data Science libraries such as Pandas, NumPy, Scikit-Learn, NLTK, Seaborn, Dplyr</li> <li>Experience in large scale computing, cluster computing, and/or cloud computing (Azure preferably)</li> <li>Experience with Linux, Unix, Git, and software development testing frameworks</li> <li>Experience in providing data engineering solutions in various Data Science domains, such as Predictive Maintenance, Forecasting, Real Time streaming analytics, Image Analysis leveraging deep learning methodologies, and optimization</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>MS strongly preferred or PhD</li> <li>3+ years professional hands on technical experience when combined with advanced education, in software development and/or developing and implementing Data Engineering workflows, pipelines, and applications, with additional experience required in the place of advanced education</li> <li>Strong programming and scripting skills in other languages, such as C#, C++, Java, Julia, or Scala</li> <li>Experience with Azure DevOps, Jupyter Notebooks, or VS Code</li> <li>Experience with stream-processing systems, Big Data querying tools, MapReduce, MongoDB, Cassandra, integration of data from multiple data sources, ETL techniques and frameworks, and/or messaging systems</li> <li>Experienced working with Data Scientists on architecting and delivering scalable, end to end advanced analytics solutions</li> <li>Knowledge of ML techniques &amp; algorithms, such as ANNs, SVM, GBM, Decision Forests, Clustering algorithms</li> <li>Experience with GPU technology, NVIDIA data science development stacks, and CUDA programming</li> <li>Experience with C3.ai is highly favorable, but is not expected</li> <br><br></ul><strong><strong>Competencies<br><br></strong></strong>Builds effective teams<br><br>Collaborates<br><br>Cultivates innovation<br><br>Customer focus<br><br>Demonstrates courage<br><br>Drives results<br><br>Ensures accountability<br><br>Instills trust and exemplifies integrity<br><br>Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.<br><br>LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.<br><br>LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here .</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Chemicals, Machinery, Mechanical or Industrial Engineering"
Data Scientist,"Denver, Colorado, United States",Sealaska,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-sealaska-2416426301?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=HTKCT%2FyUgmFdx4a%2FIg9%2FjA%3D%3D&position=12&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Overview

Cognitell is seeking a Data Scientist to support our data science and analytics practice. The Data Scientist will perform data analysis, develop and validate machine learning models, create dashboards, write analysis reports and provide recommendations for improving data analysis and models for clients. The ideal candidate is adept at using large, disparate data sets to find opportunities to answer questions and provide insight for decision making. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to put models into production environments. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve outcomes. This is a telecommuting (virtual) role that supports our federal clients and requires a US Citizenship .

Responsibilities

Conduct and evaluate policy scenarios and detailed recommendations using data.
Using critical thinking and the ability to interpret data requests, direct the collection and processing of data, analyze results, report results to users, prepare related planning and analytical documents.
Develop research questions and approaches to answering them
Work with client stakeholders to identify opportunities for leveraging data to drive solutions.
Design and develop data collection procedures and acquisition of data and analysis for data analysis.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Assist with data management, organization, extraction, and maintenance.
Using predictive analytics and data mining to develop data models driving business decisions.
Develop prescriptive analytics to predict & prescribe recommendations or actions.
Coordinate with various teams to implement models and monitor outcomes in production environments.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Prepare and present data to various audiences using tables, charts, and narrative reports in a way that stakeholders can easily understand.
Ensure that documentation is produced/updated & available for project sustainability.


Qualifications

Master’s degree or PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
5+ years of experience working in a data scientist role using statistical and machine learning methods to solve business problems
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Excellent written and verbal communication skills for coordinating across teams.
Technical expertise including

Coding knowledge and experience with statistical languages such as Python, R, Matlab, or similar languages
Experience with SQL and other data querying tools
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience visualizing/presenting data for stakeholders using: Tableau, PowerBI, R Shiny, D3, ggplot, etc.


Environment (Working Conditions, Physical Requirements)

This position will require moving of up to 10 lbs. This position will be mostly stationary requiring some movement around the office and frequent communication with others. The average working hours will be 8 hours per day for this position with occasional need to exceed.
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations will be made to enable qualified individuals with disabilities to perform the essential functions.
EOE M/F/D/V/SO


Apply Options

Apply for this job online Apply

Share

Refer this job to a friend Refer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed

Interested in this opportunity?
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong>Cognitell is seeking a Data Scientist to support our data science and analytics practice. The Data Scientist will perform data analysis, develop and validate machine learning models, create dashboards, write analysis reports and provide recommendations for improving data analysis and models for clients. The ideal candidate is adept at using large, disparate data sets to find opportunities to answer questions and provide insight for decision making. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to put models into production environments. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve outcomes. This is a <strong>telecommuting (virtual) role</strong> that supports our federal clients and requires <strong>a US Citizenship . <br><br></strong><strong><u>Responsibilities<br></u></strong><ul><li> Conduct and evaluate policy scenarios and detailed recommendations using data. </li><li> Using critical thinking and the ability to interpret data requests, direct the collection and processing of data, analyze results, report results to users, prepare related planning and analytical documents. </li><li> Develop research questions and approaches to answering them </li><li> Work with client stakeholders to identify opportunities for leveraging data to drive solutions. </li><li> Design and develop data collection procedures and acquisition of data and analysis for data analysis. </li><li> Assess the effectiveness and accuracy of new data sources and data gathering techniques. </li><li> Assist with data management, organization, extraction, and maintenance. </li><li> Using predictive analytics and data mining to develop data models driving business decisions. </li><li> Develop prescriptive analytics to predict &amp; prescribe recommendations or actions. </li><li> Coordinate with various teams to implement models and monitor outcomes in production environments. </li><li> Develop processes and tools to monitor and analyze model performance and data accuracy. </li><li> Prepare and present data to various audiences using tables, charts, and narrative reports in a way that stakeholders can easily understand. </li><li> Ensure that documentation is produced/updated &amp; available for project sustainability. <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> Master’s degree or PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) </li><li> 5+ years of experience working in a data scientist role using statistical and machine learning methods to solve business problems </li><li> Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. </li><li> Excellent written and verbal communication skills for coordinating across teams. </li><li> Technical expertise including<br><ul><li> Coding knowledge and experience with statistical languages such as Python, R, Matlab, or similar languages </li><li> Experience with SQL and other data querying tools </li><li> Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. </li><li> Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. </li><li> Experience visualizing/presenting data for stakeholders using: Tableau, PowerBI, R Shiny, D3, ggplot, etc. <br><br></li></ul></li></ul><strong><u>Environment (Working Conditions, Physical Requirements)<br></u></strong><ul><li> This position will require moving of up to 10 lbs. This position will be mostly stationary requiring some movement around the office and frequent communication with others. The average working hours will be 8 hours per day for this position with occasional need to exceed. </li><li> To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations will be made to enable qualified individuals with disabilities to perform the essential functions. </li><li> EOE M/F/D/V/SO <br><br></li></ul><strong>Apply Options<br><br></strong>Apply for this job online Apply<br><br>Share<br><br>Refer this job to a friend Refer<br><br>Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.<br><br>Share on your newsfeed<br><br>Interested in this opportunity?</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Information Technology and Services, Nonprofit Organization Management"
Data Engineer I,"New York, New York, United States",AbleTo Inc.,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-i-at-ableto-inc-2425668452?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=dIT6Q1H19oyPWT6hYdx8Mw%3D%3D&position=13&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Overview

Cognitell is seeking a Data Scientist to support our data science and analytics practice. The Data Scientist will perform data analysis, develop and validate machine learning models, create dashboards, write analysis reports and provide recommendations for improving data analysis and models for clients. The ideal candidate is adept at using large, disparate data sets to find opportunities to answer questions and provide insight for decision making. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to put models into production environments. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve outcomes. This is a telecommuting (virtual) role that supports our federal clients and requires a US Citizenship .

Responsibilities

Conduct and evaluate policy scenarios and detailed recommendations using data.
Using critical thinking and the ability to interpret data requests, direct the collection and processing of data, analyze results, report results to users, prepare related planning and analytical documents.
Develop research questions and approaches to answering them
Work with client stakeholders to identify opportunities for leveraging data to drive solutions.
Design and develop data collection procedures and acquisition of data and analysis for data analysis.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Assist with data management, organization, extraction, and maintenance.
Using predictive analytics and data mining to develop data models driving business decisions.
Develop prescriptive analytics to predict & prescribe recommendations or actions.
Coordinate with various teams to implement models and monitor outcomes in production environments.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Prepare and present data to various audiences using tables, charts, and narrative reports in a way that stakeholders can easily understand.
Ensure that documentation is produced/updated & available for project sustainability.


Qualifications

Master’s degree or PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
5+ years of experience working in a data scientist role using statistical and machine learning methods to solve business problems
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Excellent written and verbal communication skills for coordinating across teams.
Technical expertise including

Coding knowledge and experience with statistical languages such as Python, R, Matlab, or similar languages
Experience with SQL and other data querying tools
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience visualizing/presenting data for stakeholders using: Tableau, PowerBI, R Shiny, D3, ggplot, etc.


Environment (Working Conditions, Physical Requirements)

This position will require moving of up to 10 lbs. This position will be mostly stationary requiring some movement around the office and frequent communication with others. The average working hours will be 8 hours per day for this position with occasional need to exceed.
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations will be made to enable qualified individuals with disabilities to perform the essential functions.
EOE M/F/D/V/SO


Apply Options

Apply for this job online Apply

Share

Refer this job to a friend Refer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed

Interested in this opportunity?
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong>Cognitell is seeking a Data Scientist to support our data science and analytics practice. The Data Scientist will perform data analysis, develop and validate machine learning models, create dashboards, write analysis reports and provide recommendations for improving data analysis and models for clients. The ideal candidate is adept at using large, disparate data sets to find opportunities to answer questions and provide insight for decision making. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to put models into production environments. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve outcomes. This is a <strong>telecommuting (virtual) role</strong> that supports our federal clients and requires <strong>a US Citizenship . <br><br></strong><strong><u>Responsibilities<br></u></strong><ul><li> Conduct and evaluate policy scenarios and detailed recommendations using data. </li><li> Using critical thinking and the ability to interpret data requests, direct the collection and processing of data, analyze results, report results to users, prepare related planning and analytical documents. </li><li> Develop research questions and approaches to answering them </li><li> Work with client stakeholders to identify opportunities for leveraging data to drive solutions. </li><li> Design and develop data collection procedures and acquisition of data and analysis for data analysis. </li><li> Assess the effectiveness and accuracy of new data sources and data gathering techniques. </li><li> Assist with data management, organization, extraction, and maintenance. </li><li> Using predictive analytics and data mining to develop data models driving business decisions. </li><li> Develop prescriptive analytics to predict &amp; prescribe recommendations or actions. </li><li> Coordinate with various teams to implement models and monitor outcomes in production environments. </li><li> Develop processes and tools to monitor and analyze model performance and data accuracy. </li><li> Prepare and present data to various audiences using tables, charts, and narrative reports in a way that stakeholders can easily understand. </li><li> Ensure that documentation is produced/updated &amp; available for project sustainability. <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> Master’s degree or PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) </li><li> 5+ years of experience working in a data scientist role using statistical and machine learning methods to solve business problems </li><li> Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. </li><li> Excellent written and verbal communication skills for coordinating across teams. </li><li> Technical expertise including<br><ul><li> Coding knowledge and experience with statistical languages such as Python, R, Matlab, or similar languages </li><li> Experience with SQL and other data querying tools </li><li> Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. </li><li> Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. </li><li> Experience visualizing/presenting data for stakeholders using: Tableau, PowerBI, R Shiny, D3, ggplot, etc. <br><br></li></ul></li></ul><strong><u>Environment (Working Conditions, Physical Requirements)<br></u></strong><ul><li> This position will require moving of up to 10 lbs. This position will be mostly stationary requiring some movement around the office and frequent communication with others. The average working hours will be 8 hours per day for this position with occasional need to exceed. </li><li> To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations will be made to enable qualified individuals with disabilities to perform the essential functions. </li><li> EOE M/F/D/V/SO <br><br></li></ul><strong>Apply Options<br><br></strong>Apply for this job online Apply<br><br>Share<br><br>Refer this job to a friend Refer<br><br>Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.<br><br>Share on your newsfeed<br><br>Interested in this opportunity?</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Information Technology and Services, Nonprofit Organization Management"
Data Engineer,United States,Cotiviti,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-cotiviti-2417476433?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=OXVt8%2FtzAs1h1J8qYBnBKg%3D%3D&position=14&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Note: For the safety of our employees and those considering employment with Cotiviti, we are currently conducting all interviews virtually. In addition, the majority of the Cotiviti team is currently working remotely, and we are onboarding new hires remotely as well. As we monitor the pandemic, these arrangements may change and we will update accordingly.
The Data Engineer will work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions.
Principal Responsibilities And Essential Duties

Bring customer centric focus to our Internal Benchmarking platform
Work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions
Demonstrate through proof of concepts and present them to stakeholders. Formulate and provide recommendations.
Develop, construct, test and maintain Data Architecture for Business Intelligence Solutions
Develop complex, interdependent Data Load Processes, and managing execution of those plans
Identify opportunities for Process Automation using ETL tools like Streamsets, SSIS, Python ETL Framework, etc.
Analyze large and complex datasets using SQL queries and Business Intelligence tools like Tableau to provide actionable insights
Mentor, develop and train team members on various aspects of Data Architecture Implementation
Work as a team member in creation and maintenance of ETL scripts, tools, queries and applications used for data management, data validation, and program validation.
Manage Oracle or SQL Server databases hosting large and complex datasets in Healthcare domain
Program per data transformation specifications to convert source data to be loaded into target data warehouse tables using T-SQL and other Data Integration/ETL tools.
Review & test the data to ensure accuracy & validity of the data prior to uploading the data to the warehouse


Requirements

Experience developing product/solutions using MS SQL Server, SSIS and SSRS
Knowledge of dimensional modelling and experience building reports in MicroStrategy (9.3.1 or above) or any other BI reporting tool (Tableau)
Experience working with large and complex datasets
Extensive knowledge in relational database design
Experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.
Experience with RDBMS (SQL, Oracle, SQL, Vertica, etc.) and using T-SQL or other data integration/ETL tools.
3-5 years experience in the Analysis, design and development of solutions and strategies for creating extraction, transformation and loading (ETL) and real-time applications.
Excellent written and verbal communication skills, with the ability to multitask and prioritize projects to meet scheduled deadlines.
Ability to work well independently or in a team environment.
Bachelor’s degree required.
Familiarity with Agile methodologies preferred.
Critical thinker with strong analytical and problem solving skills


#ZR
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><em>Note: For the safety of our employees and those considering employment with Cotiviti, we are currently conducting all interviews virtually. In addition, the majority of the Cotiviti team is currently working remotely, and we are onboarding new hires remotely as well. As we monitor the pandemic, these arrangements may change and we will update accordingly.<br></em>The Data Engineer will work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions.<br><strong><u>Principal Responsibilities And Essential Duties<br></u></strong><ul> <li>Bring customer centric focus to our Internal Benchmarking platform </li> <li>Work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions</li> <li>Demonstrate through proof of concepts and present them to stakeholders. Formulate and provide recommendations.</li> <li>Develop, construct, test and maintain Data Architecture for Business Intelligence Solutions</li> <li>Develop complex, interdependent Data Load Processes, and managing execution of those plans</li> <li>Identify opportunities for Process Automation using ETL tools like Streamsets, SSIS, Python ETL Framework, etc.</li> <li>Analyze large and complex datasets using SQL queries and Business Intelligence tools like Tableau to provide actionable insights</li> <li>Mentor, develop and train team members on various aspects of Data Architecture Implementation</li> <li>Work as a team member in creation and maintenance of ETL scripts, tools, queries and applications used for data management, data validation, and program validation.</li> <li>Manage Oracle or SQL Server databases hosting large and complex datasets in Healthcare domain</li> <li>Program per data transformation specifications to convert source data to be loaded into target data warehouse tables using T-SQL and other Data Integration/ETL tools.</li> <li>Review &amp; test the data to ensure accuracy &amp; validity of the data prior to uploading the data to the warehouse</li> <br></ul><strong><u>Requirements<br></u></strong><ul> <li>Experience developing product/solutions using MS SQL Server, SSIS and SSRS</li> <li>Knowledge of dimensional modelling and experience building reports in MicroStrategy (9.3.1 or above) or any other BI reporting tool (Tableau)</li> <li>Experience working with large and complex datasets</li> <li>Extensive knowledge in relational database design</li> <li>Experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.</li> <li>Experience with RDBMS (SQL, Oracle, SQL, Vertica, etc.) and using T-SQL or other data integration/ETL tools.</li> <li>3-5 years experience in the Analysis, design and development of solutions and strategies for creating extraction, transformation and loading (ETL) and real-time applications.</li> <li>Excellent written and verbal communication skills, with the ability to multitask and prioritize projects to meet scheduled deadlines.</li> <li>Ability to work well independently or in a team environment.</li> <li>Bachelor’s degree required. </li> <li>Familiarity with Agile methodologies preferred.</li> <li>Critical thinker with strong analytical and problem solving skills</li> <br></ul>#ZR</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Hospital & Health Care"
Data Engineer,"San Francisco, California, United States",GoodData,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-gooddata-2410244181?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=GEuxXRMLxU9SBeMxJ86XDg%3D%3D&position=15&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Note: For the safety of our employees and those considering employment with Cotiviti, we are currently conducting all interviews virtually. In addition, the majority of the Cotiviti team is currently working remotely, and we are onboarding new hires remotely as well. As we monitor the pandemic, these arrangements may change and we will update accordingly.
The Data Engineer will work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions.
Principal Responsibilities And Essential Duties

Bring customer centric focus to our Internal Benchmarking platform
Work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions
Demonstrate through proof of concepts and present them to stakeholders. Formulate and provide recommendations.
Develop, construct, test and maintain Data Architecture for Business Intelligence Solutions
Develop complex, interdependent Data Load Processes, and managing execution of those plans
Identify opportunities for Process Automation using ETL tools like Streamsets, SSIS, Python ETL Framework, etc.
Analyze large and complex datasets using SQL queries and Business Intelligence tools like Tableau to provide actionable insights
Mentor, develop and train team members on various aspects of Data Architecture Implementation
Work as a team member in creation and maintenance of ETL scripts, tools, queries and applications used for data management, data validation, and program validation.
Manage Oracle or SQL Server databases hosting large and complex datasets in Healthcare domain
Program per data transformation specifications to convert source data to be loaded into target data warehouse tables using T-SQL and other Data Integration/ETL tools.
Review & test the data to ensure accuracy & validity of the data prior to uploading the data to the warehouse


Requirements

Experience developing product/solutions using MS SQL Server, SSIS and SSRS
Knowledge of dimensional modelling and experience building reports in MicroStrategy (9.3.1 or above) or any other BI reporting tool (Tableau)
Experience working with large and complex datasets
Extensive knowledge in relational database design
Experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.
Experience with RDBMS (SQL, Oracle, SQL, Vertica, etc.) and using T-SQL or other data integration/ETL tools.
3-5 years experience in the Analysis, design and development of solutions and strategies for creating extraction, transformation and loading (ETL) and real-time applications.
Excellent written and verbal communication skills, with the ability to multitask and prioritize projects to meet scheduled deadlines.
Ability to work well independently or in a team environment.
Bachelor’s degree required.
Familiarity with Agile methodologies preferred.
Critical thinker with strong analytical and problem solving skills


#ZR
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><em>Note: For the safety of our employees and those considering employment with Cotiviti, we are currently conducting all interviews virtually. In addition, the majority of the Cotiviti team is currently working remotely, and we are onboarding new hires remotely as well. As we monitor the pandemic, these arrangements may change and we will update accordingly.<br></em>The Data Engineer will work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions.<br><strong><u>Principal Responsibilities And Essential Duties<br></u></strong><ul> <li>Bring customer centric focus to our Internal Benchmarking platform </li> <li>Work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions</li> <li>Demonstrate through proof of concepts and present them to stakeholders. Formulate and provide recommendations.</li> <li>Develop, construct, test and maintain Data Architecture for Business Intelligence Solutions</li> <li>Develop complex, interdependent Data Load Processes, and managing execution of those plans</li> <li>Identify opportunities for Process Automation using ETL tools like Streamsets, SSIS, Python ETL Framework, etc.</li> <li>Analyze large and complex datasets using SQL queries and Business Intelligence tools like Tableau to provide actionable insights</li> <li>Mentor, develop and train team members on various aspects of Data Architecture Implementation</li> <li>Work as a team member in creation and maintenance of ETL scripts, tools, queries and applications used for data management, data validation, and program validation.</li> <li>Manage Oracle or SQL Server databases hosting large and complex datasets in Healthcare domain</li> <li>Program per data transformation specifications to convert source data to be loaded into target data warehouse tables using T-SQL and other Data Integration/ETL tools.</li> <li>Review &amp; test the data to ensure accuracy &amp; validity of the data prior to uploading the data to the warehouse</li> <br></ul><strong><u>Requirements<br></u></strong><ul> <li>Experience developing product/solutions using MS SQL Server, SSIS and SSRS</li> <li>Knowledge of dimensional modelling and experience building reports in MicroStrategy (9.3.1 or above) or any other BI reporting tool (Tableau)</li> <li>Experience working with large and complex datasets</li> <li>Extensive knowledge in relational database design</li> <li>Experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.</li> <li>Experience with RDBMS (SQL, Oracle, SQL, Vertica, etc.) and using T-SQL or other data integration/ETL tools.</li> <li>3-5 years experience in the Analysis, design and development of solutions and strategies for creating extraction, transformation and loading (ETL) and real-time applications.</li> <li>Excellent written and verbal communication skills, with the ability to multitask and prioritize projects to meet scheduled deadlines.</li> <li>Ability to work well independently or in a team environment.</li> <li>Bachelor’s degree required. </li> <li>Familiarity with Agile methodologies preferred.</li> <li>Critical thinker with strong analytical and problem solving skills</li> <br></ul>#ZR</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Hospital & Health Care"
Data Scientist,"Cranberry, Pennsylvania, United States","VertMarkets, Inc.",2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-vertmarkets-inc-2413472051?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=hyVKDMw6OhKhWD6WEd84HA%3D%3D&position=16&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Description

About GoodData

GoodData is a leading analytics and business intelligence company, revolutionizing the way companies are providing analytics to their customers and partners. Integrating into workflows, we provide authenticated access to business reporting, dashboards, and ad hoc analytics to over 1.5 million users daily. GoodData is headquartered in San Francisco and backed by Andreessen Horowitz, General Catalyst Partners, Intel Capital, TOTVS, Visa, and others.

At GoodData, you won’t just grow your career. You’ll be a part of a movement that is changing how people work and make decisions.

Why You Should Join GoodData


Help drive the future of business
Solve meaningful problems
Build and promote great technology
Work with brilliant people

As a key member of our Enablement team within Product, Data Engineers are responsible for the data pipeline build of our Proof of Concept (PoC) implementations. Data Engineers implement data models, deliver ETL in SQL, configure platform ETL components, produce automation scripts and write multidimensional queries in MAQL. In addition to POC delivery, the Data Engineer also contributes valuable demos or content to enable the GoodData developer community and end users.

The right candidate for this position is customer oriented with strong communication and technical skills. You must be able to demonstrate deep technical expertise and translate business requirements to technical use of the GoodData platform.

This role is best suited for someone who has 2+ years of work experience, has a quantitatively-oriented degree (of any variety) and thrives in an extremely analytical and technically-oriented role. This role is located in San Francisco, CA and no relocation assistance is offered.

Responsibilities


In collaboration with Sales Engineers, implement technical PoCs that showcase GoodData’s ability to exceed a prospect’s strategic goals
In collaboration with Product Marketing and Management, implement demos and deliver valuable content to enable the GoodData Developer Community
Quickly implement end-to-end data pipeline solutions
Design conceptual, logical and physical data models
Build measures, insights, and dashboards
Exercise repository management and implementation best practices
Address functional requirements and quality attributes for PoCs
Become an expert on GoodData’s products and services


About You


Bachelor’s degree in quantitative-oriented major
2+ years of overall experience working with Business Intelligence (BI) / Data Warehousing (DW) / Relational Databases
Fluency in SQL and experience in Extract, Transform, and Load (ETL) development in SQL
Familiarity with a scripting language (Ruby or Python)
Experience with REST APIs
Understanding of dimensional and normalized database models and their applications
Possessing a programming mentality and strong problem-solving skills
Customer-oriented with effective communication and technical skills

Bonus Points


Experience with Ruby / JavaScript
IT consulting skills and experience
Familiarity with git

We are committed to creating a diverse work environment and proud to be an Equal Opportunity Employer. All your information will be kept confidential according to EEO guidelines.

No relocation assistance is offered for this opportunity at this time, and local candidates will be given priority consideration.

Agency Recruiters Take Note: Please do not spam us with unsolicited candidate resumes. Unless you have a fully executed agreement with us, we will consider them a gift. Do not send resumes to any of the executives.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Description<br><br></strong><strong><strong>About GoodData<br><br></strong></strong>GoodData is a leading analytics and business intelligence company, revolutionizing the way companies are providing analytics to their customers and partners. Integrating into workflows, we provide authenticated access to business reporting, dashboards, and ad hoc analytics to over 1.5 million users daily. GoodData is headquartered in San Francisco and backed by Andreessen Horowitz, General Catalyst Partners, Intel Capital, TOTVS, Visa, and others.<br><br>At GoodData, you won’t just grow your career. You’ll be a part of a movement that is changing how people work and make decisions.<br><br><strong>Why You Should Join GoodData<br><br></strong><ul><li>Help drive the future of business</li><li>Solve meaningful problems</li><li>Build and promote great technology</li><li>Work with brilliant people<br></li></ul>As a key member of our Enablement team within Product, Data Engineers are responsible for the data pipeline build of our Proof of Concept (PoC) implementations. Data Engineers implement data models, deliver ETL in SQL, configure platform ETL components, produce automation scripts and write multidimensional queries in MAQL. In addition to POC delivery, the Data Engineer also contributes valuable demos or content to enable the GoodData developer community and end users.<br><br>The right candidate for this position is customer oriented with strong communication and technical skills. You must be able to demonstrate deep technical expertise and translate business requirements to technical use of the GoodData platform.<br><br>This role is best suited for someone who has 2+ years of work experience, has a quantitatively-oriented degree (of any variety) and thrives in an extremely analytical and technically-oriented role. This role is located in San Francisco, CA and no relocation assistance is offered.<br><br><strong>Responsibilities<br><br></strong><ul><li>In collaboration with Sales Engineers, implement technical PoCs that showcase GoodData’s ability to exceed a prospect’s strategic goals</li><li>In collaboration with Product Marketing and Management, implement demos and deliver valuable content to enable the GoodData Developer Community</li><li>Quickly implement end-to-end data pipeline solutions</li><li>Design conceptual, logical and physical data models</li><li>Build measures, insights, and dashboards</li><li>Exercise repository management and implementation best practices</li><li>Address functional requirements and quality attributes for PoCs</li><li>Become an expert on GoodData’s products and services<br><br></li></ul><strong>About You<br><br></strong><ul><li>Bachelor’s degree in quantitative-oriented major</li><li>2+ years of overall experience working with Business Intelligence (BI) / Data Warehousing (DW) / Relational Databases</li><li>Fluency in SQL and experience in Extract, Transform, and Load (ETL) development in SQL</li><li>Familiarity with a scripting language (Ruby or Python)</li><li>Experience with REST APIs</li><li>Understanding of dimensional and normalized database models and their applications</li><li>Possessing a programming mentality and strong problem-solving skills</li><li>Customer-oriented with effective communication and technical skills<br></li></ul><strong>Bonus Points<br><br></strong><ul><li>Experience with Ruby / JavaScript</li><li>IT consulting skills and experience</li><li>Familiarity with git <br></li></ul>We are committed to creating a diverse work environment and proud to be an Equal Opportunity Employer. All your information will be kept confidential according to EEO guidelines.<br><br>No relocation assistance is offered for this opportunity at this time, and local candidates will be given priority consideration.<br><br>Agency Recruiters Take Note: Please do not spam us with unsolicited candidate resumes. Unless you have a fully executed agreement with us, we will consider them a gift. Do not send resumes to any of the executives.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Analytics Model Engineer,"Jersey City, New Jersey, United States",Bank of America,2021-01-23,https://www.linkedin.com/jobs/view/analytics-model-engineer-at-bank-of-america-2414759241?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=F6u8RzdVtKHH0%2BEMivjXBA%3D%3D&position=17&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Do you love analyzing data to uncover insights and trends? Can you understand data and trends to reveal meaningful business intelligence? Are you intrigued by learning market information? If so, then a career as a Data Scientist for Life Science Connect may be for you.




Life Science Connect is a subsidiary of VertMarkets, a B2B media company devoted to connecting the world’s business and community leaders. Life Science Connect fosters collaborations in the pharmaceutical, biotech, and medical device industries through websites, publications, events, and training.




In the role of Life Science Connect Data Scientist, you'll be required to take a data driven approach to understanding the needs of our clients and apply strategies to evaluate their marketing and content promotion campaign effectiveness. The Data Scientist will also be responsible for applying these insights, as well as market data they have discovered, to make recommendations on ways to maximize a client’s marketing and content promotion campaign results. The ideal candidate should have strong analytical skills, excellent time-management and organization, a problem solving mindset, and the ability to clearly communicate information in simple yet interesting ways.




Requirements




Responsibilities:

Cultivate relationships with client’s prospects via phone calls, emails, social media, etc.
Collect, gather and organize all the data from a campaign and present it in a professional manner to the client.
Analyze data on an account-based level and identify trends.
Identify other readers/users at the target account who are not engaging with the client’s marketing and content promotion campaign and craft ways in which to engage them.
Create customized reporting not only for the client’s marketing team but also for sales to provide more information, details, insights, comparisons, next steps, etc. The goal is to be an extension of the advertiser’s sales team to help them close business.
Detailed account mapping. Fully understand the decision maker loop of prospects for our assigned clients and analyze their content behaviors/activity seeking to identify buying intent.
Take a proactive approach and expand the outreach to beyond just a few decision makers, beyond just our current circulation.
Work with key account managers to understand the business that their customers are in.
Attend and participate in monthly Account Review calls and deliver detailed analysis of results.




Required Skills:

Love analyzing big, messy data to uncover key insights
Excellent verbal, written, and presentation skills. Capable of speaking in front of groups of executives
Communicates complex findings in simple, interesting ways
Passionate about doing things differently and better
Pride yourself not only being able to bring the right tools and methods to bear on problems, but to learn or even create new tools and methods when the opportunity presents itself
Able to work at a fast pace and with multiple colleagues
Experience with analytics/business intelligence
Strong MS Excel skills, proficient implementing Excel formulas
Experience VBA for Excel/Access
Willingness to travel up to 20%




Preferred Skills:

B.S. – in Analytics or Business Intelligence, or related
Experience with R or Python
Familiarity with graphical presentations of data
Experience with sales force automation and / or marketing automation software platforms such as Marketo
Experience with content marketing/B2B publishing




Performing in a challenging Engagement Analyst role sound good so far? There's more. VertMarkets offers a generous base salary along with these benefits:

Competitive medical/prescription/vision/dental coverage for you and your family
100% company-paid short- and long-term disability insurance, and life insurance
21 paid days off from your first day of employment
13 company-paid holidays
401(k) with company match

Visit www.vertmarkets.com to learn more about the markets in which we operate. Submit a resume today!

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Do you love analyzing data to uncover insights and trends? Can you understand data and trends to reveal meaningful business intelligence? Are you intrigued by learning market information? If so, then a career as a Data Scientist for Life Science Connect may be for you.</p><p><br></p><p>Life Science Connect is a subsidiary of VertMarkets, a B2B media company devoted to connecting the world’s business and community leaders. Life Science Connect fosters collaborations in the pharmaceutical, biotech, and medical device industries through websites, publications, events, and training.</p><p><br></p><p>In the role of Life Science Connect Data Scientist, you'll be required to take a data driven approach to understanding the needs of our clients and apply strategies to evaluate their marketing and content promotion campaign effectiveness. The Data Scientist will also be responsible for applying these insights, as well as market data they have discovered, to make recommendations on ways to maximize a client’s marketing and content promotion campaign results. The ideal candidate should have strong analytical skills, excellent time-management and organization, a problem solving mindset, and the ability to clearly communicate information in simple yet interesting ways.</p><p><br></p><p>Requirements</p><p><br></p><p>Responsibilities:</p><ul><li>Cultivate relationships with client’s prospects via phone calls, emails, social media, etc.</li><li>Collect, gather and organize all the data from a campaign and present it in a professional manner to the client.</li><li>Analyze data on an account-based level and identify trends.</li><li>Identify other readers/users at the target account who are not engaging with the client’s marketing and content promotion campaign and craft ways in which to engage them.</li><li>Create customized reporting not only for the client’s marketing team but also for sales to provide more information, details, insights, comparisons, next steps, etc. The goal is to be an extension of the advertiser’s sales team to help them close business.</li><li>Detailed account mapping. Fully understand the decision maker loop of prospects for our assigned clients and analyze their content behaviors/activity seeking to identify buying intent.</li><li>Take a proactive approach and expand the outreach to beyond just a few decision makers, beyond just our current circulation.</li><li>Work with key account managers to understand the business that their customers are in.</li><li>Attend and participate in monthly Account Review calls and deliver detailed analysis of results.</li></ul><p><br></p><p>Required Skills:</p><ul><li>Love analyzing big, messy data to uncover key insights</li><li>Excellent verbal, written, and presentation skills. Capable of speaking in front of groups of executives</li><li>Communicates complex findings in simple, interesting ways</li><li>Passionate about doing things differently and better</li><li>Pride yourself not only being able to bring the right tools and methods to bear on problems, but to learn or even create new tools and methods when the opportunity presents itself</li><li>Able to work at a fast pace and with multiple colleagues</li><li>Experience with analytics/business intelligence</li><li>Strong MS Excel skills, proficient implementing Excel formulas</li><li>Experience VBA for Excel/Access</li><li>Willingness to travel up to 20%</li></ul><p><br></p><p>Preferred Skills:</p><ul><li>B.S. – in Analytics or Business Intelligence, or related</li><li>Experience with R or Python</li><li>Familiarity with graphical presentations of data</li><li>Experience with sales force automation and / or marketing automation software platforms such as Marketo</li><li>Experience with content marketing/B2B publishing</li></ul><p><br></p><p>Performing in a challenging Engagement Analyst role sound good so far? There's more. VertMarkets offers a generous base salary along with these benefits:</p><ul><li>Competitive medical/prescription/vision/dental coverage for you and your family</li><li>100% company-paid short- and long-term disability insurance, and life insurance</li><li>21 paid days off from your first day of employment</li><li>13 company-paid holidays</li><li>401(k) with company match</li></ul><p>Visit www.vertmarkets.com to learn more about the markets in which we operate. Submit a resume today!</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Banking, Financial Services"
Data Engineer (open to remote),"Richmond, Virginia, United States",Mission Lane,2021-02-08,https://www.linkedin.com/jobs/view/data-engineer-open-to-remote-at-mission-lane-2339187850?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=cRY06YAJe8ja%2B535%2FwjNwg%3D%3D&position=18&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Position Summary

Key Responsibilities

Work with business SMEs to understand data requirements and translate them into predictive models and analytical tools.
Develop state-of-the-art software tools to collect, and analyze large volumes of structured and/or unstructured data to streamline business processes.
Apply techniques in natural language processing and applied mathematics to develop text classification tools to automate the existing manual review of the documents.
Present information using data visualization techniques and communicate findings and mine useful insights.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop processes and tools to monitor and analyze model performance.

Required Skills

Education/Experience

Required: Candidate must possess an advanced graduate degree in Engineering, mathematics, statistics, computer science, actuarial science, economics or related technical field. Strong background in machine learning, hypothesis testing, regression analysis, statistics, or probability at the graduate school level or higher, as well as experience creating predictive analytics with noisy data. Background in text analytics, news aggregation and natural language processing.
1-2 years of experience and knowledge in the field of quantitative research and the specialized area of financial engineering, data science, or risk analytics as it relates to the securities industry. Knowledge of predictive model development and oversight.
Experience with and ability to work with data including rapid prototyping and coding skills using common data scientist tools (e.g., Python/R, Plotly, Shiny, Presto, Tensorflow, Keras, pyTorch)
Strong knowledge of advanced statistical methods, Bayesian learning techniques, pattern recognition and outlier detection algorithms, and predictive modeling methods including decision trees and random forest approaches..

Desired Skills

Knowledge of financial engineering to develop, maintain and/or validate models used for forecasting, valuation, instrument and strategy selection, portfolio construction, and risk management covering a wide range of financial instruments, including equities, fixed income, currencies, futures, commodities, and/or derivatives
Proficient communication skills and experience writing model documentation

Shift

1st shift (United States of America)

Hours Per Week

40
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong><u>Position Summary<br><br></u>Key Responsibilities<br><ul><li> Work with business SMEs to understand data requirements and translate them into predictive models and analytical tools.</li><li> Develop state-of-the-art software tools to collect, and analyze large volumes of structured and/or unstructured data to streamline business processes.</li><li> Apply techniques in natural language processing and applied mathematics to develop text classification tools to automate the existing manual review of the documents.</li><li> Present information using data visualization techniques and communicate findings and mine useful insights.</li><li> Assess the effectiveness and accuracy of new data sources and data gathering techniques.</li><li> Develop processes and tools to monitor and analyze model performance.<br></li></ul><strong><u>Required Skills<br><br></u></strong>Education/Experience<br><ul><li> Required: Candidate must possess an advanced graduate degree in Engineering, mathematics, statistics, computer science, actuarial science, economics or related technical field. Strong background in machine learning, hypothesis testing, regression analysis, statistics, or probability at the graduate school level or higher, as well as experience creating predictive analytics with noisy data. Background in text analytics, news aggregation and natural language processing.</li><li> 1-2 years of experience and knowledge in the field of quantitative research and the specialized area of financial engineering, data science, or risk analytics as it relates to the securities industry. Knowledge of predictive model development and oversight.</li><li> Experience with and ability to work with data including rapid prototyping and coding skills using common data scientist tools (e.g., Python/R, Plotly, Shiny, Presto, Tensorflow, Keras, pyTorch)</li><li> Strong knowledge of advanced statistical methods, Bayesian learning techniques, pattern recognition and outlier detection algorithms, and predictive modeling methods including decision trees and random forest approaches..<br></li></ul><strong><u>Desired Skills<br></u></strong><ul><li> Knowledge of financial engineering to develop, maintain and/or validate models used for forecasting, valuation, instrument and strategy selection, portfolio construction, and risk management covering a wide range of financial instruments, including equities, fixed income, currencies, futures, commodities, and/or derivatives </li><li> Proficient communication skills and experience writing model documentation<br></li><strong><u>Shift<br><br></u></strong>1st shift (United States of America)<br><br><strong><u>Hours Per Week<br><br></u></strong>40</ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Banking, Financial Services"
Data and Machine Learning Engineer,"San Antonio, Texas, United States",iHeartMedia,2021-02-12,https://www.linkedin.com/jobs/view/data-and-machine-learning-engineer-at-iheartmedia-2421354468?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=WkZjtKlKbNZITosWcSTbtg%3D%3D&position=19&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Mission Lane LLC is a fintech company on a mission (no pun intended) to provide access to fair and clear credit. What does this mean exactly? We're glad you asked. Roughly one third of Americans have experienced a significant event (or series of events) in their lives that has damaged their credit, usually due to circumstances beyond their control. As if it’s not hard enough to recover from a credit plunge, the only banks willing to take a chance on less-than-prime candidates have historically been called fee harvesters - and for a reason.

Enter Mission Lane. Our best-in-class products and services are raising the bar on fair credit access. We offer credit cards with clear pricing, no hidden fees, and a transparent path towards success. Better yet - candidates don’t need good credit to apply. Our philosophy is simple: when our customers do well, we do well. And we have only just begun.

Mission Laners are learners and here's what we know for certain: good Karma is contagious, the business demand is growing and Mission Lane is, too. Quickly. In response to our rapid growth, our teams are scouting the country in search of skilled, top-tier talent with diverse perspective and unstoppable energy.

Are you passionate about making a meaningful impact? Come join us. Are you purpose-driven, performance-oriented, and principles-led? You’ll feel right at home here. Just like for our customers, our teams create opportunities for employees to willingly learn, stretch, and grow.

Think you’ve got what it takes to be a Laner? Read on for more details about your new role.

Mission Lane’s Data Engineering team is looking for a Data Engineer to join us as an early hire in a fast-growing Fin-Tech startup conveniently located in San Francisco, California and in Richmond, Virginia.

As The Data Engineer, You Will

Author, review and approve data requirements and designs of the data warehousing and data engineering domain including ETL/data movement and pipelines, business intelligence, and analytics
Build data pipelines leveraging internal and external data sources to meet business objectives
Participate in architecting data solutions that will capture, manage, process and serve small to large data at scale
Identify and develop governance controls for systems within the data warehousing and data engineering domains and encourage the team to develop controls as well
Assist in defining and implementing standards and best practices within the data engineering domain that are communicated and leveraged by all data team members and other users of the platform and tools. Standards and best practices include datasets, tables, columns, scripts, variables, etc.
Assist in the definition of data management processes related to data governance, stewardship, data quality, training, data retention, etc.
Define how systems should be maintained, including tools to be used for monitoring, thresholds, and runbooks and actively work on refining on-call practices
Ensure that testing is performed and documented to ensure the quality of the work being delivered
Work directly with Product Owners and end-users to develop solutions in a highly collaborative and agile environment
Work with business units to understand business objectives and how to leverage our data platform and tools to achieve those objectives


To set you up for success in this role from day one, Mission Lane is looking for candidates who have:

Bachelor’s degree in Computer Science, Computer Engineering or related experience
2+ years of experience as a Data Engineer including building ETL/data pipelines as well as data visualization and BI solutions
2+ years of experience working in a fast-paced environment; continuous deployment, test-driven development, agile methodologies
2+ years experience using SQL and advanced SQL techniques
2+ years experience building robust, highly available, and scalable services
2+ years experience building and deploying services in the cloud
Demonstrated track record of scaling data warehouse solution, meeting SLAs, and expertise in performance analysis
Demonstrated strategic thinking and ability to anticipate the downstream costs of critical engineering decisions



You Get Bonus Points For

2+ years experience building consumer-facing products
2+ years of experience with SQL and databases such as Snowflake, Redshift, Postgres
2+ years experience working with ETL tools such as Matillion, Informatica, Talend, Alooma, or comparable experience with Python, Java, Scala, Hadoop or Spark
2+ years of experience with Business Intelligence and Visualization tools such as Chartio, Tableau, etc.
2 + years of experience working with automated build and continuous integration systems
2+ years experience with database architecture, design and modeling and working with a variety of data warehousing systems



At Mission Lane we strive to create a work environment that brings out the best in everyone every day. Our company's competitive pay and comprehensive benefits package are among the many ways we contribute to the betterment of our employees-- personally and professionally.




Mission Lane is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law.

Mission Lane is not currently sponsoring new applicant employment authorization for this position. And please, no third party recruiters.




Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Mission Lane LLC is a fintech company on a mission (no pun intended) to provide access to <em>fair and clear </em>credit. <em>What does this mean exactly?</em> We're glad you asked. Roughly one third of Americans have experienced a significant event (or series of events) in their lives that has damaged their credit, usually due to circumstances beyond their control. As if it’s not hard enough to recover from a credit plunge, the only banks willing to take a chance on less-than-prime candidates have historically been called <em>fee harvesters </em>- and for a reason.<br><br><em>Enter Mission Lane</em><strong><em>. </em></strong>Our best-in-class products and services are raising the bar on fair credit access. We offer credit cards with clear pricing, no hidden fees, and a transparent path towards success. Better yet - <em>candidates don’t need good credit to apply.</em> Our philosophy is simple: when our customers do well, we do well.<strong> And we have only just begun.<br><br></strong><em>Mission Laners are learners and here's what we know for certain:</em> good Karma is contagious, the business demand is growing and Mission Lane is, too. <em>Quickly</em>. In response to our rapid growth, our teams are scouting the country in search of skilled, top-tier talent with diverse perspective and unstoppable energy.<br><br><em>Are you passionate about making a meaningful impact?</em> Come join us. <em>Are you purpose-driven, performance-oriented, and principles-led?</em> You’ll feel right at home here. Just like for our customers, our teams create opportunities for employees to willingly learn, stretch, and grow.<br><br>Think you’ve got what it takes to be a Laner? Read on for more details about your new role.<br><br>Mission Lane’s Data Engineering team is looking for a Data Engineer to join us as an early hire in a fast-growing Fin-Tech startup conveniently located in San Francisco, California and in Richmond, Virginia.<br><br><strong><u>As The Data Engineer, You Will<br></u></strong><ul> <li>Author, review and approve data requirements and designs of the data warehousing and data engineering domain including ETL/data movement and pipelines, business intelligence, and analytics</li> <li>Build data pipelines leveraging internal and external data sources to meet business objectives</li> <li>Participate in architecting data solutions that will capture, manage, process and serve small to large data at scale</li> <li>Identify and develop governance controls for systems within the data warehousing and data engineering domains and encourage the team to develop controls as well</li> <li>Assist in defining and implementing standards and best practices within the data engineering domain that are communicated and leveraged by all data team members and other users of the platform and tools. Standards and best practices include datasets, tables, columns, scripts, variables, etc.</li> <li>Assist in the definition of data management processes related to data governance, stewardship, data quality, training, data retention, etc.</li> <li>Define how systems should be maintained, including tools to be used for monitoring, thresholds, and runbooks and actively work on refining on-call practices</li> <li>Ensure that testing is performed and documented to ensure the quality of the work being delivered</li> <li>Work directly with Product Owners and end-users to develop solutions in a highly collaborative and agile environment</li> <li>Work with business units to understand business objectives and how to leverage our data platform and tools to achieve those objectives</li> <br></ul><strong>To set you up for success in this role from day one, Mission Lane is looking for candidates who have</strong><strong>:<br></strong><ul> <li>Bachelor’s degree in Computer Science, Computer Engineering or related experience</li> <li>2+ years of experience as a Data Engineer including building ETL/data pipelines as well as data visualization and BI solutions</li> <li>2+ years of experience working in a fast-paced environment; continuous deployment, test-driven development, agile methodologies</li> <li>2+ years experience using SQL and advanced SQL techniques</li> <li>2+ years experience building robust, highly available, and scalable services</li> <li>2+ years experience building and deploying services in the cloud</li> <li>Demonstrated track record of scaling data warehouse solution, meeting SLAs, and expertise in performance analysis</li> <li>Demonstrated strategic thinking and ability to anticipate the downstream costs of critical engineering decisions</li> <br><br></ul><strong><u>You Get Bonus Points For<br></u></strong><ul> <li>2+ years experience building consumer-facing products</li> <li>2+ years of experience with SQL and databases such as Snowflake, Redshift, Postgres</li> <li>2+ years experience working with ETL tools such as Matillion, Informatica, Talend, Alooma, or comparable experience with Python, Java, Scala, Hadoop or Spark</li> <li>2+ years of experience with Business Intelligence and Visualization tools such as Chartio, Tableau, etc.</li> <li>2 + years of experience working with automated build and continuous integration systems</li> <li>2+ years experience with database architecture, design and modeling and working with a variety of data warehousing systems</li> <br><br></ul>At Mission Lane we strive to create a work environment that brings out the best in everyone every day. Our company's competitive pay and comprehensive benefits package are among the many ways we contribute to the betterment of our employees-- personally and professionally.<br><br><em><li><br><br><em><strong>Mission Lane is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law.<br><br></strong></em><strong><em>Mission Lane is not currently sponsoring new applicant employment authorization for this position. And please, no third party recruiters.<br><br><br><br></em></strong></li></em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Bellevue, Washington, United States",Smartsheet,2021-02-13,https://www.linkedin.com/jobs/view/data-scientist-at-smartsheet-2408961452?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=MkAkWFU8eifhm7sKaXpSUw%3D%3D&position=20&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Current employees and contingent workers click here to apply and search by the Job Posting Title.
Job Summary:
iHeartMedia is the number one audio company in the United States, reaching nine out of 10 Americans every month – and with its quarter of a billion monthly listeners, has a greater reach than any other media company in the U.S. The company’s leadership position in audio extends across multiple platforms including 850 live broadcast stations; streaming music, radio and on demand via its iHeartRadio digital service available across more than 250 platforms and 2,000 devices including smart speakers, digital auto dashes, tablets, wearables, smartphones, virtual assistants, TVs and gaming consoles; through its influencers; social; branded iconic live music events; and podcasts as the #1 commercial podcast publisher globally. iHeartMedia also leads the audio industry in analytics and attribution technology for its marketing partners, using data from its massive consumer base.

The Data Engineer will be responsible for developing expanding, testing and/or optimizing the infrastructure and architecture of existing and future data pipelines, as well as optimizing data collection, flow, and delivery for cross-functional teams including software engineers, data scientists, and business partners. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products
Responsibilities:


Assemble large, complex data sets that meet functional and non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Develop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validation
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and quality
Collaborate with data scientists to build data products that ingest data from a variety of data sources, process it with sophisticated data science techniques, and produces results that are consumed by business partners for analysis or action
Contribute to the project planning process by estimating tasks and deliverables
Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language
Utilize and stay current in programming languages and software technology


Minimum Qualifications:


Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math – Graduate degree desired
5+ years of commercial experience in a data engineer role with a proven record of manipulating, processing and extracting value from large disconnected datasets
Strong understanding of ETL processes
Expert-level knowledge of SQL and experience with both relational and distributed databases
Solid programming skills and expertise in Python
Working knowledge of CI/CD processes and Git source control
Experience writing automated tests
Experience working with REST APIs
Strong project management, organizational, communication, and presentation skills
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience supporting and working with cross-functional teams in a dynamic environment


Preferred Qualifications:


Experience with AWS or other public cloud
Experience with Machine Learning Engineering
Experience with AWS tools such as Redshift, Athena, Lambda, and Step Functions
Experience with big data tools such as Hadoop, Spark, and Kafka


Location
San Antonio, TX: 20880 Stone Oak Parkway, 78258
Position Type
Regular
The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.

Our organization participates in E-Verify. Click here to learn about E-Verify.

Current employees and contingent workers click here to apply and search by the Job Posting Title.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Current employees and contingent workers click here to apply and search by the Job Posting Title. <br></strong><strong>Job Summary:<br></strong>iHeartMedia is the number one audio company in the United States, reaching nine out of 10 Americans every month – and with its quarter of a billion monthly listeners, has a greater reach than any other media company in the U.S. The company’s leadership position in audio extends across multiple platforms including 850 live broadcast stations; streaming music, radio and on demand via its iHeartRadio digital service available across more than 250 platforms and 2,000 devices including smart speakers, digital auto dashes, tablets, wearables, smartphones, virtual assistants, TVs and gaming consoles; through its influencers; social; branded iconic live music events; and podcasts as the #1 commercial podcast publisher globally. iHeartMedia also leads the audio industry in analytics and attribution technology for its marketing partners, using data from its massive consumer base.<br><br>The Data Engineer will be responsible for developing expanding, testing and/or optimizing the infrastructure and architecture of existing and future data pipelines, as well as optimizing data collection, flow, and delivery for cross-functional teams including software engineers, data scientists, and business partners. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products<br>Responsibilities:<br><br><ul><li>Assemble large, complex data sets that meet functional and non-functional business requirements</li><li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources</li><li>Develop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validation</li><li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li><li>Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and quality</li><li>Collaborate with data scientists to build data products that ingest data from a variety of data sources, process it with sophisticated data science techniques, and produces results that are consumed by business partners for analysis or action</li><li>Contribute to the project planning process by estimating tasks and deliverables</li><li>Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language</li><li>Utilize and stay current in programming languages and software technology<br><br></li></ul>Minimum Qualifications:<br><br><ul><li>Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math – Graduate degree desired</li><li>5+ years of commercial experience in a data engineer role with a proven record of manipulating, processing and extracting value from large disconnected datasets</li><li>Strong understanding of ETL processes</li><li>Expert-level knowledge of SQL and experience with both relational and distributed databases</li><li>Solid programming skills and expertise in Python</li><li>Working knowledge of CI/CD processes and Git source control</li><li>Experience writing automated tests</li><li>Experience working with REST APIs</li><li>Strong project management, organizational, communication, and presentation skills</li><li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement</li><li>Experience supporting and working with cross-functional teams in a dynamic environment<br><br></li></ul>Preferred Qualifications:<br><br><ul><li>Experience with AWS or other public cloud</li><li>Experience with Machine Learning Engineering</li><li>Experience with AWS tools such as Redshift, Athena, Lambda, and Step Functions</li><li>Experience with big data tools such as Hadoop, Spark, and Kafka<br><br></li></ul><strong>Location<br></strong>San Antonio, TX: 20880 Stone Oak Parkway, 78258<br>Position Type<br>Regular<br>The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.<br><br>Our organization participates in E-Verify. Click here to learn about E-Verify.<br><br>Current employees and contingent workers click here to apply and search by the Job Posting Title.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Information Technology and Services, Financial Services"
Data & Visualization Engineer,"Atlanta, Georgia, United States",Varian Medical Systems,2021-02-12,https://www.linkedin.com/jobs/view/data-visualization-engineer-at-varian-medical-systems-2403725674?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=eNjRXjGZsH6NaZkh1ycGIA%3D%3D&position=21&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Smartsheet is looking for an experienced Data Scientist to help guide analyses, create insights, and influence decisions. With thousands of subscribing organizations and millions of users there is lots of opportunity to make a meaningful impact and increase growth through analytics within Smartsheet. You will use data analysis skills and work with departments across the company to communicate key insights as a part of Smartsheet's Business Intelligence team.

This full-time position reports to the Data Science Manager and is based in Smartsheet’s corporate offices in Bellevue, WA.

You Will

Partner with teams to understand their goals and execute on opportunities to drive relevant insights and impact
Translate business questions into quantitative questions and hypotheses that can be answered using the data available
Complete the full analytics lifecycle from understanding the business objective and understanding the data to developing automated reporting and visualizations
Mine large datasets to unlock business opportunities
Present analysis to teams and give data-based recommendations to encourage data-driven decisions
Identify areas for further investigation
Make quick strikes, iterate, and produce in high-volume
Support other duties as assigned



You Have

BA/BS in Mathematics, Computer Science, Operations Research, Physics, or other technical field.
3+ years of professional experience in quantitative analysis
Experience partnering with teams, solving problems, and driving execution
Experience communicating analysis clearly to others
Experience in statistics and implementing different modeling techniques (ex. regression, time series, clustering, decision trees)
Experience with data programming languages and visualization tools (ex. SQL/R/Python, Tableau)
Ability to research and learn new technologies, tools , and platforms
Ability to thrive in a dynamic environment , identify opportunities and execute autonomously



Perks & Benefits

100% employer-paid medical, dental, and vision coverage for full-time employees
Equity - Restricted Stock Units (RSUs) Equity with all offers
Lucrative Employee Stock Purchase Program (15% discount)
401k Match to help you save for your future (50% of your contribution up to the first 6% of your eligible pay)
Monthly stipend to support your work and productivity
15 days PTO to start, plus Flexible Sick Leave
Up to 24 weeks of Parental Leave
Personal paid Volunteer Day to support our community
Opportunities for professional growth and development including access to Audible for Business and LinkedIn Learning online courses
Company Funded Perks, including a counseling membership, primary care membership, local retail discounts, and your own personal Smartsheet account
Teleworking options from any registered location in the U.S. (role specific)



Equal Opportunity Employer

Smartsheet is an Equal Opportunity Employer committed to fostering an inclusive environment with the best employees. We provide employment opportunities without regard to any legally protected status in accordance with applicable laws in the US, UK, and Australia. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

At Smartsheet, we strive to build an inclusive environment that encourages, supports, and celebrates the diverse voices of our team members who also represent the diverse needs of our customers. We’re looking for people who are driven , authentic, supportive, effective , and honest. You’re encouraged to apply even if your experience doesn’t precisely match our job description —if your career path has been nontraditional, that will set you apart. At Smartsheet, we welcome diverse perspectives and people who aren’t afraid to be innovative —join us!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Smartsheet is looking for an experienced <strong>Data Scientist</strong> to help guide analyses, create insights, and influence decisions. With thousands of subscribing organizations and millions of users there is lots of opportunity to make a meaningful impact and increase growth through analytics within Smartsheet. You will use data analysis skills and work with departments across the company to communicate key insights as a part of Smartsheet's Business Intelligence team.<br><br>This full-time position reports to the Data Science Manager and is based in Smartsheet’s corporate offices in Bellevue, WA.<br><br><strong><u>You Will<br></u></strong><ul> <li>Partner with teams to understand their goals and execute on opportunities to drive relevant insights and impact </li> <li>Translate business questions into quantitative questions and hypotheses that can be answered using the data available</li> <li>Complete the full analytics lifecycle from understanding the business objective and understanding the data to developing automated reporting and visualizations</li> <li>Mine large datasets to unlock business opportunities</li> <li>Present analysis to teams and give data-based recommendations to encourage data-driven decisions</li> <li>Identify areas for further investigation</li> <li>Make quick strikes, iterate, and produce in high-volume</li> <li>Support other duties as assigned</li> <br><br></ul><strong><u>You Have<br></u></strong><ul> <li>BA/BS in Mathematics, Computer Science, Operations Research, Physics, or other technical field.</li> <li> 3+ years of professional experience in quantitative analysis</li> <li>Experience partnering with teams, solving problems, and driving execution</li> <li>Experience communicating analysis clearly to others</li> <li>Experience in statistics and implementing different modeling techniques (ex. regression, time series, clustering, decision trees)</li> <li>Experience with data programming languages and visualization tools (ex. SQL/R/Python, Tableau)</li> <li> Ability to research and learn new technologies, tools , and platforms</li> <li> Ability to thrive in a dynamic environment , identify opportunities and execute autonomously </li> <br><br></ul><strong><u>Perks &amp; Benefits<br></u></strong><ul> <li>100% employer-paid medical, dental, and vision coverage for full-time employees</li> <li>Equity - Restricted Stock Units (RSUs) Equity with all offers</li> <li>Lucrative Employee Stock Purchase Program (15% discount)</li> <li> 401k Match to help you save for your future (50% of your contribution up to the first 6% of your eligible pay)</li> <li>Monthly stipend to support your work and productivity</li> <li>15 days PTO to start, plus Flexible Sick Leave</li> <li>Up to 24 weeks of Parental Leave </li> <li>Personal paid Volunteer Day to support our community</li> <li>Opportunities for professional growth and development including access to Audible for Business and LinkedIn Learning online courses</li> <li>Company Funded Perks, including a counseling membership, primary care membership, local retail discounts, and your own personal Smartsheet account</li> <li>Teleworking options from any registered location in the U.S. (role specific)</li> <br><br></ul><strong><u>Equal Opportunity Employer<br><br></u></strong>Smartsheet is an Equal Opportunity Employer committed to fostering an inclusive environment with the best employees. We provide employment opportunities without regard to any legally protected status in accordance with applicable laws in the US, UK, and Australia. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.<br><br>At Smartsheet, we strive to build an inclusive environment that encourages, supports, and celebrates the diverse voices of our team members who also represent the diverse needs of our customers. We’re looking for people who are driven , authentic, supportive, effective , and honest. You’re encouraged to apply even if your experience doesn’t precisely match our job description —if your career path has been nontraditional, that will set you apart. At Smartsheet, we welcome diverse perspectives and people who aren’t afraid to be innovative —join us!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Portland, Oregon, United States",Science 37,2021-02-04,https://www.linkedin.com/jobs/view/data-engineer-at-science-37-2407921024?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=rsGHbGR5MyCq2ZkLr6C7ig%3D%3D&position=22&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Together, we can beat cancer.

At Varian, we bring together the worlds’ best talent to realize our vision of a world without fear of cancer. Together, we work passionately to develop and deliver easy-to-use, efficient oncology solutions. If you want to be part of this important mission, we want to hear from you.
As a data and visualization engineer you will be working with an globally distributed team on developing world class Analytics products for Cancer treatment in the cloud. This role will require collaboration with various team member across geography.
As a data and visualization engineer you will be working with an globally distributed team on developing world class Analytics products for Cancer treatment in ths cloud. This role will require collaboration with various team member across geography.

Responsibilities

Translates business needs into Business Intelligence solutions for Varian
Develop database design specification and detailed design for the feature/modules being implemented as part of the project.
Implement database modules for SQL Server, including database schemas and complex & optimized stored procedures, and develop unit test-drivers and conduct appropriate testing.
Analyze business requirements from product management and develop reports and dashboards for self-service reporting needs.
Communicate with cross functional teams to capture requirements and convert them to support system architecture
Support DB change request process and manage the associated impact.
Support project by providing detailed effort estimates for assigned modules.
Perform reviews (Code/Design) for the team.
Conduct unit testing and participates in quality assurance testing
Detect report, investigate, analyze and fix product defects.
Perform other project activities as required for team/organization support
Perform necessary duties to support Varian quality policy and compliance needs including detailed documentation.
Coordinate with other team member.
Work as Scrum Master as and when required.

Qualifications Required: BE, MSc, MCA, Computer Science or related discipline.

Experience (Years): 3-5 years

Technologies Required

PowerBI /PowerBI reporting
Azure SQL
Tableau
Azure Cloud
AzureSQL Server,Datalake, NoSql
Languages: Java, J2EE, Python (preferable)
ETL Technology: SSIS, Databricks, Dremio, Azure datafactory
BI Technology- Powerbi, Tableau


Skills

Minimum 3 years of experience in IT with at least 1 years in database design and optimization along with 1 years of experience in BI and Data Warehousing
Strong proficiency in one or more Relational Database systems preferably SQL Server in the
areas of Report/Dashboard building, Query optimization and performance improvements
Should have hands on experience in the Azure SQL,
Demonstrates solid understanding of database schema design, data warehousing principles and design considerations for multidimensional databases.
Experience writing and tuning complex SQL, MDX queries.
Strong business analysis skills are required.
Design, create, build and maintain data pipelines
Building a cloud-based platform that allows easy development of new BI applications
Experience with Big Data tools: Hadoop, Spark, Kafka, etc.


Nice To Have Experiences

Experience in report/dashboard development preferably in delivery of healthcare products is plus.
Should be able to support development using the SCRUM framework
Knowledge of one programming language- preferably Python.
Familiarity with Microsoft Azure technologies
Familiarity of Big Data Concepts and Hands-on is plus.
Hands on experience with Erwin data modeling tools or other equivalent ETL tool is plus.
Machine learning model integration with BI


Fighting cancer calls for big ideas.

We envision a world without fear of cancer. Achieving this vision takes dedication and commitment from all of us, every single day. That's why we celebrate and value the distinctly beautiful and intersectional identities of each of our employees. We are a mirror of our patient-base, which allows us to innovate. Big ideas come from everywhere, and the best ideas are fostered by our unique individual experiences. At Varian, we encourage you to bring your whole self to work and believe your bold and authentic perspective will help to power more victories over cancer.

#TogetherWeFight

Privacy Statement


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Together, we can beat cancer.<br><br></strong>At Varian, we bring together the worlds’ best talent to realize our vision of a world without fear of cancer. Together, we work passionately to develop and deliver easy-to-use, efficient oncology solutions. If you want to be part of this important mission, we want to hear from you.<br>As a data and visualization engineer you will be working with an globally distributed team on developing world class Analytics products for Cancer treatment in the cloud. This role will require collaboration with various team member across geography.<br>As a data and visualization engineer you will be working with an globally distributed team on developing world class Analytics products for Cancer treatment in ths cloud. This role will require collaboration with various team member across geography.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Translates business needs into Business Intelligence solutions for Varian</li><li>Develop database design specification and detailed design for the feature/modules being implemented as part of the project.</li><li>Implement database modules for SQL Server, including database schemas and complex &amp; optimized stored procedures, and develop unit test-drivers and conduct appropriate testing.</li><li>Analyze business requirements from product management and develop reports and dashboards for self-service reporting needs.</li><li>Communicate with cross functional teams to capture requirements and convert them to support system architecture</li><li>Support DB change request process and manage the associated impact.</li><li>Support project by providing detailed effort estimates for assigned modules.</li><li>Perform reviews (Code/Design) for the team.</li><li>Conduct unit testing and participates in quality assurance testing</li><li>Detect report, investigate, analyze and fix product defects.</li><li>Perform other project activities as required for team/organization support</li><li>Perform necessary duties to support Varian quality policy and compliance needs including detailed documentation.</li><li>Coordinate with other team member.</li><li>Work as Scrum Master as and when required.<br></li></ul><strong><u>Qualifications Required:</u></strong> <strong>BE, MSc, MCA, Computer Science or related discipline. <br><br></strong><strong><u>Experience (Years):</u> 3-5 years<br><br></strong><strong><u>Technologies Required<br></u></strong><ul><li>PowerBI /PowerBI reporting</li><li>Azure SQL</li><li>Tableau</li><li>Azure Cloud</li><li>AzureSQL Server,Datalake, NoSql</li><li>Languages: Java, J2EE, Python (preferable)</li><li>ETL Technology: SSIS, Databricks, Dremio, Azure datafactory</li><li>BI Technology- Powerbi, Tableau<br><br></li></ul><strong><u>Skills<br></u></strong><ul><li>Minimum 3 years of experience in IT with at least 1 years in database design and optimization along with 1 years of experience in BI and Data Warehousing</li><li>Strong proficiency in one or more Relational Database systems preferably SQL Server in the<br>areas of Report/Dashboard building, Query optimization and performance improvements</li><li>Should have hands on experience in the Azure SQL,</li><li>Demonstrates solid understanding of database schema design, data warehousing principles and design considerations for multidimensional databases.</li><li>Experience writing and tuning complex SQL, MDX queries.</li><li>Strong business analysis skills are required.</li><li>Design, create, build and maintain data pipelines</li><li>Building a cloud-based platform that allows easy development of new BI applications</li><li>Experience with Big Data tools: Hadoop, Spark, Kafka, etc.<br><br></li></ul><strong><u>Nice To Have Experiences<br></u></strong><ul><li>Experience in report/dashboard development preferably in delivery of healthcare products is plus.</li><li>Should be able to support development using the SCRUM framework</li><li>Knowledge of one programming language- preferably Python.</li><li>Familiarity with Microsoft Azure technologies</li><li>Familiarity of Big Data Concepts and Hands-on is plus.</li><li>Hands on experience with Erwin data modeling tools or other equivalent ETL tool is plus.</li><li>Machine learning model integration with BI<br><br></li></ul><strong>Fighting cancer calls for big ideas.<br><br></strong>We envision a world without fear of cancer. Achieving this vision takes dedication and commitment from all of us, every single day. That's why we celebrate and value the distinctly beautiful and intersectional identities of each of our employees. We are a mirror of our patient-base, which allows us to innovate. Big ideas come from everywhere, and the best ideas are fostered by our unique individual experiences. At Varian, we encourage you to bring your whole self to work and believe your bold and authentic perspective will help to power more victories over cancer.<br><br><strong>#TogetherWeFight<br><br></strong>Privacy Statement<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Banking"
Data Engineer - Remote,"Newport News, Virginia, United States",Ferguson Enterprises,2021-02-11,https://www.linkedin.com/jobs/view/data-engineer-remote-at-ferguson-enterprises-2401639133?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=HVDm0EsYZHp62beVgigO%2Fw%3D%3D&position=23&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Science 37 is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. Backed by venture investors such as Glynn Capital, Google Ventures, Redmile Group, dRx Capital and Lux Capital, we are revolutionizing the clinical trial industry one patient at a time. To help us achieve our goal, we are seeking a razor-sharp Data Engineer eager to make an impact within a mission-driven organization.

Science 37 is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. By leveraging the latest innovations in mobile technology, cloud services, telemedicine, we are breaking down traditional geographic barriers to patient trial participation while shortening the time needed to bring new treatments to the market.

As part of the Science 37 Tech team, the Data Engineer collaborates with motivated, energetic, and entrepreneurial individuals working together to achieve Science 37’s mission of changing the world of clinical research through patient-centered design. They have a hands-on role with the building and developing the data pipeline/platform that enables Science 37’s groundbreaking clinical research model and collaborates with Product, Data, Clinical Operations, and other relevant stakeholders to define study-specific platform requirements.

The Data Engineer helps drive data democracy at Science. This position will report to the Data Architect and will work with our architects, software engineers, product managers, and DevOps to help design and build data solutions and architecture. They will learn how Science 37 data is used and help make and drive the accessibility of the data that is needed, keeping in mind regulations and data privacy policies. They will be able to use data processing libraries and tools to help the end users of our data get the insights they need.

Duties Include But Are Not Limited To

Understand how to Install, configure, monitor and maintain databases in the production, development, testing environments
Working with cloud vendors like AWS or GCP
Working with cloud distributed file systems, data lakes, and data warehouses
Creating a data pipelines to help with Internal and External analytics users
Define and implement database schemas and configurations working with our development teams
Optimize database performance by identifying and resolving application bottlenecks, tuning of DB queries, implementation of stored procedures, conducting performance tests, troubleshooting and integrating new elements
Work with development team design and implement reporting capabilities
Implement solutions for database performance monitoring and tuning
Recommend operational efficiencies, eliminate duplicate work efforts and remove unnecessary complexities; create and implement new procedures and workflows
Process database change requests, including the creation and modification of databases, tables, views, stored procedures, triggers, jobs, etc. in accordance with change control policies
Utilize an understanding of Agile management to help the team with all release and configuration related tasks around software builds into preproduction and production environments.



Qualifications

Bachelor's degree in Computer Science or equivalent
Knowledge architectural & database design skills
Experience using SQL, NoSQL and Graph Databases
Must have experience with AWS (other cloud providers are a plus)
Scripting experience with Python or Bash required.
Proficient with SQL and Programming Languages like Python, Java, or Scala
Have an understanding of data architecture for microservices
Experience across different database platforms and tools such as MySQL, PostgreSQL, SQL Server, DynamoDB, MongoDB, AWS Neptune, Cassandra, Neo4j
Experience designing and building data lake and data warehouse solutions
Linux Server basic hands-on admin experience.
Some Experience with Cloud Computing management on the AWS platform
Experience with Monitoring/Alert planning for data services.
Some Experience with highly available database technologies like clustering, replication, mirroring, etc.
Knowledge of administration, replication, backup and restore of relational databases
Experience with data tools like Jupyter



Preferred Qualifications

Experience with MuleSoft Anypoint Platform and Dataweave a plus.
Experience in Clinical Trials and/or life science industry
Understanding of regulatory framework for software delivery
Experience with operational efficiency improvement initiatives
Experience with CSV (Computer Systems Validation)
Experience with SAFe methodology
Experience with JIRA, Confluence, SpiraTest is a plus



Competencies

Thrive in fast-paced, agile environments, and able to learn new areas quickly
Broad knowledge of common infrastructure technologies such as web servers, load balancers, etc.
Excellent troubleshooting skills and ability to understand complex relationships between components of multi-tiered and distributed applications.
Solid understanding of load balancing and high volume, high availability environments
Knowledge of SDLC and project management methodologies (JIRA experience is a plus)
Able to analyze and review current functionality to determine potential areas of improvement and cost savings
Ability to work independently with minimal guidance in a fast-paced environment
Demonstrate excellent communication skills including the ability to effectively communicate with internal and external customers
Strong work ethic with good time management with the ability to work with diverse teams and lead meetings
Ability to work with all levels of the organization
Experience using both SQL, NoSQL and Graph Databases
Experienced in automation and automation tools such as Jenkins, Puppet, Chef, etc.
Amazon: RDS, Aurora, Athena, DocumentDB, DynamoDB, Neptune,
Apache Cassandra
Neo4j
Snowflake
Experience programming in Python, Java, or Scala



Supervision

The incumbent reports to the Data Architect, who will also assign projects, provide general direction and guidance. Incumbent is expected to perform duties and responsibilities with minimal supervision.

Direct Reports

None

We value employee well-being and aim to provide team members with everything they need to succeed.

Submit your resume to apply!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Science 37</strong> is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. Backed by venture investors such as Glynn Capital, Google Ventures, Redmile Group, dRx Capital and Lux Capital, we are revolutionizing the clinical trial industry one patient at a time. To help us achieve our goal, we are seeking a razor-sharp <strong>Data Engineer</strong> eager to make an impact within a mission-driven organization.<br><br><strong>Science 37</strong> is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. By leveraging the latest innovations in mobile technology, cloud services, telemedicine, we are breaking down traditional geographic barriers to patient trial participation while shortening the time needed to bring new treatments to the market.<br><br>As part of the Science 37 Tech team, the <strong>Data Engineer</strong> collaborates with motivated, energetic, and entrepreneurial individuals working together to achieve Science 37’s mission of changing the world of clinical research through patient-centered design. They have a hands-on role with the building and developing the data pipeline/platform that enables Science 37’s groundbreaking clinical research model and collaborates with Product, Data, Clinical Operations, and other relevant stakeholders to define study-specific platform requirements.<br><br>The Data Engineer helps drive data democracy at Science. This position will report to the Data Architect and will work with our architects, software engineers, product managers, and DevOps to help design and build data solutions and architecture. They will learn how Science 37 data is used and help make and drive the accessibility of the data that is needed, keeping in mind regulations and data privacy policies. They will be able to use data processing libraries and tools to help the end users of our data get the insights they need.<br><br><strong><u>Duties Include But Are Not Limited To<br></u></strong><ul> <li>Understand how to Install, configure, monitor and maintain databases in the production, development, testing environments</li> <li>Working with cloud vendors like AWS or GCP</li> <li>Working with cloud distributed file systems, data lakes, and data warehouses</li> <li>Creating a data pipelines to help with Internal and External analytics users</li> <li>Define and implement database schemas and configurations working with our development teams</li> <li>Optimize database performance by identifying and resolving application bottlenecks, tuning of DB queries, implementation of stored procedures, conducting performance tests, troubleshooting and integrating new elements</li> <li>Work with development team design and implement reporting capabilities</li> <li>Implement solutions for database performance monitoring and tuning</li> <li>Recommend operational efficiencies, eliminate duplicate work efforts and remove unnecessary complexities; create and implement new procedures and workflows</li> <li>Process database change requests, including the creation and modification of databases, tables, views, stored procedures, triggers, jobs, etc. in accordance with change control policies</li> <li>Utilize an understanding of Agile management to help the team with all release and configuration related tasks around software builds into preproduction and production environments.</li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li>Bachelor's degree in Computer Science or equivalent</li> <li>Knowledge architectural &amp; database design skills</li> <li>Experience using SQL, NoSQL and Graph Databases</li> <li>Must have experience with AWS (other cloud providers are a plus)</li> <li>Scripting experience with Python or Bash required.</li> <li>Proficient with SQL and Programming Languages like Python, Java, or Scala</li> <li>Have an understanding of data architecture for microservices</li> <li>Experience across different database platforms and tools such as MySQL, PostgreSQL, SQL Server, DynamoDB, MongoDB, AWS Neptune, Cassandra, Neo4j</li> <li>Experience designing and building data lake and data warehouse solutions</li> <li>Linux Server basic hands-on admin experience.</li> <li>Some Experience with Cloud Computing management on the AWS platform</li> <li>Experience with Monitoring/Alert planning for data services.</li> <li>Some Experience with highly available database technologies like clustering, replication, mirroring, etc.</li> <li>Knowledge of administration, replication, backup and restore of relational databases</li> <li>Experience with data tools like Jupyter</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Experience with MuleSoft Anypoint Platform and Dataweave a plus.</li> <li>Experience in Clinical Trials and/or life science industry</li> <li>Understanding of regulatory framework for software delivery</li> <li>Experience with operational efficiency improvement initiatives</li> <li>Experience with CSV (Computer Systems Validation)</li> <li>Experience with SAFe methodology</li> <li>Experience with JIRA, Confluence, SpiraTest is a plus</li> <br><br></ul><strong>Competencies<br></strong><ul> <li>Thrive in fast-paced, agile environments, and able to learn new areas quickly</li> <li>Broad knowledge of common infrastructure technologies such as web servers, load balancers, etc.</li> <li>Excellent troubleshooting skills and ability to understand complex relationships between components of multi-tiered and distributed applications.</li> <li>Solid understanding of load balancing and high volume, high availability environments</li> <li>Knowledge of SDLC and project management methodologies (JIRA experience is a plus)</li> <li>Able to analyze and review current functionality to determine potential areas of improvement and cost savings</li> <li>Ability to work independently with minimal guidance in a fast-paced environment</li> <li>Demonstrate excellent communication skills including the ability to effectively communicate with internal and external customers</li> <li>Strong work ethic with good time management with the ability to work with diverse teams and lead meetings</li> <li>Ability to work with all levels of the organization</li> <li>Experience using both SQL, NoSQL and Graph Databases</li> <li>Experienced in automation and automation tools such as Jenkins, Puppet, Chef, etc.</li> <li>Amazon: RDS, Aurora, Athena, DocumentDB, DynamoDB, Neptune,</li> <li>Apache Cassandra</li> <li>Neo4j</li> <li>Snowflake</li> <li>Experience programming in Python, Java, or Scala</li> <br><br></ul><strong>Supervision<br><br></strong>The incumbent reports to the Data Architect, who will also assign projects, provide general direction and guidance. Incumbent is expected to perform duties and responsibilities with minimal supervision.<br><br><strong>Direct Reports<br><br></strong>None<br><br>We value employee well-being and aim to provide team members with everything they need to succeed.<br><br>Submit your resume to apply!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Research
Data Engineer (ETL),"Raleigh, North Carolina, United States",Bandwidth Inc.,2021-01-24,https://www.linkedin.com/jobs/view/data-engineer-etl-at-bandwidth-inc-2227740244?refId=84390f0a-9136-442f-b0a8-3e565de7e961&trackingId=378tD6n2s2%2BaHVPQaX1vhQ%3D%3D&position=24&pageNum=7&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

We realize that our greatest assets are our best-in-class associates, which is why we’re dedicated to offering limitless opportunities for growth and advancement. We want to help you build a long-lasting career with Ferguson, we can continue to lead the industry and help build our nation’s infrastructure from the ground up. Join our team today. Ferguson is currently seeking the right individual to fill an immediate need for a Data Engineer. What is the opportunity for you? The Data Engineer will have end-to-end responsibility for maintaining our data flows into the data warehouse. This includes ETL, designing & building data models, managing the business intelligence development cycle, data validation, and managing uptime. They will work closely alongside our business analysts to ensure alignment among both the technical and business aspects of business intelligence development. What are you going to do?

Design and build data models using SQL
Maintain, modify, and build upon the current model within the platform
Manage data refresh processes and uptime
Manage the BI development lifecycle from development to production
Translate business requirements into dimensional models
Maintain and build upon the semantic layer and measure/attribute definitions
Perform extensive data validation
Communicate effectively with analytics colleagues and business stakeholders
What are you going to bring to the table?

Proven experience building and validating data models
Experience with Python scripting
Self-motivated, team player, take initiative, quick learner, systematic, adaptable, etc.
Strong SQL skills required for building tables, views, and implementing complex logic
Ability to learn and use database software (SQL)
Outstanding organizational skills
Solid problem solving, numerical fluency, and analytical skills
BA or BS degree preferred
What do we bring to the table?

Competitive Compensation Packages
Great 401(k), PTO and benefits package which includes Medical, Dental, Life and Vision
Amazing work environment that makes you want to be at work everyday
Team building and company-wide events throughout the year (sometimes too many to count)
Internal Training programs suited to what you are wanting to develop in
A wide variety of local discounts plus all of Ferguson Inc. employee perks


The Company is an equal opportunity employer as well as a government contractor that shall abide by the requirements of 41 CFR 60-300.5(a), which prohibits discrimination against qualified protected Veterans and the requirements of 41 CFR 60-741.5(A), which prohibits discrimination against qualified individuals on the basis of disability.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong><strong> We realize that our greatest assets are our best-in-class associates, which is why we’re dedicated to offering limitless opportunities for growth and advancement. We want to help you build a long-lasting career with Ferguson, we can continue to lead the industry and help build our nation’s infrastructure from the ground up. Join our team today. </strong><strong> Ferguson is currently seeking the right individual to fill an immediate need for a Data Engineer. </strong><strong><strong> What is the opportunity for you? </strong></strong><strong>The Data Engineer will have end-to-end responsibility for maintaining our data flows into the data warehouse. This includes ETL, designing &amp; building data models, managing the business intelligence development cycle, data validation, and managing uptime. They will work closely alongside our business analysts to ensure alignment among both the technical and business aspects of business intelligence development.</strong><strong><strong> What are you going to </strong><strong> do? <br></strong></strong><ul><li><strong>Design and build data models using SQL</strong></li><li><strong>Maintain, modify, and build upon the current model within the platform</strong></li><li><strong>Manage data refresh processes and uptime</strong></li><li><strong>Manage the BI development lifecycle from development to production</strong></li><li><strong>Translate business requirements into dimensional models</strong></li><li><strong>Maintain and build upon the semantic layer and measure/attribute definitions</strong></li><li><strong>Perform extensive data validation</strong></li><li><strong>Communicate effectively with analytics colleagues and business stakeholders</strong></li></ul><strong><strong> What are you going to bring to the </strong><strong> table? <br></strong></strong><ul><li><strong>Proven experience building and validating data models</strong></li><li><strong>Experience with Python scripting</strong></li><li><strong>Self-motivated, team player, take initiative, quick learner, systematic, adaptable, etc.</strong></li><li><strong>Strong SQL skills required for building tables, views, and implementing complex logic</strong></li><li><strong>Ability to learn and use database software (SQL)</strong></li><li><strong>Outstanding organizational skills</strong></li><li><strong>Solid problem solving, numerical fluency, and analytical skills</strong></li><li><strong>BA or BS degree preferred</strong></li></ul><strong><strong> What do we bring to the </strong><strong> table? <br></strong></strong><ul><li><strong> Competitive Compensation Packages </strong></li><li><strong> Great 401(k), PTO and benefits package which includes Medical, Dental, Life and Vision </strong></li><li><strong> Amazing work environment that makes you want to be at work everyday </strong></li><li><strong> Team building and company-wide events throughout the year (sometimes too many to count) </strong></li><li><strong> Internal Training programs suited to what you are wanting to develop in </strong></li><li><strong> A wide variety of local discounts plus all of Ferguson Inc. employee perks <br><br></strong></li></ul><em> The Company is an equal opportunity employer as well as a government contractor that shall abide by the requirements of 41 CFR 60-300.5(a), which prohibits discrimination against qualified protected Veterans and the requirements of 41 CFR 60-741.5(A), which prohibits discrimination against qualified individuals on the basis of disability.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Wholesale, Building Materials, Construction"
Data Scientist (Remote),"Remote, Oregon, United States",Yelp,2021-01-23,https://www.linkedin.com/jobs/view/data-scientist-remote-at-yelp-2377887650?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=2pkfvLcQ4cD4%2BsRKbF826w%3D%3D&position=1&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"At Yelp, it’s our mission to connect people with great local businesses. Yelp’s unique dataset contains billions of interactions between users and local business around the globe, from a user reviewing a neighborhood coffee shop to requesting a repair quote with a photo of a leaky faucet. Data Scientists at Yelp work to make sense of these interactions to deliver impactful analyses and products to our users, business partners and the general public.

The Data Science team performs analyses, builds models, and designs experiments that directly impact Yelp’s business and users. Our centralized team is the most wide-ranging consumer of data at Yelp, adept at tasks from modeling content growth and user behavior to sharing insights about the health of local economies. With varied backgrounds and expertise, we strive for learning and growth in a collaborative environment.

We’d love to have you apply, even if you don't feel you meet every single requirement in this posting. At Yelp, we’re looking for great people, not just those who simply check off all the boxes.

We Are Looking For

3+ years of experience as a data scientist or MS/PhD and 2+ years of industry experience in a quantitative role.
Fluency with SQL and Python or R for data analysis.
Solid understanding of statistical inference, experimental design and analysis.
Enthusiasm for clean code and sharing reproducible results.
Communication skills to work with partners on engineering, product and business teams.
An eye for great data visualization with Matplotlib, Plotly, ggplot, or Tableau.
If you don't have 2+ years of industry experience in a quantitative role, please take a look at our College Data Scientist roles instead!

Where You Come In

Define key metrics to track Yelp’s performance and inform product decisions.
Assess and frame questions from partners into actionable deliverables.
Design, execute, and analyze complex experiments impacting millions of users.
Devise and evaluate models for diverse business needs, such as identifying growth opportunities, personalizing user experience, and matching consumers to businesses.
Own analyses start-to-finish and communicate key insights to stakeholders.
Share your technical skills to develop and maintain high-quality, reusable analysis tools.

At Yelp, we believe that diversity is an expression of all the unique characteristics that make us human: race, age, sexual orientation, gender identity, religion, disability, and education — and those are just a few. We recognize that diverse backgrounds and perspectives strengthen our teams and our product. The foundation of our diversity efforts are closely tied to our core values, which include “Playing Well With Others” and “Authenticity.”

We’re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition or disability.

We will consider for employment qualified candidates with arrest and conviction records, consistent with applicable law (including, for example, the San Francisco Fair Chance Ordinance for roles based in San Francisco).

CCPA Privacy Notice

We are committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-recruiting@yelp.com or 415-969-8488.

Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Yelp, it’s our mission to connect people with great local businesses. Yelp’s unique dataset contains billions of interactions between users and local business around the globe, from a user reviewing a neighborhood coffee shop to requesting a repair quote with a photo of a leaky faucet. Data Scientists at Yelp work to make sense of these interactions to deliver impactful analyses and products to our users, business partners and the general public.<br><br>The Data Science team performs analyses, builds models, and designs experiments that directly impact Yelp’s business and users. Our centralized team is the most wide-ranging consumer of data at Yelp, adept at tasks from modeling content growth and user behavior to sharing insights about the health of local economies. With varied backgrounds and expertise, we strive for learning and growth in a collaborative environment.<br><br>We’d love to have you apply, even if you don't feel you meet every single requirement in this posting. At Yelp, we’re looking for great people, not just those who simply check off all the boxes.<br><br><strong><u>We Are Looking For<br></u></strong><ul><li>3+ years of experience as a data scientist or MS/PhD and 2+ years of industry experience in a quantitative role.</li><li>Fluency with SQL and Python or R for data analysis.</li><li>Solid understanding of statistical inference, experimental design and analysis.</li><li>Enthusiasm for clean code and sharing reproducible results.</li><li>Communication skills to work with partners on engineering, product and business teams.</li><li>An eye for great data visualization with Matplotlib, Plotly, ggplot, or Tableau.</li><li>If you don't have 2+ years of industry experience in a quantitative role, please take a look at our College Data Scientist roles instead!<br></li></ul><strong><u>Where You Come In<br></u></strong><ul><li>Define key metrics to track Yelp’s performance and inform product decisions.</li><li>Assess and frame questions from partners into actionable deliverables.</li><li>Design, execute, and analyze complex experiments impacting millions of users.</li><li>Devise and evaluate models for diverse business needs, such as identifying growth opportunities, personalizing user experience, and matching consumers to businesses.</li><li>Own analyses start-to-finish and communicate key insights to stakeholders.</li><li>Share your technical skills to develop and maintain high-quality, reusable analysis tools.<br></li></ul><em>At Yelp, we believe that diversity is an expression of all the unique characteristics that make us human: race, age, sexual orientation, gender identity, religion, disability, and education — and those are just a few. We recognize that diverse backgrounds and perspectives strengthen our teams and our product. The foundation of our diversity efforts are closely tied to our core values, which include “Playing Well With Others” and “Authenticity.”<br><br></em><em>We’re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition or disability.<br><br></em><em>We will consider for employment qualified candidates with arrest and conviction records, consistent with applicable law (including, for example, the San Francisco Fair Chance Ordinance for roles based in San Francisco).<br><br></em>CCPA Privacy Notice<br><br><em>We are committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-recruiting@yelp.com or 415-969-8488.<br><br></em><em>Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.<br><br></em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Software, Internet, Marketing and Advertising"
Data Scientist I,"Jacksonville, Florida, United States",Black Knight,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-i-at-black-knight-2430189408?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=ncuH7cdJkwukIyyS9SAa3A%3D%3D&position=3&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Position:Data Scientist IJob Description:
Black Knight is the premier provider of integrated technology, services, data and analytics that lenders and servicers look to first to help successfully manage the entire loan life cycle. Our deep understanding of regulatory and compliance issues complements the knowledge, technology and solutions we offer to help our clients achieve their business goals. Black Knight offers leading software systems; data and analytics offerings; and information solutions that facilitate and automate many of the business processes across the mortgage life cycle.

Job Family Description

Responsible for analyzing data to gain insights to benefit the enterprise. Uses large data sets to find opportunities for product and process optimization and uses models to test the effectiveness of different courses of action. Responsible for using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Drives business results with data-based insights and discovers solutions hidden in large data sets improve business outcomes.

General Duties & Responsibilities

Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mines and analyzes data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assesses the effectiveness and accuracy of new data sources and data gathering techniques.
Develops custom data models and algorithms to apply to data sets.
Uses predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develops a testing framework and test model quality.
Coordinates with different functional teams to implement models and monitor outcomes.
Develops processes and tools to monitor and analyze model performance and data accuracy.
Performs other related duties as required.

EDUCATIONAL GUIDELINES

Bachelor’s degree in Mathematics, Finance or the equivalent combination of education, training, or work experience. Master’s degree or PHD in Statistics, Mathematics, Computer Science or another quantitative field is strongly preferred.

General Knowledge, Skills & Abilities

Experience manipulating data sets and building statistical models
Experience with deep learning and NLP (natural language processing) techniques
Experience working with and creating data architectures
Experience using statistical computer languages (Python, SQL, etc.) to manipulate data and draw insights from large data sets
Experience with Git and strong understanding of pull request workflows
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, etc.
Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. a plus
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, etc. a plus
Strong problem solving skills with an emphasis on product development
Excellent written and verbal communication skills for coordinating across teams

JOB FAMILY LEVELS

Entry-level role into the job family. Works with financial models of some complexity using advanced mathematical, analytical or econometric tools. Defines and discerns key aspects of problems that require intricate analysis and research, and develops moderately complex solutions within a broad technical and business context. Functions, somewhat independently, under general direction of more senior Financial Engineers or management. Generally works on a small number of projects as a project team member. Typically requires up to three (3) or more years of related work experience in developing mathematical formulas, algorithms and computer programs to create complex models of market trends and risks.

Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees’ diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight’s commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.
Location:Jacksonville, FLTime Type:Full time
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><strong>Position:</strong></strong>Data Scientist I<strong><strong>Job Description:<br></strong></strong>Black Knight is the premier provider of integrated technology, services, data and analytics that lenders and servicers look to first to help successfully manage the entire loan life cycle. Our deep understanding of regulatory and compliance issues complements the knowledge, technology and solutions we offer to help our clients achieve their business goals. Black Knight offers leading software systems; data and analytics offerings; and information solutions that facilitate and automate many of the business processes across the mortgage life cycle.<br><br><strong><u>Job Family Description<br><br></u></strong>Responsible for analyzing data to gain insights to benefit the enterprise. Uses large data sets to find opportunities for product and process optimization and uses models to test the effectiveness of different courses of action. Responsible for using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Drives business results with data-based insights and discovers solutions hidden in large data sets improve business outcomes.<br><br><strong><u>General Duties &amp; Responsibilities<br></u></strong><ul><li>Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.</li><li>Mines and analyzes data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.</li><li>Assesses the effectiveness and accuracy of new data sources and data gathering techniques.</li><li>Develops custom data models and algorithms to apply to data sets.</li><li>Uses predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.</li><li>Develops a testing framework and test model quality.</li><li>Coordinates with different functional teams to implement models and monitor outcomes.</li><li>Develops processes and tools to monitor and analyze model performance and data accuracy.</li><li>Performs other related duties as required.<br></li></ul><strong>EDUCATIONAL GUIDELINES <br><br></strong>Bachelor’s degree in Mathematics, Finance or the equivalent combination of education, training, or work experience. Master’s degree or PHD in Statistics, Mathematics, Computer Science or another quantitative field is strongly preferred.<br><br><strong><u>General Knowledge, Skills &amp; Abilities<br></u></strong><ul><li>Experience manipulating data sets and building statistical models</li><li>Experience with deep learning and NLP (natural language processing) techniques</li><li>Experience working with and creating data architectures</li><li>Experience using statistical computer languages (Python, SQL, etc.) to manipulate data and draw insights from large data sets</li><li>Experience with Git and strong understanding of pull request workflows</li><li>Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.</li><li>Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks</li><li>Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications</li><li>Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.</li><li>Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, etc.</li><li>Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. a plus</li><li>Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, etc. a plus</li><li>Strong problem solving skills with an emphasis on product development</li><li>Excellent written and verbal communication skills for coordinating across teams<br></li></ul><strong>JOB FAMILY LEVELS <br><br></strong>Entry-level role into the job family. Works with financial models of some complexity using advanced mathematical, analytical or econometric tools. Defines and discerns key aspects of problems that require intricate analysis and research, and develops moderately complex solutions within a broad technical and business context. Functions, somewhat independently, under general direction of more senior Financial Engineers or management. Generally works on a small number of projects as a project team member. Typically requires up to three (3) or more years of related work experience in developing mathematical formulas, algorithms and computer programs to create complex models of market trends and risks.<br><br>Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees’ diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight’s commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.<br><strong><strong>Location:</strong></strong>Jacksonville, FL<strong><strong>Time Type:</strong></strong>Full time</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer - Wirecutter,"New York, New York, United States",Wirecutter,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-wirecutter-at-wirecutter-2407648678?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=twEvgcSpXCahPVhez0qi3Q%3D%3D&position=4&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Position:Data Scientist IJob Description:
Black Knight is the premier provider of integrated technology, services, data and analytics that lenders and servicers look to first to help successfully manage the entire loan life cycle. Our deep understanding of regulatory and compliance issues complements the knowledge, technology and solutions we offer to help our clients achieve their business goals. Black Knight offers leading software systems; data and analytics offerings; and information solutions that facilitate and automate many of the business processes across the mortgage life cycle.

Job Family Description

Responsible for analyzing data to gain insights to benefit the enterprise. Uses large data sets to find opportunities for product and process optimization and uses models to test the effectiveness of different courses of action. Responsible for using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Drives business results with data-based insights and discovers solutions hidden in large data sets improve business outcomes.

General Duties & Responsibilities

Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mines and analyzes data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assesses the effectiveness and accuracy of new data sources and data gathering techniques.
Develops custom data models and algorithms to apply to data sets.
Uses predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develops a testing framework and test model quality.
Coordinates with different functional teams to implement models and monitor outcomes.
Develops processes and tools to monitor and analyze model performance and data accuracy.
Performs other related duties as required.

EDUCATIONAL GUIDELINES

Bachelor’s degree in Mathematics, Finance or the equivalent combination of education, training, or work experience. Master’s degree or PHD in Statistics, Mathematics, Computer Science or another quantitative field is strongly preferred.

General Knowledge, Skills & Abilities

Experience manipulating data sets and building statistical models
Experience with deep learning and NLP (natural language processing) techniques
Experience working with and creating data architectures
Experience using statistical computer languages (Python, SQL, etc.) to manipulate data and draw insights from large data sets
Experience with Git and strong understanding of pull request workflows
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, etc.
Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. a plus
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, etc. a plus
Strong problem solving skills with an emphasis on product development
Excellent written and verbal communication skills for coordinating across teams

JOB FAMILY LEVELS

Entry-level role into the job family. Works with financial models of some complexity using advanced mathematical, analytical or econometric tools. Defines and discerns key aspects of problems that require intricate analysis and research, and develops moderately complex solutions within a broad technical and business context. Functions, somewhat independently, under general direction of more senior Financial Engineers or management. Generally works on a small number of projects as a project team member. Typically requires up to three (3) or more years of related work experience in developing mathematical formulas, algorithms and computer programs to create complex models of market trends and risks.

Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees’ diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight’s commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.
Location:Jacksonville, FLTime Type:Full time
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><strong>Position:</strong></strong>Data Scientist I<strong><strong>Job Description:<br></strong></strong>Black Knight is the premier provider of integrated technology, services, data and analytics that lenders and servicers look to first to help successfully manage the entire loan life cycle. Our deep understanding of regulatory and compliance issues complements the knowledge, technology and solutions we offer to help our clients achieve their business goals. Black Knight offers leading software systems; data and analytics offerings; and information solutions that facilitate and automate many of the business processes across the mortgage life cycle.<br><br><strong><u>Job Family Description<br><br></u></strong>Responsible for analyzing data to gain insights to benefit the enterprise. Uses large data sets to find opportunities for product and process optimization and uses models to test the effectiveness of different courses of action. Responsible for using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Drives business results with data-based insights and discovers solutions hidden in large data sets improve business outcomes.<br><br><strong><u>General Duties &amp; Responsibilities<br></u></strong><ul><li>Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.</li><li>Mines and analyzes data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.</li><li>Assesses the effectiveness and accuracy of new data sources and data gathering techniques.</li><li>Develops custom data models and algorithms to apply to data sets.</li><li>Uses predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.</li><li>Develops a testing framework and test model quality.</li><li>Coordinates with different functional teams to implement models and monitor outcomes.</li><li>Develops processes and tools to monitor and analyze model performance and data accuracy.</li><li>Performs other related duties as required.<br></li></ul><strong>EDUCATIONAL GUIDELINES <br><br></strong>Bachelor’s degree in Mathematics, Finance or the equivalent combination of education, training, or work experience. Master’s degree or PHD in Statistics, Mathematics, Computer Science or another quantitative field is strongly preferred.<br><br><strong><u>General Knowledge, Skills &amp; Abilities<br></u></strong><ul><li>Experience manipulating data sets and building statistical models</li><li>Experience with deep learning and NLP (natural language processing) techniques</li><li>Experience working with and creating data architectures</li><li>Experience using statistical computer languages (Python, SQL, etc.) to manipulate data and draw insights from large data sets</li><li>Experience with Git and strong understanding of pull request workflows</li><li>Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.</li><li>Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks</li><li>Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications</li><li>Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.</li><li>Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, etc.</li><li>Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. a plus</li><li>Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, etc. a plus</li><li>Strong problem solving skills with an emphasis on product development</li><li>Excellent written and verbal communication skills for coordinating across teams<br></li></ul><strong>JOB FAMILY LEVELS <br><br></strong>Entry-level role into the job family. Works with financial models of some complexity using advanced mathematical, analytical or econometric tools. Defines and discerns key aspects of problems that require intricate analysis and research, and develops moderately complex solutions within a broad technical and business context. Functions, somewhat independently, under general direction of more senior Financial Engineers or management. Generally works on a small number of projects as a project team member. Typically requires up to three (3) or more years of related work experience in developing mathematical formulas, algorithms and computer programs to create complex models of market trends and risks.<br><br>Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees’ diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight’s commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.<br><strong><strong>Location:</strong></strong>Jacksonville, FL<strong><strong>Time Type:</strong></strong>Full time</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"San Francisco, California, United States",Front,2021-02-06,https://www.linkedin.com/jobs/view/data-engineer-at-front-2391491894?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=eFZcMoVOAzVbRDd5B595%2Fw%3D%3D&position=5&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"About The Position

Job Description

Wirecutter is seeking a Data Engineer to help build the infrastructure, data architecture, and pipelines that power our business. Data Engineers operate within a distributed, agile, cross-functional squad. The data squad has an organization-wide impact by providing the data to inform the user experience, product, editorial, growth, and financial decisions at Wirecutter. The squad is responsible for the ETL processes, architecture, storage, reliability, accuracy, monitoring, and infrastructure surrounding our internal data and analytics.

Our Data Engineering Tech Stack Consists Of

Python and Apache Airflow for ETL pipelines
PostgreSQL database and S3 data lake in AWS RDS
BigQuery analytics data
Looker BI tool


Responsibilities

Help drive the optimization, testing, and tooling to improve data quality.
Write, debug, and test complex ETL processes for new or existing data pipelines.
Write and maintain database design and architecture documentation.
Maintain an understanding of Wirecutter's data platforms as well as the data platforms of our parent company, the New York Times
Uncover dependencies and leverage features and tools from both the Wirecutter and New York Times
Collaborate with your squad leaders and stakeholders on the scoping, planning, prioritization, successful execution, and rollout of complex technical projects to provide the foundation for generating insights and address additional data for reporting needs.
Create new data models that are appropriately scalable, standardized, performant, and reliable.
Evolve our current data models from production services into readily consumable formats for all downstream data consumption.
Support and maintain the integrity and security of our internal data.
Provide insight into changing database storage and utilization requirements.
Recommend solutions that best align with our product and business goals, as well as the quality, reliability, and secure storage and replication of our data.
Improve our development workflow and infrastructure.
Share knowledge and problem solving with other members of your squad and the engineering team.
Contribute to engineering initiatives and culture as a member of Wirecutter’s engineering team.


Qualifications

You have 3+ years in software or data engineering and scaling large data sets.
You can design & optimize queries, data sets, and data pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.
You understand the challenges of reliable data replication, optimizing for a data warehouse, and maintaining the integrity of a data lake.
You have experience reliably integrating and handling data from multiple APIs.
You have experience building ETLs at scale on any major cloud provider (AWS, GCP: Cloud Composer, Kubernetes, etc.)
You are thoughtful, clear, and persuasive in writing and in person.
You have strong problem-solving skills and critical thinking abilities.
You have experience listening to analysts and other business users, and can translate their needs into actionable tasks.
You are excited to play a pivotal role in Wirecutter’s mission, innovation, and growth.
You are passionate and enthusiastic about what you do.
You have experience with version control, shell scripting, the Unix filesystem, and automating deployments.
Ideally, you have production experience with Python and Apache Airflow.
Ideally, you have experience with BI tools and managing data sets for BI tools.
Ideally, you have a basic understanding of statistics and sampling.
Ideally, you have experience working with Google Tag Manager and analytics data sets
Ideally, you’ve worked as a member of a distributed team.


About Wirecutter

Wirecutter helps people buy the right things for the way they want to live. The site was founded by journalists in September 2011 and was acquired by The New York Times Company in October 2016. Our recommendations are made through vigorous reporting, interviewing, and testing by teams of veteran journalists, scientists, and researchers. Consider us a best-of list for everyday things; a curated gallery filled with only interesting, useful objects; a thank-you note to the designers and engineers who create the stuff that makes our lives better; a geeky friend with next-level research skills who tests everything they buy so you don’t have to. The point is to make buying great gear quickly easier so you can get on with living your life.

We pride ourselves on following rigorous journalistic standards and ethics, and we maintain editorial independence from our business operations. Our recommendations are always made entirely by our editorial team without input from our revenue team, and our writers and editors are never made aware of any business relationships. Wirecutter is mission-driven and reader-supported; learn more about us here .

Our Company Principles

Our principles help us create a work environment that breeds trust, respect, learning, and is one that we all are excited about showing up to each day.

Seek Understanding: We are lifelong students who want to understand the world around us. We are curious to understand our readers, how we get better at our own disciplines, and how we can work better together. This means we are active listeners, information hunters, and empathetic.

Explain Why: Because we seek to understand, we value the importance of explaining our ideas and our understanding. This means we are constructively candid, sharing our perspectives and the thought process behind it. And then learning from the conversation that ensues. We are all teachers and students, helping each other grow.

Solve Things: We love to solve things, whether they are our own problems, our readers’ problems or our colleagues’ problems. While we often can solve problems on our own, we believe our best results come out when we solve them together.

Get It Done: We are passionate about getting things done. Whether it is our own individual work or teamwork, our instinct is to forge a path forward and learn as we go. This means we continually focus on how to turn work into achievable chunks, communicate those effectively to the team and efficiently execute against them.

Make It Better: We aren’t satisfied with perpetuating the status quo. We’re always looking forward. We live to change the world around us for the better, making a difference in our own lives and our readers’ lives. If we are being ambitious enough, this means that we will both fail and succeed and we take pride in owning both of those outcomes as long as we are learning.

Locations

Even with our offices in New York City and Los Angeles, Wirecutter remains a highly remote-friendly culture, and proud to employ incredible people across the country. Right now, we are eligible to hire in AZ, CA, CO, CT, FL, HI, IA, IL, IN, MA, ME, MI, MN, NH, NY, OH, OR, PA, TX, UT, WA.

Overview of Benefits at Wirecutter and The New York Times Company:

Though Wirecutter has physical locations in both NYC and LA, the company promotes and encourages a remote workforce, so that our employees can work in flexible and comfortable ways. We are committed to career development, supported by a formal mentoring program as well as tuition reimbursement. The New York Times Company offers frequent panel discussions and talks by industry leaders (Sheryl Sandberg, Melinda Gates and Ta-Nehisi Coates are a few recent examples), that we encourage our employees to attend.

We believe diversity fuels innovation and creativity, and we have a variety of employee groups and task forces across The New York Times Company and Wirecutter dedicated to fostering a diverse and inclusive workplace.

We offer a generous parental leave policy, which was recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid, adoptive parents and birth fathers receive 10 weeks also fully paid. Similarly, we offer competitive health and dental insurance, as well as 401k matching.

The New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.

The New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The New York Times Company will consider qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local ""Fair Chance"" laws.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About The Position<br><br></u></strong><strong> <strong>Job Description</strong> <br><br></strong>Wirecutter is seeking a Data Engineer to help build the infrastructure, data architecture, and pipelines that power our business. Data Engineers operate within a distributed, agile, cross-functional squad. The data squad has an organization-wide impact by providing the data to inform the user experience, product, editorial, growth, and financial decisions at Wirecutter. The squad is responsible for the ETL processes, architecture, storage, reliability, accuracy, monitoring, and infrastructure surrounding our internal data and analytics.<br><br><strong><u>Our Data Engineering Tech Stack Consists Of<br></u></strong><ul><li> Python and Apache Airflow for ETL pipelines </li><li> PostgreSQL database and S3 data lake in AWS RDS </li><li> BigQuery analytics data </li><li> Looker BI tool <br><br></li></ul><strong><u>Responsibilities<br></u></strong><ul><li> Help drive the optimization, testing, and tooling to improve data quality. </li><li> Write, debug, and test complex ETL processes for new or existing data pipelines. </li><li> Write and maintain database design and architecture documentation. </li><li> Maintain an understanding of Wirecutter's data platforms as well as the data platforms of our parent company, the New York Times </li><li> Uncover dependencies and leverage features and tools from both the Wirecutter and New York Times </li><li> Collaborate with your squad leaders and stakeholders on the scoping, planning, prioritization, successful execution, and rollout of complex technical projects to provide the foundation for generating insights and address additional data for reporting needs. </li><li> Create new data models that are appropriately scalable, standardized, performant, and reliable. </li><li> Evolve our current data models from production services into readily consumable formats for all downstream data consumption. </li><li> Support and maintain the integrity and security of our internal data. </li><li> Provide insight into changing database storage and utilization requirements. </li><li> Recommend solutions that best align with our product and business goals, as well as the quality, reliability, and secure storage and replication of our data. </li><li> Improve our development workflow and infrastructure. </li><li> Share knowledge and problem solving with other members of your squad and the engineering team. </li><li> Contribute to engineering initiatives and culture as a member of Wirecutter’s engineering team. <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> You have 3+ years in software or data engineering and scaling large data sets. </li><li> You can design &amp; optimize queries, data sets, and data pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs. </li><li> You understand the challenges of reliable data replication, optimizing for a data warehouse, and maintaining the integrity of a data lake. </li><li> You have experience reliably integrating and handling data from multiple APIs. </li><li> You have experience building ETLs at scale on any major cloud provider (AWS, GCP: Cloud Composer, Kubernetes, etc.) </li><li> You are thoughtful, clear, and persuasive in writing and in person. </li><li> You have strong problem-solving skills and critical thinking abilities. </li><li> You have experience listening to analysts and other business users, and can translate their needs into actionable tasks. </li><li> You are excited to play a pivotal role in Wirecutter’s mission, innovation, and growth. </li><li> You are passionate and enthusiastic about what you do. </li><li> You have experience with version control, shell scripting, the Unix filesystem, and automating deployments. </li><li> Ideally, you have production experience with Python and Apache Airflow. </li><li> Ideally, you have experience with BI tools and managing data sets for BI tools. </li><li> Ideally, you have a basic understanding of statistics and sampling. </li><li> Ideally, you have experience working with Google Tag Manager and analytics data sets </li><li> Ideally, you’ve worked as a member of a distributed team. <br><br></li></ul><strong><u>About Wirecutter<br><br></u></strong>Wirecutter helps people buy the right things for the way they want to live. The site was founded by journalists in September 2011 and was acquired by The New York Times Company in October 2016. Our recommendations are made through vigorous reporting, interviewing, and testing by teams of veteran journalists, scientists, and researchers. Consider us a best-of list for everyday things; a curated gallery filled with only interesting, useful objects; a thank-you note to the designers and engineers who create the stuff that makes our lives better; a geeky friend with next-level research skills who tests everything they buy so you don’t have to. The point is to make buying great gear quickly easier so you can get on with living your life.<br><br>We pride ourselves on following rigorous journalistic standards and ethics, and we maintain editorial independence from our business operations. Our recommendations are always made entirely by our editorial team without input from our revenue team, and our writers and editors are never made aware of any business relationships. Wirecutter is mission-driven and reader-supported; learn more about us here .<br><br><strong><u>Our Company Principles<br><br></u></strong>Our principles help us create a work environment that breeds trust, respect, learning, and is one that we all are excited about showing up to each day.<br><br>Seek Understanding: We are lifelong students who want to understand the world around us. We are curious to understand our readers, how we get better at our own disciplines, and how we can work better together. This means we are active listeners, information hunters, and empathetic.<br><br>Explain Why: Because we seek to understand, we value the importance of explaining our ideas and our understanding. This means we are constructively candid, sharing our perspectives and the thought process behind it. And then learning from the conversation that ensues. We are all teachers and students, helping each other grow.<br><br>Solve Things: We love to solve things, whether they are our own problems, our readers’ problems or our colleagues’ problems. While we often can solve problems on our own, we believe our best results come out when we solve them together.<br><br>Get It Done: We are passionate about getting things done. Whether it is our own individual work or teamwork, our instinct is to forge a path forward and learn as we go. This means we continually focus on how to turn work into achievable chunks, communicate those effectively to the team and efficiently execute against them.<br><br>Make It Better: We aren’t satisfied with perpetuating the status quo. We’re always looking forward. We live to change the world around us for the better, making a difference in our own lives and our readers’ lives. If we are being ambitious enough, this means that we will both fail and succeed and we take pride in owning both of those outcomes as long as we are learning.<br><br><strong>Locations<br><br></strong>Even with our offices in New York City and Los Angeles, Wirecutter remains a highly remote-friendly culture, and proud to employ incredible people across the country. Right now, we are eligible to hire in AZ, CA, CO, CT, FL, HI, IA, IL, IN, MA, ME, MI, MN, NH, NY, OH, OR, PA, TX, UT, WA.<br><br><strong>Overview of Benefits at Wirecutter and The New York Times Company:<br><br></strong>Though Wirecutter has physical locations in both NYC and LA, the company promotes and encourages a remote workforce, so that our employees can work in flexible and comfortable ways. We are committed to career development, supported by a formal mentoring program as well as tuition reimbursement. The New York Times Company offers frequent panel discussions and talks by industry leaders (Sheryl Sandberg, Melinda Gates and Ta-Nehisi Coates are a few recent examples), that we encourage our employees to attend.<br><br>We believe diversity fuels innovation and creativity, and we have a variety of employee groups and task forces across The New York Times Company and Wirecutter dedicated to fostering a diverse and inclusive workplace.<br><br>We offer a generous parental leave policy, which was recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid, adoptive parents and birth fathers receive 10 weeks also fully paid. Similarly, we offer competitive health and dental insurance, as well as 401k matching.<br><br><strong> The New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply. <br><br></strong><strong>The New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The New York Times Company will consider qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local ""Fair Chance"" laws.<br><br></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Python Software Engineer,"McLean, Virginia, United States","Bravo Consulting Group, LLC",2021-02-05,https://www.linkedin.com/jobs/view/python-software-engineer-at-bravo-consulting-group-llc-2409935377?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=QqiGXItwQlbwGmkQKgdKxQ%3D%3D&position=7&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Title: Python Software Engineer

Location: McLean, VA

Job Summary:

Bravo is seeking a Software Engineer with Python proficiency to support a growing data science/data engineering ecosystem currently in development. As the organization includes shifting demands and priorities, we are looking for a dynamic, flexible professional. This position fits on a small team to execute its operations and partner across the organization to ensure mission success.

Responsibilities Include:

Architect systems using enterprise tools and capabilities (e.g. authentication services, audit, etc.) as follows:
Architect a new data science system for the Sponsor that will connect with the Sponsor’s existing systems.
Design and build a system that emphasizes the ingestion of data, and push data and services to users.
Maximize efficiencies and reduce long-term O&M costs.
Manage and maintain the Sponsor’s existing software applications and environments, including managing uptime, scaling, and system administration.
Develop and maintain connections between the Sponsor’s existing systems and third party systems.
Gather requirements, develop program schedules, and monitor program execution.
Develop, coordinate, and manage system documentation and the Sponsor’s A&A process for the Sponsor’s existing systems.
Develop and disseminate progress reports for external audiences.


Required Qualifications

Expertise in building automated ETL pipelines/workflows in Python-based environment (e.g. Apache Airflow or Prefect).
Demonstrated knowledge of techniques for entity resolution/aggregation and linking rich data together across diverse and broad datasets.
Demonstrated experience successfully building and deploying applications to serve and process large volumes of data.
Demonstrated knowledge of data governance best practices on data sourcing and data compliance management.
Demonstrated experience building, deploying, and managing cloud-based applications.


Desired Qualifications

Experience developing and coordinating system-to-system interfaces across enterprise applications and data stores.
Experience using Apache NiFi.
Demonstrated experience managing heterogeneous data holdings in accordance with Sponsor’s regulations.


Compensation Package

Bravo’s commitment to people first is demonstrated in the benefits we provide to our team members: We provide industry leading benefits including:

Paid medical, dental and vision benefits
401K program with employer match
Commute stipend
32 Days PTO (15 vacation, 7 sick, 10 federal holidays)
Profit Sharing
Phantom Stock Options


Company Overview

Bravo Consulting Group, LLC (Bravo) taps into the power of Microsoft technologies to develop custom software applications and solutions for Federal, State, Local, and Commercial organizations. Since our inception in 2007, we have pioneered enterprise applications that have become central components in our clients' business success. Our customer-centric focus has allowed us to implement improved technologies, develop high-end business solutions, and transform digital services. Our vast technology and industry expertise enable us to partner with clients to deliver sophisticated solutions rapidly and on budget.

Powered by JazzHR

4u9Vxu1Inj
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Title: </strong>Python Software Engineer<br><br><strong>Location: </strong>McLean, VA<br><br><strong>Job Summary:<br><br></strong>Bravo is seeking a Software Engineer with Python proficiency to support a growing data science/data engineering ecosystem currently in development. As the organization includes shifting demands and priorities, we are looking for a dynamic, flexible professional. This position fits on a small team to execute its operations and partner across the organization to ensure mission success.<br><br>Responsibilities Include:<br><ul><li>Architect systems using enterprise tools and capabilities (e.g. authentication services, audit, etc.) as follows: </li><li>Architect a new data science system for the Sponsor that will connect with the Sponsor’s existing systems. </li><li>Design and build a system that emphasizes the ingestion of data, and push data and services to users. </li><li>Maximize efficiencies and reduce long-term O&amp;M costs. </li><li>Manage and maintain the Sponsor’s existing software applications and environments, including managing uptime, scaling, and system administration. </li><li>Develop and maintain connections between the Sponsor’s existing systems and third party systems.</li><li>Gather requirements, develop program schedules, and monitor program execution. </li><li>Develop, coordinate, and manage system documentation and the Sponsor’s A&amp;A process for the Sponsor’s existing systems. </li><li>Develop and disseminate progress reports for external audiences.<br><br></li></ul><strong><u>Required Qualifications<br></u></strong><ul><li>Expertise in building automated ETL pipelines/workflows in Python-based environment (e.g. Apache Airflow or Prefect).</li><li>Demonstrated knowledge of techniques for entity resolution/aggregation and linking rich data together across diverse and broad datasets.</li><li>Demonstrated experience successfully building and deploying applications to serve and process large volumes of data.</li><li>Demonstrated knowledge of data governance best practices on data sourcing and data compliance management.</li><li>Demonstrated experience building, deploying, and managing cloud-based applications.<br><br></li></ul><strong><u>Desired Qualifications<br></u></strong><ul><li>Experience developing and coordinating system-to-system interfaces across enterprise applications and data stores.</li><li>Experience using Apache NiFi.</li><li>Demonstrated experience managing heterogeneous data holdings in accordance with Sponsor’s regulations.<br><br></li></ul><strong><u>Compensation Package<br><br></u></strong>Bravo’s commitment to people first is demonstrated in the benefits we provide to our team members: We provide industry leading benefits including:<br><ul><li>Paid medical, dental and vision benefits </li><li>401K program with employer match </li><li>Commute stipend </li><li>32 Days PTO (15 vacation, 7 sick, 10 federal holidays) </li></ul><ul><li>Profit Sharing </li><li>Phantom Stock Options <br><br></li></ul><strong><u>Company Overview<br><br></u></strong>Bravo Consulting Group, LLC (Bravo) taps into the power of Microsoft technologies to develop custom software applications and solutions for Federal, State, Local, and Commercial organizations. Since our inception in 2007, we have pioneered enterprise applications that have become central components in our clients' business success. Our customer-centric focus has allowed us to implement improved technologies, develop high-end business solutions, and transform digital services. Our vast technology and industry expertise enable us to partner with clients to deliver sophisticated solutions rapidly and on budget.<br><br>Powered by JazzHR<br><br>4u9Vxu1Inj</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Computer & Network Security"
Data Scientist,"Austin, Texas, United States",Surveying and Mapping,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-surveying-and-mapping-2428918171?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=BElxgW75YiLU82XAyKI%2B1w%3D%3D&position=8&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Title: Python Software Engineer

Location: McLean, VA

Job Summary:

Bravo is seeking a Software Engineer with Python proficiency to support a growing data science/data engineering ecosystem currently in development. As the organization includes shifting demands and priorities, we are looking for a dynamic, flexible professional. This position fits on a small team to execute its operations and partner across the organization to ensure mission success.

Responsibilities Include:

Architect systems using enterprise tools and capabilities (e.g. authentication services, audit, etc.) as follows:
Architect a new data science system for the Sponsor that will connect with the Sponsor’s existing systems.
Design and build a system that emphasizes the ingestion of data, and push data and services to users.
Maximize efficiencies and reduce long-term O&M costs.
Manage and maintain the Sponsor’s existing software applications and environments, including managing uptime, scaling, and system administration.
Develop and maintain connections between the Sponsor’s existing systems and third party systems.
Gather requirements, develop program schedules, and monitor program execution.
Develop, coordinate, and manage system documentation and the Sponsor’s A&A process for the Sponsor’s existing systems.
Develop and disseminate progress reports for external audiences.


Required Qualifications

Expertise in building automated ETL pipelines/workflows in Python-based environment (e.g. Apache Airflow or Prefect).
Demonstrated knowledge of techniques for entity resolution/aggregation and linking rich data together across diverse and broad datasets.
Demonstrated experience successfully building and deploying applications to serve and process large volumes of data.
Demonstrated knowledge of data governance best practices on data sourcing and data compliance management.
Demonstrated experience building, deploying, and managing cloud-based applications.


Desired Qualifications

Experience developing and coordinating system-to-system interfaces across enterprise applications and data stores.
Experience using Apache NiFi.
Demonstrated experience managing heterogeneous data holdings in accordance with Sponsor’s regulations.


Compensation Package

Bravo’s commitment to people first is demonstrated in the benefits we provide to our team members: We provide industry leading benefits including:

Paid medical, dental and vision benefits
401K program with employer match
Commute stipend
32 Days PTO (15 vacation, 7 sick, 10 federal holidays)
Profit Sharing
Phantom Stock Options


Company Overview

Bravo Consulting Group, LLC (Bravo) taps into the power of Microsoft technologies to develop custom software applications and solutions for Federal, State, Local, and Commercial organizations. Since our inception in 2007, we have pioneered enterprise applications that have become central components in our clients' business success. Our customer-centric focus has allowed us to implement improved technologies, develop high-end business solutions, and transform digital services. Our vast technology and industry expertise enable us to partner with clients to deliver sophisticated solutions rapidly and on budget.

Powered by JazzHR

4u9Vxu1Inj
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Title: </strong>Python Software Engineer<br><br><strong>Location: </strong>McLean, VA<br><br><strong>Job Summary:<br><br></strong>Bravo is seeking a Software Engineer with Python proficiency to support a growing data science/data engineering ecosystem currently in development. As the organization includes shifting demands and priorities, we are looking for a dynamic, flexible professional. This position fits on a small team to execute its operations and partner across the organization to ensure mission success.<br><br>Responsibilities Include:<br><ul><li>Architect systems using enterprise tools and capabilities (e.g. authentication services, audit, etc.) as follows: </li><li>Architect a new data science system for the Sponsor that will connect with the Sponsor’s existing systems. </li><li>Design and build a system that emphasizes the ingestion of data, and push data and services to users. </li><li>Maximize efficiencies and reduce long-term O&amp;M costs. </li><li>Manage and maintain the Sponsor’s existing software applications and environments, including managing uptime, scaling, and system administration. </li><li>Develop and maintain connections between the Sponsor’s existing systems and third party systems.</li><li>Gather requirements, develop program schedules, and monitor program execution. </li><li>Develop, coordinate, and manage system documentation and the Sponsor’s A&amp;A process for the Sponsor’s existing systems. </li><li>Develop and disseminate progress reports for external audiences.<br><br></li></ul><strong><u>Required Qualifications<br></u></strong><ul><li>Expertise in building automated ETL pipelines/workflows in Python-based environment (e.g. Apache Airflow or Prefect).</li><li>Demonstrated knowledge of techniques for entity resolution/aggregation and linking rich data together across diverse and broad datasets.</li><li>Demonstrated experience successfully building and deploying applications to serve and process large volumes of data.</li><li>Demonstrated knowledge of data governance best practices on data sourcing and data compliance management.</li><li>Demonstrated experience building, deploying, and managing cloud-based applications.<br><br></li></ul><strong><u>Desired Qualifications<br></u></strong><ul><li>Experience developing and coordinating system-to-system interfaces across enterprise applications and data stores.</li><li>Experience using Apache NiFi.</li><li>Demonstrated experience managing heterogeneous data holdings in accordance with Sponsor’s regulations.<br><br></li></ul><strong><u>Compensation Package<br><br></u></strong>Bravo’s commitment to people first is demonstrated in the benefits we provide to our team members: We provide industry leading benefits including:<br><ul><li>Paid medical, dental and vision benefits </li><li>401K program with employer match </li><li>Commute stipend </li><li>32 Days PTO (15 vacation, 7 sick, 10 federal holidays) </li></ul><ul><li>Profit Sharing </li><li>Phantom Stock Options <br><br></li></ul><strong><u>Company Overview<br><br></u></strong>Bravo Consulting Group, LLC (Bravo) taps into the power of Microsoft technologies to develop custom software applications and solutions for Federal, State, Local, and Commercial organizations. Since our inception in 2007, we have pioneered enterprise applications that have become central components in our clients' business success. Our customer-centric focus has allowed us to implement improved technologies, develop high-end business solutions, and transform digital services. Our vast technology and industry expertise enable us to partner with clients to deliver sophisticated solutions rapidly and on budget.<br><br>Powered by JazzHR<br><br>4u9Vxu1Inj</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Computer & Network Security"
Software Engineer (Python),"Philadelphia, Pennsylvania, United States",HealthVerity,2021-02-09,https://www.linkedin.com/jobs/view/software-engineer-python-at-healthverity-2415531334?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=BZi6gLsExuwB5WxOOUOmJg%3D%3D&position=9&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Who We Are

SAM Companies is recognized as the industry’s technology leader in providing geospatial solutions and construction services on a national scale. Our staff encompasses 1,000+ individuals from diverse backgrounds who are deploying the latest industry technology and changing the way data is collected and delivered in our industry.

Our Culture
Our entrepreneurial culture is a key factor in SAM being recognized as a Top Workplace for nine consecutive years, and we make it our mission to ensure every one of our employees learns how to build and manage a business, not just be the subject matter expert on the team. At SAM, our employee’s development is instrumental to our success. Your learning will be supported by specialized in-house training programs and mentoring by the industry’s leading experts, who just happen to be on our staff! We make SAM a GREAT place to work, but it all starts with YOU!

Your Impact at SAM

The Data Scientist will be joining a small group within the team that develops and deploys Machine Learning solutions to advance the products that we build. We are using Machine Learning to increase the quality and efficiency of our products on remotely sensed and business data. The team adapts or develops custom architecture to business needs and assembles large in-house datasets with tens of thousands of training examples. We are only scratching the surface with what we can achieve, and you will have a front-row seat in advancing our efforts.

Develop infrastructure and tools to productionize new models in a reproducible manner
Implement machine learning lifecycle to iterate on current models to improve predictive and runtime performance
Prototype new ML approaches and design experiments for evaluation
Identify opportunities to apply machine learning methodologies to solve new problems
Participate in design discussions about new features and approaches to implementing new services


What You Bring To SAM

3+ years of experience in building software professionally
Experience contributing high quality code to large codebases; Python and .net preferred
Experience with data preparation for model training including collation, normalization, transformation, and annotation
Experience with Machine Learning APIs and libraries; TensorFlow, PyTorch, Keras
Knowledge of databases (relational and NoSQL alternatives)
Experience with Apache Spark and/or Databricks for dataset preparation
Experience with cloud ML infrastructure (e.g., Azure ML)
Experience building Machine Learning systems at scale would be a plus
Successful implementation of defect detection and other ML algorithms (CNN, GAN, kNN, salience, etc)
Real-time object detection using YOLOv3, opencv
Data science background (math/statistical) and Master’s degree+ preferred

Our Perks!

In Addition, We Offer

We offer a best-in-class benefits package that includes company paid premiums for medical, vision, dental and life insurance. SAM’s 401 (k) program offers a 100% employer match up to 3% of your contribution, along with a 401(k) profit sharing and performance-based bonuses.


Generous paid time off
Tuition reimbursement
No glass ceiling! Truly a place to spread your wings
Work/life balance with flexible work hours – priority is getting the job done
Trainings every Tuesday – Specialized in-house trainings programs designed to assist you in advancing in your career
Office snacks, free food and fun-themed, employee events provided throughout the year
Passion for our Community – You have endless opportunities to volunteer alongside your peers with our Corporate Social Responsibility Program


EEO
SAM is an EOE/Affirmative Action Employer M/F/D/V. SAM also participates in the federal E-Verify Program.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Who We Are<br><br></u></strong>SAM Companies is recognized as the industry’s technology leader in providing geospatial solutions and construction services on a national scale. Our staff encompasses 1,000+ individuals from diverse backgrounds who are deploying the latest industry technology and changing the way data is collected and delivered in our industry.<br><br><strong>Our Culture<br></strong>Our entrepreneurial culture is a key factor in SAM being recognized as a Top Workplace for nine consecutive years, and we make it our mission to ensure every one of our employees learns how to build and manage a business, not just be the subject matter expert on the team. At SAM, our employee’s development is instrumental to our success. Your learning will be supported by specialized in-house training programs and mentoring by the industry’s leading experts, who just happen to be on our staff! We make SAM a GREAT place to work, but it all starts with YOU!<br><br><strong> Your Impact at SAM <br><br></strong>The Data Scientist will be joining a small group within the team that develops and deploys Machine Learning solutions to advance the products that we build. We are using Machine Learning to increase the quality and efficiency of our products on remotely sensed and business data. The team adapts or develops custom architecture to business needs and assembles large in-house datasets with tens of thousands of training examples. We are only scratching the surface with what we can achieve, and you will have a front-row seat in advancing our efforts.<br><ul><li> Develop infrastructure and tools to productionize new models in a reproducible manner </li><li> Implement machine learning lifecycle to iterate on current models to improve predictive and runtime performance </li><li> Prototype new ML approaches and design experiments for evaluation </li><li> Identify opportunities to apply machine learning methodologies to solve new problems </li><li> Participate in design discussions about new features and approaches to implementing new services <br><br></li></ul><strong><u>What You Bring To SAM<br></u></strong><ul><li> 3+ years of experience in building software professionally </li><li> Experience contributing high quality code to large codebases; Python and .net preferred </li><li> Experience with data preparation for model training including collation, normalization, transformation, and annotation </li><li> Experience with Machine Learning APIs and libraries; TensorFlow, PyTorch, Keras </li><li> Knowledge of databases (relational and NoSQL alternatives) </li><li> Experience with Apache Spark and/or Databricks for dataset preparation </li><li> Experience with cloud ML infrastructure (e.g., Azure ML) </li><li> Experience building Machine Learning systems at scale would be a plus </li><li> Successful implementation of defect detection and other ML algorithms (CNN, GAN, kNN, salience, etc) </li><li> Real-time object detection using YOLOv3, opencv </li><li> Data science background (math/statistical) and Master’s degree+ preferred <br></li></ul><strong>Our Perks!<br><br></strong><strong><u>In Addition, We Offer<br><br></u></strong>We offer a best-in-class benefits package that includes company paid premiums for medical, vision, dental and life insurance. SAM’s 401 (k) program offers a 100% employer match up to 3% of your contribution, along with a 401(k) profit sharing and performance-based bonuses.<br><br><li> Generous paid time off</li><li> Tuition reimbursement</li><li> No glass ceiling! Truly a place to spread your wings</li><li> Work/life balance with flexible work hours – priority is getting the job done</li><li> Trainings every Tuesday – Specialized in-house trainings programs designed to assist you in advancing in your career</li><li> Office snacks, free food and fun-themed, employee events provided throughout the year</li><li> Passion for our Community – You have endless opportunities to volunteer alongside your peers with our Corporate Social Responsibility Program<br><br></li><strong>EEO<br></strong>SAM is an EOE/Affirmative Action Employer M/F/D/V. SAM also participates in the federal E-Verify Program.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Civil Engineering, Telecommunications"
Full Time Data Scientist Remote (VA Based),"Washington, District of Columbia, United States",Vaco,2021-02-19,https://www.linkedin.com/jobs/view/full-time-data-scientist-remote-va-based-at-vaco-2419644281?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=360vh7r45tZzCu042ErxYA%3D%3D&position=10&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"How you will help

You will own and be responsible for developing key components of our overall system that enables our customers to bring new insights to their own businesses. You’ll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs.

What you will do

Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin
Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data
Enjoy the peace that comes with working in a mature software development environment
Marvel at the speed with which your creation makes it into production
Research and implement new technologies with a team of developers to execute strategies and implement solutions
Produce peer reviewed quality software
Solve complex problems related to the real-time discovery of large data

You are...

Experienced in writing scalable applications on distributed architectures
Data driven, testing and measuring as much as you can
Eager to both review peer code and have your code reviewed
Comfortable on the command line and consider it an essential tool
Confident in SQL, you know it, write smart queries, it’s no big deal

Desired Skills And Experience

5+ years of experience in programming in languages such as: Python, Ruby, Perl, C++, Java
Expert knowledge of design patterns, multi-threaded systems, and automated unit testing
Experienced in processing large scale data

Our company challenges

Empowering clients with highly rewarding data discovery and licensing tools
Ingesting and managing billions of healthcare records from a wide variety of partners
Standardizing on common data models across data types
Orchestrating an industry-leading HIPAA privacy layer
Innovating our proprietary de-identification and data science algorithms
Building a culture that supports rapid iteration and new possibilities

The infrastructure and culture we are building will provide an environment that cultivates innovation. We want to move fast knowing we can fix anything we break along the way. If a new need arises, we want to turn around a solution quickly. We want to solve our challenges in ways that create even more possibilities. We’re creating a platform that lets us discover what else we might do.

We have big plans

We are building a platform that will scale to support an ever-growing array of data providers and innovative products. You must be able to think big while still delivering on near-term requirements.

HealthVerity, based in Center City Philadelphia, is a venture-backed technology company that is transforming the way data-led organizations make critical decisions. Our technology platform serves as the foundation for the rapid creation, exchange and management of healthcare and consumer data in a fully-interoperable, privacy-protecting manner. Advantaged by highly sophisticated identity resolution and matching capabilities, HealthVerity is on a mission to increase transparency, forge interoperability and activate deeper insights.

HealthVerity is an equal opportunity employer.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">How you will help<br><br>You will own and be responsible for developing key components of our overall system that enables our customers to bring new insights to their own businesses. You’ll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs.<br><br>What you will do<br><ul><li> Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin</li><li> Leverage distributed computing and serverless architecture such as AWS EMR &amp; AWS Lambda, to develop pipelines for transforming data</li><li> Enjoy the peace that comes with working in a mature software development environment</li><li> Marvel at the speed with which your creation makes it into production</li><li> Research and implement new technologies with a team of developers to execute strategies and implement solutions</li><li> Produce peer reviewed quality software</li><li> Solve complex problems related to the real-time discovery of large data<br></li></ul>You are...<br><ul><li> Experienced in writing scalable applications on distributed architectures</li><li> Data driven, testing and measuring as much as you can</li><li> Eager to both review peer code and have your code reviewed</li><li> Comfortable on the command line and consider it an essential tool</li><li> Confident in SQL, you know it, write smart queries, it’s no big deal<br></li></ul><strong> Desired Skills And Experience <br></strong><ul><li> 5+ years of experience in programming in languages such as: Python, Ruby, Perl, C++, Java</li><li> Expert knowledge of design patterns, multi-threaded systems, and automated unit testing</li><li> Experienced in processing large scale data<br></li></ul>Our company challenges<br><ul><li> Empowering clients with highly rewarding data discovery and licensing tools</li><li> Ingesting and managing billions of healthcare records from a wide variety of partners</li><li> Standardizing on common data models across data types</li><li> Orchestrating an industry-leading HIPAA privacy layer</li><li> Innovating our proprietary de-identification and data science algorithms</li><li> Building a culture that supports rapid iteration and new possibilities<br></li></ul>The infrastructure and culture we are building will provide an environment that cultivates innovation. We want to move fast knowing we can fix anything we break along the way. If a new need arises, we want to turn around a solution quickly. We want to solve our challenges in ways that create even more possibilities. We’re creating a platform that lets us discover what else we might do.<br><br>We have big plans<br><br>We are building a platform that will scale to support an ever-growing array of data providers and innovative products. You must be able to think big while still delivering on near-term requirements.<br><br>HealthVerity, based in Center City Philadelphia, is a venture-backed technology company that is transforming the way data-led organizations make critical decisions. Our technology platform serves as the foundation for the rapid creation, exchange and management of healthcare and consumer data in a fully-interoperable, privacy-protecting manner. Advantaged by highly sophisticated identity resolution and matching capabilities, HealthVerity is on a mission to increase transparency, forge interoperability and activate deeper insights.<br><br>HealthVerity is an equal opportunity employer.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Austin, Texas, United States",Striveworks,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-striveworks-2421463587?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=7tZzUa9HRlCmn3MB9l%2B1mA%3D%3D&position=11&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Looking for a Data Scientist to help customers unlock the mysteries hidden in data. Use your skills to further medical research, improve the delivery of care to fellow citizens, along with other use cases across our Federal Government clients. You will be working with large data sets combing structured and unstructured data to find new discoveries. Help build a data science team in a small and growing firm.



Essential Duties and Responsibilities:



Develop and apply the latest innovations in machine learning, artificial intelligence, and related technologies.
Lead and support research and development efforts to explore the applicability of emerging machine learning and artificial intelligence methods to address client challenges and identify and prioritize emerging methods and challenges for original research or proof of concepts.
Lead and support efforts to identify, shape, capture, and deliver data science, machine learning, and artificial intelligence contracts for clients.
Work with clients to build analytic strategies, technology roadmaps, implementation plans, and research initiatives
Help identify, recruit, lead, and develop a world-class team of data scientists, data engineers, machine learning engineers, and artificial intelligence specialists.

Minimum Qualifications



5+ years of experience with machine learning techniques (clustering, decision tree learning, artificial neural networks, Natural Language Processing,etc.) and algorithms for addressing a variety of problems
5+ years of experience with leading or managing delivery teams, projects, development efforts, research efforts, or similar
3+ years of experience with programming, including in machine learning frameworks (TensorFLow, PyTorch), python, Spark
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL
Experience with business development, client or customer relationship management, proposal development, or similar, including grant application
Experience with developing effective delivery or research teams, including recruiting, hiring, mentoring, coaching, and managing team members
Ability to effectively communicate results to both technical and non-technical audiences, including presenting to senior executives, industry conferences, technical seminars, meet-ups, or similar
BA or BS degree in Statistics, Machine Learning, Mathematics, CS, Computer Engineering, Industrial Engineering, or Operations Research
Ability to work in the US indefinitely without sponsorship
Ability to obtain a US security clearance if needed

Preferred Qualifications



MS degree in Science, Engineering, Mathematics, or related field preferred; PhD degree a plus
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Looking for a Data Scientist to help customers unlock the mysteries hidden in data. Use your skills to further medical research, improve the delivery of care to fellow citizens, along with other use cases across our Federal Government clients. You will be working with large data sets combing structured and unstructured data to find new discoveries. Help build a data science team in a small and growing firm.<br><br></p><p><span>Essential Duties and Responsibilities:<br><br></span></p><ul><li>Develop and apply the latest innovations in machine learning, artificial intelligence, and related technologies.</li><li>Lead and support research and development efforts to explore the applicability of emerging machine learning and artificial intelligence methods to address client challenges and identify and prioritize emerging methods and challenges for original research or proof of concepts.</li><li>Lead and support efforts to identify, shape, capture, and deliver data science, machine learning, and artificial intelligence contracts for clients.</li><li>Work with clients to build analytic strategies, technology roadmaps, implementation plans, and research initiatives</li><li>Help identify, recruit, lead, and develop a world-class team of data scientists, data engineers, machine learning engineers, and artificial intelligence specialists.</li></ul><p><span>Minimum Qualifications<br><br></span></p><ul><li>5+ years of experience with machine learning techniques (clustering, decision tree learning, artificial neural networks, Natural Language Processing,etc.) and algorithms for addressing a variety of problems</li><li>5+ years of experience with leading or managing delivery teams, projects, development efforts, research efforts, or similar</li><li>3+ years of experience with programming, including in machine learning frameworks (TensorFLow, PyTorch), python, Spark</li><li>Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL</li><li>Experience with business development, client or customer relationship management, proposal development, or similar, including grant application</li><li>Experience with developing effective delivery or research teams, including recruiting, hiring, mentoring, coaching, and managing team members</li><li>Ability to effectively communicate results to both technical and non-technical audiences, including presenting to senior executives, industry conferences, technical seminars, meet-ups, or similar</li><li>BA or BS degree in Statistics, Machine Learning, Mathematics, CS, Computer Engineering, Industrial Engineering, or Operations Research</li><li>Ability to work in the US indefinitely without sponsorship</li><li>Ability to obtain a US security clearance if needed</li></ul><p><span>Preferred Qualifications<br><br></span></p><ul><li>MS degree in Science, Engineering, Mathematics, or related field preferred; PhD degree a plus</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Computer Software
Data Engineer,"Denver, Colorado, United States",Kin + Carta,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-kin-%2B-carta-2387754765?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=XjlcF9AKVjsnsSkLaULDcw%3D%3D&position=12&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"As a Data Engineer at Striveworks, you'll be challenged on day one to have a definitional impact shaping and building solutions that directly affect the ""biggest headlines"" in the geopolitical realm. In this mission-critical work, you will be responsible for rapidly prototyping and delivering proofs-of-concept for customers. You'll be working alongside a team of data scientists to integrate their work into functional products. Examples include applied computer vision and the construction of data engineering pipelines.

In addition to the mission, this exciting opportunity will allow you to grow your software engineering skills in an operational and relevant setting. Striveworks encompasses a diverse book of business that includes some real blocking-and-tackling like data warehousing, all the way to applying some bleeding-edge research, such as Generative Adversarial Networks and novel research in reinforcement learning. Duties include data engineering, implementation of novel database architectures, data streaming, application CI/CD, and data architecture for our partners. Our work has briefed at the 4-Star and Congressional level. You'll have the opportunity to take the models and algorithms developed by data scientists and optimize, deploy, and refine them in a real-world setting immediately. The opportunity for personal and skills growth is unprecedented.

OUR VALUES

Perseverance: Our work has impact and saves lives. We take that trust seriously. If it was easy, it'd be done already. We will be relentless in achieving our goals, and we celebrate achievements.

Empowerment: We have a bias for action. We exercise our best judgement in pursuit of our shared goals. We manage ourselves as a whole person. We question actions that are not consistent with our values.

Commitment: We do what we say we are going to do. We excel at all things we commit to doing. When we mess up, miss a deadline, or under-deliver, we learn from those mistakes and support others in their learning as well.

Humility: There's no ""smartest person in the room"", we're a team. We listen with purpose, and work to make everyone around us better.

What We Value

2+ years relevant experience.
Expertise with Python and Java.
Knowledge of standard tooling: CI/CD tools, git, Docker, Kubernetes.
Knowledge of database design and architecture: relational and non-relational.
Comfortable with AWS or Google Cloud.
Comfortable with deep learning library (Tensorflow, Pytorch) implementation and integration.
Driven, self-directed personality.
Strong sense of mission and commitment to making a difference.
Ability to handle ITAR-controlled data.
Eligibility and willingness to obtain a US Secret Security Clearance.



Skills That Will Help In The Role

Active US Security Clearance.
Knowledge of data pipelines, especially Apache Spark/Kafka/Beam.
Knowledge of JavaScript.
Knowledge of lightweight front-end design, including Flask and Angular.



Physical Requirements

Ability to work in a stationary position in front of a computer for long periods of time.
Must be able to lift 15 pounds at times.



Striveworks is an Equal Opportunity Employer and does not discriminate in employment on the basis of race, color, religion or belief, sex (including pregnancy and gender identity or expression), national origin, social or ethnic origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor. Striveworks will not tolerate discrimination or harassment of any kind.

If you require assistance or a reasonable accommodation in the application process, please contact Operations at hr@striveworks.us

Striveworks is a participating employer in the E-Verify program.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">As a Data Engineer at Striveworks, you'll be challenged on day one to have a definitional impact shaping and building solutions that directly affect the ""biggest headlines"" in the geopolitical realm. In this mission-critical work, you will be responsible for rapidly prototyping and delivering proofs-of-concept for customers. You'll be working alongside a team of data scientists to integrate their work into functional products. Examples include applied computer vision and the construction of data engineering pipelines.<br><br>In addition to the mission, this exciting opportunity will allow you to grow your software engineering skills in an operational and relevant setting. Striveworks encompasses a diverse book of business that includes some real blocking-and-tackling like data warehousing, all the way to applying some bleeding-edge research, such as Generative Adversarial Networks and novel research in reinforcement learning. Duties include data engineering, implementation of novel database architectures, data streaming, application CI/CD, and data architecture for our partners. Our work has briefed at the 4-Star and Congressional level. You'll have the opportunity to take the models and algorithms developed by data scientists and optimize, deploy, and refine them in a real-world setting immediately. The opportunity for personal and skills growth is unprecedented.<br><br>OUR VALUES<br><br>Perseverance: Our work has impact and saves lives. We take that trust seriously. If it was easy, it'd be done already. We will be relentless in achieving our goals, and we celebrate achievements.<br><br>Empowerment: We have a bias for action. We exercise our best judgement in pursuit of our shared goals. We manage ourselves as a whole person. We question actions that are not consistent with our values.<br><br>Commitment: We do what we say we are going to do. We excel at all things we commit to doing. When we mess up, miss a deadline, or under-deliver, we learn from those mistakes and support others in their learning as well.<br><br>Humility: There's no ""smartest person in the room"", we're a team. We listen with purpose, and work to make everyone around us better.<br><br><strong><u>What We Value<br></u></strong><ul> <li>2+ years relevant experience.</li> <li>Expertise with Python and Java.</li> <li>Knowledge of standard tooling: CI/CD tools, git, Docker, Kubernetes.</li> <li>Knowledge of database design and architecture: relational and non-relational.</li> <li>Comfortable with AWS or Google Cloud.</li> <li>Comfortable with deep learning library (Tensorflow, Pytorch) implementation and integration.</li> <li>Driven, self-directed personality.</li> <li>Strong sense of mission and commitment to making a difference.</li> <li>Ability to handle ITAR-controlled data.</li> <li>Eligibility and willingness to obtain a US Secret Security Clearance.</li> <br><br></ul><strong><u>Skills That Will Help In The Role<br></u></strong><ul> <li>Active US Security Clearance.</li> <li>Knowledge of data pipelines, especially Apache Spark/Kafka/Beam.</li> <li>Knowledge of JavaScript.</li> <li>Knowledge of lightweight front-end design, including Flask and Angular.</li> <br><br></ul><strong><u>Physical Requirements<br></u></strong><ul> <li>Ability to work in a stationary position in front of a computer for long periods of time.</li> <li>Must be able to lift 15 pounds at times.</li> <br><br></ul><em>Striveworks is an Equal Opportunity Employer and does not discriminate in employment on the basis of race, color, religion or belief, sex (including pregnancy and gender identity or expression), national origin, social or ethnic origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor. Striveworks will not tolerate discrimination or harassment of any kind.<br><br></em><em>If you require assistance or a reasonable accommodation in the application process, please contact Operations at hr@striveworks.us<br><br></em><em>Striveworks is a participating employer in the E-Verify program.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Defense & Space, Computer Software"
Data Engineer,"Agoura Hills, California, United States",Visual Concepts,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-at-visual-concepts-2225609244?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=ccL5QJ%2F2OENXy34qs%2FRByQ%3D%3D&position=13&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Kin + Carta West, formerly Spire Digital, is seeking Data Engineers to join our growing data science practice. A recipient of several best-place-to-work awards, Kin + Carta offers an inclusive, fast-paced, exciting culture of passionate individuals working together to build awesome software and digital products.

If you are innovative, passionate about data and AI technologies, and look to continually learn and enjoy sharing expertise, read on!

What You Will Be Doing

Designing, Migrating, Building, and Testing large scale data processing architectures
Building enterprise applications on the cloud (Azure, Google Cloud, or AWS) and technologies such as BigQuery, Synapse Analytics, AutoML, Google Data Studio, PowerBI, or QuickSight
Improving data reliability, efficiency, and quality
Working with designers to help visualize data to provide insights to end-users
Performing ad-hoc analyses of data stored in the business’s SQL databases and writing scripts, stored procedures, functions, and views
Interfacing with our clients and providing technical recommendations
Evaluating emerging cross-platform frameworks and enterprise application platforms
Bridging between elegant front-end design and existing enterprise back end architectures
Collaborating with experienced data engineers, data scientists, and data architects to foster personal and team growth


We want all new hires to succeed in their roles at Kin + Carta. That's why we've outlined the job requirements below. To be considered for this role, it's important that you meet all Minimum Qualifications. If you do not meet all of the Preferred Qualifications, we still encourage you to apply.

Minimum Qualifications

Experience with Python
Experience with SQL and NoSQL databases such as Microsoft SQL, Postgres and Cassandra
Experience with data visualization and reporting tools like Looker, Tableau, or PowerBi
Experience with Azure, GCP, and/or AWS
Experience with designing data models and ETL
Experience with message queuing, stream processing, and highly scalable big data stores as well as tools like Storm and Spark Streaming
Experience with big data tools like BigQuery, Hadoop, Spark, Kafka, or Elasticsearch
Experience with data pipeline and workflow management tools



Preferred Qualifications

You have a strong passion for building innovative and intelligent solutions around data
Strong background in Java and/or .NET, knowledge with Kotlin and Scala is a huge plus
Familiar with Microservice design patterns including Serverless and BFF
Experience designing, building, integrating and testing with RESTful APIs
Experience in developing and implementing scripts for database maintenance, monitoring, and performance tuning to be applied across the business
Ability to effectively communicate technical topics to product owners, stakeholders and other business team members
Strong verbal and written communication
Experience working in an Agile Scrum development environment, or in a consulting capacity
Experience in Machine Learning
Certifications in Google (Professional Data Engineer) or Microsoft (Azure Data Engineer Associate, Azure AI Engineer Associate) are preferred



Salary Info

This is an hourly position (at least to start); the pay range for this position is $80-150/hr, DOE.
Applicants must be able to work in the United States.
This is a fully-remote position.



About Kin + Carta

Kin + Carta exists to make the world work better by delivering transformative digital growth for our clients. As a digital transformation firm, we apply creativity, data, and technology to help clients invent, market, and operate new digital products and services that turn prospects into customers, and customers into advocates. Kin + Carta seamlessly integrates the strategic consulting, software engineering, and marketing technology needed to help businesses 'Make It Happen'.

Consultants at Kin + Carta have the opportunity to: engage with the most cutting-edge emerging technologies, solve difficult problems for some of the world’s biggest companies, and work within a breadth of industries.

Kin + Carta is headquartered in Chicago and London with offices across four continents. Our culture and shared ways of working unite us globally, but it’s our diverse specialisms, our connections, and our courage that makes our firm a recognized best place to work.

We welcome our Kin to show up as their full selves every day. Because this is so important to us, Kin + Carta is proud to be an equal opportunity employer. If you need accommodations at any point in the application or interview process, please let us know.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Kin + Carta West, formerly Spire Digital, is seeking <strong>Data Engineers </strong>to join our growing data science practice. A recipient of several best-place-to-work awards, Kin + Carta offers an inclusive, fast-paced, exciting culture of passionate individuals working together to build awesome software and digital products.<br><br>If you are innovative, passionate about data and AI technologies, and look to continually learn and enjoy sharing expertise, read on!<br><br><strong><u>What You Will Be Doing<br></u></strong><ul> <li>Designing, Migrating, Building, and Testing large scale data processing architectures</li> <li>Building enterprise applications on the cloud (Azure, Google Cloud, or AWS) and technologies such as BigQuery, Synapse Analytics, AutoML, Google Data Studio, PowerBI, or QuickSight</li> <li>Improving data reliability, efficiency, and quality</li> <li>Working with designers to help visualize data to provide insights to end-users </li> <li>Performing ad-hoc analyses of data stored in the business’s SQL databases and writing scripts, stored procedures, functions, and views</li> <li>Interfacing with our clients and providing technical recommendations</li> <li>Evaluating emerging cross-platform frameworks and enterprise application platforms</li> <li>Bridging between elegant front-end design and existing enterprise back end architectures</li> <li>Collaborating with experienced data engineers, data scientists, and data architects to foster personal and team growth</li> <br></ul><strong>We want all new hires to succeed in their roles at Kin + Carta. That's why we've outlined the job requirements below. To be considered for this role, it's important that you meet all Minimum Qualifications. If you do not meet all of the Preferred Qualifications, we still encourage you to apply.<br><br></strong><strong><u>Minimum Qualifications<br></u></strong><ul> <li>Experience with Python</li> <li>Experience with SQL and NoSQL databases such as Microsoft SQL, Postgres and Cassandra</li> <li>Experience with data visualization and reporting tools like Looker, Tableau, or PowerBi</li> <li>Experience with Azure, GCP, and/or AWS</li> <li>Experience with designing data models and ETL</li> <li>Experience with message queuing, stream processing, and highly scalable big data stores as well as tools like Storm and Spark Streaming</li> <li>Experience with big data tools like BigQuery, Hadoop, Spark, Kafka, or Elasticsearch</li> <li>Experience with data pipeline and workflow management tools</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>You have a strong passion for building innovative and intelligent solutions around data </li> <li>Strong background in Java and/or .NET, knowledge with Kotlin and Scala is a huge plus</li> <li>Familiar with Microservice design patterns including Serverless and BFF</li> <li>Experience designing, building, integrating and testing with RESTful APIs</li> <li>Experience in developing and implementing scripts for database maintenance, monitoring, and performance tuning to be applied across the business</li> <li>Ability to effectively communicate technical topics to product owners, stakeholders and other business team members</li> <li>Strong verbal and written communication</li> <li>Experience working in an Agile Scrum development environment, or in a consulting capacity</li> <li>Experience in Machine Learning</li> <li>Certifications in Google (<em>Professional Data Engineer</em>) or Microsoft<em> (Azure Data Engineer Associate, Azure AI Engineer Associate)</em> are preferred</li> <br><br></ul><strong><u>Salary Info<br></u></strong><ul> <li>This is an hourly position (at least to start); the pay range for this position is $80-150/hr, DOE. </li> <li>Applicants must be able to work in the United States.</li> <li>This is a fully-remote position.</li> <br><br></ul><strong>About Kin + Carta<br><br></strong><strong>Kin + Carta</strong> exists to make the world work better by delivering transformative digital growth for our clients. As a digital transformation firm, we apply creativity, data, and technology to help clients invent, market, and operate new digital products and services that turn prospects into customers, and customers into advocates. Kin + Carta seamlessly integrates the strategic consulting, software engineering, and marketing technology needed to help businesses 'Make It Happen'.<br><br>Consultants at <strong>Kin + Carta</strong> have the opportunity to: engage with the most cutting-edge emerging technologies, solve difficult problems for some of the world’s biggest companies, and work within a breadth of industries.<br><br><strong>Kin + Carta </strong>is headquartered in Chicago and London with offices across four continents. Our culture and shared ways of working unite us globally, but it’s our diverse specialisms, our connections, and our courage that makes our firm a recognized best place to work.<br><br>We welcome our Kin to show up as their full selves every day. Because this is so important to us, Kin + Carta is proud to be an equal opportunity employer. If you need accommodations at any point in the application or interview process, please let us know.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Analytics Engineer,"Los Angeles, California, United States",PiñataFarms,2021-01-31,https://www.linkedin.com/jobs/view/analytics-engineer-at-pi%C3%B1atafarms-2389804453?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=Nto4I2wcoGb%2FLK6t%2FlO%2BLg%3D%3D&position=14&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Piñata Farms is a team of 25 who have been responsible for some of the biggest cultural and tech successes of the last 10 years, spanning mobile, social, video, AR, gaming and music. We are backed by the top Silicon Valley VC's and some of the most influential strategic investors in media, tech, and pop culture. We have been quietly building this company for over a year and recently launched with very promising early engagement metrics and strong buzz in the high school and college communities. Our app is a completely novel creative video platform and will be the next great cultural phenomenon -- in fact, you may have already seem some of our work racking up millions of views for Diplo, Marshmello, Kendrick Lamar’s team, Benny Blanco, Lil Dicky, the Jonas Bros…even getting even getting this comment from “🤣🤣🤣🤣🤣🤣” from LeBron.




Our mission is driven from behavioral research into how today’s connected communities work. From our insider’s view of digital media and social communities, we’ve helped establish new norms and know what’s coming next. More than half of our team is dedicated to developing novel and proprietary computer vision technologies that differentiates us from the same old commoditized and shallow video apps. We’ve brought the best technologists and best people in pop culture together - Piñata Farms will change the mobile video game forever.




Engineering Team

The Piñata Farms engineering team organizational structure is flat. We own our data ingestion/cleaning/filtering pipeline, the machine learning model training pipeline, the app client, and the backend. We believe strongly that keeping these core components in-house allows us to communicate better and build a more robust product.




Analytics Engineering

We are looking for a highly motivated Analytics Engineer to play a core role in defining plans for our Core Certified tables, as well as help implement best practices & pipelines that will allow us to scale as we grow as a company. You would be a critical part of the team as the product continues to grow. This will include work on multiple different systems & processes including but not limited to: core & derived table creation & maintenance via an ETL process, event instrumentation Q/A, dashboard creation & core metrics tracking, & in depth analysis when needed.




Skills

B.S. or higher in computer science, electrical engineering, mathematics, or similar related field and/or minimum 3 years of experience.

Experienced with:

Core & Derived Table Creation
Experience with ETL processes
Scaling & managing databases
Dashboard Creation
In Depth Analysis

Preferred Experience with:

Implementation of ETL jobs
SQL, Python, Tableau, Jupyter
DBT, AWS S3
Snowflake, Redshift, or similar DB
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Piñata Farms is a team of 25 who have been responsible for some of the biggest cultural and tech successes of the last 10 years, spanning mobile, social, video, AR, gaming and music. We are backed by the top Silicon Valley VC's and some of the most influential strategic investors in media, tech, and pop culture. We have been quietly building this company for over a year and recently launched with very promising early engagement metrics and strong buzz in the high school and college communities. Our app is a completely novel creative video platform and will be the next great cultural phenomenon -- in fact, you may have already seem some of our work racking up millions of views for Diplo, Marshmello, Kendrick Lamar’s team, Benny Blanco, Lil Dicky, the Jonas Bros…even getting even getting this comment from “🤣🤣🤣🤣🤣🤣” from LeBron.</p><p><br></p><p>Our mission is driven from behavioral research into how today’s connected communities work. From our insider’s view of digital media and social communities, we’ve helped establish new norms and know what’s coming next. More than half of our team is dedicated to developing novel and proprietary computer vision technologies that differentiates us from the same old commoditized and shallow video apps. We’ve brought the best technologists and best people in pop culture together - Piñata Farms will change the mobile video game forever.</p><p><br></p><p><strong>Engineering Team</strong></p><p>The Piñata Farms engineering team organizational structure is flat. We own our data ingestion/cleaning/filtering pipeline, the machine learning model training pipeline, the app client, and the backend. We believe strongly that keeping these core components in-house allows us to communicate better and build a more robust product.</p><p><br></p><p><strong>Analytics Engineering</strong></p><p>We are looking for a highly motivated Analytics Engineer to play a core role in defining plans for our Core Certified tables, as well as help implement best practices &amp; pipelines that will allow us to scale as we grow as a company. You would be a critical part of the team as the product continues to grow. This will include work on multiple different systems &amp; processes including but not limited to: core &amp; derived table creation &amp; maintenance via an ETL process, event instrumentation Q/A, dashboard creation &amp; core metrics tracking, &amp; in depth analysis when needed.</p><p><br></p><p><strong>Skills</strong></p><ul><li>B.S. or higher in computer science, electrical engineering, mathematics, or similar related field and/or minimum 3 years of experience.</li></ul><p>Experienced with:</p><ul><li>Core &amp; Derived Table Creation</li><li>Experience with ETL processes</li><li>Scaling &amp; managing databases</li><li>Dashboard Creation</li><li>In Depth Analysis</li></ul><p><em>Preferred</em> Experience with:</p><ul><li>Implementation of ETL jobs</li><li>SQL, Python, Tableau, Jupyter</li><li>DBT, AWS S3</li><li>Snowflake, Redshift, or similar DB</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Computer Software
Data Scientist - Remote,"Green Bay, Wisconsin, United States",Schneider,2021-02-03,https://www.linkedin.com/jobs/view/data-scientist-remote-at-schneider-2419795310?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=veKL5hHMHKqQ%2Fk3W15ymGw%3D%3D&position=15&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Piñata Farms is a team of 25 who have been responsible for some of the biggest cultural and tech successes of the last 10 years, spanning mobile, social, video, AR, gaming and music. We are backed by the top Silicon Valley VC's and some of the most influential strategic investors in media, tech, and pop culture. We have been quietly building this company for over a year and recently launched with very promising early engagement metrics and strong buzz in the high school and college communities. Our app is a completely novel creative video platform and will be the next great cultural phenomenon -- in fact, you may have already seem some of our work racking up millions of views for Diplo, Marshmello, Kendrick Lamar’s team, Benny Blanco, Lil Dicky, the Jonas Bros…even getting even getting this comment from “🤣🤣🤣🤣🤣🤣” from LeBron.




Our mission is driven from behavioral research into how today’s connected communities work. From our insider’s view of digital media and social communities, we’ve helped establish new norms and know what’s coming next. More than half of our team is dedicated to developing novel and proprietary computer vision technologies that differentiates us from the same old commoditized and shallow video apps. We’ve brought the best technologists and best people in pop culture together - Piñata Farms will change the mobile video game forever.




Engineering Team

The Piñata Farms engineering team organizational structure is flat. We own our data ingestion/cleaning/filtering pipeline, the machine learning model training pipeline, the app client, and the backend. We believe strongly that keeping these core components in-house allows us to communicate better and build a more robust product.




Analytics Engineering

We are looking for a highly motivated Analytics Engineer to play a core role in defining plans for our Core Certified tables, as well as help implement best practices & pipelines that will allow us to scale as we grow as a company. You would be a critical part of the team as the product continues to grow. This will include work on multiple different systems & processes including but not limited to: core & derived table creation & maintenance via an ETL process, event instrumentation Q/A, dashboard creation & core metrics tracking, & in depth analysis when needed.




Skills

B.S. or higher in computer science, electrical engineering, mathematics, or similar related field and/or minimum 3 years of experience.

Experienced with:

Core & Derived Table Creation
Experience with ETL processes
Scaling & managing databases
Dashboard Creation
In Depth Analysis

Preferred Experience with:

Implementation of ETL jobs
SQL, Python, Tableau, Jupyter
DBT, AWS S3
Snowflake, Redshift, or similar DB
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Piñata Farms is a team of 25 who have been responsible for some of the biggest cultural and tech successes of the last 10 years, spanning mobile, social, video, AR, gaming and music. We are backed by the top Silicon Valley VC's and some of the most influential strategic investors in media, tech, and pop culture. We have been quietly building this company for over a year and recently launched with very promising early engagement metrics and strong buzz in the high school and college communities. Our app is a completely novel creative video platform and will be the next great cultural phenomenon -- in fact, you may have already seem some of our work racking up millions of views for Diplo, Marshmello, Kendrick Lamar’s team, Benny Blanco, Lil Dicky, the Jonas Bros…even getting even getting this comment from “🤣🤣🤣🤣🤣🤣” from LeBron.</p><p><br></p><p>Our mission is driven from behavioral research into how today’s connected communities work. From our insider’s view of digital media and social communities, we’ve helped establish new norms and know what’s coming next. More than half of our team is dedicated to developing novel and proprietary computer vision technologies that differentiates us from the same old commoditized and shallow video apps. We’ve brought the best technologists and best people in pop culture together - Piñata Farms will change the mobile video game forever.</p><p><br></p><p><strong>Engineering Team</strong></p><p>The Piñata Farms engineering team organizational structure is flat. We own our data ingestion/cleaning/filtering pipeline, the machine learning model training pipeline, the app client, and the backend. We believe strongly that keeping these core components in-house allows us to communicate better and build a more robust product.</p><p><br></p><p><strong>Analytics Engineering</strong></p><p>We are looking for a highly motivated Analytics Engineer to play a core role in defining plans for our Core Certified tables, as well as help implement best practices &amp; pipelines that will allow us to scale as we grow as a company. You would be a critical part of the team as the product continues to grow. This will include work on multiple different systems &amp; processes including but not limited to: core &amp; derived table creation &amp; maintenance via an ETL process, event instrumentation Q/A, dashboard creation &amp; core metrics tracking, &amp; in depth analysis when needed.</p><p><br></p><p><strong>Skills</strong></p><ul><li>B.S. or higher in computer science, electrical engineering, mathematics, or similar related field and/or minimum 3 years of experience.</li></ul><p>Experienced with:</p><ul><li>Core &amp; Derived Table Creation</li><li>Experience with ETL processes</li><li>Scaling &amp; managing databases</li><li>Dashboard Creation</li><li>In Depth Analysis</li></ul><p><em>Preferred</em> Experience with:</p><ul><li>Implementation of ETL jobs</li><li>SQL, Python, Tableau, Jupyter</li><li>DBT, AWS S3</li><li>Snowflake, Redshift, or similar DB</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Computer Software
Data Scientist - Discovery,"San Mateo, California, United States",Roblox,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-discovery-at-roblox-2416482035?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=SiL6loL77sT00zVtdQ1nTA%3D%3D&position=16&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Location:
Green Bay, WI

Shift

First shift

Job ID

210156

Do you love being a part of developing business operations and practices, and applying specific methods, models, and analysis to create something amazing? We are looking for a Data Scientist to help design, build, and maintain next generation analytics solutions. The focus of this position is in developing practical solutions that help our customers meet their objectives. With a knowledge of statistics modeling, solution techniques and tools, you'll be able to grow your technical skills while working on impactful and challenging analytics problems. If this sounds exciting to you, review the information below and apply today.

About The Role

You will create proposals, statements of work, project logs and updates, and presentations in a clear and concise manner. Document project assumptions and approach track savings.
You will identify data sources and prepare data (merging data from different sources, cleansing, manipulation, etc.).
You will collaborate with Senior Data Scientists and engineers to decide on approach and design.
You will independently document and implement analytical models to deliver actionable business insights and decision support.
In this role you will prepare and deliver written non-technical reports and presentations to managers indicating solution or range of possible alternatives, solution pros and cons, and technical suggestions.


As an associate you will enjoy a strong work/life balance that includes paid vacation and holidays along with paid personal time off. You will also have access to medical, dental, and vision insurance and enjoy our company-paid life insurance and 401(k) savings with a company funded retirement plan. Schneider values individual development and offers a wide variety of opportunities through company-paid training and more than 170 personal development courses. What are you waiting for? You will love it here.

Our Ideal Candidate Will Have

A PhD Degree in Data Science, Statistics, Mathematics, Computer Science, or a related field, or Masters Degree plus two years of meaningful experience
The ability to understand the uses and limitations of statistical methodologies such as time-series forecasting, regression analysis, random forests, k-means clustering and Bayesian methods, machine learning, and the ability to select the appropriate methodology to complete assignments
The ability to learn and utilize statistical programming languages and tools such as R, SAS, Python SQL, SPSS, and Tableau
The ability to effectively communicate technical information and concepts to non-technical audiences
Company Overview:
Schneider is a premier provider of transportation and logistics services. Our legacy started in 1935 with one man, one truck and one dream. Since then, we’ve grown and evolved to become a nearly $5 billion company (2019 revenue) with one of the broadest portfolios of services in the industry delivering superior customer experiences.

The Schneider Way

We treat our customers, associates, shareholders and suppliers with integrity, dignity and respect.
We are a desirable employer due to our dedication to achieving mutually beneficial, lasting relationships.
We are a responsible member of the community.
Core Values:

Safety-first and always
Integrity in every action
Respect for all
Excellence in all that we do

Rise to the challenge and become a part of the Schneider family. Be the difference with a leader in an industry that impacts the world. Apply today at http://www.schneiderjobs.com.

Schneider is an equal opportunity employer.

Diversity, Equality and Inclusion at Schneider
Our history has taught us that treating everyone with dignity and respect is vital to our ongoing success. We embrace and seek out diversity that is inclusive of thought, race, ethnicity, gender, age, religion, sexual orientation, experience and background. We find that this diversity and openness ensures that all our associates have equal access to opportunities and resources to contribute fully to the organization’s success, and it fuels innovation, improves strategic thinking and cultivates leadership. Navigate to the following link
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Location:<br>Green Bay, WI<br><br><strong><u>Shift<br><br></u></strong>First shift<br><br><strong><u>Job ID<br><br></u></strong>210156<br><br>Do you love being a part of developing business operations and practices, and applying specific methods, models, and analysis to create something amazing? We are looking for a Data Scientist to help design, build, and maintain next generation analytics solutions. The focus of this position is in developing practical solutions that help our customers meet their objectives. With a knowledge of statistics modeling, solution techniques and tools, you'll be able to grow your technical skills while working on impactful and challenging analytics problems. If this sounds exciting to you, review the information below and apply today.<br><br><strong><u>About The Role<br></u></strong><ul> <li>You will create proposals, statements of work, project logs and updates, and presentations in a clear and concise manner. Document project assumptions and approach track savings. </li><li>You will identify data sources and prepare data (merging data from different sources, cleansing, manipulation, etc.). </li><li>You will collaborate with Senior Data Scientists and engineers to decide on approach and design. </li><li>You will independently document and implement analytical models to deliver actionable business insights and decision support. </li><li>In this role you will prepare and deliver written non-technical reports and presentations to managers indicating solution or range of possible alternatives, solution pros and cons, and technical suggestions. <br><br></li></ul>As an associate you will enjoy a strong work/life balance that includes paid vacation and holidays along with paid personal time off. You will also have access to medical, dental, and vision insurance and enjoy our company-paid life insurance and 401(k) savings with a company funded retirement plan. Schneider values individual development and offers a wide variety of opportunities through company-paid training and more than 170 personal development courses. What are you waiting for? You will love it here.<br><br><strong><u>Our Ideal Candidate Will Have<br></u></strong><ul> <li>A PhD Degree in Data Science, Statistics, Mathematics, Computer Science, or a related field, or Masters Degree plus two years of meaningful experience </li><li>The ability to understand the uses and limitations of statistical methodologies such as time-series forecasting, regression analysis, random forests, k-means clustering and Bayesian methods, machine learning, and the ability to select the appropriate methodology to complete assignments </li><li>The ability to learn and utilize statistical programming languages and tools such as R, SAS, Python SQL, SPSS, and Tableau </li><li>The ability to effectively communicate technical information and concepts to non-technical audiences </li></ul> <strong><strong> Company Overview: <br></strong></strong>Schneider is a premier provider of transportation and logistics services. Our legacy started in 1935 with one man, one truck and one dream. Since then, we’ve grown and evolved to become a nearly $5 billion company (2019 revenue) with one of the broadest portfolios of services in the industry delivering superior customer experiences.<br><br><strong><u>The Schneider Way<br></u></strong><ul> <li>We treat our customers, associates, shareholders and suppliers with integrity, dignity and respect. </li><li>We are a desirable employer due to our dedication to achieving mutually beneficial, lasting relationships. </li><li>We are a responsible member of the community. </li></ul> <strong><strong> Core Values: <br></strong></strong><ul> <li>Safety-first and always </li><li>Integrity in every action </li><li>Respect for all </li><li>Excellence in all that we do <br></li></ul>Rise to the challenge and become a part of the Schneider family. Be the difference with a leader in an industry that impacts the world. Apply today at http://www.schneiderjobs.com.<br><br><strong>Schneider is an equal opportunity employer. <br><br></strong><strong>Diversity, Equality and Inclusion at Schneider<br></strong>Our history has taught us that treating everyone with dignity and respect is vital to our ongoing success. We embrace and seek out diversity that is inclusive of thought, race, ethnicity, gender, age, religion, sexual orientation, experience and background. We find that this diversity and openness ensures that all our associates have equal access to opportunities and resources to contribute fully to the organization’s success, and it fuels innovation, improves strategic thinking and cultivates leadership. Navigate to the following link</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Insurance, Financial Services, Transportation/Trucking/Railroad"
Data Engineer,"Remote, Oregon, United States",Mitek Systems,2021-01-26,https://www.linkedin.com/jobs/view/data-engineer-at-mitek-systems-2420698676?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=v%2FcV2y53dvjgbCZoN%2BfFBg%3D%3D&position=17&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"WHY ROBLOX?

Roblox is ushering in the next generation of entertainment, allowing people to imagine, create, and play together in immersive, user-generated worlds. We’re the one and only fastest-growing entertainment platform that lets anyone teach themselves how to code, publish, and monetize any experience imaginable—across any device—reaching millions of players across the globe.

The impact that you can have at Roblox is powerful. We’re looking for someone who’s eager to take on a meaningful role in the success of Roblox on a massive scale. Someone who takes play seriously, but also isn’t afraid to have some fun either. Someone who’s ready to take Roblox—and their career—to the next level.

In 2021, we were honored to be recognized as a Certified Great Place to Work®. We’ve fostered a company culture that empowers people to do the most defining work of their career in an environment that’s made up of the most passionate, team-oriented, visionary, crazy-smart people you’ll ever meet. Join the Roblox team where play rules and the possibilities are endless.

WHY DATA SCIENCE & ANALYTICS?

The Data Science & Analytics organization’s mission is to increase our speed, frequency and acumen of making decisions at scale by instilling a data-influenced approach to building products. We cover a wide area of the data spectrum including analytical data engineering, product analytics, experimentation, causal inference, statistical modeling and machine learning. Aligned and partnering with product verticals, we use this extensive tool belt to discover new opportunities and unmet use cases, influence and shape the product roadmap and prioritization, build data products and measure impact on our community of players and developers.

WHY DISCOVERY?

As a Data Scientist on Discovery, you will be responsible for understanding the impact of personalization algorithms on our platform. You’ll partner with data scientists, product managers, engineers and leaders across the company to create a world-class recommendation system by performing analyses, creating dashboards, defining KPIs, applying models, and designing A/B experiments.

You Are

Passionate about data. You have the curiosity and self-drive to continuously learn new techniques and tools to extract value from data. You have a degree in Statistics, Economics, Computer Science or other relevant field.
A strong communicator. You understand that analysis must be presented in meaningful ways and engage in spirited discussions about the findings. You have the ability to explain technical concepts to non-technical audiences.
A capable statistician. You understand the value of characterizing data by its distribution. Covariance, Bias, and Conditional Probability are concepts that you rely on every day.
An expert transforming data with SQL and a scripting language such as Python or R. You’re experienced in automating efforts and crunching massive volumes of data using big data frameworks such as Spark, Hadoop or Flink.
Experienced in developing models to draw insights from data. You use regression techniques, data mining, and statistical techniques to create new, scalable solutions to solve difficult business problems. You understand when to apply the appropriate methodology to maximize impact in a pragmatic fashion.
Possess a deep knowledge of search and discovery. You have analyzed the business impact of ranking systems at companies that rely on e-commerce or content recommendations to drive engagement
Are familiar with recommendation systems, how they work and how various algorithms impact business performance



You Will

Accelerate product development through your understanding of the underlying data and your ability to partner with product and technical leaders to provide insights that drive growth.
Access raw data, and then transform it, analyze it, and render it in a compelling way--all using a custom analytics tool kit built from state-of-the-art open-source libraries.
Build dashboards to understand root causes to changes in metrics.
Evaluate A/B experiments to determine success of product feature launches.
Influence how Roblox interacts with its players and its platform developers



Basic Qualifications

4+ years of industry experience OR 2+ years of academic experience in addition to 2+ years of industry experience
1+ years of experience in statistical modeling and machine learning
1+ years working with Recommendation Systems
2+ years of experience using big data query/processing languages such as SQL, Hive or Spark to transform/manipulate very large datasets
2+ years of experience in one or more scripting languages such as Python or R
BA/BS in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field



Preferred Qualifications

MS or PhD in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field
2+ years of industry experience in analytics focused on improving content recommendations at a company with large-scale data
2+ years of experience in fast-paced environment or fast growing company, such as the tech sector
Demonstrated ability to lead or build a team from scratch as an individual contributor
Experience working with content platforms, particularly user-generated content
Ability to communicate analytics results and data storytelling to influence product teams and leaders
Creative thinker able to apply first-principles reasoning to solve complex problems


Roblox - Powering Imagination
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>WHY ROBLOX?<br><br></strong>Roblox is ushering in the next generation of entertainment, allowing people to imagine, create, and play together in immersive, user-generated worlds. We’re the one and only fastest-growing entertainment platform that lets anyone teach themselves how to code, publish, and monetize any experience imaginable—across any device—reaching millions of players across the globe.<br><br>The impact that you can have at Roblox is powerful. We’re looking for someone who’s eager to take on a meaningful role in the success of Roblox on a massive scale. Someone who takes play seriously, but also isn’t afraid to have some fun either. Someone who’s ready to take Roblox—and their career—to the next level.<br><br>In 2021, we were honored to be recognized as a Certified Great Place to Work®. We’ve fostered a company culture that empowers people to do the most defining work of their career in an environment that’s made up of the most passionate, team-oriented, visionary, crazy-smart people you’ll ever meet. Join the Roblox team where play rules and the possibilities are endless.<br><br><strong>WHY DATA SCIENCE &amp; ANALYTICS?<br><br></strong>The Data Science &amp; Analytics organization’s mission is to increase our speed, frequency and acumen of making decisions at scale by instilling a data-influenced approach to building products. We cover a wide area of the data spectrum including analytical data engineering, product analytics, experimentation, causal inference, statistical modeling and machine learning. Aligned and partnering with product verticals, we use this extensive tool belt to discover new opportunities and unmet use cases, influence and shape the product roadmap and prioritization, build data products and measure impact on our community of players and developers.<br><br><strong>WHY DISCOVERY?<br><br></strong>As a Data Scientist on Discovery, you will be responsible for understanding the impact of personalization algorithms on our platform. You’ll partner with data scientists, product managers, engineers and leaders across the company to create a world-class recommendation system by performing analyses, creating dashboards, defining KPIs, applying models, and designing A/B experiments.<br><br><strong><u>You Are<br></u></strong><ul> <li><strong>Passionate about data.</strong> You have the curiosity and self-drive to continuously learn new techniques and tools to extract value from data. You have a degree in Statistics, Economics, Computer Science or other relevant field.</li> <li><strong>A strong communicator. </strong>You understand that analysis must be presented in meaningful ways and engage in spirited discussions about the findings. You have the ability to explain technical concepts to non-technical audiences.</li> <li><strong>A capable statistician. </strong>You understand the value of characterizing data by its distribution. Covariance, Bias, and Conditional Probability are concepts that you rely on every day.</li> <li><strong>An expert transforming data</strong> with SQL and a scripting language such as Python or R. You’re experienced in automating efforts and crunching massive volumes of data using big data frameworks such as Spark, Hadoop or Flink.</li> <li><strong>Experienced in developing models</strong> to draw insights from data. You use regression techniques, data mining, and statistical techniques to create new, scalable solutions to solve difficult business problems. You understand when to apply the appropriate methodology to maximize impact in a pragmatic fashion.</li> <li><strong>Possess a deep knowledge</strong> of search and discovery. You have analyzed the business impact of ranking systems at companies that rely on e-commerce or content recommendations to drive engagement</li> <li><strong>Are familiar with recommendation systems, </strong>how they work and how various algorithms impact business performance </li> <br><br></ul><strong><u>You Will<br></u></strong><ul> <li>Accelerate product development through your understanding of the underlying data and your ability to partner with product and technical leaders to provide insights that drive growth.</li> <li>Access raw data, and then transform it, analyze it, and render it in a compelling way--all using a custom analytics tool kit built from state-of-the-art open-source libraries.</li> <li>Build dashboards to understand root causes to changes in metrics.</li> <li>Evaluate A/B experiments to determine success of product feature launches.</li> <li>Influence how Roblox interacts with its players and its platform developers</li> <br><br></ul><strong><u>Basic Qualifications<br></u></strong><ul> <li>4+ years of industry experience OR 2+ years of academic experience in addition to 2+ years of industry experience</li> <li>1+ years of experience in statistical modeling and machine learning</li> <li>1+ years working with Recommendation Systems</li> <li>2+ years of experience using big data query/processing languages such as SQL, Hive or Spark to transform/manipulate very large datasets</li> <li>2+ years of experience in one or more scripting languages such as Python or R</li> <li>BA/BS in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field</li> <br><br></ul><strong><u>Preferred Qualifications<br></u></strong><ul> <li>MS or PhD in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field</li> <li>2+ years of industry experience in analytics focused on improving content recommendations at a company with large-scale data</li> <li>2+ years of experience in fast-paced environment or fast growing company, such as the tech sector</li> <li>Demonstrated ability to lead or build a team from scratch as an individual contributor</li> <li>Experience working with content platforms, particularly user-generated content</li> <li>Ability to communicate analytics results and data storytelling to influence product teams and leaders</li> <li>Creative thinker able to apply first-principles reasoning to solve complex problems</li> <br></ul><strong>Roblox - Powering Imagination</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Seattle, Washington, United States",Twistle,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-at-twistle-2426049585?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=2wdz7PKiZZ%2F5SsDEPdBs%2FQ%3D%3D&position=18&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"We’re Mitek, a NASDAQ-listed global leader in mobile capture and digital identity verification solutions built on the latest advancements in AI and machine learning. Our Mobile Verify and Mobile Deposit products power and protect millions of identity evaluations and mobile deposits every day, around the world.

Mitek is committed to the health and safety of our employees and candidates during the current pandemic. Our global team of Mitekians are successfully and productively working full-time from home. Your experience with us - from introduction, to interview, to onboarding - will be a virtual one.





Mitek is seeking a Data Engineer to join our US Data Engineering team. As the analytic muscle behind our large scale, globally distributed Digital Identity Verification cloud platforms, our technology teams rely on us to deliver large quantities of structured, semi-structured and unstructured data that enable them to build new capabilities and derive insights that drive all aspects of our platform delivery. Our goal is to continually build and implement solutions that support the operationalization of data acquisition and pipelining.

As a Data Engineer at Mitek, you'll join us in continually building and implementing solutions that support the operationalization of data acquisition and pipelining. The data solutions you create will directly impact our machine learning capabilities and global document coverage. We're a big data environment, and you'll be building data sets, working with data sources and data pipelines, and potentially even owning our data modeling. You'll work directly with our internal leaders in our Engineering, Product, R&D, and Testing groups to support and ensure our teams can measure the performance and success of their efforts.

You'll need to have strong skills in Python development, as well as SQL. Experience in a big data environment like Hadoop is critical. And if you know some Golang, that'll be helpful too!

What You'll Do

Develop, test and maintain data processing pipelines that provide access to critical data and train machine learning models that are core to Mitek’s core product
Develop and maintain processes to ensure the quality, consistency and versioning of datasets used in the delivery of Mitek products
Leverage Tableau for the development of analysis, dashboarding and reporting solutions to monitor key measures associated with the performance of data management initiatives
Design data collection methods, evaluate large amounts of data, decompose high level information into details, abstract up from low-level information to a general understanding, analyze trends, and distinguish appropriate requirements
Provide additional support as necessary to create and modify datasets, label data, and manipulate data for product improvement or development purposes


What You Bring

Bachelor's degree in Mathematics, Statistics, Computer Science, or a related discipline
3+ years of experience in data engineering or software engineering
Experience using Python or Go/Golang to perform scripting/development, data management, and data manipulation
Experience working with datasets used in the delivery of machine learning-based solutions
Experience with distributed messaging and streaming technologies (RabbitMQ, Kinesis, Kafka)
Experience creating dashboards and effective data visualization
Training and experience in statistics, data manipulation, visualization, and analysis
Successful history of creating and providing documentation to convey information and drive decision making


What Would Be Nice

Knowledge of data mining, machine learning, natural language processing, or information retrieval
2-4 years of experience in a quantitative role
Experience using Tableau as a tool for the development of data analytics and decision support solutions
Experience deploying software to a cloud platform environment. AWS, GCP, Azure.
Exposure to Big Data platforms and technologies
Exposure to SQL and NoSQL databases and document stores such as MySQL, Aurora, RedShift, MongoDB, RavenDB etc.
Experience processing large amounts of structured and unstructured data
Prior experience in secure practices of handling sensitive data and PII
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We’re Mitek, a NASDAQ-listed global leader in mobile capture and digital identity verification solutions built on the latest advancements in AI and machine learning. Our Mobile Verify and Mobile Deposit products power and protect millions of identity evaluations and mobile deposits every day, around the world.<br><br>Mitek is committed to the health and safety of our employees and candidates during the current pandemic. Our global team of Mitekians are successfully and productively working full-time from home. Your experience with us - from introduction, to interview, to onboarding - will be a virtual one.<br><br><li><br><br></li>Mitek is seeking a Data Engineer to join our US Data Engineering team. As the analytic muscle behind our large scale, globally distributed Digital Identity Verification cloud platforms, our technology teams rely on us to deliver large quantities of structured, semi-structured and unstructured data that enable them to build new capabilities and derive insights that drive all aspects of our platform delivery. Our goal is to continually build and implement solutions that support the operationalization of data acquisition and pipelining.<br><br>As a Data Engineer at Mitek, you'll join us in continually building and implementing solutions that support the operationalization of data acquisition and pipelining. The data solutions you create will directly impact our machine learning capabilities and global document coverage. We're a big data environment, and you'll be building data sets, working with data sources and data pipelines, and potentially even owning our data modeling. You'll work directly with our internal leaders in our Engineering, Product, R&amp;D, and Testing groups to support and ensure our teams can measure the performance and success of their efforts.<br><br>You'll need to have strong skills in Python development, as well as SQL. Experience in a big data environment like Hadoop is critical. And if you know some Golang, that'll be helpful too!<br><br><strong> What You'll Do <br></strong><ul><li>Develop, test and maintain data processing pipelines that provide access to critical data and train machine learning models that are core to Mitek’s core product </li><li>Develop and maintain processes to ensure the quality, consistency and versioning of datasets used in the delivery of Mitek products </li><li>Leverage Tableau for the development of analysis, dashboarding and reporting solutions to monitor key measures associated with the performance of data management initiatives </li><li>Design data collection methods, evaluate large amounts of data, decompose high level information into details, abstract up from low-level information to a general understanding, analyze trends, and distinguish appropriate requirements </li><li>Provide additional support as necessary to create and modify datasets, label data, and manipulate data for product improvement or development purposes <br><br></li></ul><strong> What You Bring <br></strong><ul><li>Bachelor's degree in Mathematics, Statistics, Computer Science, or a related discipline</li><li>3+ years of experience in data engineering or software engineering </li><li>Experience using Python or Go/Golang to perform scripting/development, data management, and data manipulation</li><li>Experience working with datasets used in the delivery of machine learning-based solutions</li><li>Experience with distributed messaging and streaming technologies (RabbitMQ, Kinesis, Kafka)</li><li>Experience creating dashboards and effective data visualization</li><li>Training and experience in statistics, data manipulation, visualization, and analysis</li><li>Successful history of creating and providing documentation to convey information and drive decision making<br><br></li></ul><strong> What Would Be Nice <br></strong><ul><li>Knowledge of data mining, machine learning, natural language processing, or information retrieval </li><li>2-4 years of experience in a quantitative role </li><li>Experience using Tableau as a tool for the development of data analytics and decision support solutions </li><li>Experience deploying software to a cloud platform environment. AWS, GCP, Azure. </li><li>Exposure to Big Data platforms and technologies </li><li>Exposure to SQL and NoSQL databases and document stores such as MySQL, Aurora, RedShift, MongoDB, RavenDB etc. </li><li>Experience processing large amounts of structured and unstructured data </li><li>Prior experience in secure practices of handling sensitive data and PII</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Big Data Engineer,"Detroit, Michigan, United States",Quicken Loans,2021-02-07,https://www.linkedin.com/jobs/view/big-data-engineer-at-quicken-loans-1978544889?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=pLT9xoudlOyXpnAmrVxF4Q%3D%3D&position=19&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Are you a motivated self-starter with a proven track record of delivering high-quality projects on time? We're looking for an experienced mid-to-senior level data engineer to join our team and work on a rapidly growing healthcare platform that is proven to change lives.

The Data Engineer will be an integral part of our growing engineering team. He or she will bring expertise with a strong background in data integrations and ETL processes to a growing and innovative healthcare organization, while building, managing, and maintaining data integration projects across a wide variety of information systems and EHRs.

This role requires strong knowledge and expertise in building and validating healthcare data, while maintaining the analytical infrastructure and development of architectures that enables functionality and reporting between large scale processing systems and databases (e.g., EHRs, CRMs, Practice Management Systems, Data Warehouses)

Responsibilities

Identify, design, and implement process improvements related to (data mapping, optimizing data delivery, and scalability of transformations while automating manual processes.
Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies.
Build analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition.
Maintain both test and production library of interfaces, applying appropriate methods, procedures, and safeguards to protect the integrity of interfaces, ensuring their recoverability.
Demonstrate experience working with various payloads including (JSON, XML APIs, Web Services, ETL, and File Transfers
Monitor, triage, and modify configuration for integrated healthcare messaging within Twistle Platform.
Automate and monitor business critical applications and troubleshoot or escalate appropriately when issues arise.
Participate in code reviews with languages like LookerML, Python, Django, JavaScript
Collaborate with other engineers, implementation, customer success managers throughout the development process to release functional, performant and secure data on a regular basis.
Qualifications

BS/MS degree in Computer Science, Engineering, and/or related Healthcare experience.
5+ years’ experience in healthcare integrations, with at least 2+ years in Cloud applications.
3 years of experience in working in multi-tenant SaaS applications and services.
Experience working in an Agile/Scrum development process.
Strong experience demonstrating and understanding tools like Kafka, Spark and Hadoop; relational NoSQL and SQL databases including Cassandra and PostgreSQL.
Strong working knowledge of AWS services including Redshift, RDS, EMR and EC2.
Strong knowledge of and experience with reporting software such as Looker, BusinessObjects, Power BI, Tableau, etc.
Strong working knowledge of tools like JIRA, Asana, Confluence, and Tettra.
Hands on experience with SQL, developing stored procedures, functions, views and triggers, while validating and analyzing data integrity.
Familiarity with one or more of the following development languages: Python, C#, Java.
Twistle is a high-growth startup made up of self-starters obsessed with improving health care. Our vision is to make sure every patient feels connected, supported and reassured through their care journey. Our diverse and committed team is proud to partner with leading healthcare and life sciences organizations across the country who are dedicated to improving their patient’s lives and providing tools to better support their teams. It’s an exciting time to join us and have a huge impact on our growth and mission. Twistle’s patient communications platform is deployed at over 200 hospitals, including some of the largest delivery networks in the United States.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Are you a motivated self-starter with a proven track record of delivering high-quality projects on time? We're looking for an experienced mid-to-senior level data engineer to join our team and work on a rapidly growing healthcare platform that is proven to change lives.<br><br>The Data Engineer will be an integral part of our growing engineering team. He or she will bring expertise with a strong background in data integrations and ETL processes to a growing and innovative healthcare organization, while building, managing, and maintaining data integration projects across a wide variety of information systems and EHRs.<br><br>This role requires strong knowledge and expertise in building and validating healthcare data, while maintaining the analytical infrastructure and development of architectures that enables functionality and reporting between large scale processing systems and databases (e.g., EHRs, CRMs, Practice Management Systems, Data Warehouses)<br><br><strong> Responsibilities <br></strong><ul><li>Identify, design, and implement process improvements related to (data mapping, optimizing data delivery, and scalability of transformations while automating manual processes.</li></ul><ul><li>Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies.</li></ul><ul><li>Build analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition.</li></ul><ul><li>Maintain both test and production library of interfaces, applying appropriate methods, procedures, and safeguards to protect the integrity of interfaces, ensuring their recoverability.</li></ul><ul><li>Demonstrate experience working with various payloads including (JSON, XML APIs, Web Services, ETL, and File Transfers</li></ul><ul><li>Monitor, triage, and modify configuration for integrated healthcare messaging within Twistle Platform.</li></ul><ul><li>Automate and monitor business critical applications and troubleshoot or escalate appropriately when issues arise.</li><li>Participate in code reviews with languages like LookerML, Python, Django, JavaScript</li><li>Collaborate with other engineers, implementation, customer success managers throughout the development process to release functional, performant and secure data on a regular basis.</li></ul>Qualifications<br><ul><li>BS/MS degree in Computer Science, Engineering, and/or related Healthcare experience.</li></ul><ul><li>5+ years’ experience in healthcare integrations, with at least 2+ years in Cloud applications.</li></ul><ul><li>3 years of experience in working in multi-tenant SaaS applications and services.</li><li>Experience working in an Agile/Scrum development process.</li></ul><ul><li>Strong experience demonstrating and understanding tools like Kafka, Spark and Hadoop; relational NoSQL and SQL databases including Cassandra and PostgreSQL. </li></ul><ul><li>Strong working knowledge of AWS services including Redshift, RDS, EMR and EC2.</li></ul><ul><li>Strong knowledge of and experience with reporting software such as Looker, BusinessObjects, Power BI, Tableau, etc.</li></ul><ul><li>Strong working knowledge of tools like JIRA, Asana, Confluence, and Tettra.</li></ul><ul><li>Hands on experience with SQL, developing stored procedures, functions, views and triggers, while validating and analyzing data integrity. </li></ul><ul><li>Familiarity with one or more of the following development languages: Python, C#, Java.</li></ul>Twistle is a high-growth startup made up of self-starters obsessed with improving health care. Our vision is to make sure every patient feels connected, supported and reassured through their care journey. Our diverse and committed team is proud to partner with leading healthcare and life sciences organizations across the country who are dedicated to improving their patient’s lives and providing tools to better support their teams. It’s an exciting time to join us and have a huge impact on our growth and mission. Twistle’s patient communications platform is deployed at over 200 hospitals, including some of the largest delivery networks in the United States.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
"Data Scientist, Analytics, Intern","Remote, Oregon, United States",Facebook,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-analytics-intern-at-facebook-2413413703?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=YWrh65hlrzRMUPZhTrqkJg%3D%3D&position=20&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"The Big Data Engineer is responsible for engaging in the design, development and maintenance of the big data platform and solutions at Quicken Loans. This includes the platform host data sets that support various business operations and enable data-driven decisions as well as the analytical solutions that provide visibility and decision support using big data technologies. The Big Data Engineer is responsible for administering a Hadoop cluster, developing data integration solutions, resolving technical issues, and working with Data Scientists, Business Analysts, System Administrators and Data Architects to ensure the platform meets business demands. This team member also ensures that solutions are scalable, include necessary monitoring, and adhere to best practices and guidelines. The Big Data Engineer helps mentor new team members and continues to grow their knowledge of new technologies.

Responsibilities

Develop ELT processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiency
Develop data processing scripts using Spark
Develop relational and NoSQL data models to help conform data to meet users’ needs using Hive and HBase
Integrate platform into the existing enterprise data warehouse and various operational systems
Develop administration processes to monitor cluster performance, resource usage, backup and mirroring to ensure a highly available platform
Address performance and scalability issues in a large-scale data lake environment
Provide big data platform support and issue resolutions to Data Scientists and fellow engineers


Requirements

Master's degree in computer science, software engineering or a closely related field
2 years of experience with Hadoop distribution and ecosystem tools such as Hive, Spark, NiFi and Oozie
2 years of experience developing batch and streaming ETL processes
2 years of experience with relational and NoSQL databases, including modeling and writing complex queries
Proficiency in at least one programming language, such as Python or Java
Experience with Linux system administration, scripting and basic network skills
Excellent communication, analytical and problem-solving skills


Who We Are

We’re America’s largest mortgage lender, closing loans in all 50 states. J.D. Power ranked Quicken Loans “Highest in Customer Satisfaction in Primary Mortgage Origination” for the past nine consecutive years, 2010 – 2018. The company was also ranked highest in the nation for client satisfaction among mortgage servicers by J.D. Power for five consecutive years, 2014 through 2018, each year the company was eligible. There’s a simple reason we’ve been so successful: We care about the people we work with.

If you’re tired of stuffy, bureaucratic workplaces, then you’ll be delighted to find something different here. We strive to make a creative, fun and collaborative environment you simply won’t find anywhere else. Quicken Loans was named #1 in ESSENCE Magazine’s first ever list of “Best Places to Work for African Americans” in 2015. We've been on Computerworld's ""Best Places to Work in IT"" list for 13 years running, hitting #1 the last five years. We were also ranked #14 in FORTUNE Magazine’s list of ""100 Best Companies to Work For"" in 2018, remaining in the top-30 for the past 15 years.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The Big Data Engineer is responsible for engaging in the design, development and maintenance of the big data platform and solutions at Quicken Loans. This includes the platform host data sets that support various business operations and enable data-driven decisions as well as the analytical solutions that provide visibility and decision support using big data technologies. The Big Data Engineer is responsible for administering a Hadoop cluster, developing data integration solutions, resolving technical issues, and working with Data Scientists, Business Analysts, System Administrators and Data Architects to ensure the platform meets business demands. This team member also ensures that solutions are scalable, include necessary monitoring, and adhere to best practices and guidelines. The Big Data Engineer helps mentor new team members and continues to grow their knowledge of new technologies.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Develop ELT processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiency</li><li>Develop data processing scripts using Spark</li><li>Develop relational and NoSQL data models to help conform data to meet users’ needs using Hive and HBase</li><li>Integrate platform into the existing enterprise data warehouse and various operational systems</li><li>Develop administration processes to monitor cluster performance, resource usage, backup and mirroring to ensure a highly available platform</li><li>Address performance and scalability issues in a large-scale data lake environment</li><li>Provide big data platform support and issue resolutions to Data Scientists and fellow engineers<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>Master's degree in computer science, software engineering or a closely related field</li><li>2 years of experience with Hadoop distribution and ecosystem tools such as Hive, Spark, NiFi and Oozie</li><li>2 years of experience developing batch and streaming ETL processes</li><li>2 years of experience with relational and NoSQL databases, including modeling and writing complex queries</li><li>Proficiency in at least one programming language, such as Python or Java</li><li>Experience with Linux system administration, scripting and basic network skills</li><li>Excellent communication, analytical and problem-solving skills<br><br></li></ul><strong><u>Who We Are<br><br></u></strong>We’re America’s largest mortgage lender, closing loans in all 50 states. J.D. Power ranked Quicken Loans “Highest in Customer Satisfaction in Primary Mortgage Origination” for the past nine consecutive years, 2010 – 2018. The company was also ranked highest in the nation for client satisfaction among mortgage servicers by J.D. Power for five consecutive years, 2014 through 2018, each year the company was eligible. There’s a simple reason we’ve been so successful: We care about the people we work with.<br><br>If you’re tired of stuffy, bureaucratic workplaces, then you’ll be delighted to find something different here. We strive to make a creative, fun and collaborative environment you simply won’t find anywhere else. Quicken Loans was named #1 in ESSENCE Magazine’s first ever list of “Best Places to Work for African Americans” in 2015. We've been on Computerworld's ""Best Places to Work in IT"" list for 13 years running, hitting #1 the last five years. We were also ranked #14 in FORTUNE Magazine’s list of ""100 Best Companies to Work For"" in 2018, remaining in the top-30 for the past 15 years.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Other,Full-time,"Marketing and Advertising, Computer Software, Financial Services"
Data Scientist,"Plymouth, Minnesota, United States",Polaris Inc.,2021-02-12,https://www.linkedin.com/jobs/view/data-scientist-at-polaris-inc-2421423031?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=kFBRRbNNtWv5x6dMn92CcQ%3D%3D&position=21&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.

Are you passionate about Facebook’s product, analytics and technology? The Analytics team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Candidates will help own analytics for a particular product or business at Facebook and work with product managers and engineers to translate the analysis into meaningful impact to the business. Please note that candidates will have a general interview and then we will make a determination of actual team assignments.

Responsibilities

Perform large-scale data analysis to extract useful business insights
Identify actionable insights, suggest recommendations and influence the direction of the business by communicating results to cross-functional groups
Work closely with a Product Manager and Engineering team to proactively create rule and manage decisions
Classify leads so that the teams work on the most valuable cases
Suggest improvements in the tools and techniques to help scale the team

Minimum Qualification

Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Applied Mathematics, Statistics, Economics, or related technical field
Experience in solving analytical problems using quantitative approaches (or equivalent)
Experience with SQL or other programming languages (Python, Java, and/or C++)
Development experience in at least one scripting language (PHP, Perl, Python, etc.)
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment


Preferred Qualification

Intent to return to degree-program after the completion of the internship
Curious, self-driven, analytical and excited to play with data
Ability to thrive in a fast paced work environment

Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.<br><br>Are you passionate about Facebook’s product, analytics and technology? The Analytics team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Candidates will help own analytics for a particular product or business at Facebook and work with product managers and engineers to translate the analysis into meaningful impact to the business. Please note that candidates will have a general interview and then we will make a determination of actual team assignments.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Perform large-scale data analysis to extract useful business insights</li><li>Identify actionable insights, suggest recommendations and influence the direction of the business by communicating results to cross-functional groups</li><li>Work closely with a Product Manager and Engineering team to proactively create rule and manage decisions</li><li>Classify leads so that the teams work on the most valuable cases</li><li>Suggest improvements in the tools and techniques to help scale the team<br></li></ul><strong>Minimum Qualification<br></strong><ul><li>Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Applied Mathematics, Statistics, Economics, or related technical field</li><li>Experience in solving analytical problems using quantitative approaches (or equivalent)</li><li>Experience with SQL or other programming languages (Python, Java, and/or C++)</li><li>Development experience in at least one scripting language (PHP, Perl, Python, etc.)</li><li>Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment<br><br></li></ul><strong><u>Preferred Qualification<br></u></strong><ul><li>Intent to return to degree-program after the completion of the internship</li><li>Curious, self-driven, analytical and excited to play with data</li><li>Ability to thrive in a fast paced work environment<br></li></ul>Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Internship,"Engineering, Information Technology",Full-time,Internet
Data Engineer,"Yonkers, New York, United States",Consumer Reports,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-consumer-reports-2396524276?refId=8c3ce8c5-8025-4920-ad50-66bf9db925a6&trackingId=cB68djTEnP6XgwIOn0XhFQ%3D%3D&position=22&pageNum=8&trk=public_jobs_job-result-card_result-card_full-click,"At Polaris Inc., we have fun doing what we love by driving change and innovation. We empower employees to take on challenging assignments and roles with an elevated level of responsibility in our agile working environment. Our people make us who we are, and we create incredible products and experiences that empower us to Think Outside.

Position Summary

Polaris’s Data Science team works with business leaders across the enterprise to drive optimized strategy using data. The Data Scientist is responsible for creating recommendations for complex business decisions using predictive analytics. In addition to advanced analytics skills, this role is also proficient at integrating and preparing large, varied datasets, designing and implementing production algorithm scoring, and communicating results. Your focus will be on the front-end of the business, optimizing decisions related to customer acquisition and retention, retail inventory position, pricing and promotions, and multi-channel marketing, among others. You are primarily a data scientist but are passionate about developing advanced end-to-end analytics and technology solutions that drive value for our business.

Responsibilities

Develop analytical approaches to strategic business decisions
Extract, cleanse, and combine data from multiple sources and systems
Perform exploratory and targeted analyses, with a wide variety of statistical methods including: cluster, regression, decision tree/random forest, time series, neural network and others
Collaborate cross-functionally to arrive at actionable insights
Synthesize analytic results with business input to drive measurable change
Effectively communicate technical analyses and results to business management
Develop and continually improve multi-source data architecture and analytics procedures, systems, workflows
Contribute to the development of end-to-end data driven solutions
Integrate and productionalize model results into both cloud and edge compute hardware platforms


Qualifications

2+ years of work experience in a predictive analytics-focused role
Masters degree in Applied Statistics/Mathematics, Data or Computer Science, or work experience equivalent
Strong knowledge of statistical methods and predictive/analytical modeling techniques and practices
Experience with data preparation, rationalization, and processing in a cloud environment, Azure a plus
Highly proficient with one or more data mining/predictive modeling tools: SQL, R, Python
Highly proficient with one or more data visualization tools: Tableau, Power BI Practical understanding of mechanical systems and diverse hardware integration methods both a plus

We are an ambitious, resourceful, and driven workforce, which empowers us to Think Outside.Apply today!

About Polaris

As the global leader in Powersports, Polaris Inc. (NYSE: PII) pioneers product breakthroughs and enriching experiences and services that have invited people to discover the joy of being outdoors since our founding in 1954. With annual 2019 sales of $6.8 billion, Polaris’ high-quality product line-up includes the Polaris RANGER®, RZR® and Polaris GENERAL™ side-by-side off-road vehicles; Sportsman® all-terrain off-road vehicles; Indian Motorcycle® mid-size and heavyweight motorcycles; Slingshot® moto-roadsters; snowmobiles; and deck, cruiser and pontoon boats, including industry-leading Bennington pontoons. Polaris enhances the riding experience with parts, garments, and accessories, along with a growing aftermarket portfolio, including Transamerican Auto Parts. Polaris’ presence in adjacent markets includes military and commercial off-road vehicles, quadricycles, and electric vehicles. Proudly headquartered in Minnesota, Polaris serves more than 100 countries across the globe. www.polaris.com

EEO Statement

Polaris is an Equal Opportunity Employer and will make all employment-related decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, marital status, familial status, status with regard to public assistance, membership or activity in a local commission, protected veteran status, or any other status protected by applicable law.

EEO/AA/M/F/Vets/Disabled
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>At Polaris Inc., we have fun doing what we love by driving change and innovation. We empower employees to take on challenging assignments and roles with an elevated level of responsibility in our agile working environment. Our people make us who we are, and we create incredible products and experiences that empower us to Think Outside.<br><br></strong><strong><u>Position Summary<br><br></u></strong>Polaris’s Data Science team works with business leaders across the enterprise to drive optimized strategy using data. The Data Scientist is responsible for creating recommendations for complex business decisions using predictive analytics. In addition to advanced analytics skills, this role is also proficient at integrating and preparing large, varied datasets, designing and implementing production algorithm scoring, and communicating results. Your focus will be on the front-end of the business, optimizing decisions related to customer acquisition and retention, retail inventory position, pricing and promotions, and multi-channel marketing, among others. You are primarily a data scientist but are passionate about developing advanced end-to-end analytics and technology solutions that drive value for our business.<br><br><strong><u>Responsibilities<br></u></strong><ul><li>Develop analytical approaches to strategic business decisions</li><li>Extract, cleanse, and combine data from multiple sources and systems</li><li>Perform exploratory and targeted analyses, with a wide variety of statistical methods including: cluster, regression, decision tree/random forest, time series, neural network and others</li><li>Collaborate cross-functionally to arrive at actionable insights</li><li>Synthesize analytic results with business input to drive measurable change</li><li>Effectively communicate technical analyses and results to business management</li><li>Develop and continually improve multi-source data architecture and analytics procedures, systems, workflows</li><li>Contribute to the development of end-to-end data driven solutions</li><li>Integrate and productionalize model results into both cloud and edge compute hardware platforms<br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>2+ years of work experience in a predictive analytics-focused role</li><li>Masters degree in Applied Statistics/Mathematics, Data or Computer Science, or work experience equivalent</li><li>Strong knowledge of statistical methods and predictive/analytical modeling techniques and practices</li><li>Experience with data preparation, rationalization, and processing in a cloud environment, Azure a plus</li><li>Highly proficient with one or more data mining/predictive modeling tools: SQL, R, Python</li><li>Highly proficient with one or more data visualization tools: Tableau, Power BI Practical understanding of mechanical systems and diverse hardware integration methods both a plus<br></li></ul><em>We are an ambitious, resourceful, and driven workforce, which empowers us to Think Outside.Apply today!<br><br></em><strong><u>About Polaris<br><br></u></strong>As the global leader in Powersports, Polaris Inc. (NYSE: PII) pioneers product breakthroughs and enriching experiences and services that have invited people to discover the joy of being outdoors since our founding in 1954. With annual 2019 sales of $6.8 billion, Polaris’ high-quality product line-up includes the Polaris RANGER®, RZR® and Polaris GENERAL™ side-by-side off-road vehicles; Sportsman® all-terrain off-road vehicles; Indian Motorcycle® mid-size and heavyweight motorcycles; Slingshot® moto-roadsters; snowmobiles; and deck, cruiser and pontoon boats, including industry-leading Bennington pontoons. Polaris enhances the riding experience with parts, garments, and accessories, along with a growing aftermarket portfolio, including Transamerican Auto Parts. Polaris’ presence in adjacent markets includes military and commercial off-road vehicles, quadricycles, and electric vehicles. Proudly headquartered in Minnesota, Polaris serves more than 100 countries across the globe. www.polaris.com<br><br><strong>EEO Statement<br><br></strong>Polaris is an Equal Opportunity Employer and will make all employment-related decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, marital status, familial status, status with regard to public assistance, membership or activity in a local commission, protected veteran status, or any other status protected by applicable law.<br><br>EEO/AA/M/F/Vets/Disabled</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Automotive, Consumer Goods, Military"
Data Engineer,"New York, United States",OTC Markets Group,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-otc-markets-group-2416512237?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=Hk%2FazwCTyDLxSz7qIHTbFg%3D%3D&position=1&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"OTC Markets Group Inc., operator of premier US financial marketplaces, is seeking a passionate and dedicated Spark/Scala/Kafka Data Engineer with three to five years of experience to join our Cloud Data Reporting team based in our New York, NY office. Our team is responsible for building the next generation real-time applications which include but are not limited to internet and internal websites, real-time application tools and various internal processes. We utilize a home-grown Spark based platform to execute monitoring, surveillance analytics and data mining on the data sets. We are looking for a talented Data Engineer to work in the Data Reporting Team building and scaling the next generation data platform. As a member of the team you will work in an intimate, collaborative environment along with other Engineers to create systems that organize, analyze, and maintain the data for the firm. 




You will participate in the continuous advancement of the data infrastructure in our company and support the large data sets required to expand our product lines to provide the best (real-time) information possible. In addition, you will collaborate with a stellar engineering team to ensure our support process is more efficient, get projects done in a timely manner and work as a team to be an integral part in the success of the company. If you are up to the challenge and are comfortable multi-tasking while building relationships across the organization then this is an exciting and amazing opportunity a for you to be part of a team which will continue to embark on both new technologies and our cloud initiative. Our clients include domestic and international companies, both public and private.

 

OTC Markets Group’s newly redesigned headquarters foster an open and collaborative environment for employees and clients, utilizing more than 33,000 square feet of space. Our NY office is located in Brookfield Place, in the heart of the financial district, surrounded by Hudson River Park and home to luxury retail and dining establishments, featuring extensive public space and world-class amenities.  

 

Our Core Values are incorporated in each aspect of our Company. We encourage autonomy, professionally passionate discussions of opposing viewpoints, creativity and transparency. We are Open, Transparent, and Connected. We are OTC strong. At OTC Markets, we all win together.

 

We invest heavily in employee satisfaction and offer all our employees a highly competitive compensation package. As a dynamic, growing company that fosters an open culture, we emphasize autonomy, responsibility, innovation and self-discipline. We are looking for someone who wants to make an impressive impact at a company known for its reputation on quality and achievement.

 

The Data Engineer will be provided with the tools needed for success including a team of passionate individuals who are there to support your achievements and celebrate the wins!

 

Please note, due to COVID-19, OTC Markets is currently operating in a remote work environment with the voluntary option to work in-office a few days a week. This is a temporary adjustment to the start date work location with phase-in updates provided by the Human Resources team.




Our successful candidate will:

Code and test reliable and resilient real-time Spark Applications.
Learn our architecture and start to contribute immediately as we value and encourage brainstorming and input from everyone on the team.
Participate in all phases of the SDLC including but not limited to architecture, technical design and documentation, testing, implementation and product launch.
Write unit/integration tests as part of the development initiative providing great test coverage which will enable continuous delivery of code.
Implement readable, maintainable, and highly performant Scala/Python code.
Use many of the available AWS services to build applications.
Create and maintain technical documentation and architecture diagrams.
Support projects through their entire lifecycle from analysis to production rollout.
Plan and coordinate project schedules, goals, and milestones.
Collaborate with the business stake holders on the feature set specifications.
Collaborate with team members on the implementation and planning.

 

If you are excited to code in Scala/Python with Spark, Kafka and AWS services, deliver projects from start to finish, and most of all work in a fantastic work environment, then review the requirements below, and see if you are a good fit. We will provide any required training and mentoring to bring you to the next level. We are passionate and use the best of breed new technology. We are looking for engineers who are not afraid to ask questions and reach out to the internal teams and external message boards for help. You will write and own the microservices to support both the business lines and the technical implementation. As you grow in the company you will mentor new team members.

 

Requirements:

Data Engineering - 3-5 years’ experience with AWS, Scala, Spark, Kafka, S3, Python
Spark streaming and optimization
You have experience with continuous integration/deployment and Scala build tool.
Good Debugging Skills, excellent troubleshooting skills
Must be self-motivated and willing to learn. You love to stay on top of new technology and share with others.
Good knowledge of SQL. The ability to recognize when you require input from the DBA team.
Excellent verbal and written communication skills with employees both onsite and in remote locations.
Proven ability to work with individuals at all organization levels.
Ability to work on concurrent projects, when required.
Ability to develop a detailed project plan when working on a project.
Support production issues when required.
Experience in agile project development.
Must know how to use GIT.
Strong Linux knowledge.

 

Nice to haves:

You have experience with key AWS services, such as EC2, RDS (Postgres, Aurora), Lambda, Athena
Experience working with equity financial data (Quotes, Trades, Company Information)
You have worked with large data sets.
You have worked in the Financial Markets.

 

Please note, we will neither sponsor nor relocate for this position.

 

What OTC Markets offers its Team Members (why you should choose us):

·        Generous vacation policy in addition to 9 annual holidays observed and Summer Fridays.

·        Snacks and sodas and a very chic coffee bar.

·        Annual bonus and stock incentive program.

·        Office refreshments and company happy hours.

·        Monday Bagels and Friday Pizza.

·        Life and disability insurance, including paid parental leave.

·        Health insurance plans designed to meet the various coverage needs and preferences (Medical, Dental, Vision).

·        Flexible Spending Accounts for health, transit, parking and dependent care, as well as Healthcare Savings.

·        Accounts for qualifying plans.




Come as you are and just be you. We are an equal opportunity and e-verify employer and prohibit discrimination and harassment of any kind. All employment decisions are based on business needs, job requirements, and individual qualifications, without regard to race, creed, color, religion, gender, national origin, age, marital status, political belief, physical or mental disability, sexual orientation, military or veteran status, genetic information, family or parental status, gender identity, pregnancy, including childbirth or related medical condition, or any other characteristic protected by federal, state, or local law. We encourage applicants of all ages and backgrounds.




OTC Markets Group Inc. (OTCQX: OTCM) operates Open, Transparent and Connected financial markets for 10,000 U.S. and global securities. Through our OTC Link® ATS, we directly link a diverse network of broker-dealers that provide liquidity and execution services for a wide spectrum of securities. We organize these securities into markets to inform investors of opportunities and risks: the OTCQX® Best Market; the OTCQB® Venture Market; and the OTC Pink® Open Market. Our data-driven platform enables investors to easily trade through the broker of their choice at the best possible price and empowers a broad range of companies to improve the quality and availability of information for their investors. To learn more about how we create better informed and more efficient financial markets, visit www.otcmarkets.com.

OTC Link ATS is operated by OTC Link LLC, member FINRA/SIPC and SEC regulated ATS.

Applicants have rights under the federal law:

Equal Employment Opportunity is the Law

Polygraph Protection Act

FMLA

 

Please no calls or 3rd party recruiter submissions.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>OTC Markets Group Inc., operator of premier US financial marketplaces, is seeking a passionate and dedicated Spark/Scala/Kafka Data Engineer with three to five years of experience to join our Cloud Data Reporting team based in our New York, NY office. Our team is responsible for building the next generation real-time applications which include but are not limited to internet and internal websites, real-time application tools and various internal processes.&nbsp;We utilize a home-grown Spark based platform to execute monitoring, surveillance analytics and data mining on the data sets. We are looking for a talented Data Engineer to work in the Data Reporting Team building and scaling the next generation data platform. As a member of the team you will work in an intimate, collaborative environment along with other Engineers to create systems that organize, analyze, and maintain the data for the firm.&nbsp;</p><p><br></p><p>You will participate in the continuous advancement of the data infrastructure in our company and support the large data sets required to expand our product lines to provide the best (real-time) information possible. In addition, you will collaborate with a stellar engineering team to ensure our support process is more efficient, get projects done in a timely manner and work as a team to be an integral part in the success of the company.&nbsp;If you are up to the challenge and are comfortable multi-tasking while building relationships across the organization then this is an exciting and amazing opportunity a for you to be part of a team which will continue to embark on both new technologies and our cloud initiative. Our clients include domestic and international companies, both public and private. </p><p>&nbsp;</p><p>OTC Markets Group’s newly redesigned headquarters foster an open and collaborative environment for employees and clients, utilizing more than 33,000 square feet of space. Our NY office is located in Brookfield Place, in the heart of the financial district, surrounded by Hudson River Park and home to luxury retail and dining establishments, featuring extensive public space and world-class amenities.&nbsp;&nbsp;</p><p>&nbsp;</p><p>Our Core Values are incorporated in each aspect of our Company. We encourage autonomy, professionally passionate discussions of opposing viewpoints, creativity and transparency. We are <strong><u>O</u></strong>pen, <strong><u>T</u></strong>ransparent, and <strong><u>C</u></strong>onnected. We are OTC strong. At OTC Markets, we all win together. </p><p>&nbsp;</p><p>We invest heavily in employee satisfaction and offer all our employees a highly competitive compensation package. As a dynamic, growing company that fosters an open culture, we emphasize autonomy, responsibility, innovation and self-discipline. We are looking for someone who wants to make an impressive impact at a company known for its reputation on quality and achievement.</p><p>&nbsp;</p><p>The Data Engineer will be provided with the tools needed for success including a team of passionate individuals who are there to support your achievements and celebrate the wins!</p><p>&nbsp;</p><p><em><u>Please note, due to COVID-19, OTC Markets is currently operating in a remote work environment with the voluntary option to work in-office a few days a week. This is a temporary adjustment to the start date work location with phase-in updates provided by the Human Resources team. </u></em></p><p><br></p><p><strong>Our successful candidate will:</strong></p><ul><li>Code and test reliable and resilient real-time Spark Applications.</li><li>Learn our architecture and start to contribute immediately as we value and encourage brainstorming and input from everyone on the team.</li><li>Participate in all phases of the SDLC including but not limited to architecture, technical design and documentation, testing, implementation and product launch.</li><li>Write unit/integration tests as part of the development initiative providing great test coverage which will enable continuous delivery of code.</li><li>Implement readable, maintainable, and highly performant Scala/Python code.</li><li>Use many of the available AWS services to build applications.</li><li>Create and maintain technical documentation and architecture diagrams.</li><li>Support projects through their entire lifecycle from analysis to production rollout.</li><li>Plan and coordinate project schedules, goals, and milestones.</li><li>Collaborate with the business stake holders on the feature set specifications.</li><li>Collaborate with team members on the implementation and planning.</li></ul><p>&nbsp;</p><p>If you are excited to code in Scala/Python with Spark, Kafka and AWS services, deliver projects from start to finish, and most of all work in a fantastic work environment, then review the requirements below, and see if you are a good fit.&nbsp;We will provide any required training and mentoring to bring you to the next level.&nbsp;We are passionate and use the best of breed new technology.&nbsp;We are looking for engineers who are not afraid to ask questions and reach out to the internal teams and external message boards for help.&nbsp;You will write and own the microservices to support both the business lines and the technical implementation.&nbsp;As you grow in the company you will mentor new team members.</p><p>&nbsp;</p><p><strong>Requirements:</strong></p><ul><li>Data Engineering - 3-5 years’ experience with AWS, Scala, Spark, Kafka, S3, Python</li><li>Spark streaming and optimization</li><li>You have experience with continuous integration/deployment and Scala build tool.</li><li>Good Debugging Skills, excellent troubleshooting skills</li><li>Must be self-motivated and willing to learn.&nbsp;You love to stay on top of new technology and share with others.</li><li>Good knowledge of SQL.&nbsp;The ability to recognize when you require input from the DBA team.</li><li>Excellent verbal and written communication skills with employees both onsite and in remote locations.</li><li>Proven ability to work with individuals at all organization levels.</li><li>Ability to work on concurrent projects, when required.</li><li>Ability to develop a detailed project plan when working on a project.</li><li>Support production issues when required.</li><li>Experience in agile project development.</li><li>Must know how to use GIT.</li><li>Strong Linux knowledge.</li></ul><p>&nbsp;</p><p><strong>Nice to haves:</strong></p><ul><li>You have experience with key AWS services, such as EC2, RDS (Postgres, Aurora), Lambda, Athena</li><li>Experience working with equity financial data (Quotes, Trades, Company Information)</li><li>You have worked with large data sets.</li><li>You have worked in the Financial Markets.</li></ul><p>&nbsp;</p><p><strong><u>Please note, we will neither sponsor nor relocate for this position.</u></strong></p><p>&nbsp;</p><p><strong>What OTC Markets offers its Team Members (why you should choose us):</strong></p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generous vacation policy in addition to 9 annual holidays observed and Summer Fridays.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Snacks and sodas and a very chic coffee bar.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Annual bonus and stock incentive program.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Office refreshments and company happy hours.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Monday Bagels and Friday Pizza.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Life and disability insurance, including paid parental leave.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Health insurance plans designed to meet the various coverage needs and preferences (Medical, Dental, Vision).</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flexible Spending Accounts for health, transit, parking and dependent care, as well as Healthcare Savings.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accounts for qualifying plans.</p><p><br></p><p><u>Come as you are and just be you.</u> We are an equal opportunity and e-verify employer and prohibit discrimination and harassment of any kind.&nbsp;All employment decisions are based on business needs, job requirements, and individual qualifications, without regard to race, creed, color, religion, gender, national origin, age, marital status, political belief, physical or mental disability, sexual orientation, military or veteran status, genetic information, family or parental status, gender identity, pregnancy, including childbirth or related medical condition, or any other characteristic protected by federal, state, or local law. We encourage applicants of all ages and backgrounds.</p><p><br></p><p>OTC Markets Group Inc.&nbsp;(OTCQX: OTCM) operates Open, Transparent and Connected financial markets for 10,000 U.S. and global securities.&nbsp;Through our OTC Link® ATS, we directly link a diverse network of broker-dealers that provide liquidity and execution services for a wide spectrum of securities.&nbsp;We organize these securities into markets to inform investors of opportunities and risks: the OTCQX® Best Market; the OTCQB® Venture Market; and the OTC Pink® Open Market.&nbsp;Our data-driven platform enables investors to easily trade through the broker of their choice at the best possible price and empowers a broad range of companies to improve the quality and availability of information for their investors.&nbsp;To learn more about how we create better informed and more efficient financial markets, visit www.otcmarkets.com.</p><p>OTC Link ATS is operated by OTC Link LLC, member FINRA/SIPC and SEC regulated ATS.</p><p>Applicants have rights under the federal law:</p><p>Equal Employment Opportunity is the Law</p><p>Polygraph Protection Act</p><p>FMLA</p><p>&nbsp;</p><p><strong><u>Please no calls or 3rd party recruiter submissions.</u></strong></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Financial Services
Data Engineer II,"Seattle, Washington, United States",Expedia Group,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-ii-at-expedia-group-2369105908?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=uOOM%2F17g1i9WIyLyorkVNg%3D%3D&position=2&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"OTC Markets Group Inc., operator of premier US financial marketplaces, is seeking a passionate and dedicated Spark/Scala/Kafka Data Engineer with three to five years of experience to join our Cloud Data Reporting team based in our New York, NY office. Our team is responsible for building the next generation real-time applications which include but are not limited to internet and internal websites, real-time application tools and various internal processes. We utilize a home-grown Spark based platform to execute monitoring, surveillance analytics and data mining on the data sets. We are looking for a talented Data Engineer to work in the Data Reporting Team building and scaling the next generation data platform. As a member of the team you will work in an intimate, collaborative environment along with other Engineers to create systems that organize, analyze, and maintain the data for the firm. 




You will participate in the continuous advancement of the data infrastructure in our company and support the large data sets required to expand our product lines to provide the best (real-time) information possible. In addition, you will collaborate with a stellar engineering team to ensure our support process is more efficient, get projects done in a timely manner and work as a team to be an integral part in the success of the company. If you are up to the challenge and are comfortable multi-tasking while building relationships across the organization then this is an exciting and amazing opportunity a for you to be part of a team which will continue to embark on both new technologies and our cloud initiative. Our clients include domestic and international companies, both public and private.

 

OTC Markets Group’s newly redesigned headquarters foster an open and collaborative environment for employees and clients, utilizing more than 33,000 square feet of space. Our NY office is located in Brookfield Place, in the heart of the financial district, surrounded by Hudson River Park and home to luxury retail and dining establishments, featuring extensive public space and world-class amenities.  

 

Our Core Values are incorporated in each aspect of our Company. We encourage autonomy, professionally passionate discussions of opposing viewpoints, creativity and transparency. We are Open, Transparent, and Connected. We are OTC strong. At OTC Markets, we all win together.

 

We invest heavily in employee satisfaction and offer all our employees a highly competitive compensation package. As a dynamic, growing company that fosters an open culture, we emphasize autonomy, responsibility, innovation and self-discipline. We are looking for someone who wants to make an impressive impact at a company known for its reputation on quality and achievement.

 

The Data Engineer will be provided with the tools needed for success including a team of passionate individuals who are there to support your achievements and celebrate the wins!

 

Please note, due to COVID-19, OTC Markets is currently operating in a remote work environment with the voluntary option to work in-office a few days a week. This is a temporary adjustment to the start date work location with phase-in updates provided by the Human Resources team.




Our successful candidate will:

Code and test reliable and resilient real-time Spark Applications.
Learn our architecture and start to contribute immediately as we value and encourage brainstorming and input from everyone on the team.
Participate in all phases of the SDLC including but not limited to architecture, technical design and documentation, testing, implementation and product launch.
Write unit/integration tests as part of the development initiative providing great test coverage which will enable continuous delivery of code.
Implement readable, maintainable, and highly performant Scala/Python code.
Use many of the available AWS services to build applications.
Create and maintain technical documentation and architecture diagrams.
Support projects through their entire lifecycle from analysis to production rollout.
Plan and coordinate project schedules, goals, and milestones.
Collaborate with the business stake holders on the feature set specifications.
Collaborate with team members on the implementation and planning.

 

If you are excited to code in Scala/Python with Spark, Kafka and AWS services, deliver projects from start to finish, and most of all work in a fantastic work environment, then review the requirements below, and see if you are a good fit. We will provide any required training and mentoring to bring you to the next level. We are passionate and use the best of breed new technology. We are looking for engineers who are not afraid to ask questions and reach out to the internal teams and external message boards for help. You will write and own the microservices to support both the business lines and the technical implementation. As you grow in the company you will mentor new team members.

 

Requirements:

Data Engineering - 3-5 years’ experience with AWS, Scala, Spark, Kafka, S3, Python
Spark streaming and optimization
You have experience with continuous integration/deployment and Scala build tool.
Good Debugging Skills, excellent troubleshooting skills
Must be self-motivated and willing to learn. You love to stay on top of new technology and share with others.
Good knowledge of SQL. The ability to recognize when you require input from the DBA team.
Excellent verbal and written communication skills with employees both onsite and in remote locations.
Proven ability to work with individuals at all organization levels.
Ability to work on concurrent projects, when required.
Ability to develop a detailed project plan when working on a project.
Support production issues when required.
Experience in agile project development.
Must know how to use GIT.
Strong Linux knowledge.

 

Nice to haves:

You have experience with key AWS services, such as EC2, RDS (Postgres, Aurora), Lambda, Athena
Experience working with equity financial data (Quotes, Trades, Company Information)
You have worked with large data sets.
You have worked in the Financial Markets.

 

Please note, we will neither sponsor nor relocate for this position.

 

What OTC Markets offers its Team Members (why you should choose us):

·        Generous vacation policy in addition to 9 annual holidays observed and Summer Fridays.

·        Snacks and sodas and a very chic coffee bar.

·        Annual bonus and stock incentive program.

·        Office refreshments and company happy hours.

·        Monday Bagels and Friday Pizza.

·        Life and disability insurance, including paid parental leave.

·        Health insurance plans designed to meet the various coverage needs and preferences (Medical, Dental, Vision).

·        Flexible Spending Accounts for health, transit, parking and dependent care, as well as Healthcare Savings.

·        Accounts for qualifying plans.




Come as you are and just be you. We are an equal opportunity and e-verify employer and prohibit discrimination and harassment of any kind. All employment decisions are based on business needs, job requirements, and individual qualifications, without regard to race, creed, color, religion, gender, national origin, age, marital status, political belief, physical or mental disability, sexual orientation, military or veteran status, genetic information, family or parental status, gender identity, pregnancy, including childbirth or related medical condition, or any other characteristic protected by federal, state, or local law. We encourage applicants of all ages and backgrounds.




OTC Markets Group Inc. (OTCQX: OTCM) operates Open, Transparent and Connected financial markets for 10,000 U.S. and global securities. Through our OTC Link® ATS, we directly link a diverse network of broker-dealers that provide liquidity and execution services for a wide spectrum of securities. We organize these securities into markets to inform investors of opportunities and risks: the OTCQX® Best Market; the OTCQB® Venture Market; and the OTC Pink® Open Market. Our data-driven platform enables investors to easily trade through the broker of their choice at the best possible price and empowers a broad range of companies to improve the quality and availability of information for their investors. To learn more about how we create better informed and more efficient financial markets, visit www.otcmarkets.com.

OTC Link ATS is operated by OTC Link LLC, member FINRA/SIPC and SEC regulated ATS.

Applicants have rights under the federal law:

Equal Employment Opportunity is the Law

Polygraph Protection Act

FMLA

 

Please no calls or 3rd party recruiter submissions.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>OTC Markets Group Inc., operator of premier US financial marketplaces, is seeking a passionate and dedicated Spark/Scala/Kafka Data Engineer with three to five years of experience to join our Cloud Data Reporting team based in our New York, NY office. Our team is responsible for building the next generation real-time applications which include but are not limited to internet and internal websites, real-time application tools and various internal processes.&nbsp;We utilize a home-grown Spark based platform to execute monitoring, surveillance analytics and data mining on the data sets. We are looking for a talented Data Engineer to work in the Data Reporting Team building and scaling the next generation data platform. As a member of the team you will work in an intimate, collaborative environment along with other Engineers to create systems that organize, analyze, and maintain the data for the firm.&nbsp;</p><p><br></p><p>You will participate in the continuous advancement of the data infrastructure in our company and support the large data sets required to expand our product lines to provide the best (real-time) information possible. In addition, you will collaborate with a stellar engineering team to ensure our support process is more efficient, get projects done in a timely manner and work as a team to be an integral part in the success of the company.&nbsp;If you are up to the challenge and are comfortable multi-tasking while building relationships across the organization then this is an exciting and amazing opportunity a for you to be part of a team which will continue to embark on both new technologies and our cloud initiative. Our clients include domestic and international companies, both public and private. </p><p>&nbsp;</p><p>OTC Markets Group’s newly redesigned headquarters foster an open and collaborative environment for employees and clients, utilizing more than 33,000 square feet of space. Our NY office is located in Brookfield Place, in the heart of the financial district, surrounded by Hudson River Park and home to luxury retail and dining establishments, featuring extensive public space and world-class amenities.&nbsp;&nbsp;</p><p>&nbsp;</p><p>Our Core Values are incorporated in each aspect of our Company. We encourage autonomy, professionally passionate discussions of opposing viewpoints, creativity and transparency. We are <strong><u>O</u></strong>pen, <strong><u>T</u></strong>ransparent, and <strong><u>C</u></strong>onnected. We are OTC strong. At OTC Markets, we all win together. </p><p>&nbsp;</p><p>We invest heavily in employee satisfaction and offer all our employees a highly competitive compensation package. As a dynamic, growing company that fosters an open culture, we emphasize autonomy, responsibility, innovation and self-discipline. We are looking for someone who wants to make an impressive impact at a company known for its reputation on quality and achievement.</p><p>&nbsp;</p><p>The Data Engineer will be provided with the tools needed for success including a team of passionate individuals who are there to support your achievements and celebrate the wins!</p><p>&nbsp;</p><p><em><u>Please note, due to COVID-19, OTC Markets is currently operating in a remote work environment with the voluntary option to work in-office a few days a week. This is a temporary adjustment to the start date work location with phase-in updates provided by the Human Resources team. </u></em></p><p><br></p><p><strong>Our successful candidate will:</strong></p><ul><li>Code and test reliable and resilient real-time Spark Applications.</li><li>Learn our architecture and start to contribute immediately as we value and encourage brainstorming and input from everyone on the team.</li><li>Participate in all phases of the SDLC including but not limited to architecture, technical design and documentation, testing, implementation and product launch.</li><li>Write unit/integration tests as part of the development initiative providing great test coverage which will enable continuous delivery of code.</li><li>Implement readable, maintainable, and highly performant Scala/Python code.</li><li>Use many of the available AWS services to build applications.</li><li>Create and maintain technical documentation and architecture diagrams.</li><li>Support projects through their entire lifecycle from analysis to production rollout.</li><li>Plan and coordinate project schedules, goals, and milestones.</li><li>Collaborate with the business stake holders on the feature set specifications.</li><li>Collaborate with team members on the implementation and planning.</li></ul><p>&nbsp;</p><p>If you are excited to code in Scala/Python with Spark, Kafka and AWS services, deliver projects from start to finish, and most of all work in a fantastic work environment, then review the requirements below, and see if you are a good fit.&nbsp;We will provide any required training and mentoring to bring you to the next level.&nbsp;We are passionate and use the best of breed new technology.&nbsp;We are looking for engineers who are not afraid to ask questions and reach out to the internal teams and external message boards for help.&nbsp;You will write and own the microservices to support both the business lines and the technical implementation.&nbsp;As you grow in the company you will mentor new team members.</p><p>&nbsp;</p><p><strong>Requirements:</strong></p><ul><li>Data Engineering - 3-5 years’ experience with AWS, Scala, Spark, Kafka, S3, Python</li><li>Spark streaming and optimization</li><li>You have experience with continuous integration/deployment and Scala build tool.</li><li>Good Debugging Skills, excellent troubleshooting skills</li><li>Must be self-motivated and willing to learn.&nbsp;You love to stay on top of new technology and share with others.</li><li>Good knowledge of SQL.&nbsp;The ability to recognize when you require input from the DBA team.</li><li>Excellent verbal and written communication skills with employees both onsite and in remote locations.</li><li>Proven ability to work with individuals at all organization levels.</li><li>Ability to work on concurrent projects, when required.</li><li>Ability to develop a detailed project plan when working on a project.</li><li>Support production issues when required.</li><li>Experience in agile project development.</li><li>Must know how to use GIT.</li><li>Strong Linux knowledge.</li></ul><p>&nbsp;</p><p><strong>Nice to haves:</strong></p><ul><li>You have experience with key AWS services, such as EC2, RDS (Postgres, Aurora), Lambda, Athena</li><li>Experience working with equity financial data (Quotes, Trades, Company Information)</li><li>You have worked with large data sets.</li><li>You have worked in the Financial Markets.</li></ul><p>&nbsp;</p><p><strong><u>Please note, we will neither sponsor nor relocate for this position.</u></strong></p><p>&nbsp;</p><p><strong>What OTC Markets offers its Team Members (why you should choose us):</strong></p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generous vacation policy in addition to 9 annual holidays observed and Summer Fridays.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Snacks and sodas and a very chic coffee bar.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Annual bonus and stock incentive program.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Office refreshments and company happy hours.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Monday Bagels and Friday Pizza.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Life and disability insurance, including paid parental leave.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Health insurance plans designed to meet the various coverage needs and preferences (Medical, Dental, Vision).</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flexible Spending Accounts for health, transit, parking and dependent care, as well as Healthcare Savings.</p><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accounts for qualifying plans.</p><p><br></p><p><u>Come as you are and just be you.</u> We are an equal opportunity and e-verify employer and prohibit discrimination and harassment of any kind.&nbsp;All employment decisions are based on business needs, job requirements, and individual qualifications, without regard to race, creed, color, religion, gender, national origin, age, marital status, political belief, physical or mental disability, sexual orientation, military or veteran status, genetic information, family or parental status, gender identity, pregnancy, including childbirth or related medical condition, or any other characteristic protected by federal, state, or local law. We encourage applicants of all ages and backgrounds.</p><p><br></p><p>OTC Markets Group Inc.&nbsp;(OTCQX: OTCM) operates Open, Transparent and Connected financial markets for 10,000 U.S. and global securities.&nbsp;Through our OTC Link® ATS, we directly link a diverse network of broker-dealers that provide liquidity and execution services for a wide spectrum of securities.&nbsp;We organize these securities into markets to inform investors of opportunities and risks: the OTCQX® Best Market; the OTCQB® Venture Market; and the OTC Pink® Open Market.&nbsp;Our data-driven platform enables investors to easily trade through the broker of their choice at the best possible price and empowers a broad range of companies to improve the quality and availability of information for their investors.&nbsp;To learn more about how we create better informed and more efficient financial markets, visit www.otcmarkets.com.</p><p>OTC Link ATS is operated by OTC Link LLC, member FINRA/SIPC and SEC regulated ATS.</p><p>Applicants have rights under the federal law:</p><p>Equal Employment Opportunity is the Law</p><p>Polygraph Protection Act</p><p>FMLA</p><p>&nbsp;</p><p><strong><u>Please no calls or 3rd party recruiter submissions.</u></strong></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Financial Services
Data Engineer,"Richardson, Texas, United States",PeopleFun,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-at-peoplefun-2425511006?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=IblQzTp%2B9F4L7ztNHzxMeQ%3D%3D&position=3&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"The online travel market is a $2 trillion industry that never stands still. Expedia Global Payments team (EGP) provides and operates software solutions that enable payment processing between Expedia and its network of customers and partners. This includes payment methods that Expedia brands offer to customers around the world and the payment options that Expedia uses to support effective relationships with partners and suppliers. We process billions of dollars in customer and partner transactions every month.

Why build your career with the EGP group? We offer a chance to work with the brightest minds in the travel business in an energetic and international work environment focused on innovation, creative problem-solving and collaboration.

In this role you will a part of the Payments Business Intelligence team and play a significant role in advancing Expedia’s analytics capabilities. As an important part of the EGP division, the Payments Business Intelligence team is responsible for building and maintaining the EGP data warehouse as well as delivering analytic insights, reports and self-service tools to global stakeholders.

We are looking for a driven, dynamic individual with a proven track record of developing Big Data solutions. The ideal candidate will have a solid experience developing modern data solutions in Amazon Web Services and have a solid understanding of traditional data warehousing paradigms.

What You’ll Do

Gather, document, and analyze business requirements; produce development estimates
Design, develop, test and deploy data collection, flow and transformation components
Troubleshoot and support existing data workflow processes; deliver fixes and optimizations where appropriate
Drives consensus on design/delivery
Participates in identifying/solving problems at the program and group level
Partner with BI users, software engineers and operations specialists on data related investigations, research and issue management
Helps prioritize work for the team in the absence of a manager

Who You Are

Passion for improving business outcomes through Big Data and Analytics
Experience building data solutions with Amazon Web Services, such as S3, EMR, Redshift and RDS
Experience building AWS infrastructure preferred
Experience with Big Data Technologies (Hadoop, Hive, Spark, etc.)
Outstanding SQL scripting and ETL skills
Strong understanding of traditional Data Warehousing principles and architecture
Experience with scripting languages like Bash, PowerShell, or Python
*nix and/or Windows in an enterprise environment
Experience with report applications like Tableau, QlikSense, and QlikView a plus
Experience working in an Agile/SCRUM model
Excellent written and oral communication skills
Background in e-commerce or payment technologies is strongly preferred
Ability to work with a variety of stakeholders and effectively handle multiple tasks/deadlines with success
Bachelor's degree in a technology or a related discipline is preferred

Why join us

Expedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them to tools to do so.

Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.

If you have a hunger to make a difference with one of the most loved consumer brands in the world and to work in the dynamic travel industry, this is the job for you.

Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, HomeAway®, Orbitz®, Travelocity®, Wotif®, lastminute.com.au®, ebookers®, CheapTickets®, Hotwire®, Classic Vacations®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia® CruiseShipCenters®, SilverRail Technologies, Inc., ALICE and Traveldoo®.

Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The online travel market is a $2 trillion industry that never stands still. Expedia Global Payments team (EGP) provides and operates software solutions that enable payment processing between Expedia and its network of customers and partners. This includes payment methods that Expedia brands offer to customers around the world and the payment options that Expedia uses to support effective relationships with partners and suppliers. We process billions of dollars in customer and partner transactions every month.<br><br>Why build your career with the EGP group? We offer a chance to work with the brightest minds in the travel business in an energetic and international work environment focused on innovation, creative problem-solving and collaboration.<br><br>In this role you will a part of the Payments Business Intelligence team and play a significant role in advancing Expedia’s analytics capabilities. As an important part of the EGP division, the Payments Business Intelligence team is responsible for building and maintaining the EGP data warehouse as well as delivering analytic insights, reports and self-service tools to global stakeholders.<br><br>We are looking for a driven, dynamic individual with a proven track record of developing Big Data solutions. The ideal candidate will have a solid experience developing modern data solutions in Amazon Web Services and have a solid understanding of traditional data warehousing paradigms.<br><br><strong><u>What You’ll Do<br></u></strong><ul><li>Gather, document, and analyze business requirements; produce development estimates</li><li>Design, develop, test and deploy data collection, flow and transformation components</li><li>Troubleshoot and support existing data workflow processes; deliver fixes and optimizations where appropriate</li><li>Drives consensus on design/delivery</li><li>Participates in identifying/solving problems at the program and group level</li><li>Partner with BI users, software engineers and operations specialists on data related investigations, research and issue management</li><li>Helps prioritize work for the team in the absence of a manager<br></li></ul><strong><u>Who You Are<br></u></strong><ul><li>Passion for improving business outcomes through Big Data and Analytics</li><li>Experience building data solutions with Amazon Web Services, such as S3, EMR, Redshift and RDS</li><li>Experience building AWS infrastructure preferred</li><li>Experience with Big Data Technologies (Hadoop, Hive, Spark, etc.)</li><li>Outstanding SQL scripting and ETL skills</li><li>Strong understanding of traditional Data Warehousing principles and architecture</li><li>Experience with scripting languages like Bash, PowerShell, or Python</li><li>*nix and/or Windows in an enterprise environment</li><li>Experience with report applications like Tableau, QlikSense, and QlikView a plus</li><li>Experience working in an Agile/SCRUM model</li><li>Excellent written and oral communication skills</li><li>Background in e-commerce or payment technologies is strongly preferred</li><li>Ability to work with a variety of stakeholders and effectively handle multiple tasks/deadlines with success</li><li>Bachelor's degree in a technology or a related discipline is preferred<br></li></ul><strong>Why join us<br><br></strong>Expedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them to tools to do so.<br><br>Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.<br><br>If you have a hunger to make a difference with one of the most loved consumer brands in the world and to work in the dynamic travel industry, this is the job for you.<br><br>Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, HomeAway®, Orbitz®, Travelocity®, Wotif®, lastminute.com.au®, ebookers®, CheapTickets®, Hotwire®, Classic Vacations®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia® CruiseShipCenters®, SilverRail Technologies, Inc., ALICE and Traveldoo®.<br><br>Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Information Technology and Services, Leisure, Travel & Tourism"
Python Data Engineer,"Sunnyvale, California, United States","Amick Brown - Cloud Technologies, SAP and Business Intelligence Staffing & Consulting",2021-01-30,https://www.linkedin.com/jobs/view/python-data-engineer-at-amick-brown-cloud-technologies-sap-and-business-intelligence-staffing-consulting-2401331594?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=dEgaJKy7%2FvmjbVrg42hP9A%3D%3D&position=4&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"About PeopleFun

PeopleFun is a rapidly growing studio where development teams thrive on collaboration, creativity, teamwork and fun. Our mission is to create the best family-friendly casual games in mobile and have a great time doing it! Our current games are played by over 25 million players each month and include Wordscapes, the #1 word game.

PeopleFun is seeking a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Important To be considered, please provide a cover letter to explain, in your own words, your interest in this position and why you feel you'd be a great fit.

Responsibilities

Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and GCP ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.



Requirements

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Comfortable working within Bash terminal environment.
Applied experience with Python using libraries such as pandas, requests, various SQL connection stacks. Object oriented programming experience is a bonus.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.



Benefits

Competitive compensation package
Performance bonuses
401K with 3% employer matching
Family friendly culture
Flex PTO policy
Medical/Dental/Vision insurance
On-Site Gym and free Yoga classes
$1,000 annual game device and IAP budget
Free drinks & snacks, catered lunch on Fridays
Happy hours, social events and more



PeopleFun is an equal opportunity employer. All applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, ancestry, pregnancy, age, sexual orientation, gender identity, marital status, protected veteran status, medical condition or disability, or any other characteristic protected by law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About PeopleFun<br><br></u></strong>PeopleFun is a rapidly growing studio where development teams thrive on collaboration, creativity, teamwork and fun. Our mission is to create the best family-friendly casual games in mobile and have a great time doing it! Our current games are played by over 25 million players each month and include Wordscapes, the #1 word game.<br><br>PeopleFun is seeking a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.<br><br><em>Important To be considered, please provide a cover letter to explain, in your own words, your interest in this position and why you feel you'd be a great fit.<br><br></em><strong><u>Responsibilities<br></u></strong><ul> <li>Create and maintain optimal data pipeline architecture.</li> <li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li> <li>Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li> <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and GCP ‘big data’ technologies.</li> <li>Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.</li> <li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.</li> <li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li> <li>Work with data and analytics experts to strive for greater functionality in our data systems.</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li> <li>Comfortable working within Bash terminal environment.</li> <li>Applied experience with Python using libraries such as pandas, requests, various SQL connection stacks. Object oriented programming experience is a bonus.</li> <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li> <li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li> <li>Strong analytic skills related to working with unstructured datasets.</li> <li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li> <li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li> <li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li> <li>Strong project management and organizational skills.</li> <br><br></ul><u><strong>Benefits<br></strong></u><ul> <li>Competitive compensation package</li> <li>Performance bonuses</li> <li>401K with 3% employer matching</li> <li>Family friendly culture</li> <li>Flex PTO policy</li> <li>Medical/Dental/Vision insurance</li> <li>On-Site Gym and free Yoga classes</li> <li>$1,000 annual game device and IAP budget</li> <li>Free drinks &amp; snacks, catered lunch on Fridays</li> <li>Happy hours, social events and more</li> <br><br></ul>PeopleFun is an equal opportunity employer. All applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, ancestry, pregnancy, age, sexual orientation, gender identity, marital status, protected veteran status, medical condition or disability, or any other characteristic protected by law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Computer Games"
Data Engineer,"Smithfield, Virginia, United States",Smithfield Foods,2021-02-04,https://www.linkedin.com/jobs/view/data-engineer-at-smithfield-foods-2367450586?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=OaqQbtFb%2BGwWsixvGAnAAA%3D%3D&position=5&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Amick Brown is seeking an experienced Python Data Engineer for our direct client.

Location: Sunnyvale, CA 94086.
Duration: 6 Months with possible extension.

Description

Python Data Engineer Job Responsibilities:

Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.
Designs data integrations and data quality framework.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.



Minimum Qualifications

BS/BA in Technical Field, Computer Science or Mathematics.
Strong understanding of Data Structures & Algorithms
3+ years’ experience in the data warehouse space.
3+ years’ experience in custom ETL design, implementation and maintenance.
3+ years’ experience with schema design and dimensional data modeling.
3+ years of SQL experience (No-SQL experience is a plus)
2+ years’ experience in building visualizations
Ability to analyze data to identify deliverables, gaps and inconsistencies.
Communication skills including the ability to identify and communicate data driven insights.
Ability to document in details with data flow & architecture diagrams.



Expert

Preferred Qualifications:

3+ years’ experience using Python
Communication & Documentation



Intermediate

Plot.ly – Intermediate - Expert
d3.js – Intermediate- Expert
Django/Flask – Intermediate - Expert
SQL – Intermediate
ELK Stack


Amick Brown is an Information Technology consulting company specializing in ERP, Data Analytics, Information Security, Application Development, Networking, and Cloud Computing. The company was founded in 2010 and is headquartered in San Ramon, California.

Regular full-time employees are eligible for the following Amick Brown provided benefits:

Health
Vision
Dental
401k with company match
Paid time off
Sick Leave
Short-Term Disability
Life Insurance
Wellness & Discount Programs
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Amick Brown is seeking an experienced <strong>Python</strong> <strong>Data Engineer </strong>for our direct client.<br><br><strong>Location: Sunnyvale, CA 94086.<br>Duration: 6 Months with possible extension.<br><br></strong><strong><u>Description<br><br></u></strong>Python Data Engineer Job Responsibilities:<br><ul> <li>Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.</li> <li>Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.</li> <li>Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.</li> <li>Writes unit/integration tests, contributes to engineering wiki, and documents work.</li> <li>Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.</li> <li>Works closely with a team of frontend and backend engineers, product managers, and analysts.</li> <li>Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.</li> <li>Designs data integrations and data quality framework.</li> <li>Designs and evaluates open source and vendor tools for data lineage.</li> <li>Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.</li> <br><br></ul><strong><u>Minimum Qualifications<br></u></strong><ul> <li>BS/BA in Technical Field, Computer Science or Mathematics.</li> <li>Strong understanding of Data Structures &amp; Algorithms</li> <li>3+ years’ experience in the data warehouse space.</li> <li>3+ years’ experience in custom ETL design, implementation and maintenance.</li> <li>3+ years’ experience with schema design and dimensional data modeling.</li> <li>3+ years of SQL experience (No-SQL experience is a plus)</li> <li>2+ years’ experience in building visualizations</li> <li>Ability to analyze data to identify deliverables, gaps and inconsistencies.</li> <li>Communication skills including the ability to identify and communicate data driven insights.</li> <li>Ability to document in details with data flow &amp; architecture diagrams.</li> <br><br></ul><strong><u>Expert<br><br></u></strong><strong>Preferred Qualifications:<br></strong><ul> <li>3+ years’ experience using Python</li> <li>Communication &amp; Documentation</li> <br><br></ul><strong><u>Intermediate<br></u></strong><ul> <li>Plot.ly – Intermediate - Expert</li> <li>d3.js – Intermediate- Expert</li> <li>Django/Flask – Intermediate - Expert</li> <li>SQL – Intermediate</li> <li>ELK Stack</li> <br></ul>Amick Brown is an Information Technology consulting company specializing in ERP, Data Analytics, Information Security, Application Development, Networking, and Cloud Computing. The company was founded in 2010 and is headquartered in San Ramon, California.<br><br>Regular full-time employees are eligible for the following Amick Brown provided benefits:<br><ul> <li>Health</li> <li>Vision</li> <li>Dental</li> <li>401k with company match</li> <li>Paid time off</li> <li>Sick Leave</li> <li>Short-Term Disability</li> <li>Life Insurance</li> <li>Wellness &amp; Discount Programs</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Associate Data Scientist,"Austin, Texas, United States",Edelman Data & Intelligence (DxI),2021-02-06,https://www.linkedin.com/jobs/view/associate-data-scientist-at-edelman-data-intelligence-dxi-2392701301?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=v%2Bkh59svAIpNIKUgwrMtTw%3D%3D&position=6&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Job Locations

US-VA-Smithfield

Your Opportunity

Headquartered in Smithfield, Va., since 1936, Smithfield Foods, Inc. is an American food company with agricultural roots and a global reach. Our 40,000 U.S. employees are dedicated to producing ""Good food. Responsibly.®"" and have made us one of the world's leading vertically integrated protein companies. We have pioneered sustainability standards for more than two decades, including many industry firsts, such as our ambitious commitment to cut our carbon impact by 25 percent by 2025. We believe in the power of protein to end food insecurity and have donated hundreds of millions of food servings to our neighbors in need. Smithfield boasts a portfolio of high-quality iconic brands, such as Smithfield ® , Eckrich ® , and Nathan's Famous ® , among many others. For more information, visit www.smithfieldfoods.com , and connect with us on Facebook , Twitter , LinkedIn , and Instagram .

As a Data Engineer in the Finance Data Analytics department at Smithfield Foods you will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. You will be responsible for supporting the data pipeline needs of the Finance Data Analytics team, ensuring data is delivered accurately and automated. You will work to support the Data Analytics team as they work on projects from various functional areas of the business. You will implement process improvements to streamline the efficiency and accuracy of the reporting process. You will build data pipelines to support the delivery of daily/weekly/monthly reports. You will also be involved in ad hoc analysis of large datasets to quickly provide insight into the business.

Core Responsibilities

Create and maintain optimal data pipeline architecture
Function as a support service for the Data Analytics team to facilitate the development of standard reports, curated data pools, and ad hoc queries
Participate in the development of reports, metrics, models, scorecards, and dashboards by gathering data and transforming it into stories/insights that drive recommendations and decision-making.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python, Altreyx, Power BI, etc.
Build automated Processes using scripting tools
Hold Training sessions on how to use the various tools and reports created by the department
Communicate effectively with report stake holders to ensure strong understanding of the methodology behind all calculations
Perform ad hoc analysis using data from various systems and explain results of analysis to all levels of management
Create SOPs and documentation for processes
Demonstrate continuous efforts to improve processes, increase data integrity, and provide quality customer service to our business partners.
Provide comprehensive analytical and fact-based reporting to support and/or identify opportunities to impact operational results, make changes to processes, and support strategic initiatives.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. May perform other duties as assigned.

Qualifications

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals to perform the essential functions.

Bachelor's Degree from a regionally accredited four-year college or university in Accounting/Finance, Computer Science/Data Analytics or related field and 2+ years of relevant work experience in a Manufacturing/Logistics business environment, or equivalent combination of education and/or experience, required.
Ability to build models using advanced features of Excel.
Strong experience with Power BI / Tableau, Power Pivot, SAP, SAP Analysis for Office, BPC, Bex Query Designer.
Strong Experience in analyzing data within relational database systems such as MS Access, MS SQL Server, and MySQL.
Experience with ETL Tools such as Alteryx, Paxata, DataGuru or equivalent technologies, preferred.
Understanding of Windows environment command line tools, .BAT files, and Task Scheduler, preferred.
Experience with HTML/CSS/Javascript and a backend technology like python-flask, preferred.
Experience with Data analysis in Python using Pandas/Numpy/Jupyter Notebooks, preferred.
Ability to quickly learn new technology and business logic.
Superior analytical and problem-solving skills with superb attention to detail.
Strong written and verbal communication skills.
Ability to work independently in a fast-paced and rapidly changing and ambiguous environment.
Ability to work well with others in fast paced, dynamic environment.
Ability to be respectful, approachable and team oriented while building strong working relationships and a positive work environment.
Up to 10% travel required.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Job Locations <br><br></strong>US-VA-Smithfield<br><br><strong> Your Opportunity <br><br></strong>Headquartered in Smithfield, Va., since 1936, Smithfield Foods, Inc. is an American food company with agricultural roots and a global reach. Our 40,000 U.S. employees are dedicated to producing ""Good food. Responsibly.®"" and have made us one of the world's leading vertically integrated protein companies. We have pioneered sustainability standards for more than two decades, including many industry firsts, such as our ambitious commitment to cut our carbon impact by 25 percent by 2025. We believe in the power of protein to end food insecurity and have donated hundreds of millions of food servings to our neighbors in need. Smithfield boasts a portfolio of high-quality iconic brands, such as Smithfield ® , Eckrich ® , and Nathan's Famous ® , among many others. For more information, visit www.smithfieldfoods.com , and connect with us on Facebook , Twitter , LinkedIn , and Instagram .<br><br>As a Data Engineer in the Finance Data Analytics department at Smithfield Foods you will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. You will be responsible for supporting the data pipeline needs of the Finance Data Analytics team, ensuring data is delivered accurately and automated. You will work to support the Data Analytics team as they work on projects from various functional areas of the business. You will implement process improvements to streamline the efficiency and accuracy of the reporting process. You will build data pipelines to support the delivery of daily/weekly/monthly reports. You will also be involved in ad hoc analysis of large datasets to quickly provide insight into the business.<br><br><strong><u>Core Responsibilities<br></u></strong><ul><li> Create and maintain optimal data pipeline architecture </li><li> Function as a support service for the Data Analytics team to facilitate the development of standard reports, curated data pools, and ad hoc queries </li><li> Participate in the development of reports, metrics, models, scorecards, and dashboards by gathering data and transforming it into stories/insights that drive recommendations and decision-making. </li><li> Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery </li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python, Altreyx, Power BI, etc. </li><li> Build automated Processes using scripting tools </li><li> Hold Training sessions on how to use the various tools and reports created by the department </li><li> Communicate effectively with report stake holders to ensure strong understanding of the methodology behind all calculations </li><li> Perform ad hoc analysis using data from various systems and explain results of analysis to all levels of management </li><li> Create SOPs and documentation for processes </li><li> Demonstrate continuous efforts to improve processes, increase data integrity, and provide quality customer service to our business partners. </li><li> Provide comprehensive analytical and fact-based reporting to support and/or identify opportunities to impact operational results, make changes to processes, and support strategic initiatives. <br></li></ul>The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. May perform other duties as assigned.<br><br><strong><u>Qualifications<br><br></u></strong>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals to perform the essential functions.<br><ul><li> Bachelor's Degree from a regionally accredited four-year college or university in Accounting/Finance, Computer Science/Data Analytics or related field and 2+ years of relevant work experience in a Manufacturing/Logistics business environment, or equivalent combination of education and/or experience, required. </li><li> Ability to build models using advanced features of Excel. </li><li> Strong experience with Power BI / Tableau, Power Pivot, SAP, SAP Analysis for Office, BPC, Bex Query Designer. </li><li> Strong Experience in analyzing data within relational database systems such as MS Access, MS SQL Server, and MySQL. </li><li> Experience with ETL Tools such as Alteryx, Paxata, DataGuru or equivalent technologies, preferred. </li><li> Understanding of Windows environment command line tools, .BAT files, and Task Scheduler, preferred. </li><li> Experience with HTML/CSS/Javascript and a backend technology like python-flask, preferred. </li><li> Experience with Data analysis in Python using Pandas/Numpy/Jupyter Notebooks, preferred. </li><li> Ability to quickly learn new technology and business logic. </li><li> Superior analytical and problem-solving skills with superb attention to detail. </li><li> Strong written and verbal communication skills. </li><li> Ability to work independently in a fast-paced and rapidly changing and ambiguous environment. </li><li> Ability to work well with others in fast paced, dynamic environment. </li><li> Ability to be respectful, approachable and team oriented while building strong working relationships and a positive work environment. </li><li> Up to 10% travel required.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Food & Beverages, Food Production"
Data Engineer,"Pittsburgh, Pennsylvania, United States","KCF Technologies, Inc.",2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-kcf-technologies-inc-2429851833?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=qd6swQNszSHzu5%2F%2FujHIIQ%3D%3D&position=7&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"This role is open to be based from: New York, NY; Chicago, IL; Washington, DC; Los Angeles, CA; Portland, OR; San Francisco, CA; Atlanta, GA; Seattle, WA; Miami, FL; Dallas, TX; Austin, TX; Orlando, FL

Summary

Edelman Intelligence is seeking an Associate Data Scientist. The person in this role is expected to help drive Advanced Analytics client work, bringing together expertise in statistics, programming, and the communication of analytical insights. This person will contribute significantly towards client deliverables, help develop new analytical approaches and offerings, and mentor more junior team members.

Responsibilities

Assist in the leadership of day to day project execution, including client deliverables, status updates, and project management
Efficiently manage data from disparate sources, distilling into datasets prepared for modeling
Execute statistical models to support client projects, including marketing mix modeling, attribution, and purchase funnel analytics
Prepare client facing material (example: PowerPoint slides and charts), distilling analytical insights effectively into stories for EI clients
Develop standardized code and processes that can be easily used by the larger team
Support senior staff in the development of client proposals


Qualifications

Academic background in econometrics or applied statistics and related technologies, including statistical concepts, (example: Time-Series Regression, Logistic Regression, Factor Analysis)
Comfortable with prepping and visualizing data
Experience in statistical programming in R, SAS, or Python–experience in more than one language is a preferred
Excellent organizational and communication skills, coupled with the ability to adapt to new conditions, assignments and deadlines


Edelman Data & Intelligence (DxI) is a global, multidisciplinary research, analytics and data consultancy with a distinctly human mission.

We use data and intelligence to help businesses and organizations build trusting relationships with people: making communications more authentic, engagement more exciting and connections more meaningful.

DxI brings together and integrates the necessary people-based PR, communications, social, research and exogenous data, as well as the technology infrastructure to create, collect, store and manage first-party data and identity resolution. DxI is comprised of over 350 research specialists, business scientists, data engineers, behavioral and machine-learning experts, and data strategy consultants based in 15 markets around the world.

Edelman DxI is an equal opportunity employer of all protected classes, including veterans and individuals with disabilities.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>This role is open to be based from: New York, NY; Chicago, IL; Washington, DC; Los Angeles, CA; Portland, OR; San Francisco, CA; Atlanta, GA; Seattle, WA; Miami, FL; Dallas, TX; Austin, TX; Orlando, FL<br><br></strong><strong><u>Summary<br><br></u></strong>Edelman Intelligence is seeking an Associate Data Scientist. The person in this role is expected to help drive Advanced Analytics client work, bringing together expertise in statistics, programming, and the communication of analytical insights. This person will contribute significantly towards client deliverables, help develop new analytical approaches and offerings, and mentor more junior team members.<br><br><strong><u>Responsibilities<br></u></strong><ul><ul><li>Assist in the leadership of day to day project execution, including client deliverables, status updates, and project management</li><li>Efficiently manage data from disparate sources, distilling into datasets prepared for modeling</li><li>Execute statistical models to support client projects, including marketing mix modeling, attribution, and purchase funnel analytics</li><li>Prepare client facing material (example: PowerPoint slides and charts), distilling analytical insights effectively into stories for EI clients</li><li>Develop standardized code and processes that can be easily used by the larger team</li><li>Support senior staff in the development of client proposals<br><br></li></ul></ul><strong><u>Qualifications<br></u></strong><ul><ul><li>Academic background in econometrics or applied statistics and related technologies, including statistical concepts, (example: Time-Series Regression, Logistic Regression, Factor Analysis) </li><li>Comfortable with prepping and visualizing data</li><li>Experience in statistical programming in R, SAS, or Python–experience in more than one language is a preferred</li><li>Excellent organizational and communication skills, coupled with the ability to adapt to new conditions, assignments and deadlines<br><br></li></ul></ul>Edelman Data &amp; Intelligence (DxI) is a global, multidisciplinary research, analytics and data consultancy with a distinctly human mission.<br><br>We use data and intelligence to help businesses and organizations build trusting relationships with people: making communications more authentic, engagement more exciting and connections more meaningful.<br><br>DxI brings together and integrates the necessary people-based PR, communications, social, research and exogenous data, as well as the technology infrastructure to create, collect, store and manage first-party data and identity resolution. DxI is comprised of over 350 research specialists, business scientists, data engineers, behavioral and machine-learning experts, and data strategy consultants based in 15 markets around the world.<br><br>Edelman DxI is an equal opportunity employer of all protected classes, including veterans and individuals with disabilities.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Research, Public Relations, Analyst",Full-time,"Public Relations and Communications, Research, Market Research"
Data Analytics (TX),"Austin, Texas, United States",Movoto,2021-02-04,https://www.linkedin.com/jobs/view/data-analytics-tx-at-movoto-2408736464?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=9ev38ELj13v35lg4mcF1TA%3D%3D&position=8&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Movoto Director of Data Analytics

Remote, CA or Remote, TX

This is a CA remote or Texas-Remote, Exempt, Full Time position. This position reports to the Chief Technology Officer of the Company.

Why Movoto?

Movoto Real Estate is the fastest growing top 5 residential real estate site used by 650,000 buyers and sellers daily. As we scale for rapid growth, we are looking for a Director of Data Analytics to lead a global team of Data Engineers to enable Movoto to provide the most comprehensive, accurate and timely data, and build advanced data analytics products to enable data-enhanced decision support. You will provide technical leadership for the team and help them establish strong engineering discipline while taking an idea from concept to completion.

What you'll be doing:

Hire, lead and grow global Data Engineering team in realizing Movoto data architecture

Take hands on approach and lead design discussions and reviews

Partner with Product team in defining and executing on the vision, strategy and roadmap of managing MLS and other Property related data

Partner with the Analytics team in defining and executing on the vision, strategy and roadmap of Data Analytics solutions

Execute multiple projects by utilizing Agile SCRUM methodologies for continuous delivery

Engage with cross functional leaders to remove obstacles for their teams, deliver on stated goals and influence the way of working between teams

Provide technical leadership to a team of engineers located globally




What you should have:

Bachelor's Degree with 10+ years of overall professional experience is required. A Master's Degree is highly desirable

5+ years of experience leading Data Engineers and 10+ years as Software or Data engineer

Built development teams and led them toward a big vision and consistent execution through mentoring, coaching, retrospectives, and feedback loop

Proficiency in building and productionizing Data Pipelines using Python or Java or Scala is required

Proficiency in building Data Warehouse and Dashboards is required

Proficiency in building MLS and other Property Data Pipeline will be highly desirable

Prior experience in Cloud technologies, e.g. AWS is a must

Experience working with Development & Integration partners and other vendors

Strong analytical abilities, growth/metrics orientation, and problem-solving acumen

Highly organized, detail-oriented approach to handling multiple projects under tight deadlines.




Why should you join Movoto?

Medical, Dental & Vision Benefits

100%/75% premium coverage for employees/dependents

Basic & Supplemental Life Insurance, AD&D and Disability, FSA and Commuter Benefits

Retirement Plan

Equity

Flexible Paid Time Off

Paid Holidays

Parental Leave Benefits

Competitive Salaries

Volunteer Opportunities

Employee Engagement Events

PetPlan (10-15% off premiums)

PerkSpot – exclusive corporate discounts

Rocket Lawyer Legal Benefits and more!



About Movoto Real Estate

Movoto Real Estate was founded on a simple principle: Real estate should be easy.

This foundational idea continues to drive our mission every day, building cutting edge, optimized technology tools and connecting talented, customer-focused agents with motivated buyers and sellers. Today, we are the fastest-growing top five residential real estate site in the United States with nearly 26 million monthly visits. But we are more than a real estate brokerage and research site—we're a technology company that is bringing real estate into the future with our end-to-end suite of proprietary tools for buyers, sellers, and agents.

In 2020, Movoto was acquired by OJO Labs, a leader in personalized, AI-enabled real estate tools. Combining OJO and Movoto's deep commitment to creating end-to-end home-buying solutions, we continue to strive to become the most trusted real estate company in North America. Our real estate technology platform comprises the latest data-driven AI technology, client communication tools, marketing and transaction support, a real team of dedicated transaction coordinators, and an agent earnings structure that ensures our agents are successful and can focus on serving their clients.

Movoto is not only committed to making real estate accessible to a diverse community through technology, we strive to increase representation—across all races, ethnicities, genders, ages, sexual orientations, and physical or mental abilities—in our teams. We continue to promote an inclusive work environment where everyone, from any background, can do their best work.

Together with OJO and our growing team, we have renewed our dedication to the mission that started it all: making real estate easy in this rapidly changing world.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Movoto Director of Data Analytics<br><br></strong><strong>Remote, CA or Remote, TX<br><br></strong>This is a CA remote or Texas-Remote, Exempt, Full Time position. This position reports to the Chief Technology Officer of the Company.<br><br><strong>Why Movoto?<br><br></strong>Movoto Real Estate is the fastest growing top 5 residential real estate site used by 650,000 buyers and sellers daily. As we scale for rapid growth, we are looking for a Director of Data Analytics to lead a global team of Data Engineers to enable Movoto to provide the most comprehensive, accurate and timely data, and build advanced data analytics products to enable data-enhanced decision support. You will provide technical leadership for the team and help them establish strong engineering discipline while taking an idea from concept to completion.<br><br><strong>What you'll be doing:<br></strong><ul> <li>Hire, lead and grow global Data Engineering team in realizing Movoto data architecture<br></li> <li>Take hands on approach and lead design discussions and reviews<br></li> <li>Partner with Product team in defining and executing on the vision, strategy and roadmap of managing MLS and other Property related data<br></li> <li>Partner with the Analytics team in defining and executing on the vision, strategy and roadmap of Data Analytics solutions<br></li> <li>Execute multiple projects by utilizing Agile SCRUM methodologies for continuous delivery<br></li> <li>Engage with cross functional leaders to remove obstacles for their teams, deliver on stated goals and influence the way of working between teams<br></li> <li>Provide technical leadership to a team of engineers located globally<br></li> <br><br></ul><strong>What you should have:<br></strong><ul> <li>Bachelor's Degree with 10+ years of overall professional experience is required. A Master's Degree is highly desirable<br></li> <li>5+ years of experience leading Data Engineers and 10+ years as Software or Data engineer<br></li> <li>Built development teams and led them toward a big vision and consistent execution through mentoring, coaching, retrospectives, and feedback loop<br></li> <li>Proficiency in building and productionizing Data Pipelines using Python or Java or Scala is required<br></li> <li>Proficiency in building Data Warehouse and Dashboards is required<br></li> <li>Proficiency in building MLS and other Property Data Pipeline will be highly desirable<br></li> <li>Prior experience in Cloud technologies, e.g. AWS is a must<br></li> <li>Experience working with Development &amp; Integration partners and other vendors<br></li> <li>Strong analytical abilities, growth/metrics orientation, and problem-solving acumen<br></li> <li>Highly organized, detail-oriented approach to handling multiple projects under tight deadlines.<br></li> <br><br></ul><strong>Why should you join Movoto?<br></strong><ul> <li>Medical, Dental &amp; Vision Benefits<br></li></ul><ul> <li>100%/75% premium coverage for employees/dependents<br></li> </ul> <li>Basic &amp; Supplemental Life Insurance, AD&amp;D and Disability, FSA and Commuter Benefits<br></li> <li>Retirement Plan<br></li> <li>Equity<br></li> <li>Flexible Paid Time Off<br></li> <li>Paid Holidays<br></li> <li>Parental Leave Benefits<br></li> <li>Competitive Salaries<br></li> <li>Volunteer Opportunities<br></li> <li>Employee Engagement Events<br></li> <li>PetPlan (10-15% off premiums)<br></li> <li>PerkSpot – exclusive corporate discounts<br></li> <li>Rocket Lawyer Legal Benefits and more!<br></li> <br><br><strong><u>About Movoto Real Estate<br><br></u></strong>Movoto Real Estate was founded on a simple principle: Real estate should be easy.<br><br>This foundational idea continues to drive our mission every day, building cutting edge, optimized technology tools and connecting talented, customer-focused agents with motivated buyers and sellers. Today, we are the fastest-growing top five residential real estate site in the United States with nearly 26 million monthly visits. But we are more than a real estate brokerage and research site—we're a technology company that is bringing real estate into the future with our end-to-end suite of proprietary tools for buyers, sellers, and agents.<br><br>In 2020, Movoto was acquired by OJO Labs, a leader in personalized, AI-enabled real estate tools. Combining OJO and Movoto's deep commitment to creating end-to-end home-buying solutions, we continue to strive to become the most trusted real estate company in North America. Our real estate technology platform comprises the latest data-driven AI technology, client communication tools, marketing and transaction support, a real team of dedicated transaction coordinators, and an agent earnings structure that ensures our agents are successful and can focus on serving their clients.<br><br>Movoto is not only committed to making real estate accessible to a diverse community through technology, we strive to increase representation—across all races, ethnicities, genders, ages, sexual orientations, and physical or mental abilities—in our teams. We continue to promote an inclusive work environment where everyone, from any background, can do their best work.<br><br>Together with OJO and our growing team, we have renewed our dedication to the mission that started it all: making real estate easy in this rapidly changing world.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Insurance, Financial Services, Real Estate"
"Data Engineer, People Insights & Analytics","San Francisco, California, United States",Pinterest,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-people-insights-analytics-at-pinterest-2403588963?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=gq%2BqIspVuVEehO9U9eDQaA%3D%3D&position=9&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Movoto Director of Data Analytics

Remote, CA or Remote, TX

This is a CA remote or Texas-Remote, Exempt, Full Time position. This position reports to the Chief Technology Officer of the Company.

Why Movoto?

Movoto Real Estate is the fastest growing top 5 residential real estate site used by 650,000 buyers and sellers daily. As we scale for rapid growth, we are looking for a Director of Data Analytics to lead a global team of Data Engineers to enable Movoto to provide the most comprehensive, accurate and timely data, and build advanced data analytics products to enable data-enhanced decision support. You will provide technical leadership for the team and help them establish strong engineering discipline while taking an idea from concept to completion.

What you'll be doing:

Hire, lead and grow global Data Engineering team in realizing Movoto data architecture

Take hands on approach and lead design discussions and reviews

Partner with Product team in defining and executing on the vision, strategy and roadmap of managing MLS and other Property related data

Partner with the Analytics team in defining and executing on the vision, strategy and roadmap of Data Analytics solutions

Execute multiple projects by utilizing Agile SCRUM methodologies for continuous delivery

Engage with cross functional leaders to remove obstacles for their teams, deliver on stated goals and influence the way of working between teams

Provide technical leadership to a team of engineers located globally




What you should have:

Bachelor's Degree with 10+ years of overall professional experience is required. A Master's Degree is highly desirable

5+ years of experience leading Data Engineers and 10+ years as Software or Data engineer

Built development teams and led them toward a big vision and consistent execution through mentoring, coaching, retrospectives, and feedback loop

Proficiency in building and productionizing Data Pipelines using Python or Java or Scala is required

Proficiency in building Data Warehouse and Dashboards is required

Proficiency in building MLS and other Property Data Pipeline will be highly desirable

Prior experience in Cloud technologies, e.g. AWS is a must

Experience working with Development & Integration partners and other vendors

Strong analytical abilities, growth/metrics orientation, and problem-solving acumen

Highly organized, detail-oriented approach to handling multiple projects under tight deadlines.




Why should you join Movoto?

Medical, Dental & Vision Benefits

100%/75% premium coverage for employees/dependents

Basic & Supplemental Life Insurance, AD&D and Disability, FSA and Commuter Benefits

Retirement Plan

Equity

Flexible Paid Time Off

Paid Holidays

Parental Leave Benefits

Competitive Salaries

Volunteer Opportunities

Employee Engagement Events

PetPlan (10-15% off premiums)

PerkSpot – exclusive corporate discounts

Rocket Lawyer Legal Benefits and more!



About Movoto Real Estate

Movoto Real Estate was founded on a simple principle: Real estate should be easy.

This foundational idea continues to drive our mission every day, building cutting edge, optimized technology tools and connecting talented, customer-focused agents with motivated buyers and sellers. Today, we are the fastest-growing top five residential real estate site in the United States with nearly 26 million monthly visits. But we are more than a real estate brokerage and research site—we're a technology company that is bringing real estate into the future with our end-to-end suite of proprietary tools for buyers, sellers, and agents.

In 2020, Movoto was acquired by OJO Labs, a leader in personalized, AI-enabled real estate tools. Combining OJO and Movoto's deep commitment to creating end-to-end home-buying solutions, we continue to strive to become the most trusted real estate company in North America. Our real estate technology platform comprises the latest data-driven AI technology, client communication tools, marketing and transaction support, a real team of dedicated transaction coordinators, and an agent earnings structure that ensures our agents are successful and can focus on serving their clients.

Movoto is not only committed to making real estate accessible to a diverse community through technology, we strive to increase representation—across all races, ethnicities, genders, ages, sexual orientations, and physical or mental abilities—in our teams. We continue to promote an inclusive work environment where everyone, from any background, can do their best work.

Together with OJO and our growing team, we have renewed our dedication to the mission that started it all: making real estate easy in this rapidly changing world.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Movoto Director of Data Analytics<br><br></strong><strong>Remote, CA or Remote, TX<br><br></strong>This is a CA remote or Texas-Remote, Exempt, Full Time position. This position reports to the Chief Technology Officer of the Company.<br><br><strong>Why Movoto?<br><br></strong>Movoto Real Estate is the fastest growing top 5 residential real estate site used by 650,000 buyers and sellers daily. As we scale for rapid growth, we are looking for a Director of Data Analytics to lead a global team of Data Engineers to enable Movoto to provide the most comprehensive, accurate and timely data, and build advanced data analytics products to enable data-enhanced decision support. You will provide technical leadership for the team and help them establish strong engineering discipline while taking an idea from concept to completion.<br><br><strong>What you'll be doing:<br></strong><ul> <li>Hire, lead and grow global Data Engineering team in realizing Movoto data architecture<br></li> <li>Take hands on approach and lead design discussions and reviews<br></li> <li>Partner with Product team in defining and executing on the vision, strategy and roadmap of managing MLS and other Property related data<br></li> <li>Partner with the Analytics team in defining and executing on the vision, strategy and roadmap of Data Analytics solutions<br></li> <li>Execute multiple projects by utilizing Agile SCRUM methodologies for continuous delivery<br></li> <li>Engage with cross functional leaders to remove obstacles for their teams, deliver on stated goals and influence the way of working between teams<br></li> <li>Provide technical leadership to a team of engineers located globally<br></li> <br><br></ul><strong>What you should have:<br></strong><ul> <li>Bachelor's Degree with 10+ years of overall professional experience is required. A Master's Degree is highly desirable<br></li> <li>5+ years of experience leading Data Engineers and 10+ years as Software or Data engineer<br></li> <li>Built development teams and led them toward a big vision and consistent execution through mentoring, coaching, retrospectives, and feedback loop<br></li> <li>Proficiency in building and productionizing Data Pipelines using Python or Java or Scala is required<br></li> <li>Proficiency in building Data Warehouse and Dashboards is required<br></li> <li>Proficiency in building MLS and other Property Data Pipeline will be highly desirable<br></li> <li>Prior experience in Cloud technologies, e.g. AWS is a must<br></li> <li>Experience working with Development &amp; Integration partners and other vendors<br></li> <li>Strong analytical abilities, growth/metrics orientation, and problem-solving acumen<br></li> <li>Highly organized, detail-oriented approach to handling multiple projects under tight deadlines.<br></li> <br><br></ul><strong>Why should you join Movoto?<br></strong><ul> <li>Medical, Dental &amp; Vision Benefits<br></li></ul><ul> <li>100%/75% premium coverage for employees/dependents<br></li> </ul> <li>Basic &amp; Supplemental Life Insurance, AD&amp;D and Disability, FSA and Commuter Benefits<br></li> <li>Retirement Plan<br></li> <li>Equity<br></li> <li>Flexible Paid Time Off<br></li> <li>Paid Holidays<br></li> <li>Parental Leave Benefits<br></li> <li>Competitive Salaries<br></li> <li>Volunteer Opportunities<br></li> <li>Employee Engagement Events<br></li> <li>PetPlan (10-15% off premiums)<br></li> <li>PerkSpot – exclusive corporate discounts<br></li> <li>Rocket Lawyer Legal Benefits and more!<br></li> <br><br><strong><u>About Movoto Real Estate<br><br></u></strong>Movoto Real Estate was founded on a simple principle: Real estate should be easy.<br><br>This foundational idea continues to drive our mission every day, building cutting edge, optimized technology tools and connecting talented, customer-focused agents with motivated buyers and sellers. Today, we are the fastest-growing top five residential real estate site in the United States with nearly 26 million monthly visits. But we are more than a real estate brokerage and research site—we're a technology company that is bringing real estate into the future with our end-to-end suite of proprietary tools for buyers, sellers, and agents.<br><br>In 2020, Movoto was acquired by OJO Labs, a leader in personalized, AI-enabled real estate tools. Combining OJO and Movoto's deep commitment to creating end-to-end home-buying solutions, we continue to strive to become the most trusted real estate company in North America. Our real estate technology platform comprises the latest data-driven AI technology, client communication tools, marketing and transaction support, a real team of dedicated transaction coordinators, and an agent earnings structure that ensures our agents are successful and can focus on serving their clients.<br><br>Movoto is not only committed to making real estate accessible to a diverse community through technology, we strive to increase representation—across all races, ethnicities, genders, ages, sexual orientations, and physical or mental abilities—in our teams. We continue to promote an inclusive work environment where everyone, from any background, can do their best work.<br><br>Together with OJO and our growing team, we have renewed our dedication to the mission that started it all: making real estate easy in this rapidly changing world.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Human Resources, Administrative",Full-time,"Internet, Computer Software, Information Technology and Services"
Data and Machine Learning Engineer,"Cambridge, Massachusetts, United States",Flagship Pioneering,2021-02-06,https://www.linkedin.com/jobs/view/data-and-machine-learning-engineer-at-flagship-pioneering-2411566435?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=FJDoTuNFWWU2ucTO7%2BNZLA%3D%3D&position=11&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"About Pinterest

Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.

The People Insights and Analytics team is looking for a data engineer to build and maintain a data platform to help Pinterest make better decisions about its employees using data. You’ll own the flow of data between multiple systems that track data for our employees and employee data warehouse systems, which fuels analytics, dashboards, surveys and other tools that help our leaders and managers build a world-class people experience at Pinterest. The successful candidate will have experience working with enterprise data warehouses, be passionate about empowering people to make data driven decisions and be excited to own and build a data platform.

What You’ll Do

Architect the data strategy for the People Team. We’re just getting started building a system that can scale with our business and analytics needs
Establish relationships across People team, Engineering and the Business to understand our data landscape, and create a strategy to bridge the gaps
Utilization of data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)
Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights
Design, develop, and implement data processing pipelines at scale
Present programming documentation and design to team members and convey complex information in a clear and concise manner
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Maintain suite of data tools platforms and dashboards in Tableau, Django, d3, Jupyter, R and other analytical tools.



What We're Looking For

Hands-on experience in data modeling, data visualization and pipeline design and development
Hands-on experience with data platforms (Hadoop, Hive, Presto, Snowflake, Cloudera ) and familiarity with data visualization (Tableau, D3) technologies
Strong in at least one of these programming languages: Python, Java, Go
Comfortable working across a wide array of technologies, project types, and business requirements. Strength in AWS and cloud data technology strongly preferred
Experienced at organizing and executing against sprints
Ability to handle confidential material discreetly
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Pinterest<br><br></u></strong>Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.<br><br>The People Insights and Analytics team is looking for a data engineer to build and maintain a data platform to help Pinterest make better decisions about its employees using data. You’ll own the flow of data between multiple systems that track data for our employees and employee data warehouse systems, which fuels analytics, dashboards, surveys and other tools that help our leaders and managers build a world-class people experience at Pinterest. The successful candidate will have experience working with enterprise data warehouses, be passionate about empowering people to make data driven decisions and be excited to own and build a data platform.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Architect the data strategy for the People Team. We’re just getting started building a system that can scale with our business and analytics needs </li> <li>Establish relationships across People team, Engineering and the Business to understand our data landscape, and create a strategy to bridge the gaps</li> <li>Utilization of data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)</li> <li>Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights</li> <li>Design, develop, and implement data processing pipelines at scale</li> <li>Present programming documentation and design to team members and convey complex information in a clear and concise manner</li> <li>Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes</li> <li>Maintain suite of data tools platforms and dashboards in Tableau, Django, d3, Jupyter, R and other analytical tools.</li> <br><br></ul><strong><u>What We're Looking For<br></u></strong><ul> <li>Hands-on experience in data modeling, data visualization and pipeline design and development</li> <li>Hands-on experience with data platforms (Hadoop, Hive, Presto, Snowflake, Cloudera ) and familiarity with data visualization (Tableau, D3) technologies</li> <li>Strong in at least one of these programming languages: Python, Java, Go</li> <li>Comfortable working across a wide array of technologies, project types, and business requirements. Strength in AWS and cloud data technology strongly preferred</li> <li>Experienced at organizing and executing against sprints</li> <li>Ability to handle confidential material discreetly</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Human Resources, Administrative",Full-time,"Internet, Computer Software, Information Technology and Services"
Data Engineer,"Croydon, Utah, United States",Home Office,2021-02-17,https://au.linkedin.com/jobs/view/data-engineer-at-home-office-2429888037?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=0pokqfJa0G3RB4m2n9d2fA%3D%3D&position=12&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"What if…you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies in order to transform health care and sustainability?

Montai Health is a privately held, early-stage biotechnology company developing a platform for understanding and leveraging complex molecular interactions within organisms to solve global challenges in human health and sustainability. The company leverages a multidisciplinary approach that integrates tools ranging from machine learning and big data to multi-omics and high-throughput screening.

Montai Health was founded in Flagship’s venture creation engine, where companies such as Moderna Therapeutics (NASDAQ: MRNA), Rubius Therapeutics (NASDAQ: RUBY), and Editas Medicines (NASDAQ: EDIT) were conceived and created. Since Flagship’s founding in 2000, the firm has originated and fostered the development of more than 100 scientific ventures, resulting in over $34 billion in aggregate value, 500+ issued patents, and more than 50 clinical trials for novel therapeutic agents.

Position Summary

We are looking for an experienced engineer to join a small and growing team of machine learning and computational biology scientists. This person will work directly with scientists to:

Improve our computational workflows with an eye towards solid software engineering principles
Help manage and scale our compute and data resources
Build and adapt software that scales our ability to develop, run and reproduce intensive computational experiments



We hope to find someone who is an expert in their field and curious to work with experts in molecular/computational biology and machine learning. We are a diverse and multidisciplinary team and love to learn!

Required Experience

6 or more years, or BS/MS + 3 years combined experience in software, data & machine learning engineering
Dependency and environment tracking and management
Data organization, versioning and provenance tracking
Code and repository organization
Applying principles of good software design to data processing and machine learning pipelines (reproducibility, functional decomposition, abstraction design)
Building, maintaining, documenting and evangelizing software tools for use within a team
Working directly and communicating effectively with computational scientists (who may have less software engineering experience)
Communicating directly with business development to stay current on quickly evolving goals



Recommended Experience

Machine learning computational workloads (Large data payloads, batching and chunking. Memory, CPU and GPU resource management.)
Distributed computation methods and cluster management



Specific Familiarity With

Python 3, Numeric python ecosystem (Some of: numpy, pandas, pytorch, tensorflow, jax)
AWS (Some of: EC2, S3, Cloudwatch, ECS, EMR, RDS)
Python dependency management tools (Some of: conda, pip, setuptools)
SQL and non-SQL database systems (Some of: Postgres, Mongodb, Elasticsearch)
Cluster management and containerization (Some of: Docker, Kubernetes, AWS EMR, AWS ECS, Spark, Dask, Ray, Distributed PyTorch/Tensorflow)
Data warehouse/lake frameworks (Some of: Snowflake, Redshift)
ML-focused data and workflow management frameworks (Some of: DVC, MetaFlow)
Git
Linux commandline, bash



Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>What if…</strong>you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies in order to transform health care and sustainability?<br><br>Montai Health is a privately held, early-stage biotechnology company developing a platform for understanding and leveraging complex molecular interactions within organisms to solve global challenges in human health and sustainability. The company leverages a multidisciplinary approach that integrates tools ranging from machine learning and big data to multi-omics and high-throughput screening.<br><br>Montai Health was founded in Flagship’s venture creation engine, where companies such as Moderna Therapeutics (NASDAQ: MRNA), Rubius Therapeutics (NASDAQ: RUBY), and Editas Medicines (NASDAQ: EDIT) were conceived and created. Since Flagship’s founding in 2000, the firm has originated and fostered the development of more than 100 scientific ventures, resulting in over $34 billion in aggregate value, 500+ issued patents, and more than 50 clinical trials for novel therapeutic agents.<br><br><strong><u>Position Summary<br><br></u></strong>We are looking for an experienced engineer to join a small and growing team of machine learning and computational biology scientists. This person will work directly with scientists to:<br><ul> <li>Improve our computational workflows with an eye towards solid software engineering principles</li> <li>Help manage and scale our compute and data resources</li> <li>Build and adapt software that scales our ability to develop, run and reproduce intensive computational experiments</li> <br><br></ul>We hope to find someone who is an expert in their field and curious to work with experts in molecular/computational biology and machine learning. We are a diverse and multidisciplinary team and love to learn!<br><br><strong><u>Required Experience<br></u></strong><ul> <li>6 or more years, or BS/MS + 3 years combined experience in software, data &amp; machine learning engineering</li> <li>Dependency and environment tracking and management</li> <li>Data organization, versioning and provenance tracking</li> <li>Code and repository organization</li> <li>Applying principles of good software design to data processing and machine learning pipelines (reproducibility, functional decomposition, abstraction design)</li> <li>Building, maintaining, documenting and evangelizing software tools for use within a team</li> <li>Working directly and communicating effectively with computational scientists (who may have less software engineering experience)</li> <li>Communicating directly with business development to stay current on quickly evolving goals</li> <br><br></ul><strong><u>Recommended Experience<br></u></strong><ul> <li>Machine learning computational workloads (Large data payloads, batching and chunking. Memory, CPU and GPU resource management.)</li> <li>Distributed computation methods and cluster management</li> <br><br></ul><strong><u>Specific Familiarity With<br></u></strong><ul> <li>Python 3, Numeric python ecosystem (Some of: numpy, pandas, pytorch, tensorflow, jax)</li> <li>AWS (Some of: EC2, S3, Cloudwatch, ECS, EMR, RDS)</li> <li>Python dependency management tools (Some of: conda, pip, setuptools)</li> <li>SQL and non-SQL database systems (Some of: Postgres, Mongodb, Elasticsearch)</li> <li>Cluster management and containerization (Some of: Docker, Kubernetes, AWS EMR, AWS ECS, Spark, Dask, Ray, Distributed PyTorch/Tensorflow)</li> <li>Data warehouse/lake frameworks (Some of: Snowflake, Redshift)</li> <li>ML-focused data and workflow management frameworks (Some of: DVC, MetaFlow)</li> <li>Git</li> <li>Linux commandline, bash</li> <br><br></ul>Flagship Pioneering and our ecosystem companies are <strong>committed to equal employment opportunity</strong> regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.<br><br><em><strong>Recruitment &amp; Staffing Agencies</strong>: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Biotechnology, Research"
Data Engineer,"Florida, United States",sticky.io,2021-02-11,https://www.linkedin.com/jobs/view/data-engineer-at-sticky-io-2341774768?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=ImdLKvL3at9fwEwTJ%2FXiYQ%3D%3D&position=13&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Your main day to day responsibilities will be: working with NDQIS end-users to understand the end-to-end processes they carry out, when working with a set of data analysing problems and experimenting with possible solutions to find the underlying causes of issues with users' processes to identify problems and to assist in the development of innovative solutions designing natural-language processing rules that (1) mimic the way the end-users would interpret the content of text, and (2) carry out actions on the records, driven by the meaning within the text supporting NDQIS team members with the tool implementation and software releases; including developing & contributing to testing strategies, and implementing them, based on your understanding of the data and your knowledge of the processing rules designing and implementing comprehensive reports that meet stakeholders reporting requirements to supplement data analysis projects using a variety of reporting tools (e.g. Excel, PowerBI, Tableau etc.) analysing and reporting activities and presentation of results, supporting users on data analysis and data quality issues designing, implementing and improving development of new data models and ETL processes ensuring the successful delivery of completed data sets and results for customers, troubleshooting where required designing, building and testing data and solutions that are complex, through full development, test and deployment lifecycles applying concepts and principles of data modelling and producing relevant and varied data models across multiple subject areas and providing guidance on how to use them Other day to day activities You will also be expected to carry out the following day to day activities: delivering continuous improvement by identifying positive changes that can be carried out to improve performance e.g. to improve data quality providing support and guidance to NDIQS users on best practices and processes when using the system designing, writing, iterating and optimising code from prototype to production-ready leading work on mapping data to the agreed data model translating and presenting clear insights from available data to support NDQIS users while being an advocate for the team reviewing requirements, specifications and defining test conditions working with data privacy and information security staff to assure that security and privacy requirements are identified and addressed in solutions Please refer to the Data Engineer Role Definition document attached, for further information.ResponsibilitiesThe main responsibilities of the role are covered in the job description. Essential Criteria You'll have a demonstrable passion for Data, with the following skills or some experience in: the delivery of projects in data analysis, solution design and user-centric approach to analysis and reporting user and stakeholder management, including effectively managing and communicating with non-technical and senior stakeholders about performance and analysis IT programming and automation using tools such as industry standard ETL tools, network databases and scheduling and orchestration tools e.g. SQL, Python, R The skills listed above are reflective of the Home Office DDaT Profession Skills and Competency Model (based on the industry standard SFIA framework). Please see below for the relevant skills required for your role: Strategy and Architecture Business Strategy and Planning o Innovation INOV
Level 3 Technical Strategy and Planning o Data Management DATM
Level 2 o Methods and Tools METL
Level 2 Development and Implementation Systems Development o Data Modelling and Design DTAN
Level 3 o Database design DBDS
Level 2 Qualifications A numerate degree or equivalent experience An Agile Foundation is desirable Desirable Criteria Ideally, you will also have the following skills or some experience in: applying data analysis techniques and tools working with Big Data tools and data stores e.g. Apache tools using Cloud Data technologies, solutions and future Cloud Data Strategies e.g. AWS and CloudWatch working in an agile and complex data environment understanding industry recognised data patterns and standards and their applications working with the Home Office stakeholders and data setsBehaviours We'll assess you against these behaviours during the selection process: Changing and Improving Communicating and Influencing Technical skills We'll assess you against these technical skills during the selection process: Development and Implementation Strategy and Architecture Technical Strategy and Planning Benefits Learning and development tailored to your role An environment with flexible working options A culture encouraging inclusion and diversity A Civil Service pensionThings you need to knowSecuritySuccessful candidates must meet the security requirements before they can be appointed. The level of security needed is security check .People working with government assets must complete basic personnel security standard checks.Selection process detailsThis vacancy is using Success Profiles , and will assess your Behaviours, Experience and Technical skills.As part of the application process you will be asked to complete a CV and Personal Statement (Max Word Limit:500). Further details around what this will entail are listed on the application form. Please note your personal statement and CV should be aligned to the Essential Criteria detailed within the job advertisement. If you are successful at sift stage you will be invited to an Interview which will be a blended approach of Behaviour-based questions as listed on the advertisement, Technical skills and Experience. Sift and Interview dates Sift will take place week commencing 1st March 20
Interviews will take place week commencing 15th March 20
Interviews will be conducted by video via Skype for business due to Covid-
Further information Please read the essential skills for this position carefully. We will only consider those who meet the listed requirement. If you have previously made an unsuccessful application for a role with the same essential skills and are not able to demonstrate how you have developed these skills since your last application please reconsider applying as your application is unlikely to be successful. A reserve list may be held for a period up to 12 months from which further appointment may be made. We often have similar roles available at different grades. If a candidate is suitable for a similar role or a lower grade than they have applied for, we may offer the candidate that role without the need for them to go through a further selection process providing the role has the same behaviours and essential skills. Every day, Home Office civil servants do brilliant work to develop and deliver policies and services that affect the lives of people across the country and beyond. To do this effectively and fairly, the Home Office is committed to representing modern Britain in all its diversity, and creating a welcoming, inclusive workplace where all our people are able to bring their whole selves to work and perform at their best. We are flexible, skilled, professional and diverse. We work to recruit and retain disabled staff and area Disability Confident Leader. We are proud to be one of the most ethnically diverse departments in the civil service. We are Stonewall top 100 Workplace Equality Employer and a Social Mobility Foundation top 75 employer. New entrants are expected to join on the minimum of the pay band. Applicants who are successful at interview will be, as part of pre-employment screening, subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant's details held on the IFD will be refused employment. For further information please see the attached notes for candidates which must be read before making an application. Existing Civil Servants should note that some of the Home Office terms and conditions of employment have changed. It is the candidate's responsibility to ensure they are aware of the Terms and Conditions they will adopt should they be successful in application and should refer to the notes for candidates for further details. Transfer Terms: Voluntary. If you are invited to an interview you will be required to bring a range of documentation for the purposes of establishing identity and to aid any pre-employment checks. Please see the attached list of Home Office acceptable ID documents. Any move to the Home Office from another employer will mean you can no longer access childcare vouchers. This includes moves between government departments. You may however be eligible for other government schemes, including Tax Free Childcare. Determine your eligibility at https://www.childcarechoices.gov.uk Reasonable Adjustments If a person with disabilities is at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes. If you need a change to be made so that you can make your application, you should: Contact Government Recruitment Service via HOrecruitment.grs@cabinetoffice.gov.uk as soon as possible before the closing date to discuss your needs Complete the ""Assistance Required"" section in the ""Additional Requirements"" page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you're deaf, a language service professional If you are experiencing accessibility problems with any attachments on this advert, please contact the email address in the 'Contact point for applicants' section. FeedbackFeedback will only be provided if you attend an
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Your main day to day responsibilities will be: working with NDQIS end-users to understand the end-to-end processes they carry out, when working with a set of data analysing problems and experimenting with possible solutions to find the underlying causes of issues with users' processes to identify problems and to assist in the development of innovative solutions designing natural-language processing rules that (1) mimic the way the end-users would interpret the content of text, and (2) carry out actions on the records, driven by the meaning within the text supporting NDQIS team members with the tool implementation and software releases; including developing &amp; contributing to testing strategies, and implementing them, based on your understanding of the data and your knowledge of the processing rules designing and implementing comprehensive reports that meet stakeholders reporting requirements to supplement data analysis projects using a variety of reporting tools (e.g. Excel, PowerBI, Tableau etc.) analysing and reporting activities and presentation of results, supporting users on data analysis and data quality issues designing, implementing and improving development of new data models and ETL processes ensuring the successful delivery of completed data sets and results for customers, troubleshooting where required designing, building and testing data and solutions that are complex, through full development, test and deployment lifecycles applying concepts and principles of data modelling and producing relevant and varied data models across multiple subject areas and providing guidance on how to use them Other day to day activities You will also be expected to carry out the following day to day activities: delivering continuous improvement by identifying positive changes that can be carried out to improve performance e.g. to improve data quality providing support and guidance to NDIQS users on best practices and processes when using the system designing, writing, iterating and optimising code from prototype to production-ready leading work on mapping data to the agreed data model translating and presenting clear insights from available data to support NDQIS users while being an advocate for the team reviewing requirements, specifications and defining test conditions working with data privacy and information security staff to assure that security and privacy requirements are identified and addressed in solutions Please refer to the Data Engineer Role Definition document attached, for further information.ResponsibilitiesThe main responsibilities of the role are covered in the job description. Essential Criteria You'll have a demonstrable passion for Data, with the following skills or some experience in: the delivery of projects in data analysis, solution design and user-centric approach to analysis and reporting user and stakeholder management, including effectively managing and communicating with non-technical and senior stakeholders about performance and analysis IT programming and automation using tools such as industry standard ETL tools, network databases and scheduling and orchestration tools e.g. SQL, Python, R The skills listed above are reflective of the Home Office DDaT Profession Skills and Competency Model (based on the industry standard SFIA framework). Please see below for the relevant skills required for your role: Strategy and Architecture Business Strategy and Planning o Innovation INOV<li>Level 3 Technical Strategy and Planning o Data Management DATM</li><li>Level 2 o Methods and Tools METL</li><li>Level 2 Development and Implementation Systems Development o Data Modelling and Design DTAN</li><li>Level 3 o Database design DBDS</li><li>Level 2 Qualifications A numerate degree or equivalent experience An Agile Foundation is desirable Desirable Criteria Ideally, you will also have the following skills or some experience in: applying data analysis techniques and tools working with Big Data tools and data stores e.g. Apache tools using Cloud Data technologies, solutions and future Cloud Data Strategies e.g. AWS and CloudWatch working in an agile and complex data environment understanding industry recognised data patterns and standards and their applications working with the Home Office stakeholders and data setsBehaviours We'll assess you against these behaviours during the selection process: Changing and Improving Communicating and Influencing Technical skills We'll assess you against these technical skills during the selection process: Development and Implementation Strategy and Architecture Technical Strategy and Planning Benefits Learning and development tailored to your role An environment with flexible working options A culture encouraging inclusion and diversity A Civil Service pensionThings you need to knowSecuritySuccessful candidates must meet the security requirements before they can be appointed. The level of security needed is security check .People working with government assets must complete basic personnel security standard checks.Selection process detailsThis vacancy is using Success Profiles , and will assess your Behaviours, Experience and Technical skills.As part of the application process you will be asked to complete a CV and Personal Statement (Max Word Limit:500). Further details around what this will entail are listed on the application form. Please note your personal statement and CV should be aligned to the Essential Criteria detailed within the job advertisement. If you are successful at sift stage you will be invited to an Interview which will be a blended approach of Behaviour-based questions as listed on the advertisement, Technical skills and Experience. Sift and Interview dates Sift will take place week commencing 1st March 20</li><li>Interviews will take place week commencing 15th March 20</li><li>Interviews will be conducted by video via Skype for business due to Covid-</li><li>Further information Please read the essential skills for this position carefully. We will only consider those who meet the listed requirement. If you have previously made an unsuccessful application for a role with the same essential skills and are not able to demonstrate how you have developed these skills since your last application please reconsider applying as your application is unlikely to be successful. A reserve list may be held for a period up to 12 months from which further appointment may be made. We often have similar roles available at different grades. If a candidate is suitable for a similar role or a lower grade than they have applied for, we may offer the candidate that role without the need for them to go through a further selection process providing the role has the same behaviours and essential skills. Every day, Home Office civil servants do brilliant work to develop and deliver policies and services that affect the lives of people across the country and beyond. To do this effectively and fairly, the Home Office is committed to representing modern Britain in all its diversity, and creating a welcoming, inclusive workplace where all our people are able to bring their whole selves to work and perform at their best. We are flexible, skilled, professional and diverse. We work to recruit and retain disabled staff and area Disability Confident Leader. We are proud to be one of the most ethnically diverse departments in the civil service. We are Stonewall top 100 Workplace Equality Employer and a Social Mobility Foundation top 75 employer. New entrants are expected to join on the minimum of the pay band. Applicants who are successful at interview will be, as part of pre-employment screening, subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant's details held on the IFD will be refused employment. For further information please see the attached notes for candidates which must be read before making an application. Existing Civil Servants should note that some of the Home Office terms and conditions of employment have changed. It is the candidate's responsibility to ensure they are aware of the Terms and Conditions they will adopt should they be successful in application and should refer to the notes for candidates for further details. Transfer Terms: Voluntary. If you are invited to an interview you will be required to bring a range of documentation for the purposes of establishing identity and to aid any pre-employment checks. Please see the attached list of Home Office acceptable ID documents. Any move to the Home Office from another employer will mean you can no longer access childcare vouchers. This includes moves between government departments. You may however be eligible for other government schemes, including Tax Free Childcare. Determine your eligibility at https://www.childcarechoices.gov.uk Reasonable Adjustments If a person with disabilities is at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes. If you need a change to be made so that you can make your application, you should: Contact Government Recruitment Service via HOrecruitment.grs@cabinetoffice.gov.uk as soon as possible before the closing date to discuss your needs Complete the ""Assistance Required"" section in the ""Additional Requirements"" page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you're deaf, a language service professional If you are experiencing accessibility problems with any attachments on this advert, please contact the email address in the 'Contact point for applicants' section. FeedbackFeedback will only be provided if you attend an</li></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Internet
Data Scientist,"Hillsboro, Oregon, United States",Intel Corporation,2021-02-03,https://www.linkedin.com/jobs/view/data-scientist-at-intel-corporation-2393685637?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=xhEe8d9yvGlRuZiUyoZv7w%3D%3D&position=14&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Initiates the research, development and implementation of Resolution Enhancement Techniques (RET) for nanoscale process technologies. Investigates potential inventions typically 2 to 4 years prior to being applied to a product. Scope includes models and software to perform layout correction for high resolution reproduction on wafers. Applies software engineering methods, theories and research in the investigation and solution of technical RET problems. Defines and selects new approaches and implementation of RET software engineering applications, design specifications and parameters. Maintains substantial knowledge of state of the art principles and theories in lithography, optics, resists, modeling, and software engineering. Contributes to scientific literature, conferences, and the development of intellectual property. Coordinates interdepartmental activities and research efforts. Must be able to interact with both VLSI design and silicon process technology development, and mask making communities to ensure solutions are optimal. Additionally, can use use predictive modeling, statistics, machine learning, data mining, and other data analysis techniques to collect, explore, visualize, and to develop software algorithms and applications to compensate for empirical effects in photolithography imaging and etch pattern transferal process.

Qualifications

You must possess the below minimum requirements to be initially considered for this position. Relevant experience can be obtained through school work, classes and project work, internships, military training, and/or work experience.

This is an entry level position and compensation will be given accordingly.

Minimum Qualifications

Successful candidates must possess a Master's or Ph.D. in Electrical, Chemical, or Mechanical Engineering; Mathematics, Optics, Nano-Engineering, Materials Science, Physics or Related Scientific Discipline.
Candidates must have at least one of the following qualifications (having more than one will be preferred):

1+year experience in mathematics, including algebra, linear algebra, calculus, statistics and familiarity with DOE Techniques.
1+ years' experience in C++ Programming or Python scripting, Statistics packages such as JMP, General scientific applications such as MATLAB or Mathematica.
6+ months experience and comfort in Linux/Unix environments.
6+ months of experience in Computational simulation.
6+ months of experience in Semiconductor fabrication, Nano-Lithography.
6+ months of experience in algorithm development.
6+ months experience in Nanometrology (e.g. Scanning Electron Microscopy, Atomic Force Microscopy, etc.)
6+ months experience in Image Processing, Geometric and Fourier optics.


Inside this Business Group

As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth

Posting Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Initiates the research, development and implementation of Resolution Enhancement Techniques (RET) for nanoscale process technologies. Investigates potential inventions typically 2 to 4 years prior to being applied to a product. Scope includes models and software to perform layout correction for high resolution reproduction on wafers. Applies software engineering methods, theories and research in the investigation and solution of technical RET problems. Defines and selects new approaches and implementation of RET software engineering applications, design specifications and parameters. Maintains substantial knowledge of state of the art principles and theories in lithography, optics, resists, modeling, and software engineering. Contributes to scientific literature, conferences, and the development of intellectual property. Coordinates interdepartmental activities and research efforts. Must be able to interact with both VLSI design and silicon process technology development, and mask making communities to ensure solutions are optimal. Additionally, can use use predictive modeling, statistics, machine learning, data mining, and other data analysis techniques to collect, explore, visualize, and to develop software algorithms and applications to compensate for empirical effects in photolithography imaging and etch pattern transferal process.<br><br><strong><u>Qualifications<br><br></u></strong>You must possess the below minimum requirements to be initially considered for this position. Relevant experience can be obtained through school work, classes and project work, internships, military training, and/or work experience.<br><br><strong> This is an entry level position and compensation will be given accordingly.<br><br></strong><strong><u>Minimum Qualifications<br></u></strong><ul><li>Successful candidates must possess a Master's or Ph.D. in Electrical, Chemical, or Mechanical Engineering; Mathematics, Optics, Nano-Engineering, Materials Science, Physics or Related Scientific Discipline.</li><li>Candidates must have at least one of the following qualifications (having more than one will be preferred):<br><ul><li>1+year experience in mathematics, including algebra, linear algebra, calculus, statistics and familiarity with DOE Techniques.</li><li>1+ years' experience in C++ Programming or Python scripting, Statistics packages such as JMP, General scientific applications such as MATLAB or Mathematica.</li><li>6+ months experience and comfort in Linux/Unix environments.</li><li>6+ months of experience in Computational simulation.</li><li>6+ months of experience in Semiconductor fabrication, Nano-Lithography.</li><li>6+ months of experience in algorithm development.</li><li>6+ months experience in Nanometrology (e.g. Scanning Electron Microscopy, Atomic Force Microscopy, etc.)</li><li>6+ months experience in Image Processing, Geometric and Fourier optics.<br><br></li></ul></li></ul><strong>Inside this Business Group<br><br></strong>As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth<br><br><strong>Posting Statement<br><br></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Electrical/Electronic Manufacturing, Computer Software, Semiconductors"
Data Engineer,"Irvine, California, United States",LightBox,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-at-lightbox-2426800653?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=DRKhkkyoeok%2FrgovIXfkyA%3D%3D&position=15&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Initiates the research, development and implementation of Resolution Enhancement Techniques (RET) for nanoscale process technologies. Investigates potential inventions typically 2 to 4 years prior to being applied to a product. Scope includes models and software to perform layout correction for high resolution reproduction on wafers. Applies software engineering methods, theories and research in the investigation and solution of technical RET problems. Defines and selects new approaches and implementation of RET software engineering applications, design specifications and parameters. Maintains substantial knowledge of state of the art principles and theories in lithography, optics, resists, modeling, and software engineering. Contributes to scientific literature, conferences, and the development of intellectual property. Coordinates interdepartmental activities and research efforts. Must be able to interact with both VLSI design and silicon process technology development, and mask making communities to ensure solutions are optimal. Additionally, can use use predictive modeling, statistics, machine learning, data mining, and other data analysis techniques to collect, explore, visualize, and to develop software algorithms and applications to compensate for empirical effects in photolithography imaging and etch pattern transferal process.

Qualifications

You must possess the below minimum requirements to be initially considered for this position. Relevant experience can be obtained through school work, classes and project work, internships, military training, and/or work experience.

This is an entry level position and compensation will be given accordingly.

Minimum Qualifications

Successful candidates must possess a Master's or Ph.D. in Electrical, Chemical, or Mechanical Engineering; Mathematics, Optics, Nano-Engineering, Materials Science, Physics or Related Scientific Discipline.
Candidates must have at least one of the following qualifications (having more than one will be preferred):

1+year experience in mathematics, including algebra, linear algebra, calculus, statistics and familiarity with DOE Techniques.
1+ years' experience in C++ Programming or Python scripting, Statistics packages such as JMP, General scientific applications such as MATLAB or Mathematica.
6+ months experience and comfort in Linux/Unix environments.
6+ months of experience in Computational simulation.
6+ months of experience in Semiconductor fabrication, Nano-Lithography.
6+ months of experience in algorithm development.
6+ months experience in Nanometrology (e.g. Scanning Electron Microscopy, Atomic Force Microscopy, etc.)
6+ months experience in Image Processing, Geometric and Fourier optics.


Inside this Business Group

As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth

Posting Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Initiates the research, development and implementation of Resolution Enhancement Techniques (RET) for nanoscale process technologies. Investigates potential inventions typically 2 to 4 years prior to being applied to a product. Scope includes models and software to perform layout correction for high resolution reproduction on wafers. Applies software engineering methods, theories and research in the investigation and solution of technical RET problems. Defines and selects new approaches and implementation of RET software engineering applications, design specifications and parameters. Maintains substantial knowledge of state of the art principles and theories in lithography, optics, resists, modeling, and software engineering. Contributes to scientific literature, conferences, and the development of intellectual property. Coordinates interdepartmental activities and research efforts. Must be able to interact with both VLSI design and silicon process technology development, and mask making communities to ensure solutions are optimal. Additionally, can use use predictive modeling, statistics, machine learning, data mining, and other data analysis techniques to collect, explore, visualize, and to develop software algorithms and applications to compensate for empirical effects in photolithography imaging and etch pattern transferal process.<br><br><strong><u>Qualifications<br><br></u></strong>You must possess the below minimum requirements to be initially considered for this position. Relevant experience can be obtained through school work, classes and project work, internships, military training, and/or work experience.<br><br><strong> This is an entry level position and compensation will be given accordingly.<br><br></strong><strong><u>Minimum Qualifications<br></u></strong><ul><li>Successful candidates must possess a Master's or Ph.D. in Electrical, Chemical, or Mechanical Engineering; Mathematics, Optics, Nano-Engineering, Materials Science, Physics or Related Scientific Discipline.</li><li>Candidates must have at least one of the following qualifications (having more than one will be preferred):<br><ul><li>1+year experience in mathematics, including algebra, linear algebra, calculus, statistics and familiarity with DOE Techniques.</li><li>1+ years' experience in C++ Programming or Python scripting, Statistics packages such as JMP, General scientific applications such as MATLAB or Mathematica.</li><li>6+ months experience and comfort in Linux/Unix environments.</li><li>6+ months of experience in Computational simulation.</li><li>6+ months of experience in Semiconductor fabrication, Nano-Lithography.</li><li>6+ months of experience in algorithm development.</li><li>6+ months experience in Nanometrology (e.g. Scanning Electron Microscopy, Atomic Force Microscopy, etc.)</li><li>6+ months experience in Image Processing, Geometric and Fourier optics.<br><br></li></ul></li></ul><strong>Inside this Business Group<br><br></strong>As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth<br><br><strong>Posting Statement<br><br></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Electrical/Electronic Manufacturing, Computer Software, Semiconductors"
Data Engineer - Data & Integration,"New York, New York, United States",Haven Life,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-data-integration-at-haven-life-2429625002?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=n85ygTYcYaIL9jBRPBFdRQ%3D%3D&position=16&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Position Overview

We are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.

What You Will Do And Achieve

Reporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:

Create data pipelines to prepare and maintain data to solve specific use cases
Model and architect data to solve business problems
Adhere to high-quality development principles while delivering solutions on-time and on-budget
Analyze and resolve technical and application problems
Migrate existing workflows to newer infrastructures
Analyze use cases and propose solutions to meet business objectives
Who you are:Education

Bachelor's degree or better in Computer Science or equivalent
Must have an excellent academic record with a good grounding in Software Engineering theory including at least one modern programming language
Familiar with Standards, concepts, practices, and procedures within the field of Computer Science
Experience

2 to 5 years’ experience as a software engineer
Key Knowledge & Skills

At least one modern programming language, preferably Python
Knowledge and experience with OOP design patterns
Any RDBMS, such as MySQL, MS-SQL
Experience building scalable and maintainable data intensive applications
Pipeline orchestration technology, such as Prefect, Luigi or Airflow
Pipeline transformation tools, preferably dbt
Big data technologies, such as Hadoop & Spark, ideally including Python pandas and Dask
Core Competencies

Keen interest in data engineering and a “tinkering” mindset
Driven to continually learn about and incorporate new technologies
Thrive in a self-driven environment
Understanding and integrating human and machine workflows
Data Lake & Warehouse Modeling
Git, Docker, Kubernetes
Cloud infrastructure, such as Azure, AWS, or Google Cloud
Development on Linux
Other Desirable Attributes

Distributed systems – storage, compute & access patterns
Unstructured Data extraction – pdf, scraping
Graph database, such as Neo4j
Location – Spatial Data
Data catalog platforms, such as Amundsen

This job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.

This position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.

The employee will regularly be required to talk, hear, walk, use hands, kneel, crouch and lift up to 25 pounds. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

LightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.

We thank all applicants for their interest; however, only those selected for an interview will be contacted.

NO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Position Overview<br><br></u></strong>We are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.<br><br><strong><u>What You Will Do And Achieve<br><br></u></strong>Reporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:<br><ul><li>Create data pipelines to prepare and maintain data to solve specific use cases</li><li>Model and architect data to solve business problems</li><li>Adhere to high-quality development principles while delivering solutions on-time and on-budget</li><li>Analyze and resolve technical and application problems</li><li>Migrate existing workflows to newer infrastructures</li><li>Analyze use cases and propose solutions to meet business objectives</li></ul><strong>Who you are:</strong><strong>Education<br></strong><ul><li>Bachelor's degree or better in Computer Science or equivalent</li><li>Must have an excellent academic record with a good grounding in Software Engineering theory including at least one modern programming language</li><li>Familiar with Standards, concepts, practices, and procedures within the field of Computer Science</li></ul><strong>Experience<br></strong><ul><li>2 to 5 years’ experience as a software engineer</li></ul><strong>Key Knowledge &amp; Skills<br></strong><ul><li>At least one modern programming language, preferably Python</li><li>Knowledge and experience with OOP design patterns</li><li>Any RDBMS, such as MySQL, MS-SQL</li><li>Experience building scalable and maintainable data intensive applications</li><li>Pipeline orchestration technology, such as Prefect, Luigi or Airflow</li><li>Pipeline transformation tools, preferably dbt</li><li>Big data technologies, such as Hadoop &amp; Spark, ideally including Python pandas and Dask</li></ul><strong>Core Competencies<br></strong><ul><li>Keen interest in data engineering and a “tinkering” mindset</li><li>Driven to continually learn about and incorporate new technologies</li><li>Thrive in a self-driven environment</li><li>Understanding and integrating human and machine workflows</li><li>Data Lake &amp; Warehouse Modeling</li><li>Git, Docker, Kubernetes</li><li>Cloud infrastructure, such as Azure, AWS, or Google Cloud</li><li>Development on Linux</li></ul><strong>Other Desirable Attributes<br></strong><ul><li>Distributed systems – storage, compute &amp; access patterns</li><li>Unstructured Data extraction – pdf, scraping</li><li>Graph database, such as Neo4j</li><li>Location – Spatial Data</li><li>Data catalog platforms, such as Amundsen<br></li></ul>This job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.<br><br>This position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.<br><br>The employee will regularly be required to talk, hear, walk, use hands, kneel, crouch and lift up to 25 pounds. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><br>LightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.<br><br>We thank all applicants for their interest; however, only those selected for an interview will be contacted.<br><br><strong>NO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.</strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer - Python - San Francisco - $95-140K,"San Francisco, California, United States",Jefferson Frank,2021-01-22,https://www.linkedin.com/jobs/view/data-engineer-python-san-francisco-%2495-140k-at-jefferson-frank-2404137418?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=flxBmqnUS25fhby59KsQqw%3D%3D&position=17&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Haven Life is an insuretech innovator at MassMutual that offers a new way to get life insurance online that's actually simple.

We combine the culture of a startup with the stability and backing of a Fortune 100 company to create an environment that's truly unique.

Our diverse team is comprised of smart, collaborative people who think big, execute quickly and don't take themselves too seriously. We're located in New York's Flatiron District and in case you're wondering, yes, we provide free snacks. Cold brew too.

If you're creative, professional and kind, we love to hear from you.

You will be joining a small, experienced technology team as one of the main developers responsible for our advanced online financial services application. Experience with web development is a plus, although more important to us is real programming experience and thoughtfulness about how and why you do what you do.

Your job will require you to work closely with your fellow technology team members, coordinate with QA resources, and to communicate with business team members in the completion of your work. Working with other developers you might work on items such as: developing components for algorithmic or manual underwriting module, creating workflow tools for routing insurance applications, defining and applying rule sets for third party data feeds, or building customer-facing components for taking new business applications. The job will be varied and challenging.

Requirements

These are essential to success in this role:

4+ years of of experience as a developer in a data-centric application environment
Involvement in all aspects of data integration projects - from business requirements and interface discovery and definition through design, modeling, and development, to testing and deployment
A solid grounding in data-driven applications and concepts (data/object modeling, database systems, structured and unstructured data, enterprise data frameworks)
Extensive experience with diverse systems integration paradigms including nightly batch, intra-day incremental data loading, and near-real-time interfaces
Strong experience with production support, troubleshooting, and batch/interface optimization
Define and implement data quality and reconciliation processes across complex systems
High proficiency with Talend (ETL tool); extensive experience of SQL and query evaluation & optimization
Solid experience of DB development with PostgreSQL, Oracle, or other RDBMS (stored proc, trigger etc.)
Good knowledge with traditional object-oriented languages (especially in Javascript or GraphQL; Ruby and Python are plus)
Hands on experience on GraphDB (Neo4j) and Cypher or GraphQL query language
Comfortable expressing and defending points of view while respecting those of others
Excellent communication skills with a variety of audiences and varying degrees of technical knowledge
BA/BS degree in CS or equivalent major
Authorized to work in the US with or without sponsorship
Self-starter and self-motivated team player



These Skills Are Not Required But Are a Plus

Testing strategy definition and framework creation
Experiance with Informatica, AbInitio
Experience and familiarity with financial services or other mathematically oriented applications.
Working in a startup or agile development environments
Working experience of AWS Cloud and EKS Kubernetes framework
Experience in multi-platform websites (desktop, mobile)
Exposure to modern MVC (Model-view-controller) frameworks
Experience with, node, meteor, and/or angular frameworks a plus



Benefits

We have a stellar team of co-workers, a really cool office, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K).

The privacy of your personal information is important to us, click here to review our privacy notice.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Haven Life is an insuretech innovator at MassMutual that offers a new way to get life insurance online that's actually simple.<br><br>We combine the culture of a startup with the stability and backing of a Fortune 100 company to create an environment that's truly unique.<br><br>Our diverse team is comprised of smart, collaborative people who think big, execute quickly and don't take themselves too seriously. We're located in New York's Flatiron District and in case you're wondering, yes, we provide free snacks. Cold brew too.<br><br>If you're creative, professional and kind, we love to hear from you.<br><br>You will be joining a small, experienced technology team as one of the main developers responsible for our advanced online financial services application. Experience with web development is a plus, although more important to us is real programming experience and thoughtfulness about how and why you do what you do.<br><br>Your job will require you to work closely with your fellow technology team members, coordinate with QA resources, and to communicate with business team members in the completion of your work. Working with other developers you might work on items such as: developing components for algorithmic or manual underwriting module, creating workflow tools for routing insurance applications, defining and applying rule sets for third party data feeds, or building customer-facing components for taking new business applications. The job will be varied and challenging.<br><br><strong><u>Requirements<br><br></u></strong>These are essential to success in this role:<br><ul> <li>4+ years of of experience as a developer in a data-centric application environment</li> <li>Involvement in all aspects of data integration projects - from business requirements and interface discovery and definition through design, modeling, and development, to testing and deployment</li> <li>A solid grounding in data-driven applications and concepts (data/object modeling, database systems, structured and unstructured data, enterprise data frameworks)</li> <li>Extensive experience with diverse systems integration paradigms including nightly batch, intra-day incremental data loading, and near-real-time interfaces</li> <li>Strong experience with production support, troubleshooting, and batch/interface optimization</li> <li>Define and implement data quality and reconciliation processes across complex systems</li> <li>High proficiency with Talend (ETL tool); extensive experience of SQL and query evaluation &amp; optimization</li> <li>Solid experience of DB development with PostgreSQL, Oracle, or other RDBMS (stored proc, trigger etc.) </li> <li>Good knowledge with traditional object-oriented languages (especially in Javascript or GraphQL; Ruby and Python are plus)</li> <li>Hands on experience on GraphDB (Neo4j) and Cypher or GraphQL query language</li> <li>Comfortable expressing and defending points of view while respecting those of others</li> <li>Excellent communication skills with a variety of audiences and varying degrees of technical knowledge</li> <li>BA/BS degree in CS or equivalent major</li> <li>Authorized to work in the US with or without sponsorship</li> <li>Self-starter and self-motivated team player</li> <br><br></ul><strong><u>These Skills Are Not Required But Are a Plus<br></u></strong><ul> <li>Testing strategy definition and framework creation</li> <li>Experiance with Informatica, AbInitio</li> <li>Experience and familiarity with financial services or other mathematically oriented applications.</li> <li>Working in a startup or agile development environments</li> <li>Working experience of AWS Cloud and EKS Kubernetes framework</li> <li>Experience in multi-platform websites (desktop, mobile)</li> <li>Exposure to modern MVC (Model-view-controller) frameworks</li> <li>Experience with, node, meteor, and/or angular frameworks a plus</li> <br><br></ul><strong><u>Benefits<br><br></u></strong>We have a stellar team of co-workers, a really cool office, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K).<br><br>The privacy of your personal information is important to us, click here to review our privacy notice.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Integration Engineer,"Chicago, Illinois, United States",Green Thumb Industries (GTI),2021-02-10,https://www.linkedin.com/jobs/view/data-integration-engineer-at-green-thumb-industries-gti-2417931818?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=9XTYK1RpcxBtj1T5xg8yNg%3D%3D&position=18&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"Data Engineer - Python - San Francisco - $95-140K

One of my top clients is looking to bring on a number of Data engineers of varying levels of experience and salary. This is a great opportunity to join a team of strong developers in a fast paced collaborative environment.

The Ideal Candidate Will Have

Previous data engineering experience
Strong Python development experience particularly with Spark
Integration with Restful APIs
Experience with AWS technologies including S3, Glue, and Redshift

I am actively scheduling interviews for this role. To be submitted, please send your resume to w.pope1@jeffersonfrank.com
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Data Engineer - Python - San Francisco - $95-140K<br><br>One of my top clients is looking to bring on a number of Data engineers of varying levels of experience and salary. This is a great opportunity to join a team of strong developers in a fast paced collaborative environment.<br><br><strong><u>The Ideal Candidate Will Have<br></u></strong><ul><li> Previous data engineering experience</li><li> Strong Python development experience particularly with Spark</li><li> Integration with Restful APIs</li><li> Experience with AWS technologies including S3, Glue, and Redshift<br></li></ul>I am actively scheduling interviews for this role. To be submitted, please send your resume to w.pope1@jeffersonfrank.com</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Analytics Engineer,"New York, New York, United States","Starry, Inc.",2021-02-13,https://www.linkedin.com/jobs/view/analytics-engineer-at-starry-inc-2408974018?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=AQBoLzgDaIdVK2E71ZOgPg%3D%3D&position=19&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"The Role

The Data Integration Engineer is responsible to help build, automate, and maintain corporate automation workflows. As a green field project this is an incredibly exciting opportunity to help design the systems and team that you have always wanted to be a part of. As a Data Integration Engineer you are a problem solver and genuinely like helping others solve complex problems. We are specifically seeking a candidate with AWS integration technologies, Python, SQL, PowerShell.

Responsibilities

Translate Green Thumb business needs into technical specifications to design, build and deploy various Business Intelligence solutions
Work collaboratively with various business partners to assist in the design and implementation of analysis tools to answer business challenges
Drive operational excellence for data ingestion, transformation and publication to ensure confidence in systems
Partner with finance, operations, and technology to prioritize and define data and BI development needs
Work with business partners in different teams to identify new BI capabilities and projects
Analyze and visualize large scale data to present the findings and opportunities, and output solid analysis report with recommendations
Maintain and update existing scripts as well as create new ones to support various processes
Manage SaaS integrations and SQL databases, 0365 integration, and utilize AWS technologies (Glue, Data Pipeline, EC2, S3, EMR, RDS, etc.)
Sync your activities and share your experience with a diverse team
Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting



Qualifications

3+ years related experience, Bachelor's degree required in technical field; Masters Degree preferred
Proven proficiency in Python, SQL, AWS technologies
Proven experience and knowledge with major BI reporting tools, Tableau preferred
Advanced data analysis skills – e.g. database query construction, data warehousing, regression modeling, and experience in market and business analysis
Experience designing and implementing scalable ETL design and mappings, database query construction and data warehousing skills
Ability to make recommendations for new metrics, strategies, and methods to improve measurement and data collection practices
Experience in SharePoint Online management preferred
Great communication and troubleshooting skills
Passion for technology and growth mindset
Highly motivated, self-directed, innovative and able to work independently or among teams with keen judgement, common sense and resourcefulness
Adapts and thrives in a demanding, fast-paced environment
Possesses a high level of critical thinking
Operates with a high level of professionalism and integrity, including dealing with confidential information
Must understand and comply with the rules, regulations, policies, and procedures of Green Thumb
Must have a solid understanding of the Cannabis laws, rules and regulations and passion to further their understanding and knowledge of the industry and the laws.



Additional Requirements

Must pass any and all required background checks
Must be and remain compliant with all legal or company regulations for working in the industry
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>The Role<br><br></strong>The Data Integration Engineer is responsible to help build, automate, and maintain corporate automation workflows. As a green field project this is an incredibly exciting opportunity to help design the systems and team that you have always wanted to be a part of. As a Data Integration Engineer you are a problem solver and genuinely like helping others solve complex problems. We are specifically seeking a candidate with AWS integration technologies, Python, SQL, PowerShell.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Translate Green Thumb business needs into technical specifications to design, build and deploy various Business Intelligence solutions </li> <li>Work collaboratively with various business partners to assist in the design and implementation of analysis tools to answer business challenges </li> <li>Drive operational excellence for data ingestion, transformation and publication to ensure confidence in systems </li> <li>Partner with finance, operations, and technology to prioritize and define data and BI development needs </li> <li>Work with business partners in different teams to identify new BI capabilities and projects </li> </ul><ul> <li>Analyze and visualize large scale data to present the findings and opportunities, and output solid analysis report with recommendations </li> <li>Maintain and update existing scripts as well as create new ones to support various processes </li> <li>Manage SaaS integrations and SQL databases, 0365 integration, and utilize AWS technologies (Glue, Data Pipeline, EC2, S3, EMR, RDS, etc.) </li> <li>Sync your activities and share your experience with a diverse team </li> <li>Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting </li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li>3+ years related experience, Bachelor's degree required in technical field; Masters Degree preferred </li> <li>Proven proficiency in Python, SQL, AWS technologies </li> <li>Proven experience and knowledge with major BI reporting tools, Tableau preferred </li> </ul><ul> <li>Advanced data analysis skills – e.g. database query construction, data warehousing, regression modeling, and experience in market and business analysis </li> <li>Experience designing and implementing scalable ETL design and mappings, database query construction and data warehousing skills </li> <li>Ability to make recommendations for new metrics, strategies, and methods to improve measurement and data collection practices </li> <li>Experience in SharePoint Online management preferred </li> <li>Great communication and troubleshooting skills </li> </ul><ul> <li>Passion for technology and growth mindset </li> <li>Highly motivated, self-directed, innovative and able to work independently or among teams with keen judgement, common sense and resourcefulness </li> <li>Adapts and thrives in a demanding, fast-paced environment </li> <li>Possesses a high level of critical thinking </li> <li>Operates with a high level of professionalism and integrity, including dealing with confidential information </li> </ul><ul> <li>Must understand and comply with the rules, regulations, policies, and procedures of Green Thumb </li> <li>Must have a solid understanding of the Cannabis laws, rules and regulations and passion to further their understanding and knowledge of the industry and the laws. </li> <br><br></ul><strong><u>Additional Requirements<br></u></strong><ul> <li>Must pass any and all required background checks </li> </ul><ul> <li>Must be and remain compliant with all legal or company regulations for working in the industry</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Consumer Goods, Retail, Hospital & Health Care"
"Software Engineer, Implementation (Python)","South San Francisco, California, United States",Alpha Health,2021-02-06,https://www.linkedin.com/jobs/view/software-engineer-implementation-python-at-alpha-health-2429535171?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=lRGd9yS9dSdyUnDdkJ7fXg%3D%3D&position=20&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"About Starry

Starry is proud to be an Equal Opportunity workplace. Just like the internet service we provide, we do not discriminate. We welcome people from all over the world to share their knowledge and perspectives. At Starry, you can discover the many careers and opportunities that are made possible when you connect people to the limitless possibilities of the internet.

Our mission focuses on two things. First, we’re making the experience of accessing the internet simple, transparent, and delightful. Second, we’re bringing that experience to underserved communities around the world. We approach our mission with a cutting-edge wireless technology, customer service designed to delight, and a culture of innovation and intellectual curiosity.

Why you'll love working here

Starry is a fast-growing company, with incredible ambition to build new markets, and new products and services. At Starry, autonomy and creativity are rewarded; you’ll have control of your own time and the opportunity to develop your ideas and initiatives. The team is tightly-knit, highly collaborative, and very driven.

What You’ll Do

Design, build and maintain scalable data models to power self-service business intelligence tools and promote data-driven decision making
Own data projects end-to-end working with tools like Airflow, DBT, and Looker
Analyze complex datasets and communicate findings to stakeholders
Work with stakeholders across the organization to gather and understand data requirements
Architect and maintain pipelines for moving data into various third-party services, furthering our personalization capabilities
Build and maintain data tests and documentation
Serve as resident data quality advocate
Collaborate with engineering on infrastructure projects
Proactively seek out and investigate new technologies to advance Starry’s analytics practice



Skills And Experience Required

Eagerness to build a best-in-class data practice
4+ years of experience modeling, visualizing and interpreting data
Expert-level knowledge of SQL
Proficiency in a scripting language, Python preferred
Familiar with modern data technologies/stack such as Airflow, DBT, Snowflake, Redshift, Docker, Git, Looker, Mode, Tableau etc.
Enthusiasm for conducting reproducible analysis; we believe in code review, version control, and solid documentation
Strong ability to build collaborative, productive relationships with colleagues/teams across Starry
Skilled at working in an autonomous environment where you’ll work independently to execute on various projects



We work hard, so we take care of each other and try to enjoy ourselves along the way.

All Full Time Starry Employees Receive

100% employer paid low deductible health plan, dental plan, vision plan, AD&D and life insurance
401(k) retirement plan and stock options
12 weeks of 100% paid parental leave for new mothers and fathers after six months of continuous employment
Professional development assistance after six months of employment
Catered meals on a weekly basis for employees working in the office
Casual dress, community clubs, annual fitness reimbursement, stocked kitchen and other perks and discounts


Happy Interneting!

Qualified Applicants must be legally authorized for employment in the United States. Qualified Applicants will not require employer sponsored work authorization now or in the future for employment in the United States.

Disclaimer: This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Starry<br><br></u></strong>Starry is proud to be an Equal Opportunity workplace. Just like the internet service we provide, we do not discriminate. We welcome people from all over the world to share their knowledge and perspectives. At Starry, you can discover the many careers and opportunities that are made possible when you connect people to the limitless possibilities of the internet.<br><br>Our mission focuses on two things. First, we’re making the experience of accessing the internet simple, transparent, and delightful. Second, we’re bringing that experience to underserved communities around the world. We approach our mission with a cutting-edge wireless technology, customer service designed to delight, and a culture of innovation and intellectual curiosity.<br><br><strong>Why you'll love working here<br><br></strong>Starry is a fast-growing company, with incredible ambition to build new markets, and new products and services. At Starry, autonomy and creativity are rewarded; you’ll have control of your own time and the opportunity to develop your ideas and initiatives. The team is tightly-knit, highly collaborative, and very driven.<br><br><strong><u>What You’ll Do<br></u></strong><ul> <li>Design, build and maintain scalable data models to power self-service business intelligence tools and promote data-driven decision making</li> <li>Own data projects end-to-end working with tools like Airflow, DBT, and Looker</li> <li>Analyze complex datasets and communicate findings to stakeholders</li> <li>Work with stakeholders across the organization to gather and understand data requirements </li> <li>Architect and maintain pipelines for moving data into various third-party services, furthering our personalization capabilities</li> <li>Build and maintain data tests and documentation</li> <li>Serve as resident data quality advocate</li> <li>Collaborate with engineering on infrastructure projects</li> <li>Proactively seek out and investigate new technologies to advance Starry’s analytics practice</li> <br><br></ul><strong><u>Skills And Experience Required<br></u></strong><ul> <li>Eagerness to build a best-in-class data practice</li> <li>4+ years of experience modeling, visualizing and interpreting data</li> <li>Expert-level knowledge of SQL</li> <li>Proficiency in a scripting language, Python preferred</li> <li>Familiar with modern data technologies/stack such as Airflow, DBT, Snowflake, Redshift, Docker, Git, Looker, Mode, Tableau etc.</li> <li>Enthusiasm for conducting reproducible analysis; we believe in code review, version control, and solid documentation</li> <li>Strong ability to build collaborative, productive relationships with colleagues/teams across Starry</li> <li>Skilled at working in an autonomous environment where you’ll work independently to execute on various projects</li> <br><br></ul><strong>We work hard, so we take care of each other and try to enjoy ourselves along the way. <br><br></strong><strong><u>All Full Time Starry Employees Receive<br></u></strong><ul> <li>100% employer paid low deductible health plan, dental plan, vision plan, AD&amp;D and life insurance</li> <li>401(k) retirement plan and stock options </li> <li>12 weeks of 100% paid parental leave for new mothers and fathers after six months of continuous employment</li> <li>Professional development assistance after six months of employment</li> <li>Catered meals on a weekly basis for employees working in the office</li> <li>Casual dress, community clubs, annual fitness reimbursement, stocked kitchen and other perks and discounts</li> <br></ul>Happy Interneting!<br><br>Qualified Applicants must be legally authorized for employment in the United States. Qualified Applicants will not require employer sponsored work authorization now or in the future for employment in the United States.<br><br>Disclaimer: This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Telecommunications"
Data Developer,"Denver, Colorado, United States",Janus Henderson Investors U.S.,2021-02-17,https://www.linkedin.com/jobs/view/data-developer-at-janus-henderson-investors-u-s-2426507454?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=G00xNUoXsKao2YY2LdBdPQ%3D%3D&position=22&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"We are a leading independent global asset manager, dedicated to delivering the best outcomes for our clients through a highly diversified range of actively-managed products. We are truly global, supporting our individual and institutional investors across a range of products, encompassing equities, fixed income, multi-asset and alternatives. Our high-energy and collaborative culture at Janus Henderson helps our client achieve their goals and ensures that our people love the place they work.

The department

The Technology department plays a crucial role in supporting the success of Janus Henderson. We are responsible for developing, implementing and supporting state-of-the-art software to support our fund management, trading, distribution and operational areas and for maintaining a stable and resilient IT infrastructure platform.

The Global Technology department has 400+ employees, running numerous change projects across all areas of the firm, including vendor implementations, regulatory change, in-house development, as well as overseeing change delivery from third party suppliers.

The Distribution Technology team is responsible for providing the best solutions and newest innovations to the globally located Sales, Marketing, Operations and Product teams within Distribution. The team work very closely with the business and third parties and have a strong relationship and respected reputation for delivering change. Change is either delivered through major initiative funded projects or through Product Management.

Overview of the role

You will be a data developer in the team, working with Distribution Reporting teams and Data Management teams in Technology with a focus on building data integration solutions for the automation of our Distribution Reporting.

This role requires a significant set of technical skills, including knowledge of SQL database and multiple programming languages. The ideal candidate has software development skills and can pick up new technologies and assist in all aspects of the team’s work such as development using data warehouse and master data vendor platform tools.

You will need excellent problem-solving skills and strong teamwork skills.

The distribution data space is in a transition period. Significant data assets are located in on-premise hardware and software, such as Oracle, Informatica, Autosys, and Microsoft SQL Server. Currently Janus Henderson is embarking on an effort to consolidate data stores from all of our global locations and provide an efficient and reliable set of distribution ready data for use in all reporting teams. This consolidation is being designed and built in the cloud, so you would have experience in one or more cloud platforms.

Duties and responsibilities

You Will

Understand about Data Lakes, Data Warehouses and Data Marts
Have knowledge of at least one high-level programming language
Be able to apply a basic understanding of cloud-native applications to write code
Understand of the use of containers in the development process
Use data to discover tasks that can be automated
Perform unit and integration tests, as well as support UAT testing
Provide estimates, work independently and meet deadlines
Manage the releases and the related builds in each environment
Knowledge of cloud computing
Perform development, testing, and support using such tools as AWS Glue, Azure Data Factory or similar ETL/ELT platforms, as well as knowledge of data warehousing, data mart, and data lake concepts and processes
Work within the team as directed to improve existing data designs and data models, including relational table structures, using Unix Shell Scripting, Oracle, SQL Server, Azure SQL Data Warehouse, or Amazon Redshift
Support and learn the associated scheduling logic for data pipelines using scheduling tool such as Autosys or Airflow
Read and translate logical data models and use ETL skills to load the physical layer, based on an understanding of timing of data loads, data transformation, and optimization of ETL load performance.
Provide production support and test approaches for data management projects
Coordinate with infrastructure teams as required
Work on the automation of data quality and testing checks of data pipeline code
Work within the agile delivery methodology, picking up data development tasks within a 2-week sprint, providing work estimates for tasks to project management, and participating in agile ceremonies.
Following existing Janus standards and procedures for data movement
Work closely with Janus Henderson Technology (business analysts and developers) and Janus Henderson Business people on efforts of various scope
Carry out additional duties as assigned.



Supervisory responsibilities

No



Technical Skills And Qualifications

Solid understanding of Azure DevOps (Git, build and release pipelines), Python, databricks, and snowflake as a requirement. Nice to haves are: PowerBI, and Attunity Replicate
3 years+ in information technology and/or application development
3 years+ database development and python scripting experience
Must have experience with SQL Server (2014/16) and Oracle 11g
Ability to write, test/debug, and tune complex queries
Write stored procedures and stored functions
Experience with architecture principles and design best practices
Must have experience with data modeling in an Enterprise Data warehouse and data marts
Autosys or comparable job scheduler (control-M or Tivoli)
Bachelors degree in Computer Science or related preferred, or certification with relevant work experience



Competencies required

Role

In addition to putting clients first, acting like an owner, and succeeding as a team, the competencies for this role include

Team working – collegiate approach to work circulating important information and contributing to team discussion.
Problem solving / analysis – understanding of complex issues and problems, ability to distill them into measurable components and able to identify practical / pragmatic solutions.
Self-motivated with an enthusiastic approach – a completer-finisher able to work on own initiative with a focus on ownership to resolution.
Ability to communicate, present, influence, reason and demonstrate the ability to articulate information technology concepts to non-technology personnel in a clear and compelling manner.
Ability to deliver on full workloads and exceed high expectations while remaining focused and organised in a fast-paced environment



Ongoing competence in the role to be assessed, in line with applicable regulatory requirements, by:

Annual performance appraisal
Completion of all assigned compliance training
Annual attestation (Knowledge and Competence in-scope roles only)



Compliance requirements

At a Minimum The Role Will Require You To

Place the interest of Janus Henderson’s Clients first, act in accordance with TCF (Treating Customers Fairly) principles
Understand and follow laws and regulations applicable for your role, seeking the help of your supervising manager or Compliance if additional guidance is required
Understand and abide by all Janus Henderson policies applicable to your role, and seek support/guidance of the policy owner guidance when required
You are ultimately accountable for your actions and responsible for seeking further information on any or all of the above as necessary.



Compensation Information

The base salary range for this position is $85,000 - $100,000 This range is estimated for this role. Actual pay may be different.

Legal disclosure

Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as set by Janus Henderson at its sole discretion).

You should be willing to adhere to the provisions of our Investment Advisory Code of Ethics related to personal securities activities and other disclosure and certification requirements, including past political contributions and political activities. Applicants’ past political contributions or activity may impact applicants’ eligibility for this position.

Annual Bonus Opportunity: Position is eligible to receive an annual discretionary bonus award from the profit pool. The profit pool is funded based on Company profits. Individual bonuses are determined based on Company, department, team and individual performance.

Benefits: Janus Henderson is committed to offering a comprehensive total rewards package to eligible employees that includes; competitive compensation, pension/retirement plans, and various health, wellbeing and lifestyle benefits. To learn more about our offerings please visit the Why Join Us section on the career page here.

Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as determined by Janus Henderson at its sole discretion).
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are a leading independent global asset manager, dedicated to delivering the best outcomes for our clients through a highly diversified range of actively-managed products. We are truly global, supporting our individual and institutional investors across a range of products, encompassing equities, fixed income, multi-asset and alternatives. Our high-energy and collaborative culture at Janus Henderson helps our client achieve their goals and ensures that our people love the place they work.<br><br>The department<br><br>The Technology department plays a crucial role in supporting the success of Janus Henderson. We are responsible for developing, implementing and supporting state-of-the-art software to support our fund management, trading, distribution and operational areas and for maintaining a stable and resilient IT infrastructure platform.<br><br>The Global Technology department has 400+ employees, running numerous change projects across all areas of the firm, including vendor implementations, regulatory change, in-house development, as well as overseeing change delivery from third party suppliers.<br><br>The Distribution Technology team is responsible for providing the best solutions and newest innovations to the globally located Sales, Marketing, Operations and Product teams within Distribution. The team work very closely with the business and third parties and have a strong relationship and respected reputation for delivering change. Change is either delivered through major initiative funded projects or through Product Management.<br><br>Overview of the role<br><br>You will be a data developer in the team, working with Distribution Reporting teams and Data Management teams in Technology with a focus on building data integration solutions for the automation of our Distribution Reporting.<br><br>This role requires a significant set of technical skills, including knowledge of SQL database and multiple programming languages. The ideal candidate has software development skills and can pick up new technologies and assist in all aspects of the team’s work such as development using data warehouse and master data vendor platform tools.<br><br>You will need excellent problem-solving skills and strong teamwork skills.<br><br>The distribution data space is in a transition period. Significant data assets are located in on-premise hardware and software, such as Oracle, Informatica, Autosys, and Microsoft SQL Server. Currently Janus Henderson is embarking on an effort to consolidate data stores from all of our global locations and provide an efficient and reliable set of distribution ready data for use in all reporting teams. This consolidation is being designed and built in the cloud, so you would have experience in one or more cloud platforms.<br><br>Duties and responsibilities<br><br><strong><u>You Will<br></u></strong><ul> <li>Understand about Data Lakes, Data Warehouses and Data Marts</li> <li>Have knowledge of at least one high-level programming language</li> <li>Be able to apply a basic understanding of cloud-native applications to write code</li> <li>Understand of the use of containers in the development process</li> <li>Use data to discover tasks that can be automated</li> <li>Perform unit and integration tests, as well as support UAT testing</li> <li>Provide estimates, work independently and meet deadlines</li> <li>Manage the releases and the related builds in each environment</li> <li>Knowledge of cloud computing</li> <li>Perform development, testing, and support using such tools as AWS Glue, Azure Data Factory or similar ETL/ELT platforms, as well as knowledge of data warehousing, data mart, and data lake concepts and processes</li> <li>Work within the team as directed to improve existing data designs and data models, including relational table structures, using Unix Shell Scripting, Oracle, SQL Server, Azure SQL Data Warehouse, or Amazon Redshift</li> <li>Support and learn the associated scheduling logic for data pipelines using scheduling tool such as Autosys or Airflow</li> <li>Read and translate logical data models and use ETL skills to load the physical layer, based on an understanding of timing of data loads, data transformation, and optimization of ETL load performance.</li> <li>Provide production support and test approaches for data management projects</li> <li>Coordinate with infrastructure teams as required</li> <li>Work on the automation of data quality and testing checks of data pipeline code</li> <li>Work within the agile delivery methodology, picking up data development tasks within a 2-week sprint, providing work estimates for tasks to project management, and participating in agile ceremonies.</li> <li>Following existing Janus standards and procedures for data movement</li> <li>Work closely with Janus Henderson Technology (business analysts and developers) and Janus Henderson Business people on efforts of various scope</li> <li>Carry out additional duties as assigned. </li> <br><br></ul>Supervisory responsibilities<br><ul> <li>No</li> <br><br></ul><strong><u>Technical Skills And Qualifications<br></u></strong><ul> <li>Solid understanding of Azure DevOps (Git, build and release pipelines), Python, databricks, and snowflake as a requirement. Nice to haves are: PowerBI, and Attunity Replicate</li> <li>3 years+ in information technology and/or application development</li> <li>3 years+ database development and python scripting experience</li> <li>Must have experience with SQL Server (2014/16) and Oracle 11g</li> <li>Ability to write, test/debug, and tune complex queries</li> <li>Write stored procedures and stored functions</li> <li>Experience with architecture principles and design best practices</li> <li>Must have experience with data modeling in an Enterprise Data warehouse and data marts</li> <li>Autosys or comparable job scheduler (control-M or Tivoli)</li> <li>Bachelors degree in Computer Science or related preferred, or certification with relevant work experience</li> <br><br></ul>Competencies required<br><br><strong><u>Role<br><br></u></strong>In addition to putting clients first, acting like an owner, and succeeding as a team, the competencies for this role include<br><ul> <li>Team working – collegiate approach to work circulating important information and contributing to team discussion.</li> <li>Problem solving / analysis – understanding of complex issues and problems, ability to distill them into measurable components and able to identify practical / pragmatic solutions.</li> <li>Self-motivated with an enthusiastic approach – a completer-finisher able to work on own initiative with a focus on ownership to resolution.</li> <li>Ability to communicate, present, influence, reason and demonstrate the ability to articulate information technology concepts to non-technology personnel in a clear and compelling manner.</li> <li>Ability to deliver on full workloads and exceed high expectations while remaining focused and organised in a fast-paced environment</li> <br><br></ul>Ongoing competence in the role to be assessed, in line with applicable regulatory requirements, by:<br><ul> <li>Annual performance appraisal</li> <li>Completion of all assigned compliance training</li> <li>Annual attestation (Knowledge and Competence in-scope roles only)</li> <br><br></ul>Compliance requirements<br><br><strong><u>At a Minimum The Role Will Require You To<br></u></strong><ul> <li>Place the interest of Janus Henderson’s Clients first, act in accordance with TCF (Treating Customers Fairly) principles</li> <li>Understand and follow laws and regulations applicable for your role, seeking the help of your supervising manager or Compliance if additional guidance is required </li> <li>Understand and abide by all Janus Henderson policies applicable to your role, and seek support/guidance of the policy owner guidance when required </li> <li>You are ultimately accountable for your actions and responsible for seeking further information on any or all of the above as necessary. </li> <br><br></ul>Compensation Information<br><br>The base salary range for this position is $85,000 - $100,000 This range is estimated for this role. Actual pay may be different.<br><br>Legal disclosure<br><br>Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as set by Janus Henderson at its sole discretion).<br><br>You should be willing to adhere to the provisions of our Investment Advisory Code of Ethics related to personal securities activities and other disclosure and certification requirements, including past political contributions and political activities. Applicants’ past political contributions or activity may impact applicants’ eligibility for this position.<br><br><strong>Annual Bonus Opportunity:</strong> Position is eligible to receive an annual discretionary bonus award from the profit pool. The profit pool is funded based on Company profits. Individual bonuses are determined based on Company, department, team and individual performance.<br><br><strong>Benefits:</strong> Janus Henderson is committed to offering a comprehensive total rewards package to eligible employees that includes; competitive compensation, pension/retirement plans, and various health, wellbeing and lifestyle benefits. To learn more about our offerings please visit the Why Join Us section on the career page here.<br><br>Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as determined by Janus Henderson at its sole discretion).</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Banking, Financial Services"
Data Engineer,"Overland Park, Kansas, United States",Shamrock Trading Corporation,2021-02-15,https://www.linkedin.com/jobs/view/data-engineer-at-shamrock-trading-corporation-2425047002?refId=7b72ca91-045b-4fe9-afe3-64500f4400c7&trackingId=wV9XqGxqxDjdeb18PNeZYA%3D%3D&position=23&pageNum=9&trk=public_jobs_job-result-card_result-card_full-click,"We are a leading independent global asset manager, dedicated to delivering the best outcomes for our clients through a highly diversified range of actively-managed products. We are truly global, supporting our individual and institutional investors across a range of products, encompassing equities, fixed income, multi-asset and alternatives. Our high-energy and collaborative culture at Janus Henderson helps our client achieve their goals and ensures that our people love the place they work.

The department

The Technology department plays a crucial role in supporting the success of Janus Henderson. We are responsible for developing, implementing and supporting state-of-the-art software to support our fund management, trading, distribution and operational areas and for maintaining a stable and resilient IT infrastructure platform.

The Global Technology department has 400+ employees, running numerous change projects across all areas of the firm, including vendor implementations, regulatory change, in-house development, as well as overseeing change delivery from third party suppliers.

The Distribution Technology team is responsible for providing the best solutions and newest innovations to the globally located Sales, Marketing, Operations and Product teams within Distribution. The team work very closely with the business and third parties and have a strong relationship and respected reputation for delivering change. Change is either delivered through major initiative funded projects or through Product Management.

Overview of the role

You will be a data developer in the team, working with Distribution Reporting teams and Data Management teams in Technology with a focus on building data integration solutions for the automation of our Distribution Reporting.

This role requires a significant set of technical skills, including knowledge of SQL database and multiple programming languages. The ideal candidate has software development skills and can pick up new technologies and assist in all aspects of the team’s work such as development using data warehouse and master data vendor platform tools.

You will need excellent problem-solving skills and strong teamwork skills.

The distribution data space is in a transition period. Significant data assets are located in on-premise hardware and software, such as Oracle, Informatica, Autosys, and Microsoft SQL Server. Currently Janus Henderson is embarking on an effort to consolidate data stores from all of our global locations and provide an efficient and reliable set of distribution ready data for use in all reporting teams. This consolidation is being designed and built in the cloud, so you would have experience in one or more cloud platforms.

Duties and responsibilities

You Will

Understand about Data Lakes, Data Warehouses and Data Marts
Have knowledge of at least one high-level programming language
Be able to apply a basic understanding of cloud-native applications to write code
Understand of the use of containers in the development process
Use data to discover tasks that can be automated
Perform unit and integration tests, as well as support UAT testing
Provide estimates, work independently and meet deadlines
Manage the releases and the related builds in each environment
Knowledge of cloud computing
Perform development, testing, and support using such tools as AWS Glue, Azure Data Factory or similar ETL/ELT platforms, as well as knowledge of data warehousing, data mart, and data lake concepts and processes
Work within the team as directed to improve existing data designs and data models, including relational table structures, using Unix Shell Scripting, Oracle, SQL Server, Azure SQL Data Warehouse, or Amazon Redshift
Support and learn the associated scheduling logic for data pipelines using scheduling tool such as Autosys or Airflow
Read and translate logical data models and use ETL skills to load the physical layer, based on an understanding of timing of data loads, data transformation, and optimization of ETL load performance.
Provide production support and test approaches for data management projects
Coordinate with infrastructure teams as required
Work on the automation of data quality and testing checks of data pipeline code
Work within the agile delivery methodology, picking up data development tasks within a 2-week sprint, providing work estimates for tasks to project management, and participating in agile ceremonies.
Following existing Janus standards and procedures for data movement
Work closely with Janus Henderson Technology (business analysts and developers) and Janus Henderson Business people on efforts of various scope
Carry out additional duties as assigned.



Supervisory responsibilities

No



Technical Skills And Qualifications

Solid understanding of Azure DevOps (Git, build and release pipelines), Python, databricks, and snowflake as a requirement. Nice to haves are: PowerBI, and Attunity Replicate
3 years+ in information technology and/or application development
3 years+ database development and python scripting experience
Must have experience with SQL Server (2014/16) and Oracle 11g
Ability to write, test/debug, and tune complex queries
Write stored procedures and stored functions
Experience with architecture principles and design best practices
Must have experience with data modeling in an Enterprise Data warehouse and data marts
Autosys or comparable job scheduler (control-M or Tivoli)
Bachelors degree in Computer Science or related preferred, or certification with relevant work experience



Competencies required

Role

In addition to putting clients first, acting like an owner, and succeeding as a team, the competencies for this role include

Team working – collegiate approach to work circulating important information and contributing to team discussion.
Problem solving / analysis – understanding of complex issues and problems, ability to distill them into measurable components and able to identify practical / pragmatic solutions.
Self-motivated with an enthusiastic approach – a completer-finisher able to work on own initiative with a focus on ownership to resolution.
Ability to communicate, present, influence, reason and demonstrate the ability to articulate information technology concepts to non-technology personnel in a clear and compelling manner.
Ability to deliver on full workloads and exceed high expectations while remaining focused and organised in a fast-paced environment



Ongoing competence in the role to be assessed, in line with applicable regulatory requirements, by:

Annual performance appraisal
Completion of all assigned compliance training
Annual attestation (Knowledge and Competence in-scope roles only)



Compliance requirements

At a Minimum The Role Will Require You To

Place the interest of Janus Henderson’s Clients first, act in accordance with TCF (Treating Customers Fairly) principles
Understand and follow laws and regulations applicable for your role, seeking the help of your supervising manager or Compliance if additional guidance is required
Understand and abide by all Janus Henderson policies applicable to your role, and seek support/guidance of the policy owner guidance when required
You are ultimately accountable for your actions and responsible for seeking further information on any or all of the above as necessary.



Compensation Information

The base salary range for this position is $85,000 - $100,000 This range is estimated for this role. Actual pay may be different.

Legal disclosure

Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as set by Janus Henderson at its sole discretion).

You should be willing to adhere to the provisions of our Investment Advisory Code of Ethics related to personal securities activities and other disclosure and certification requirements, including past political contributions and political activities. Applicants’ past political contributions or activity may impact applicants’ eligibility for this position.

Annual Bonus Opportunity: Position is eligible to receive an annual discretionary bonus award from the profit pool. The profit pool is funded based on Company profits. Individual bonuses are determined based on Company, department, team and individual performance.

Benefits: Janus Henderson is committed to offering a comprehensive total rewards package to eligible employees that includes; competitive compensation, pension/retirement plans, and various health, wellbeing and lifestyle benefits. To learn more about our offerings please visit the Why Join Us section on the career page here.

Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as determined by Janus Henderson at its sole discretion).
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are a leading independent global asset manager, dedicated to delivering the best outcomes for our clients through a highly diversified range of actively-managed products. We are truly global, supporting our individual and institutional investors across a range of products, encompassing equities, fixed income, multi-asset and alternatives. Our high-energy and collaborative culture at Janus Henderson helps our client achieve their goals and ensures that our people love the place they work.<br><br>The department<br><br>The Technology department plays a crucial role in supporting the success of Janus Henderson. We are responsible for developing, implementing and supporting state-of-the-art software to support our fund management, trading, distribution and operational areas and for maintaining a stable and resilient IT infrastructure platform.<br><br>The Global Technology department has 400+ employees, running numerous change projects across all areas of the firm, including vendor implementations, regulatory change, in-house development, as well as overseeing change delivery from third party suppliers.<br><br>The Distribution Technology team is responsible for providing the best solutions and newest innovations to the globally located Sales, Marketing, Operations and Product teams within Distribution. The team work very closely with the business and third parties and have a strong relationship and respected reputation for delivering change. Change is either delivered through major initiative funded projects or through Product Management.<br><br>Overview of the role<br><br>You will be a data developer in the team, working with Distribution Reporting teams and Data Management teams in Technology with a focus on building data integration solutions for the automation of our Distribution Reporting.<br><br>This role requires a significant set of technical skills, including knowledge of SQL database and multiple programming languages. The ideal candidate has software development skills and can pick up new technologies and assist in all aspects of the team’s work such as development using data warehouse and master data vendor platform tools.<br><br>You will need excellent problem-solving skills and strong teamwork skills.<br><br>The distribution data space is in a transition period. Significant data assets are located in on-premise hardware and software, such as Oracle, Informatica, Autosys, and Microsoft SQL Server. Currently Janus Henderson is embarking on an effort to consolidate data stores from all of our global locations and provide an efficient and reliable set of distribution ready data for use in all reporting teams. This consolidation is being designed and built in the cloud, so you would have experience in one or more cloud platforms.<br><br>Duties and responsibilities<br><br><strong><u>You Will<br></u></strong><ul> <li>Understand about Data Lakes, Data Warehouses and Data Marts</li> <li>Have knowledge of at least one high-level programming language</li> <li>Be able to apply a basic understanding of cloud-native applications to write code</li> <li>Understand of the use of containers in the development process</li> <li>Use data to discover tasks that can be automated</li> <li>Perform unit and integration tests, as well as support UAT testing</li> <li>Provide estimates, work independently and meet deadlines</li> <li>Manage the releases and the related builds in each environment</li> <li>Knowledge of cloud computing</li> <li>Perform development, testing, and support using such tools as AWS Glue, Azure Data Factory or similar ETL/ELT platforms, as well as knowledge of data warehousing, data mart, and data lake concepts and processes</li> <li>Work within the team as directed to improve existing data designs and data models, including relational table structures, using Unix Shell Scripting, Oracle, SQL Server, Azure SQL Data Warehouse, or Amazon Redshift</li> <li>Support and learn the associated scheduling logic for data pipelines using scheduling tool such as Autosys or Airflow</li> <li>Read and translate logical data models and use ETL skills to load the physical layer, based on an understanding of timing of data loads, data transformation, and optimization of ETL load performance.</li> <li>Provide production support and test approaches for data management projects</li> <li>Coordinate with infrastructure teams as required</li> <li>Work on the automation of data quality and testing checks of data pipeline code</li> <li>Work within the agile delivery methodology, picking up data development tasks within a 2-week sprint, providing work estimates for tasks to project management, and participating in agile ceremonies.</li> <li>Following existing Janus standards and procedures for data movement</li> <li>Work closely with Janus Henderson Technology (business analysts and developers) and Janus Henderson Business people on efforts of various scope</li> <li>Carry out additional duties as assigned. </li> <br><br></ul>Supervisory responsibilities<br><ul> <li>No</li> <br><br></ul><strong><u>Technical Skills And Qualifications<br></u></strong><ul> <li>Solid understanding of Azure DevOps (Git, build and release pipelines), Python, databricks, and snowflake as a requirement. Nice to haves are: PowerBI, and Attunity Replicate</li> <li>3 years+ in information technology and/or application development</li> <li>3 years+ database development and python scripting experience</li> <li>Must have experience with SQL Server (2014/16) and Oracle 11g</li> <li>Ability to write, test/debug, and tune complex queries</li> <li>Write stored procedures and stored functions</li> <li>Experience with architecture principles and design best practices</li> <li>Must have experience with data modeling in an Enterprise Data warehouse and data marts</li> <li>Autosys or comparable job scheduler (control-M or Tivoli)</li> <li>Bachelors degree in Computer Science or related preferred, or certification with relevant work experience</li> <br><br></ul>Competencies required<br><br><strong><u>Role<br><br></u></strong>In addition to putting clients first, acting like an owner, and succeeding as a team, the competencies for this role include<br><ul> <li>Team working – collegiate approach to work circulating important information and contributing to team discussion.</li> <li>Problem solving / analysis – understanding of complex issues and problems, ability to distill them into measurable components and able to identify practical / pragmatic solutions.</li> <li>Self-motivated with an enthusiastic approach – a completer-finisher able to work on own initiative with a focus on ownership to resolution.</li> <li>Ability to communicate, present, influence, reason and demonstrate the ability to articulate information technology concepts to non-technology personnel in a clear and compelling manner.</li> <li>Ability to deliver on full workloads and exceed high expectations while remaining focused and organised in a fast-paced environment</li> <br><br></ul>Ongoing competence in the role to be assessed, in line with applicable regulatory requirements, by:<br><ul> <li>Annual performance appraisal</li> <li>Completion of all assigned compliance training</li> <li>Annual attestation (Knowledge and Competence in-scope roles only)</li> <br><br></ul>Compliance requirements<br><br><strong><u>At a Minimum The Role Will Require You To<br></u></strong><ul> <li>Place the interest of Janus Henderson’s Clients first, act in accordance with TCF (Treating Customers Fairly) principles</li> <li>Understand and follow laws and regulations applicable for your role, seeking the help of your supervising manager or Compliance if additional guidance is required </li> <li>Understand and abide by all Janus Henderson policies applicable to your role, and seek support/guidance of the policy owner guidance when required </li> <li>You are ultimately accountable for your actions and responsible for seeking further information on any or all of the above as necessary. </li> <br><br></ul>Compensation Information<br><br>The base salary range for this position is $85,000 - $100,000 This range is estimated for this role. Actual pay may be different.<br><br>Legal disclosure<br><br>Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as set by Janus Henderson at its sole discretion).<br><br>You should be willing to adhere to the provisions of our Investment Advisory Code of Ethics related to personal securities activities and other disclosure and certification requirements, including past political contributions and political activities. Applicants’ past political contributions or activity may impact applicants’ eligibility for this position.<br><br><strong>Annual Bonus Opportunity:</strong> Position is eligible to receive an annual discretionary bonus award from the profit pool. The profit pool is funded based on Company profits. Individual bonuses are determined based on Company, department, team and individual performance.<br><br><strong>Benefits:</strong> Janus Henderson is committed to offering a comprehensive total rewards package to eligible employees that includes; competitive compensation, pension/retirement plans, and various health, wellbeing and lifestyle benefits. To learn more about our offerings please visit the Why Join Us section on the career page here.<br><br>Janus Henderson (including its subsidiaries) will not maintain existing or sponsor new industry registrations or licenses where not supported by an employee’s job functions (as determined by Janus Henderson at its sole discretion).</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Banking, Financial Services"
Data Analyst/Engineer,"San Diego, California, United States",San Diego Workforce Partnership,2021-01-22,https://www.linkedin.com/jobs/view/data-analyst-engineer-at-san-diego-workforce-partnership-2390128975?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=EKJXPIpnvmPSnvz2HdZ2IQ%3D%3D&position=2&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Company Overview

Shamrock Trading Corporation is the parent company for a family of brands in transportation services, finance and technology. Headquartered in Overland Park, KS, Shamrock has been named “Best Places to Work” by the Kansas City Business Journal every year since 2015. We also have offices in Chicago, Dallas, Laredo, Midland and Nashville.

With an average annual revenue growth of 25% since 1986, Shamrock’s success is attributed to three key factors: hiring the best people, cultivating long-term relationships with our customers and continually evolving in the marketplace.

Responsibilities

Shamrock Trading Corporation is looking for a Data Engineer who wants to utilize their expertise in data warehousing, data pipeline creation/support and analytical reporting skills by joining our Data Services team. This role is responsible for gathering and analyzing data from several internal and external sources, designing a cloud-focused data platform for analytics and business intelligence, reliably providing data to our analysts.
This role requires significant understanding of data mining and analytical techniques. An ideal candidate will have strong technical capabilities, business acumen, and the ability to work effectively with cross-functional teams.

Work with Data architects to understand current data models, to build pipelines for data ingestion and transformation.
Design, build, and maintain a framework for pipeline observation and monitoring, focusing on reliability and performance of jobs.
Surface data integration errors to the proper teams, ensuring timely processing of new data.
Provide technical consultation for other team members on best practices for automation, monitoring, and deployments.
Provide technical consultation for the team with “infrastructure as code” best practices: building deployment processes utilizing technologies such as Terraform or AWS Cloud Formation.


Qualifications

Bachelor’s degree in computer science, data science or related technical field, or equivalent practical experience
Proven experience with relational and NoSQL databases (e.g. Postgres, Redshift, MongoDB, Elasticsearch)
Experience building and maintaining AWS based data pipelines: Technologies currently utilized include AWS Lambda, Docker / ECS, MSK
Mid/Senior level development utilizing Python: (Pandas/Numpy, Boto3, SimpleSalesforce)
Experience with version control (git) and peer code reviews
Enthusiasm for working directly with customer teams (Business units and internal IT)
Preferred but not required qualifications include:

Experience with data processing and analytics using AWS Glue or Apache Spark
Hands-on experience building data-lake style infrastructures using streaming data set technologies (particularly with Apache Kafka)
Experience data processing using Parquet and Avro
Experience developing, maintaining, and deploying Python packages
Experience with Kafka and the Kafka Connect ecosystem.
Familiarity with data visualization techniques using tools such as Grafana, PowerBI, AWS Quick Sight, and Excel.


Benefits Package

At Shamrock we hire bright, ambitious people and give them the tools they need to be successful. By investing in training and development, we hope to become a long-term career for employees, where there are always opportunities for advancement. Shamrock also offers a premier set of benefits for employees and their families:

Medical: Fully-paid healthcare, dental and vision premiums for employees and eligible dependents
Financial: Generous company 401(k) contributions and employee stock ownership after one year
Wellness: Onsite gym, jogging trail and discounted membership to nearby fitness center
Work-Life Balance: Competitive PTO and paid leave options


Options

Apply for this job online Apply

Share

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed

Need help finding the right job?

We can recommend jobs specifically for you! Click here to get started.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Company Overview<br><br></u></strong>Shamrock Trading Corporation is the parent company for a family of brands in transportation services, finance and technology. Headquartered in Overland Park, KS, Shamrock has been named “Best Places to Work” by the Kansas City Business Journal every year since 2015. We also have offices in Chicago, Dallas, Laredo, Midland and Nashville.<br><br>With an average annual revenue growth of 25% since 1986, Shamrock’s success is attributed to three key factors: hiring the best people, cultivating long-term relationships with our customers and continually evolving in the marketplace.<br><br><strong><u>Responsibilities<br><br></u></strong>Shamrock Trading Corporation is looking for a Data Engineer who wants to utilize their expertise in data warehousing, data pipeline creation/support and analytical reporting skills by joining our Data Services team. This role is responsible for gathering and analyzing data from several internal and external sources, designing a cloud-focused data platform for analytics and business intelligence, reliably providing data to our analysts.<br>This role requires significant understanding of data mining and analytical techniques. An ideal candidate will have strong technical capabilities, business acumen, and the ability to work effectively with cross-functional teams.<br><ul><li> Work with Data architects to understand current data models, to build pipelines for data ingestion and transformation. </li><li> Design, build, and maintain a framework for pipeline observation and monitoring, focusing on reliability and performance of jobs. </li><li> Surface data integration errors to the proper teams, ensuring timely processing of new data. </li><li> Provide technical consultation for other team members on best practices for automation, monitoring, and deployments. </li><li> Provide technical consultation for the team with “infrastructure as code” best practices: building deployment processes utilizing technologies such as Terraform or AWS Cloud Formation. <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> Bachelor’s degree in computer science, data science or related technical field, or equivalent practical experience </li><li> Proven experience with relational and NoSQL databases (e.g. Postgres, Redshift, MongoDB, Elasticsearch) </li><li> Experience building and maintaining AWS based data pipelines: Technologies currently utilized include AWS Lambda, Docker / ECS, MSK </li><li> Mid/Senior level development utilizing Python: (Pandas/Numpy, Boto3, SimpleSalesforce) </li><li> Experience with version control (git) and peer code reviews </li><li> Enthusiasm for working directly with customer teams (Business units and internal IT) </li><li> Preferred but not required qualifications include:<br><ul><li> Experience with data processing and analytics using AWS Glue or Apache Spark </li><li> Hands-on experience building data-lake style infrastructures using streaming data set technologies (particularly with Apache Kafka) </li><li> Experience data processing using Parquet and Avro </li><li> Experience developing, maintaining, and deploying Python packages </li><li> Experience with Kafka and the Kafka Connect ecosystem. </li><li> Familiarity with data visualization techniques using tools such as Grafana, PowerBI, AWS Quick Sight, and Excel. <br><br></li></ul></li></ul><strong><u>Benefits Package<br><br></u></strong>At Shamrock we hire bright, ambitious people and give them the tools they need to be successful. By investing in training and development, we hope to become a long-term career for employees, where there are always opportunities for advancement. Shamrock also offers a premier set of benefits for employees and their families:<br><ul><li> <strong>Medical</strong>: Fully-paid healthcare, dental and vision premiums for employees and eligible dependents </li><li> <strong>Financial</strong>: Generous company 401(k) contributions and employee stock ownership after one year </li><li> <strong>Wellness</strong>: Onsite gym, jogging trail and discounted membership to nearby fitness center </li><li> <strong>Work-Life Balance</strong>: Competitive PTO and paid leave options <br><br></li></ul><strong>Options<br><br></strong>Apply for this job online Apply<br><br>Share<br><br>Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.<br><br>Share on your newsfeed<br><br><strong> Need help finding the right job? <br><br></strong>We can recommend jobs specifically for you! Click here to get started.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer - Data Science Engineering,"Boston, Massachusetts, United States",Datadog,2021-02-07,https://www.linkedin.com/jobs/view/data-engineer-data-science-engineering-at-datadog-2354673770?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=evCNbpVqD2nxlpHSIZS4Qw%3D%3D&position=3&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"The San Diego Workforce Partnership, Inc. (the Workforce Partnership) is a nonprofit entity chartered by the City and County of San Diego to administer employment and training programs that empower job seekers to meet the current and future workforce needs of employers in San Diego County.

Our Values

Collaboration Engaging in inclusive, respectful relationships among colleagues, customers and community that foster the achievement of shared goals.
Excellence Driving quality, innovation and measurable outcomes through a customer-centered focus and a high-performance culture.
Stewardship Strategic, efficient, effective use of resources to meet the evolving needs of our customers and community with the highest levels of integrity.



Position Summary

We are looking for a Data Analyst who will support our program, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to understand program outcomes and performance and using models to test the effectiveness of different courses of action. The ideal candidate must also have experience with data pipeline development and database modeling. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

To support our research and data analysis efforts, SDWP is looking for a talented and experienced Data Scientist who will focus on

The Work

What You Will Be Doing

Managing projects end-to-end to meet objectives and deadlines
Working with IT and cross functional teams to identify data sources, design data ingestion, clean up, and pre-processing scripts as needed.
Leading research, data analysis and development projects
Working with development team to develop and support data pipeline automations using Python and Pantaho.
Establishing scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Analyzing, processing, evaluating and documenting large data sets
Designing data structure and data storage schemes for efficient data manipulation and information retrieval
Leveraging tools for data processing and information retrieval
Developing data driven models to quantify the value of a given data set
Organizing and merging data from multiple sources, and running data quality assurance checks
Maintaining and enhancing our Data Analytics landscape
Designing, architecting and supporting new and existing data and ETL pipelines and recommend improvements and modifications



Requirements

What you bring

Practical experience with programming languages like SQL, Python, R
Practical experience building complex extraction, transformation, and loading (ETL) pipelines to clean and fuse data together. Examples of what we use Domo’s ETL magic and Pentaho.
Extensive knowledge of relational databases and data modeling
Worked with large scale data systems
Experience with identifying analytic insight in data, developing visualizations, presenting findings to stakeholders, and statistical analysis techniques



Your Experience And Knowledge

+2 years working as a data analyst or data engineer is required
Demonstrated ability with business intelligence tools (e.g., Domo, Tableau, PowerBI)
Experience working with and creating data architectures
A drive to learn and master new technologies and techniques
Degree in Applied Mathematics, Computer Science, or Electrical Engineering



Benefits

We Love to Take Care of Our Workforce Partnership Associates – PTO, PTO Sell-Back Program. Generous Employer Paid Benefits (Platinum Plans), Learning and Professional Development company paid program. Equity, Diversity and Inclusion Committee, Activities Committee, Pension Plan, and 457 Retirement Plan. The salary range for this position is $80,000-$85,000 DOE.

At the Workforce Partnership, we don’t just accept difference — we celebrate it, we support it, and we thrive on it for the benefit of our employees, and the work that we do in the communities we serve. We are proud to be an equal opportunity workplace for all. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. Auxiliary aids and services are available upon request to individuals with disabilities.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The San Diego Workforce Partnership, Inc. (the Workforce Partnership) is a nonprofit entity chartered by the City and County of San Diego to administer employment and training programs that empower job seekers to meet the current and future workforce needs of employers in San Diego County.<br><br><strong>Our Values<br></strong><ul> <li>Collaboration Engaging in inclusive, respectful relationships among colleagues, customers and community that foster the achievement of shared goals.</li> <li>Excellence Driving quality, innovation and measurable outcomes through a customer-centered focus and a high-performance culture.</li> <li>Stewardship Strategic, efficient, effective use of resources to meet the evolving needs of our customers and community with the highest levels of integrity.</li> <br><br></ul><strong><u>Position Summary<br><br></u></strong>We are looking for a Data Analyst who will support our program, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to understand program outcomes and performance and using models to test the effectiveness of different courses of action. The ideal candidate must also have experience with data pipeline development and database modeling. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.<br><br>To support our research and data analysis efforts, SDWP is looking for a talented and experienced Data Scientist who will focus on<br><br><strong>The Work<br><br></strong><strong><u>What You Will Be Doing<br></u></strong><ul> <li>Managing projects end-to-end to meet objectives and deadlines</li> <li>Working with IT and cross functional teams to identify data sources, design data ingestion, clean up, and pre-processing scripts as needed. </li> <li>Leading research, data analysis and development projects </li> <li>Working with development team to develop and support data pipeline automations using Python and Pantaho. </li> <li>Establishing scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation</li> <li>Analyzing, processing, evaluating and documenting large data sets</li> <li>Designing data structure and data storage schemes for efficient data manipulation and information retrieval</li> <li>Leveraging tools for data processing and information retrieval</li> <li>Developing data driven models to quantify the value of a given data set</li> <li>Organizing and merging data from multiple sources, and running data quality assurance checks</li> <li>Maintaining and enhancing our Data Analytics landscape </li> <li>Designing, architecting and supporting new and existing data and ETL pipelines and recommend improvements and modifications</li> <br><br></ul><strong><u>Requirements<br><br></u></strong><strong>What you bring<br></strong><ul> <li>Practical experience with programming languages like SQL, Python, R</li> <li>Practical experience building complex extraction, transformation, and loading (ETL) pipelines to clean and fuse data together. Examples of what we use Domo’s ETL magic and Pentaho. </li> <li>Extensive knowledge of relational databases and data modeling </li> <li>Worked with large scale data systems </li> <li>Experience with identifying analytic insight in data, developing visualizations, presenting findings to stakeholders, and statistical analysis techniques</li> <br><br></ul><strong><u>Your Experience And Knowledge<br></u></strong><ul> <li>+2 years working as a data analyst or data engineer is required</li> <li>Demonstrated ability with business intelligence tools (e.g., Domo, Tableau, PowerBI)</li> <li>Experience working with and creating data architectures</li> <li>A drive to learn and master new technologies and techniques</li> <li>Degree in Applied Mathematics, Computer Science, or Electrical Engineering</li> <br><br></ul><u><strong>Benefits<br><br></strong></u><strong>We Love to Take Care of Our Workforce Partnership Associates</strong> – PTO, PTO Sell-Back Program. Generous Employer Paid Benefits (Platinum Plans), Learning and Professional Development company paid program. Equity, Diversity and Inclusion Committee, Activities Committee, Pension Plan, and 457 Retirement Plan. The salary range for this position is $80,000-$85,000 DOE.<br><br>At the Workforce Partnership, we don’t just accept difference — we celebrate it, we support it, and we thrive on it for the benefit of our employees, and the work that we do in the communities we serve. We are proud to be an equal opportunity workplace for all. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. Auxiliary aids and services are available upon request to individuals with disabilities.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Analyst,Full-time,"Information Technology and Services, Nonprofit Organization Management, Financial Services"
Data Engineer,"Boston, Massachusetts, United States",Cervello,2021-02-03,https://www.linkedin.com/jobs/view/data-engineer-at-cervello-2384568771?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=wJ%2BvIGYQlaDNCUwXoco1Ew%3D%3D&position=4&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"About Datadog

We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies.

Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way. We need you to design and build machine learning-powered products that help our customers learn from their data and make better decisions in real-time.

The Team

We extract and manage data and events from our core products and live systems to make them centrally available for our Data Science team in both batch and real-time ways. We enable Data Scientists to productionize their models and expose their data assets to the rest of the company.

If you’re excited to work on a fast-moving data engineering team with the best open-source data tools at high scale, we want to meet you.

You Will

Build distributed, real-time, high-volume data pipelines and work together with others to enable high-scale Data Science
Do it with Spark, Luigi, Kafka and other open-source technologies
Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more
Join a tightly knit team solving hard problems the right way
Own meaningful parts of our service, have an impact, grow with the company



Requirements

You have a BS/MS/PhD in a scientific field or equivalent experience
You have built and operated data pipelines for real customers in production systems
You are fluent in several programming languages (JVM & otherwise)
You enjoy wrangling huge amounts of data and exploring new data sets
You value code simplicity and performance
You want to work in a fast, high growth startup environment that respects its engineers and customers
You are preferably familiar with Spark and/or Hadoop and know how to put machine learning models in production



Is this you? Send your resume and link to your GitHub if available.

Equal Opportunity At Datadog

Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

Your Privacy

For more information on how we maintain the privacy of the information you submit as part of your application, please refer to our Applicant and Candidate Privacy Notice.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Datadog<br><br></u></strong>We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies.<br><br>Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way. We need you to design and build machine learning-powered products that help our customers learn from their data and make better decisions in real-time.<br><br><strong><u>The Team<br><br></u></strong>We extract and manage data and events from our core products and live systems to make them centrally available for our Data Science team in both batch and real-time ways. We enable Data Scientists to productionize their models and expose their data assets to the rest of the company.<br><br>If you’re excited to work on a fast-moving data engineering team with the best open-source data tools at high scale, we want to meet you.<br><br><strong><u>You Will<br></u></strong><ul> <li>Build distributed, real-time, high-volume data pipelines and work together with others to enable high-scale Data Science</li> <li>Do it with Spark, Luigi, Kafka and other open-source technologies</li> <li>Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more</li> <li>Join a tightly knit team solving hard problems the right way</li> <li>Own meaningful parts of our service, have an impact, grow with the company</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>You have a BS/MS/PhD in a scientific field or equivalent experience</li> <li>You have built and operated data pipelines for real customers in production systems</li> <li>You are fluent in several programming languages (JVM &amp; otherwise)</li> <li>You enjoy wrangling huge amounts of data and exploring new data sets</li> <li>You value code simplicity and performance</li> <li>You want to work in a fast, high growth startup environment that respects its engineers and customers</li> <li>You are preferably familiar with Spark and/or Hadoop and know how to put machine learning models in production</li> <br><br></ul>Is this you? Send your resume and link to your GitHub if available.<br><br><strong><u>Equal Opportunity At Datadog<br><br></u></strong>Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.<br><br><strong><u>Your Privacy<br><br></u></strong>For more information on how we maintain the privacy of the information you submit as part of your application, please refer to our Applicant and Candidate Privacy Notice.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Fort Worth, Texas, United States",Freese and Nichols,2021-02-10,https://www.linkedin.com/jobs/view/data-scientist-at-freese-and-nichols-2418335346?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=44OX7YMfMoBqCMRewGmctQ%3D%3D&position=5&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Summary

You have experience with client projects and in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.

Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science


Qualifications

Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds

ABOUT US: OUR WORKPLACE IS FUN AND FAST-PACED:
We are Cervello. We believe in the power of connected data. We are laser focused on helping organizations harness the interconnectedness of digital, data and decision-making. We are problem solvers and builders focused on helping our clients win with data. Our culture is cool and innovative. Our environment is casual and conducive to collaboration and problem solving. We take our work seriously but not ourselves. It’s the perfect balance of freedom and accountability. If you want to be part of something great – join us!

Equal Employment Opportunity and Nondiscrimination
Cervello prides itself on providing a culture that allows employees to bring their best selves to work every day. Our people can feel comfortable, confident, and joyful to do great things for our firm, our teams, and our clients. Cervello aims to build diverse capabilities to help our clients solve their most mission critical problems. Cervello is committed to building a diverse, unbiased and inclusive workforce. Cervello is an equal opportunity employer; we recruit, hire, train, promote, develop, and provide other conditions of employment without regard to a person’s gender identity or expression, sexual orientation, race, religion, age, national origin, disability, marital status, pregnancy status, veteran status, genetic information or any other differences consistent with applicable laws. This includes providing reasonable accommodation for disabilities, or religious beliefs and practices. Members of communities historically underrepresented in analytics and consulting are encouraged to apply.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Summary<br><br></u></strong>You have experience with client projects and in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.<br><ul><li>Plan and execute secure, good practice data integration strategies and approaches</li><li>Acquire, ingest, and process data from multiple sources and systems into Big Data platforms</li><li>Create and manage data environments in the Cloud</li><li>Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models</li><li>Have a strong understanding of Information Security principles to ensure compliant handling and management of client data</li><li>This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science<br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>Experience on client-facing projects, including working in close-knit teams</li><li>Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)</li><li>Experience or familiarity with real-time ingestion and streaming frameworks is a plus</li><li>Experience and desire to work with open source and branded open source frameworks</li><li>Experience working on projects within the cloud ideally AWS or Azure</li><li>Experience with NLP, Machine Learning, etc. is a plus</li><li>Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time</li><li>Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R</li><li>Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models</li><li>Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.</li><li>A deep personal motivation to always produce outstanding work for your clients and colleagues</li><li>Excel in team collaboration and working with others from diverse skill-sets and backgrounds<br></li></ul><strong>ABOUT US: OUR WORKPLACE IS FUN AND FAST-PACED:<br></strong>We are Cervello. We believe in the power of connected data. We are laser focused on helping organizations harness the interconnectedness of digital, data and decision-making. We are problem solvers and builders focused on helping our clients win with data. Our culture is cool and innovative. Our environment is casual and conducive to collaboration and problem solving. We take our work seriously but not ourselves. It’s the perfect balance of freedom and accountability. If you want to be part of something great – join us!<br><br><strong>Equal Employment Opportunity and Nondiscrimination<br></strong>Cervello prides itself on providing a culture that allows employees to bring their best selves to work every day. Our people can feel comfortable, confident, and joyful to do great things for our firm, our teams, and our clients. Cervello aims to build diverse capabilities to help our clients solve their most mission critical problems. Cervello is committed to building a diverse, unbiased and inclusive workforce. Cervello is an equal opportunity employer; we recruit, hire, train, promote, develop, and provide other conditions of employment without regard to a person’s gender identity or expression, sexual orientation, race, religion, age, national origin, disability, marital status, pregnancy status, veteran status, genetic information or any other differences consistent with applicable laws. This includes providing reasonable accommodation for disabilities, or religious beliefs and practices. Members of communities historically underrepresented in analytics and consulting are encouraged to apply.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Management Consulting"
Analytics Software Engineer II,"Northridge, California, United States",Medtronic,2021-02-18,https://www.linkedin.com/jobs/view/analytics-software-engineer-ii-at-medtronic-2427684092?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=u8GmIsaDd1HQ8GqTNfSR6Q%3D%3D&position=6&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"At Freese and Nichols, everyone on our team gets to make a meaningful difference in our communities. For more than 125 years, we have been planning and designing the infrastructure our society needs: developing water supplies, designing roadways and bridges, preparing for natural disasters, and much more. We’ve built our business on long-term relationships with clients and employees alike, resulting in financial stability, career opportunities, and a nationally recognized workplace culture.

We offer a comprehensive benefits package including health insurance, paid time off, 401(k) matching, paid overtime for salaried employees, tuition reimbursement, and much more. Our unique culture creates an environment for professional growth where we focus on caring for our clients, coworkers, and the communities where we work. Join our team of 1,000 employees as we continue to expand our services throughout the United States. Learn more about working here at freese.com/careers

Summary

Responsible for supporting the development and expansion of a service line providing technical business intelligence, data science, and data engineering expertise for data collection, pipelines, storage, analytics, and visualization. As part of our Management Consulting team and in partnership with our technical teams across the company, this position will help identify, prioritize, scope, and execute business intelligence and data science initiatives to foster a culture of data-driven decision making. The Data Scientist will work with other technical subject matter experts to establish company standards in analytic methodologies, tools, skill development paths, and applications maintenance. This position includes opportunities to develop and manage a team of data engineers, data scientists, and data analysts, actively participate in the team’s work, and provide ongoing thought leadership around data science and business intelligence vision / roadmap to the broader Management Consulting team and the company overall.

Essential Functions

Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Business Intelligence and Data Science
Coordinate and execute initiatives focused on transforming data into actionable insights informing FNI’s clients’ business decisions through our professional services.
Use available business intelligence tools (e.g., Power BI, Esri ArcGIS) to design dynamic data products with analytical findings best suited for sponsoring departments’ needs. (e.g., dashboards, maps, graphs, charts)
When appropriate, coordinate application of more advanced data science principles to meet department needs. (e.g., regression analysis, forecasting, machine learning, natural language processing)
Coordinate the preparation of different types of data from separate and distinct data storage sources for analysis, including data transformation, cleaning, and normalizing, using tools, methods, and programming languages. (e.g., R, Python, SQL)
Identify and coordinate data engineering and database administration roles establishing appropriate data storage and extract, transform, and load (ETL) pipelines for required data services on clients’ projects.
Project Coordination and Execution
Develop data-driven solutions for internal and external clients’ needs.
Assist in the identification of business intelligence analysts, data scientists, data engineers, and database administrators to execute projects from conception to completion.
Develop approaches to deliver high quality data products meeting internal and external clients’ expectations.
Identify approaches to engage additional resources when needed on projects, including within FNI, hiring, and through teaming partnerships.
Facilitate ‘business development’ activities with FNI’s technical service lines, assisting in scoping projects to deliver data products that inform key strategic and business decisions.
Data Governance and Management
In coordination with a select team of FNI leadership, support the development and implementation of the data management policies and data management plans for the effective and secure acquisition, storage, and use of data for internal and external clients.
Coordinate approaches and technical standards with FNI’s Business Technology team for effective data governance and management.
Other duties as assigned. This job description is not designed to cover or contain a comprehensive list of activities or responsibilities that are required of the employee for this job. Duties and activities may change at any time.

Skills Needed

Broad knowledge of business intelligence and data science methods.
Experience working with multiple data types and data storage methods to prepare data for analysis.
Ability to design and deliver compelling, informative, and interactive data products using variety of tools to communicate analysis results to stakeholders with varying data literacy levels.
General knowledge of best practices in data storage, data sharing, data quality, and ethical and inclusive use of data.
Willingness and ability to learn new tools, programming languages, and data methods and techniques as needed.
Excellent verbal and written communication skills, with ability to interact with all levels of personnel within and external to the company in a positive and cooperative manner.

Software Knowledge

Working Knowledge Of

eResource
BST
Bluebeam
Sales Funnel
Cosential

Intermediate Knowledge Of

Specialty software (e.g., Experience with Microsoft Power BI, Tableau, Python)
Experience with cloud services (e.g., AWS, Azure)

Preferred Skills

Graduate-level or intensive coursework in data analytics, statistics, data science, or another field with strong data methods courses.
Several years of team and project management experience
At least 2 years of experience with the Public Sector industry.
Experience with specific business intelligence and data science methods, including visual analytics, explorative analytics, descriptive and inferential statistics, hypothesis testing, projection and forecasting, regression analysis, and evaluation and experimental design.
Experience with data extraction, cleaning, and processing, combining data from multiple sources and formats, and creating data pipelines to streamline and automate processes (e.g., SQL)
Experience establishing or working within an enterprise data ecosystem (e.g., data warehouse, data marts)
Experience working in a variety of new technology systems to extract data, including using extract, transform, load (ETL) tools or application programming interfaces (API)
Familiarity with geographic information system (GIS) and mapping concepts, particularly use of Esri and Microsoft products
Experience leading workshops and training sessions on technical topics for non-technical audiences.
Experience working in more advanced data science areas (e.g., machine learning, natural language processing)

F reese and Nichols is firmly committed to Equal Employment Opportunity (EEO) and prohibits employment discrimination for employees and applicants based on his or her age, race, color, pregnancy, gender, gender identity, sexual orientation, national origin, religion, marital status, citizenship, or because he or she is an individual with a disability, protected veteran or other status protected by federal, state, and local laws.

We recognize that our workforce reflects the increasingly diverse nature of our society, and we strive to take advantage of that diversity with both our external and internal customers. As a Federal Contractor, Freese and Nichols is an equal employment, affirmative action employer.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Freese and Nichols, everyone on our team gets to make a meaningful difference in our communities. For more than 125 years, we have been planning and designing the infrastructure our society needs: developing water supplies, designing roadways and bridges, preparing for natural disasters, and much more. We’ve built our business on long-term relationships with clients and employees alike, resulting in financial stability, career opportunities, and a nationally recognized workplace culture.<br><br>We offer a comprehensive benefits package including health insurance, paid time off, 401(k) matching, paid overtime for salaried employees, tuition reimbursement, and much more. Our unique culture creates an environment for professional growth where we focus on caring for our clients, coworkers, and the communities where we work. Join our team of 1,000 employees as we continue to expand our services throughout the United States. Learn more about working here at freese.com/careers<br><br><strong><u>Summary<br><br></u></strong>Responsible for supporting the development and expansion of a service line providing technical business intelligence, data science, and data engineering expertise for data collection, pipelines, storage, analytics, and visualization. As part of our Management Consulting team and in partnership with our technical teams across the company, this position will help identify, prioritize, scope, and execute business intelligence and data science initiatives to foster a culture of data-driven decision making. The Data Scientist will work with other technical subject matter experts to establish company standards in analytic methodologies, tools, skill development paths, and applications maintenance. This position includes opportunities to develop and manage a team of data engineers, data scientists, and data analysts, actively participate in the team’s work, and provide ongoing thought leadership around data science and business intelligence vision / roadmap to the broader Management Consulting team and the company overall.<br><br><strong><u>Essential Functions<br><br></u></strong>Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><ul><li>Business Intelligence and Data Science </li><li>Coordinate and execute initiatives focused on transforming data into actionable insights informing FNI’s clients’ business decisions through our professional services.</li><li>Use available business intelligence tools (e.g., Power BI, Esri ArcGIS) to design dynamic data products with analytical findings best suited for sponsoring departments’ needs. (e.g., dashboards, maps, graphs, charts)</li><li>When appropriate, coordinate application of more advanced data science principles to meet department needs. (e.g., regression analysis, forecasting, machine learning, natural language processing)</li><li>Coordinate the preparation of different types of data from separate and distinct data storage sources for analysis, including data transformation, cleaning, and normalizing, using tools, methods, and programming languages. (e.g., R, Python, SQL)</li><li>Identify and coordinate data engineering and database administration roles establishing appropriate data storage and extract, transform, and load (ETL) pipelines for required data services on clients’ projects.</li> <li>Project Coordination and Execution</li> <li>Develop data-driven solutions for internal and external clients’ needs.</li><li>Assist in the identification of business intelligence analysts, data scientists, data engineers, and database administrators to execute projects from conception to completion.</li><li>Develop approaches to deliver high quality data products meeting internal and external clients’ expectations.</li><li>Identify approaches to engage additional resources when needed on projects, including within FNI, hiring, and through teaming partnerships.</li><li>Facilitate ‘business development’ activities with FNI’s technical service lines, assisting in scoping projects to deliver data products that inform key strategic and business decisions.</li> <li>Data Governance and Management</li> <li>In coordination with a select team of FNI leadership, support the development and implementation of the data management policies and data management plans for the effective and secure acquisition, storage, and use of data for internal and external clients.</li><li>Coordinate approaches and technical standards with FNI’s Business Technology team for effective data governance and management.</li> <li>Other duties as assigned. This job description is not designed to cover or contain a comprehensive list of activities or responsibilities that are required of the employee for this job. Duties and activities may change at any time.<br></li></ul><strong><u>Skills Needed<br></u></strong><ul><li>Broad knowledge of business intelligence and data science methods.</li><li>Experience working with multiple data types and data storage methods to prepare data for analysis.</li><li>Ability to design and deliver compelling, informative, and interactive data products using variety of tools to communicate analysis results to stakeholders with varying data literacy levels.</li><li>General knowledge of best practices in data storage, data sharing, data quality, and ethical and inclusive use of data.</li><li>Willingness and ability to learn new tools, programming languages, and data methods and techniques as needed.</li><li>Excellent verbal and written communication skills, with ability to interact with all levels of personnel within and external to the company in a positive and cooperative manner.<br></li></ul><strong>Software Knowledge <br><br></strong><strong><u>Working Knowledge Of<br></u></strong><ul><li>eResource</li><li>BST</li><li>Bluebeam</li><li>Sales Funnel</li><li>Cosential<br></li></ul><strong><u>Intermediate Knowledge Of<br></u></strong><ul><li>Specialty software (e.g., Experience with Microsoft Power BI, Tableau, Python)</li> <li>Experience with cloud services (e.g., AWS, Azure)<br></li></ul><strong><u>Preferred Skills<br></u></strong><ul><li>Graduate-level or intensive coursework in data analytics, statistics, data science, or another field with strong data methods courses.</li><li>Several years of team and project management experience</li> <li>At least 2 years of experience with the Public Sector industry.</li><li>Experience with specific business intelligence and data science methods, including visual analytics, explorative analytics, descriptive and inferential statistics, hypothesis testing, projection and forecasting, regression analysis, and evaluation and experimental design.</li><li>Experience with data extraction, cleaning, and processing, combining data from multiple sources and formats, and creating data pipelines to streamline and automate processes (e.g., SQL)</li><li>Experience establishing or working within an enterprise data ecosystem (e.g., data warehouse, data marts)</li><li>Experience working in a variety of new technology systems to extract data, including using extract, transform, load (ETL) tools or application programming interfaces (API)</li><li>Familiarity with geographic information system (GIS) and mapping concepts, particularly use of Esri and Microsoft products</li><li>Experience leading workshops and training sessions on technical topics for non-technical audiences.</li><li>Experience working in more advanced data science areas (e.g., machine learning, natural language processing)<br></li></ul>F reese and Nichols is firmly committed to Equal Employment Opportunity (EEO) and prohibits employment discrimination for employees and applicants based on his or her age, race, color, pregnancy, gender, gender identity, sexual orientation, national origin, religion, marital status, citizenship, or because he or she is an individual with a disability, protected veteran or other status protected by federal, state, and local laws.<br><br>We recognize that our workforce reflects the increasingly diverse nature of our society, and we strive to take advantage of that diversity with both our external and internal customers. As a Federal Contractor, Freese and Nichols is an equal employment, affirmative action employer.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Architecture & Planning, Civil Engineering"
Data Scientist,"Boston, Massachusetts, United States",Known,2021-02-10,https://www.linkedin.com/jobs/view/data-scientist-at-known-2404834647?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=krBhQ4z3fa1lcyhF2JYOJg%3D%3D&position=7&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Careers that Change Lives

This exciting positions involves research and development of algorithms related to glucose sensing technology. The role will involve all aspects of the R&D process, including data gathering, analysis, theory and algorithm development through to validation for regulatory submissions. A successful candidate will have experience leading technical programs and will have in-depth technical knowledge of signal processing and machine learning methodologies. Preference will be given to candidates with direct experience in the software and algorithm development lifecycle.

Engineers create our market-leading portfolio of innovations. Combine the best of your experience with training and mentorship to move forward. If you want a challenging, energizing, rewarding career that changes lives, join us. Help us bring the next generation of life-changing medical technology to patients worldwide.

We believe that when people from different cultures, genders, and points of view come together, innovation is the result —and everyone wins. Medtronic walks the walk, creating an inclusive culture where you can thrive.

DIABETES BUSINESS DESCRIPTION:

The Diabetes Group is working with the global community to change the way people manage diabetes. Together, we will transform diabetes care by expanding access, integrating care, and improving outcomes; so people with diabetes can enjoy greater freedom and better health.

We value what makes you unique. Be a part of a company that thinks differently to solve problems, make progress, and deliver meaningful innovations.
A Day in the Life
Responsibilities may include the following and other duties may be assigned.

Designs, develops, tests, debugs and implements operating systems components, software tools and utilities.
Determines systems software design requirements.
Ensures that system improvements are successfully implemented and monitored to increase efficiency.
Generates systems software engineering policies, standards and procedures.



Must Have: Minimum Requirements
Bachelors degree required

Minimum of 2 years of relevant experience, or advanced degree with 0 years of experience


Nice to Have
Knowledge of and direct experience working with signal processing and machine learning methodologies


Extensive programming experience with MATLAB and/or Python
Demonstrated ability to work and lead within a team-based project environment
Ability to effectively communicate technical information through presentation and through the preparation of technical documentation and/or manuscripts
Ability to read, analyze, and interpret common scientific and technical journals
Experience in a regulated industry and exposure to regulatory submissions
Experience interacting with a multi-disciplinary, cross-functional team
Direct experience working with and implementing advanced analytics and algorithm methodologies


PHYSICAL JOB REQUIREMENTS:

The physical demands described within the Responsibilities section of this job description are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.


While performing the duties of this job, the employee is regularly required to be independently mobile.
The employee is also required to interact with a computer, communicate with peers and co-workers, and sit for prolonged periods of time doing computer based work.
Employee must occasionally lift and/or move up to 20 pounds.
The noise level in the work environment is usually moderate.
Typical office and lab working environments.


About Medtronic

Together, we can change healthcare worldwide. At Medtronic, we push the limits of what technology can do to help alleviate pain, restore health and extend life. We challenge ourselves and each other to make tomorrow better than yesterday. It is what makes this an exciting and rewarding place to be.

We can accelerate and advance our ability to create meaningful innovations – but we will only succeed with the right people on our team. Let’s work together to address universal healthcare needs and improve patients’ lives. Help us shape the future.

EEO STATEMENT

It is the policy of Medtronic to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, Medtronic will provide reasonable accommodations for qualified individuals with disabilities.

This employer participates in the federal E-Verify program to confirm the identity and employment authorization of all newly hired employees. For further information about the E-Verify program, please click here:

http://www.uscis.gov/e-verify/employees

DISCLAIMER

The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position.

Additional Information

Posting Date: Feb 16, 2021
Travel: No
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Careers that Change Lives<br><br></strong>This exciting positions involves research and development of algorithms related to glucose sensing technology. The role will involve all aspects of the R&amp;D process, including data gathering, analysis, theory and algorithm development through to validation for regulatory submissions. A successful candidate will have experience leading technical programs and will have in-depth technical knowledge of signal processing and machine learning methodologies. Preference will be given to candidates with direct experience in the software and algorithm development lifecycle.<br><br>Engineers create our market-leading portfolio of innovations. Combine the best of your experience with training and mentorship to move forward. If you want a challenging, energizing, rewarding career that changes lives, join us. Help us bring the next generation of life-changing medical technology to patients worldwide.<br><br>We believe that when people from different cultures, genders, and points of view come together, innovation is the result —and everyone wins. Medtronic walks the walk, creating an inclusive culture where you can thrive.<br><br><strong>DIABETES BUSINESS DESCRIPTION:<br><br></strong>The Diabetes Group is working with the global community to change the way people manage diabetes. Together, we will transform diabetes care by expanding access, integrating care, and improving outcomes; so people with diabetes can enjoy greater freedom and better health.<br><br>We value what makes you unique. Be a part of a company that thinks differently to solve problems, make progress, and deliver meaningful innovations.<br><strong>A Day in the Life<br></strong>Responsibilities may include the following and other duties may be assigned.<br><ul> <li> Designs, develops, tests, debugs and implements operating systems components, software tools and utilities. </li> <li> Determines systems software design requirements. </li> <li> Ensures that system improvements are successfully implemented and monitored to increase efficiency. </li> <li> Generates systems software engineering policies, standards and procedures. </li> <br><br></ul><strong>Must Have: Minimum Requirements<br></strong>Bachelors degree required<br><ul> <li>Minimum of 2 years of relevant experience, or advanced degree with 0 years of experience</li> <br></ul><strong>Nice to Have<br></strong>Knowledge of and direct experience working with signal processing and machine learning methodologies<br><br><li> Extensive programming experience with MATLAB and/or Python</li><li> Demonstrated ability to work and lead within a team-based project environment</li><li> Ability to effectively communicate technical information through presentation and through the preparation of technical documentation and/or manuscripts</li><li> Ability to read, analyze, and interpret common scientific and technical journals</li><li> Experience in a regulated industry and exposure to regulatory submissions</li><li> Experience interacting with a multi-disciplinary, cross-functional team</li><li> Direct experience working with and implementing advanced analytics and algorithm methodologies<br><br></li><strong>PHYSICAL JOB REQUIREMENTS:<br><br></strong>The physical demands described within the Responsibilities section of this job description are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><br><li> While performing the duties of this job, the employee is regularly required to be independently mobile.</li><li> The employee is also required to interact with a computer, communicate with peers and co-workers, and sit for prolonged periods of time doing computer based work.</li><li> Employee must occasionally lift and/or move up to 20 pounds.</li><li> The noise level in the work environment is usually moderate.</li><li> Typical office and lab working environments.<br><br></li><strong><u>About Medtronic<br><br></u></strong>Together, we can change healthcare worldwide. At Medtronic, we push the limits of what technology can do to help alleviate pain, restore health and extend life. We challenge ourselves and each other to make tomorrow better than yesterday. It is what makes this an exciting and rewarding place to be.<br><br>We can accelerate and advance our ability to create meaningful innovations – but we will only succeed with the right people on our team. Let’s work together to address universal healthcare needs and improve patients’ lives. Help us shape the future.<br><br><strong>EEO STATEMENT<br><br></strong>It is the policy of Medtronic to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, Medtronic will provide reasonable accommodations for qualified individuals with disabilities.<br><br>This employer participates in the federal E-Verify program to confirm the identity and employment authorization of all newly hired employees. For further information about the E-Verify program, please click here:<br><br>http://www.uscis.gov/e-verify/employees<br><br><strong>DISCLAIMER<br><br></strong>The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position.<br><br>Additional Information<br><ul> <li> Posting Date: Feb 16, 2021 </li> <li> Travel: No</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Data Engineer/Data Analyst,"Boston, Massachusetts, United States",Altman Solon,2021-02-15,https://www.linkedin.com/jobs/view/data-engineer-data-analyst-at-altman-solon-2407132608?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=evFBuuV3ytOKnHpm7yRAyQ%3D%3D&position=8&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"About Known

Known ( www.known.is ) is a modern marketing company engineered to meet the unprecedented challenges and opportunities facing marketers today. We are setting a new standard by data scientists with award-winning creatives, expert research teams and strategists to deliver clients the most advanced, end-to-end solutions they need, in the most efficient, effective, and transparent ways. Anchored by two decades of groundbreaking market research and data science, we provide brands with consumer intelligence, strategy, media planning and buying, and renowned creative in all media, producing some of the most innovative, cutting-edge work in culture today. With offices in New York, Los Angeles, Boston, Austin, Seattle, and San Francisco, we are 300 people, a community of extraordinary talent, working as one team to help our clients succeed.

The Opportunity

Known’s Data/Media Science team uses advanced analytics, machine learning, statistics, and algorithms to plan and optimize our client’s advertising and media dollars. We partner with our clients to translate their business goals into meaningful metrics and buy media across all channels to drive those target outcomes. We are looking for a Data Scientist to join the team and work alongside other data analysts, data scientists, and software engineers.

Data Scientists at Known have a diverse set of responsibilities which go beyond traditional technical disciplines like machine learning. This includes business strategy, client-facing engagement, and quantitative solution design.

Key Responsibilities

Responsible for the day-to-day management of the media spend you’re responsible for, including ideation on quantitative approaches for driving value, monitoring metrics, and troubleshooting issues
Design and execute every technical aspect of an engagement, including machine learning, analytics, and visualization
Develop new techniques (e.g., ML models, optimization algorithms, and automation) to optimize KPIs and improve Known IP
Discuss and defend your analyses and ensure that it directly meets the client’s needs.
Build presentations and present work to clients with the ability to articulate results
Productionalize workflows and contributing code to our Known repos
Operate existing software infrastructure to traffic, evaluate performance, and analyze media
May mentor others



Who You Are And What You Have

A Masters or PhD from a well-regarded college or university. STEM degrees are preferred
5+ years of hands-on experience doing quantitative analysis, predictive modeling, optimization and/or statistics
Some professional experience in marketing, advertising or media is a plus



Skills, Abilities, And Knowledge

Experience utilizing Python (or similar language) and SQL
Experience using Machine Learning
Understanding of statistics/science/evidence/experimentation
Proficient with Microsoft office suite of products (Excel, Word, PowerPoint)
Ability to build and maintain external relationships (clients, vendors, etc.)
Superb written and verbal communication and presentation skills
Ability to articulate clearly and communicate a “data story”
Ability to build a presentation deck
A desire to work on advertising challenges that require flexibility in approach -- everything from on-the-fly analytics to statistics, big data, machine learning, and mathematical algorithms
An ability to translate business challenges into quantitative problems, and solve them by whatever means necessary, which may not always be strict machine learning
A willingness to learn foundational knowledge and skills rapidly
An ability to think strategically, analytically, and proactively about diverse business problems
A commitment to managing the quality & accuracy of analytics, ensuring high standards with your and others’ work
Experience multi-tasking in a fast-paced environment


Competencies

Ability to prioritize time, work and effort while multitasking on multiple projects
Desire to mentor and teach others
Ability to think strategically, analytically, and proactively about diverse business problems
Collaborative attitude
Self-motivated and exhibits initiative
Willing & able to learn quickly
Abundant intellectual curiosity and integrity
Collaborative attitude



Here Are Just Some Examples Of What We Offer

Known is a marketing company like no other. In addition to competitive salaries, we are very generous to our employees.

Unlimited paid time off
Equity plan with profit sharing
Annual bonuses
Vacation and birthday cash bonuses
Generous medical plan
Paid parental leave
Company-paid cell phone service
In-house barista plus cold brew on tap!
Fully stocked kitchen
Weekly company lunches
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Known<br><br></u></strong>Known ( www.known.is ) is a modern marketing company engineered to meet the unprecedented challenges and opportunities facing marketers today. We are setting a new standard by data scientists with award-winning creatives, expert research teams and strategists to deliver clients the most advanced, end-to-end solutions they need, in the most efficient, effective, and transparent ways. Anchored by two decades of groundbreaking market research and data science, we provide brands with consumer intelligence, strategy, media planning and buying, and renowned creative in all media, producing some of the most innovative, cutting-edge work in culture today. With offices in New York, Los Angeles, Boston, Austin, Seattle, and San Francisco, we are 300 people, a community of extraordinary talent, working as one team to help our clients succeed.<br><br><strong>The Opportunity<br><br></strong>Known’s Data/Media Science team uses advanced analytics, machine learning, statistics, and algorithms to plan and optimize our client’s advertising and media dollars. We partner with our clients to translate their business goals into meaningful metrics and buy media across all channels to drive those target outcomes. We are looking for a Data Scientist to join the team and work alongside other data analysts, data scientists, and software engineers.<br><br>Data Scientists at Known have a diverse set of responsibilities which go beyond traditional technical disciplines like machine learning. This includes business strategy, client-facing engagement, and quantitative solution design.<br><br><strong><u>Key Responsibilities<br></u></strong><ul> <li>Responsible for the day-to-day management of the media spend you’re responsible for, including ideation on quantitative approaches for driving value, monitoring metrics, and troubleshooting issues</li> <li>Design and execute every technical aspect of an engagement, including machine learning, analytics, and visualization </li> <li>Develop new techniques (e.g., ML models, optimization algorithms, and automation) to optimize KPIs and improve Known IP</li> <li>Discuss and defend your analyses and ensure that it directly meets the client’s needs. </li> <li>Build presentations and present work to clients with the ability to articulate results</li> <li>Productionalize workflows and contributing code to our Known repos </li> <li>Operate existing software infrastructure to traffic, evaluate performance, and analyze media</li> <li>May mentor others</li> <br><br></ul><strong><u>Who You Are And What You Have<br></u></strong><ul> <li>A Masters or PhD from a well-regarded college or university. STEM degrees are preferred </li> <li>5+ years of hands-on experience doing quantitative analysis, predictive modeling, optimization and/or statistics</li> <li>Some professional experience in marketing, advertising or media is a plus</li> <br><br></ul><strong><u>Skills, Abilities, And Knowledge<br></u></strong><ul> <li>Experience utilizing Python (or similar language) and SQL</li> <li>Experience using Machine Learning</li> <li>Understanding of statistics/science/evidence/experimentation</li> <li>Proficient with Microsoft office suite of products (Excel, Word, PowerPoint)</li> <li>Ability to build and maintain external relationships (clients, vendors, etc.)</li> <li>Superb written and verbal communication and presentation skills</li> <li>Ability to articulate clearly and communicate a “data story”</li> <li>Ability to build a presentation deck</li> <li>A desire to work on advertising challenges that require flexibility in approach -- everything from on-the-fly analytics to statistics, big data, machine learning, and mathematical algorithms </li> <li>An ability to translate business challenges into quantitative problems, and solve them by whatever means necessary, which may not always be strict machine learning</li> <li>A willingness to learn foundational knowledge and skills rapidly</li> <li>An ability to think strategically, analytically, and proactively about diverse business problems</li> <li>A commitment to managing the quality &amp; accuracy of analytics, ensuring high standards with your and others’ work</li> <li>Experience multi-tasking in a fast-paced environment</li> <br></ul><strong>Competencies<br></strong><ul> <li>Ability to prioritize time, work and effort while multitasking on multiple projects</li> <li>Desire to mentor and teach others</li> <li>Ability to think strategically, analytically, and proactively about diverse business problems</li> <li>Collaborative attitude</li> <li>Self-motivated and exhibits initiative</li> <li>Willing &amp; able to learn quickly</li> <li>Abundant intellectual curiosity and integrity</li> <li>Collaborative attitude</li> <br><br></ul><strong><u>Here Are Just Some Examples Of What We Offer<br><br></u></strong>Known is a marketing company like no other. In addition to competitive salaries, we are very generous to our employees.<br><ul> <li>Unlimited paid time off</li> <li>Equity plan with profit sharing</li> <li>Annual bonuses</li> <li>Vacation and birthday cash bonuses</li> <li>Generous medical plan</li> <li>Paid parental leave</li> <li>Company-paid cell phone service</li> <li>In-house barista plus cold brew on tap!</li> <li>Fully stocked kitchen</li> <li>Weekly company lunches</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Information Technology and Services, Computer Software"
Python Data Engineer for Quant Strategies Research (200-300k),"New York, New York, United States",Gambit Technologies,2021-02-03,https://www.linkedin.com/jobs/view/python-data-engineer-for-quant-strategies-research-200-300k-at-gambit-technologies-2271486504?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=P1ysJKwMBx2S0Irnso6Y2w%3D%3D&position=9&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Altman Solon is a 300-person strategy consulting group that focuses exclusively on the telecommunications, media and technology (TMT) related sectors. As the largest global TMT strategy firm, we assist clients in fast, high-impact, confident decision making. We enable clients to seize new opportunities, improve performance, and increase shareholder value within complex and converging industries.




The Analytics Innovation Team

Altman Solon delivers actionable, data-driven results to our clients. Our Analytics Innovation team is an analytics technology group that is focused on developing a suite of advanced analytics products and supporting business strategy consulting teams to meet the evolving needs of our clients.




Duties and Responsibilities

To meet the demand of growth, Altman Solon is looking for a Data Engineer/Analyst who can play several important roles:

Collaborate with internal partners to understand client needs and develop data products and analytical solutions that deliver actionable, high-value results.
Plan and build complex automated analytics solutions using Apache Spark or other big data platforms.
Investigate, load and transform data sources for use by internal teams. Manage scheduled data pipelines for frequently updated sources.
Identify, evaluate, test, and solve data quality issues and document outcomes.

 

Qualifications

The Data Engineer/Analyst role is a mid-level position for applicants with a passion for working with large data sets and collaborating with diverse teams to solve an ever-changing set of problems. We seek specialists with strong problem-solving skills and a track record of achieving results, as well as a desire for the personal impact that can only be found within a boutique organization. Candidates should have the following qualifications:

 

Required Skills

1-4 years’ experience analyzing and transforming data using SQL or Python
1-4 years’ experience automating repetitive workflows using Python, SQL, Bash, JavaScript or similar.
Experience working across multiple platforms and distributed systems such as AWS S3/EC2/Redshift, Azure, Google Cloud Platform, Databricks, Snowflake, Qubole.
Knowledge of data ETLs and scheduling (Apache Airflow, AWS Glue, DBT, Alteryx)
Experience working with end users to conduct needs assessment and user testing.

 

Desired Skills

Experience working with and running ETLs on traditional relational databases – MySQL, PostgreSQL, MSSQL, Oracle SQL
Experience publishing to BI solutions such as Tableau, Qlik, Looker, or Power BI.
Knowledge of geospatial data management and analysis

 

Experience/Education

Bachelor’s Degree (Computer Science, Information Systems or related IT/Engineering field preferred) or equivalent work experience

 

Location: Boston, MA / New York NY

 

Please visit https://www.altmansolon.com/careers/join-us/ and select ""Apply Here"" under ""Application Process - Americas"". Please only submit your application through the Altman Solon portal. Applications via email or linkedin will not be accepted.




Please note that we are unable to consider applicants who now or in the future require sponsorship for work visa status (e.g. F (OPT), H-1B)

 

We believe that diversity, equity, and inclusion are key principles for the successful operation of any business, and especially ours. We are committed to ensuring that all employees, at all levels, feel supported, feel a sense of belonging, and are equally invested in the success of our shared work. This starts with ensuring that we draw the most talented people from all backgrounds. If your access to educational or extracurricular opportunities has been impacted by factors you would like to make us aware of, please include this information in your cover letter.

Altman Solon is an Equal Opportunity Employer and E-Verify user. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status, or other protected status.

 

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Altman Solon is a 300-person strategy consulting group that focuses exclusively on the telecommunications, media and technology (TMT) related sectors. As the largest global TMT strategy firm, we assist clients in fast, high-impact, confident decision making. We enable clients to seize new opportunities, improve performance, and increase shareholder value within complex and converging industries.</p><p><br></p><p><strong>The Analytics Innovation Team</strong></p><p>Altman Solon delivers actionable, data-driven results to our clients. Our Analytics Innovation team is an analytics technology group that is focused on developing a suite of advanced analytics products and supporting business strategy consulting teams to meet the evolving needs of our clients.</p><p><br></p><p><strong>Duties and Responsibilities</strong></p><p>To meet the demand of growth, Altman Solon is looking for a Data Engineer/Analyst&nbsp;who can play several important roles:</p><ol><li>Collaborate with internal partners to understand client needs and develop data products and analytical solutions that deliver actionable, high-value results.</li><li>Plan and build complex automated analytics solutions using Apache Spark or other big data platforms.</li><li>Investigate, load and transform data sources for use by internal teams. Manage scheduled data pipelines for frequently updated sources.</li><li>Identify, evaluate, test, and solve data quality issues and document outcomes.</li></ol><p><strong>&nbsp;</strong></p><p><strong>Qualifications</strong></p><p>The Data Engineer/Analyst role is a mid-level position for applicants with a passion for working with large data sets and collaborating with diverse teams to solve an ever-changing set of problems. We seek specialists with strong problem-solving skills and a track record of achieving results, as well as a desire for the personal impact that can only be found within a boutique organization. Candidates should have the following qualifications:</p><p><strong>&nbsp;</strong></p><p><strong>Required Skills</strong></p><ul><li>1-4 years’ experience analyzing and transforming data using SQL or Python</li><li>1-4 years’ experience automating repetitive workflows using Python, SQL, Bash, JavaScript or similar.</li><li>Experience working across multiple platforms and distributed systems such as AWS S3/EC2/Redshift, Azure, Google Cloud Platform, Databricks, Snowflake, Qubole.</li><li>Knowledge of data ETLs and scheduling (Apache Airflow, AWS Glue, DBT, Alteryx)</li><li>Experience working with end users to conduct needs assessment and user testing.</li></ul><p><strong>&nbsp;</strong></p><p><strong>Desired Skills</strong></p><ul><li>Experience working with and running ETLs on traditional relational databases – MySQL, PostgreSQL, MSSQL, Oracle SQL</li><li>Experience publishing to BI solutions such as Tableau, Qlik, Looker, or Power BI.</li><li>Knowledge of geospatial data management and analysis</li></ul><p><strong>&nbsp;</strong></p><p><strong>Experience/Education</strong></p><ul><li>Bachelor’s Degree (Computer Science, Information Systems or related IT/Engineering field preferred) or equivalent work experience</li></ul><p><strong>&nbsp;</strong></p><p><strong>Location:&nbsp;</strong>Boston, MA / New York NY</p><p><strong>&nbsp;</strong></p><p>Please visit https://www.altmansolon.com/careers/join-us/ and select ""Apply Here"" under ""Application Process - Americas"". Please only submit your application through the Altman Solon portal. Applications via email or linkedin will not be accepted.</p><p><br></p><p>Please note that we are unable to consider applicants who now or in the future require sponsorship for work visa status (e.g. F (OPT), H-1B)</p><p>&nbsp;</p><p>We believe that diversity, equity, and inclusion are key principles for the successful operation of any business, and especially ours. We are committed to ensuring that all employees, at all levels, feel supported, feel a sense of belonging, and are equally invested in the success of our shared work. This starts with ensuring that we draw the most talented people from all backgrounds. If your access to educational or extracurricular opportunities has been impacted by factors you would like to make us aware of, please include this information in your cover letter.</p><p>Altman Solon is an Equal Opportunity Employer and E-Verify user. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status, or other protected status.</p><p>&nbsp;</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Management Consulting
Software Engineer Python,"West Palm Beach, Florida, United States",Two Fish Creative,2021-01-31,https://www.linkedin.com/jobs/view/software-engineer-python-at-two-fish-creative-2402589328?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=GLv%2FJYvUBlcm0NwFdHbAag%3D%3D&position=10&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Python Data Engineer for Quant Strategies Research (200-300k)
Summary
Quant strategies team at Macro/Systematic hedgefund needs a solid Python engineer to work with their chief researcher on the build out of a data engineering pipeline that will be used for portfolio construction, research and NLP processing. Python engineer will be embedded in the Quant strategies team and will get exposed to investment mechanics, modelling and portfolio optimization.
Responsibilities

Be the sole Python data engineer to architect, design and implement a research driven ML data pipeline for financial data.
Leverage best practice tools for real-time data (khafka, airflow, etc) and implement all tools and libraries for data validation and monitoring.
Build out the NLP processing platform to help deliver market insights in simple to understand language.

﻿Requirements

Bachelor’s degree (preferred to be in a computer science, or tech related field with demonstrated Math/Statistics)
Excellent large scale Python (numpy, pandas) experience building real-time data pipelines for researchers/quants.
Understanding of compute cost optimization for back testing of complex datasets
Excellent communication skills to face off with researchers and quants to translate data needs into deliverables.

Not In The Job Description
Lead researcher really wants someone who understands financial markets, has built real-time data validation tools and can sit at the table with the other researchers distilling their holistic data requirements and then can build out both the pipelines and the python calculators/libraries. They will consider someone non finance but will want to see work collaborating with data scientist and large scale python projects they have delivered.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Python Data Engineer for Quant Strategies Research (200-300k)<br></strong><strong><u>Summary<br></u></strong>Quant strategies team at Macro/Systematic hedgefund needs a solid Python engineer to work with their chief researcher on the build out of a data engineering pipeline that will be used for portfolio construction, research and NLP processing. Python engineer will be embedded in the Quant strategies team and will get exposed to investment mechanics, modelling and portfolio optimization.<br><strong><u>Responsibilities<br></u></strong><ul><li>Be the sole Python data engineer to architect, design and implement a research driven ML data pipeline for financial data.</li><li>Leverage best practice tools for real-time data (khafka, airflow, etc) and implement all tools and libraries for data validation and monitoring.</li><li>Build out the NLP processing platform to help deliver market insights in simple to understand language.<br></li></ul><strong><u>﻿Requirements<br></u></strong><ul><li>Bachelor’s degree (preferred to be in a computer science, or tech related field with demonstrated Math/Statistics)</li><li>Excellent large scale Python (numpy, pandas) experience building real-time data pipelines for researchers/quants.</li><li>Understanding of compute cost optimization for back testing of complex datasets</li><li>Excellent communication skills to face off with researchers and quants to translate data needs into deliverables.<br></li></ul><strong><u>Not In The Job Description<br></u></strong>Lead researcher really wants someone who understands financial markets, has built real-time data validation tools and can sit at the table with the other researchers distilling their holistic data requirements and then can build out both the pipelines and the python calculators/libraries. They will consider someone non finance but will want to see work collaborating with data scientist and large scale python projects they have delivered.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Analytics Engineer,"Chicago, Illinois, United States",OpenSesame,2021-02-13,https://www.linkedin.com/jobs/view/analytics-engineer-at-opensesame-2422982635?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=Xq1n6QNCHkaOgH73LJvy7g%3D%3D&position=11&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"We are looking for a Python Developer to join our engineering team and help us develop and maintain various software products. Two Fish Creative is founded on the idea of ""Swim against the Current"" and we are looking for talented intellectual team members who embody this idea. We have collaboration at our core and work in team first agile environment. We want to be your dream job.

Python Developer Responsibilities Include

Writing and testing code, debugging programs and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.

Writing effective, scalable code
Developing back-end components to improve responsiveness and overall performance
Integrating user-facing elements into applications

Ultimately, you’ll build highly responsive web applications that align with our or our clients business needs.Responsibilities

Write effective, scalable code
Develop back-end components to improve responsiveness and overall performance
Integrate user-facing elements into applications
Test and debug programs
Improve functionality of existing systems
Implement security and data protection solutions
Assess and prioritize feature requests
Coordinate with internal teams to understand user requirements and provide technical solutions


Requirements

Work experience as a Python Developer (other development languages also considered)
Expertise in at least one popular Python framework (like Django, Flask or Pyramid)
Knowledge of object-relational mapping (ORM)
Knowledge of SQL
Familiarity with front-end technologies (JavaScript and HTML5)
Team player
Good problem-solving skills
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are looking for a Python Developer to join our engineering team and help us develop and maintain various software products. Two Fish Creative is founded on the idea of ""Swim against the Current"" and we are looking for talented intellectual team members who embody this idea. We have collaboration at our core and work in team first agile environment. We want to be your dream job.<br><br><strong><u>Python Developer Responsibilities Include<br><br></u></strong>Writing and testing code, debugging programs and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.<br><ul><li>Writing effective, scalable code</li><li>Developing back-end components to improve responsiveness and overall performance</li><li>Integrating user-facing elements into applications<br></li></ul>Ultimately, you’ll build highly responsive web applications that align with our or our clients business needs.Responsibilities<br><ul><li>Write effective, scalable code</li><li>Develop back-end components to improve responsiveness and overall performance</li><li>Integrate user-facing elements into applications</li><li>Test and debug programs</li><li>Improve functionality of existing systems</li><li>Implement security and data protection solutions</li><li>Assess and prioritize feature requests</li><li>Coordinate with internal teams to understand user requirements and provide technical solutions<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>Work experience as a Python Developer (other development languages also considered)</li><li>Expertise in at least one popular Python framework (like Django, Flask or Pyramid)</li><li>Knowledge of object-relational mapping (ORM)</li><li>Knowledge of SQL</li><li>Familiarity with front-end technologies (JavaScript and HTML5)</li><li>Team player</li><li>Good problem-solving skills</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Hawaii, United States",AEP Professional Group,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-aep-professional-group-2416456511?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=uxwEB0fpx16pQ5vo79LOEw%3D%3D&position=12&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"While it appears to most people that we just sell training courses (over 20,000 of them), what we really offer is the opportunity for companies to upgrade the skills of each of their employees. In fact, we have strategic partnerships with 100+ Global2000 companies who rely on our training programs to develop the world's most productive and admired workforces.

Help build OpenSesame from the emerging leader in enterprise business training to the clear, worldwide leader over the next four years. You will build and maintain OpenSesame's enterprise data model, delivering critical data to drive decision making and analysis across all business units. Your expertise and skill in bringing software engineering concepts like source control, CI/CD, and automated testing to our data sources, pipelines, ETL/ELT processes and data modeling and visualization tools will enhance and complete our significant investment in enabling each team to develop actionable insights from a consistent, ever-improving platform.

If you want a chance to thrill our customers and your teammates, we need to talk. When we do talk we'll be discussing all of the details behind these major performance objectives. We hope you'll be the one building the plan and delivering on these goals.

First 180 day Performance Objectives:

Implement CI/CD pipeline for DBT packages running in Fivetran and Snowflake
Migrate current set of LookML models into DBT models without affecting existing Looker looks, explores, and dashboards
Secure and limit proliferation of customer personal data in analytics data pipelines, models, and reports


We are looking for specific examples from your previous experience that proves you can do this job successfully so that when you look back month-after-month and reflect on your efforts and your team's accomplishments at OpenSesame, it is with great confidence knowing you exceeded all of the performance expectations and have advanced the business to a much better place than when you arrived.

Responsibilities:

Build and maintain Data Pipelines and ETL/ELT processes
Develop and administer governance strategies for protection of customer data
Work with Data Analysts, Data Science, and other stakeholders to identify and develop sources and destinations of data
Ensure data integrity for downstream consumers
Manage data migrations seamlessly as producing teams migrate source schemas



Requirements

You have outstanding analytical, problem-solving, and technical skills along with great attention to detail
You possess the business acumen necessary to understand urgent stakeholder challenges in the context of
Real-world experience with modern data stack tools such as dbt, Looker, Fivetran, Google BigQuery and/or Snowflake
Experience using software development methods (git, CI/CD, automated testing, code reuse etc) in an analytics context
Strong interpersonal skills to translate key requirements into actionable technical requests
A pragmatic approach to getting things done and good time management skills
Python or JavaScript experience a plus


Tools and Technologies

Snowflake
Looker
DBT
SQL
Terraform
AWS
Fivetran


Become the Best Version of Yourself

We want OpenSesame to reflect the diversity of the communities we serve and the world we live in.
We know that a variety of perspectives and voices strengthen our ability to deliver the spark of learning to everyone.
We hold ourselves accountable to create more diverse, equitable, and inclusive communities through continuous learning, personal growth, and working to support our customers.
We welcome you to bring your authentic self to our team and grow beyond your expectations.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">While it appears to most people that we just sell training courses (over 20,000 of them), what we really offer is the opportunity for companies to upgrade the skills of each of their employees. In fact, we have strategic partnerships with 100+ Global2000 companies who rely on our training programs to develop the world's most productive and admired workforces.<br><br>Help build OpenSesame from the emerging leader in enterprise business training to the clear, worldwide leader over the next four years. You will build and maintain OpenSesame's enterprise data model, delivering critical data to drive decision making and analysis across all business units. Your expertise and skill in bringing software engineering concepts like source control, CI/CD, and automated testing to our data sources, pipelines, ETL/ELT processes and data modeling and visualization tools will enhance and complete our significant investment in enabling each team to develop actionable insights from a consistent, ever-improving platform.<br><br>If you want a chance to thrill our customers and your teammates, we need to talk. When we do talk we'll be discussing all of the details behind these major performance objectives. We hope you'll be the one building the plan and delivering on these goals.<br><br><strong>First 180 day Performance Objectives:<br></strong><ul> <li>Implement CI/CD pipeline for DBT packages running in Fivetran and Snowflake</li> <li>Migrate current set of LookML models into DBT models without affecting existing Looker looks, explores, and dashboards</li> <li>Secure and limit proliferation of customer personal data in analytics data pipelines, models, and reports</li> <br></ul>We are looking for specific examples from your previous experience that proves you can do this job successfully so that when you look back month-after-month and reflect on your efforts and your team's accomplishments at OpenSesame, it is with great confidence knowing you exceeded all of the performance expectations and have advanced the business to a much better place than when you arrived.<br><br><strong>Responsibilities: <br></strong><ul> <li>Build and maintain Data Pipelines and ETL/ELT processes</li> <li>Develop and administer governance strategies for protection of customer data</li> <li>Work with Data Analysts, Data Science, and other stakeholders to identify and develop sources and destinations of data</li> <li>Ensure data integrity for downstream consumers</li> <li>Manage data migrations seamlessly as producing teams migrate source schemas</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>You have outstanding analytical, problem-solving, and technical skills along with great attention to detail</li> <li>You possess the business acumen necessary to understand urgent stakeholder challenges in the context of </li> <li>Real-world experience with modern data stack tools such as dbt, Looker, Fivetran, Google BigQuery and/or Snowflake</li> <li>Experience using software development methods (git, CI/CD, automated testing, code reuse etc) in an analytics context</li> <li>Strong interpersonal skills to translate key requirements into actionable technical requests</li> <li>A pragmatic approach to getting things done and good time management skills</li> <li>Python or JavaScript experience a plus</li> <br></ul><strong>Tools and Technologies<br></strong><ul> <li>Snowflake</li> <li>Looker</li> <li>DBT</li> <li>SQL</li> <li>Terraform</li> <li>AWS</li> <li>Fivetran</li> <br></ul><strong>Become the Best Version of Yourself<br><br></strong><em>We want OpenSesame to reflect the diversity of the communities we serve and the world we live in.<br></em><em>We know that a variety of perspectives and voices strengthen our ability to deliver the spark of learning to everyone. <br></em><em>We hold ourselves accountable to create more diverse, equitable, and inclusive communities through continuous learning, personal growth, and working to support our customers.<br></em><em>We welcome you to bring your authentic self to our team and grow beyond your expectations.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Visualization Engineer,"New York, New York, United States",New Fortress Energy,2021-01-27,https://www.linkedin.com/jobs/view/data-visualization-engineer-at-new-fortress-energy-2398070826?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=BmSdNYoSkW%2BbO2DWfQVb1w%3D%3D&position=13&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Remote Data Scientist role with a scaling tech company in the transportation space.

Please apply and PM me for any questions.

JOB DESCRIPTION:

Data Scientist (Remote Hawaii/PST)

- MS or Bachelor’s degree in, Statistics, Economics, Machine Learning, Operations Research, Computer Science or other quantitative fields. (PHD a plus)

- Python required

- Spark, Kafka preferred

- Focus on numerical statistics

-5+ years post-academic experience in analytics, machine learning, data engineering, and data science

- Full Tech Stack: Spark, R, Scala,Java, Product, Kafka, Python, SQL, Databricks


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Remote Data Scientist role with a scaling tech company in the transportation space.<br><br>Please apply and PM me for any questions.<br><br>JOB DESCRIPTION:<br><br>Data Scientist (Remote Hawaii/PST)<br><br>- MS or Bachelor’s degree in, Statistics, Economics, Machine Learning, Operations Research, Computer Science or other quantitative fields. (PHD a plus)<br><br>- Python required<br><br>- Spark, Kafka preferred<br><br>- Focus on numerical statistics<br><br>-5+ years post-academic experience in analytics, machine learning, data engineering, and data science<br><br>- Full Tech Stack: Spark, R, Scala,Java, Product, Kafka, Python, SQL, Databricks<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Management Consulting
Junior Data Scientist,"Pittsburgh, Pennsylvania, United States","Othot, Inc.",2021-02-19,https://www.linkedin.com/jobs/view/junior-data-scientist-at-othot-inc-2400521010?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=zOjYXFmL%2BT11k2rGjK7rGg%3D%3D&position=15&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Junior Data Scientist

 

Othot Overview: Othot is the leader in artificial intelligence and prescriptive analytics solutions for higher education institutions across the United States. Together, Othot and its partner schools focus on each institution’s specific enrollment, retention, student success, and alumni engagement goals. Othot’s cloud-based solution provides continuous intelligence in real time and empowers schools to engage each prospective, current, and former student with the right tactic at the right time. Othot is higher intelligence for higher education.

 

Othot employs smart, curious, and adventurous team members. We hire individuals who do their best work in a collaborative environment and have a passion for innovation. We are looking for entrepreneurial-minded people to join our team.

 

Job Summary:  The Junior Data Scientist supports the Data Architect and Data Scientists with the design, development, automation, build out, analysis, application, and assessment of the predictive models for customers.  

 

Essential Duties and Responsibilities:

 

Build, validate, and troubleshoot predictive data science models using internal tools and metrics
Perform stringent data checks to identify and address inconsistent data issues and leak variables
Tailor customer models to each individual institution’s needs, processes, and goals
Contribute creative feature engineering solutions for use in customer models
Analyze output from automated tests to identify significant changes or issues in new customer data
Build out necessary configuration files to deploy customer models in the Othot platform
Communicate data science results and insights to other Othot team members and our customers
Research data science modeling solutions using independent judgment for Othot to implement
Collaborate in designing and improving the functionalities of internal tools and the Othot platform
Automate or help automate as many manual data science activities as possible




Qualifications:

 

Education:
Bachelor’s degree from accredited institution in mathematics, data science, computer science, engineering, or another technical field required.

*Demonstrated related experience may substitute for preferred education.

 

Experience:
Minimum 1year industry experience in solving machine learning and data science problems using Python required.




Skills:
Proficiency in libraries such as NumPy, SciPy, Pandas, Scikit-learn is a plus
Capacity to work independently and/or as part of a team
Strong communication and interpersonal skills

 

To apply: https://secure.entertimeonline.com/ta/OTHOT.careers?ApplyToJob=352458688

 

Othot is an equal opportunity employer 

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>Junior Data Scientist</strong></p><p><strong>&nbsp;</strong></p><p><strong>Othot Overview:</strong> Othot is the leader in artificial intelligence and prescriptive analytics solutions for higher education institutions across the United States. Together, Othot and its partner schools focus on each institution’s specific enrollment, retention, student success, and alumni engagement goals. Othot’s cloud-based solution provides continuous intelligence in real time and empowers schools to engage each prospective, current, and former student with the right tactic at the right time. Othot is higher intelligence for higher education.</p><p><strong>&nbsp;</strong></p><p>Othot employs smart, curious, and adventurous team members. We hire individuals who do their best work in a collaborative environment and have a passion for innovation. We are looking for entrepreneurial-minded people to join our team.</p><p><strong>&nbsp;</strong></p><p><strong>Job Summary:</strong>&nbsp; The Junior Data Scientist supports the Data Architect and Data Scientists with the design, development, automation, build out, analysis, application, and assessment of the predictive models for customers.&nbsp;&nbsp;</p><p>&nbsp;</p><p><strong>Essential Duties and Responsibilities:</strong></p><p><strong>&nbsp;</strong></p><ul><li>Build, validate, and troubleshoot predictive data science models using internal tools and metrics</li><li>Perform stringent data checks to identify and address inconsistent data issues and leak variables</li><li>Tailor customer models to each individual institution’s needs, processes, and goals</li><li>Contribute creative feature engineering solutions for use in customer models</li><li>Analyze output from automated tests to identify significant changes or issues in new customer data</li><li>Build out necessary configuration files to deploy customer models in the Othot platform</li><li>Communicate data science results and insights to other Othot team members and our customers</li><li>Research data science modeling solutions using independent judgment for Othot to implement</li><li>Collaborate in designing and improving the functionalities of internal tools and the Othot platform</li><li>Automate or help automate as many manual data science activities as possible</li></ul><p><br></p><p><strong>Qualifications:</strong></p><p><strong>&nbsp;</strong></p><ul><li><strong>Education:</strong></li><li>Bachelor’s degree from accredited institution in mathematics, data science, computer science, engineering, or another technical field required.</li></ul><p>      *Demonstrated related experience may substitute for preferred education.</p><p>&nbsp;</p><ul><li><strong>Experience:</strong></li><li>Minimum 1year industry experience in solving machine learning and data science problems using Python required.</li></ul><p><br></p><ul><li><strong>Skills:</strong></li><li>Proficiency in libraries such as NumPy, SciPy, Pandas, Scikit-learn is a plus</li><li>Capacity to work independently and/or as part of a team</li><li>Strong communication and interpersonal skills</li></ul><p><strong>&nbsp;</strong></p><p><strong>To apply:&nbsp;https://secure.entertimeonline.com/ta/OTHOT.careers?ApplyToJob=352458688</strong></p><p><strong>&nbsp;</strong></p><p><strong>Othot is an equal opportunity employer</strong>&nbsp;</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Scientist,"South Plainfield, New Jersey, United States",Robert Half,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-robert-half-2427660827?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=imAzsG2FEDeM5qPWVW5nUA%3D%3D&position=16&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Junior Data Scientist

 

Othot Overview: Othot is the leader in artificial intelligence and prescriptive analytics solutions for higher education institutions across the United States. Together, Othot and its partner schools focus on each institution’s specific enrollment, retention, student success, and alumni engagement goals. Othot’s cloud-based solution provides continuous intelligence in real time and empowers schools to engage each prospective, current, and former student with the right tactic at the right time. Othot is higher intelligence for higher education.

 

Othot employs smart, curious, and adventurous team members. We hire individuals who do their best work in a collaborative environment and have a passion for innovation. We are looking for entrepreneurial-minded people to join our team.

 

Job Summary:  The Junior Data Scientist supports the Data Architect and Data Scientists with the design, development, automation, build out, analysis, application, and assessment of the predictive models for customers.  

 

Essential Duties and Responsibilities:

 

Build, validate, and troubleshoot predictive data science models using internal tools and metrics
Perform stringent data checks to identify and address inconsistent data issues and leak variables
Tailor customer models to each individual institution’s needs, processes, and goals
Contribute creative feature engineering solutions for use in customer models
Analyze output from automated tests to identify significant changes or issues in new customer data
Build out necessary configuration files to deploy customer models in the Othot platform
Communicate data science results and insights to other Othot team members and our customers
Research data science modeling solutions using independent judgment for Othot to implement
Collaborate in designing and improving the functionalities of internal tools and the Othot platform
Automate or help automate as many manual data science activities as possible




Qualifications:

 

Education:
Bachelor’s degree from accredited institution in mathematics, data science, computer science, engineering, or another technical field required.

*Demonstrated related experience may substitute for preferred education.

 

Experience:
Minimum 1year industry experience in solving machine learning and data science problems using Python required.




Skills:
Proficiency in libraries such as NumPy, SciPy, Pandas, Scikit-learn is a plus
Capacity to work independently and/or as part of a team
Strong communication and interpersonal skills

 

To apply: https://secure.entertimeonline.com/ta/OTHOT.careers?ApplyToJob=352458688

 

Othot is an equal opportunity employer 

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>Junior Data Scientist</strong></p><p><strong>&nbsp;</strong></p><p><strong>Othot Overview:</strong> Othot is the leader in artificial intelligence and prescriptive analytics solutions for higher education institutions across the United States. Together, Othot and its partner schools focus on each institution’s specific enrollment, retention, student success, and alumni engagement goals. Othot’s cloud-based solution provides continuous intelligence in real time and empowers schools to engage each prospective, current, and former student with the right tactic at the right time. Othot is higher intelligence for higher education.</p><p><strong>&nbsp;</strong></p><p>Othot employs smart, curious, and adventurous team members. We hire individuals who do their best work in a collaborative environment and have a passion for innovation. We are looking for entrepreneurial-minded people to join our team.</p><p><strong>&nbsp;</strong></p><p><strong>Job Summary:</strong>&nbsp; The Junior Data Scientist supports the Data Architect and Data Scientists with the design, development, automation, build out, analysis, application, and assessment of the predictive models for customers.&nbsp;&nbsp;</p><p>&nbsp;</p><p><strong>Essential Duties and Responsibilities:</strong></p><p><strong>&nbsp;</strong></p><ul><li>Build, validate, and troubleshoot predictive data science models using internal tools and metrics</li><li>Perform stringent data checks to identify and address inconsistent data issues and leak variables</li><li>Tailor customer models to each individual institution’s needs, processes, and goals</li><li>Contribute creative feature engineering solutions for use in customer models</li><li>Analyze output from automated tests to identify significant changes or issues in new customer data</li><li>Build out necessary configuration files to deploy customer models in the Othot platform</li><li>Communicate data science results and insights to other Othot team members and our customers</li><li>Research data science modeling solutions using independent judgment for Othot to implement</li><li>Collaborate in designing and improving the functionalities of internal tools and the Othot platform</li><li>Automate or help automate as many manual data science activities as possible</li></ul><p><br></p><p><strong>Qualifications:</strong></p><p><strong>&nbsp;</strong></p><ul><li><strong>Education:</strong></li><li>Bachelor’s degree from accredited institution in mathematics, data science, computer science, engineering, or another technical field required.</li></ul><p>      *Demonstrated related experience may substitute for preferred education.</p><p>&nbsp;</p><ul><li><strong>Experience:</strong></li><li>Minimum 1year industry experience in solving machine learning and data science problems using Python required.</li></ul><p><br></p><ul><li><strong>Skills:</strong></li><li>Proficiency in libraries such as NumPy, SciPy, Pandas, Scikit-learn is a plus</li><li>Capacity to work independently and/or as part of a team</li><li>Strong communication and interpersonal skills</li></ul><p><strong>&nbsp;</strong></p><p><strong>To apply:&nbsp;https://secure.entertimeonline.com/ta/OTHOT.careers?ApplyToJob=352458688</strong></p><p><strong>&nbsp;</strong></p><p><strong>Othot is an equal opportunity employer</strong>&nbsp;</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Scientist-Python,"Creve Coeur, Missouri, United States",Corestaff Services,2021-02-16,https://www.linkedin.com/jobs/view/data-scientist-python-at-corestaff-services-2412593984?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=dse4VsBOqpjsfmKKy3NyHg%3D%3D&position=18&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Description

We are looking for a Data Engineer that can leverage creative programming and database knowledge for data preparation, analysis, visualization. Ideal candidate will build state-of-the-art workflows, including machine learning, to help researchers uncover new trends in experimental data. Through a close collaborative relationship with project teams, IT and research operations, ideal candidate will communicate creative solutions that will meet the needs of a growing research data infrastructure.

Description

Work with stakeholders throughout research to create solutions for analyzing, transforming, and storing drug discovery project data.
Develop processes and tools to monitor and analyze data accuracy.
Work closely with the IT department to provide a secure and efficient infrastructure for researchers.
Provide expertise and hands-on training for data visualization tools such as Spotfire.
Continually strive to improve research team performance by maintaining a strong understanding of the state-of-the-art tools and software.
Performs other tasks as assigned.

Requirements

Requirements:.

Master's degree in computer science or related field with three to five years of hands-on experience with database management.
Experience working with relational databases, ETL concepts and using statistical computer languages: R, Python, SLQ, etc..
Coding knowledge and experience with several languages: C, C++, Python, Java, JavaScript, HTML, etc.
Hands-on experience with data visualization tools (Spotfire, Plotly, etc.)
Attention to detail, team player, and a strong commitment to excellence.
Excellent verbal and written communication and skills
Ability to work independently and collaboratively, as required, in a fast-paced environment.
Analytical thinker with excellent problem-solving skills
Ability to quickly adapt to changing priorities and deadlines.

Robert Half Technology matches IT professionals with remote or on-site jobs on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities.

Our experienced staffing professionals can promote you to employers and advocate on your behalf. We provide access to top jobs, competitive compensation and benefits, and free online training. For more opportunities, get the Robert Half app and receive instant notifications when our AI matches you with jobs.

When you work with us, you’re working with the best. Robert Half has been recognized as one of FORTUNE’s “Most Admired Companies” every year since 1998 and was named to Forbes’ inaugural list of America’s Best Temporary Staffing Firms.

Questions? Call your local office at 1.888.490.4429. All applicants applying for U.S. job openings must be authorized to work in the United States. Benefits are available to temporary professionals. Visit

© 2020 Robert Half Technology. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to Robert Half’s Terms of Use (
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>We are looking for a Data Engineer that can leverage creative programming and database knowledge for data preparation, analysis, visualization. Ideal candidate will build state-of-the-art workflows, including machine learning, to help researchers uncover new trends in experimental data. Through a close collaborative relationship with project teams, IT and research operations, ideal candidate will communicate creative solutions that will meet the needs of a growing research data infrastructure.<br><br><strong><u>Description<br></u></strong><ul><li> Work with stakeholders throughout research to create solutions for analyzing, transforming, and storing drug discovery project data.</li><li> Develop processes and tools to monitor and analyze data accuracy.</li><li> Work closely with the IT department to provide a secure and efficient infrastructure for researchers.</li><li> Provide expertise and hands-on training for data visualization tools such as Spotfire.</li><li> Continually strive to improve research team performance by maintaining a strong understanding of the state-of-the-art tools and software.</li><li> Performs other tasks as assigned.<br></li></ul><strong><u>Requirements<br><br></u></strong>Requirements:.<br><ul><li> Master's degree in computer science or related field with three to five years of hands-on experience with database management.</li><li> Experience working with relational databases, ETL concepts and using statistical computer languages: R, Python, SLQ, etc..</li><li> Coding knowledge and experience with several languages: C, C++, Python, Java, JavaScript, HTML, etc.</li><li> Hands-on experience with data visualization tools (Spotfire, Plotly, etc.)</li><li> Attention to detail, team player, and a strong commitment to excellence.</li><li> Excellent verbal and written communication and skills</li><li> Ability to work independently and collaboratively, as required, in a fast-paced environment.</li><li> Analytical thinker with excellent problem-solving skills</li><li> Ability to quickly adapt to changing priorities and deadlines.<br></li></ul>Robert Half Technology matches IT professionals with remote or on-site jobs on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities.<br><br>Our experienced staffing professionals can promote you to employers and advocate on your behalf. We provide access to top jobs, competitive compensation and benefits, and free online training. For more opportunities, get the Robert Half app and receive instant notifications when our AI matches you with jobs.<br><br>When you work with us, you’re working with the best. Robert Half has been recognized as one of FORTUNE’s “Most Admired Companies” every year since 1998 and was named to Forbes’ inaugural list of America’s Best Temporary Staffing Firms.<br><br>Questions? Call your local office at 1.888.490.4429. All applicants applying for U.S. job openings must be authorized to work in the United States. Benefits are available to temporary professionals. Visit<br><br>© 2020 Robert Half Technology. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to Robert Half’s Terms of Use (</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Staffing and Recruiting
Data Engineer,"Sunnyvale, California, United States",HAN Staffing,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-at-han-staffing-2429523902?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=P%2B%2F8y26oftwaY%2F49y1U3Hw%3D%3D&position=19&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Job Overview

Data Scientist

Data Scientist with Python and R coding skills, SQL, Statistics Mixed model and machine learning modeling experience is needed to design and prototype models based on machine learning, data mining, and statistical modeling in order to solve challenging analytics problems for a dynamic company in the crop and agriculture industry. This is a long term contract position with potential to convert to full-time. Candidate will initially work remote, but will need to work on-site once the virus clears. Due to contractual obligations, candidate must be on our W2.

Requirements For The Data Scientist

Design and prototype models based on machine learning, data mining, and statistical modeling in order to solve challenging analytics problems ranging from exploratory to highly applied.
Manipulate, transform, and analyze abstract data structures
Select the most appropriate modeling techniques and data visualization for big data analysis
Develop code to implement analysis workflows in a robust and reproducible fashion Assist with high-level analysis, design, and code reviews

Requirements for the Data Scientist:
PhD with academic experience or MS with 1-2 years of experience in Statistics, Data Science, Math, Computer Science, Computational Statistics or other related quantitative discipline
Full proficiency with Python, R, and SQL
Experience with database, data wrangling, statistical models, machine learning methods, and their proper application to different data Strong communication and organizational skills
Python and R coding skills, SQL, Statistics Mixed model and machine learning modeling is required

Considered a Plus for the Data Scientist
Basic knowledge in agriculture and plant genetics would be an advantage
Passionate about agricultural science by extracting quantitative insights from data and apply them to crop modeling frameworks is a plus

“Employer will not sponsor applicants for work visas for this position.”

Please apply online or email ian.mulloy@lorienglobal.com. If you don’t meet these requirements, but are interested in other Impellam NA, Corestaff Services or Lorien opportunities, please register with us online at ess.impellam.com .

Lorien is an Equal Opportunity Employer - All qualified applicants will receive consideration without regard to race, color, religion, gender, national origin, age, disability, veteran status, or any other factor determined to be unlawful under applicable law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Overview<br><br></u></strong><strong>Data Scientist<br><br></strong>Data Scientist with <strong>Python and R coding skills, SQL, Statistics Mixed model and machine learning modeling </strong>experience is needed to design and prototype models based on machine learning, data mining, and statistical modeling in order to solve challenging analytics problems for a dynamic company in the crop and agriculture industry. This is a long term contract position with potential to convert to full-time. <strong>Candidate will initially work remote, but will need to work on-site once the virus clears. Due to contractual obligations, candidate must be on our W2. <br><br></strong><strong><u>Requirements For The Data Scientist<br></u></strong><ul><li>Design and prototype models based on machine learning, data mining, and statistical modeling in order to solve challenging analytics problems ranging from exploratory to highly applied.</li><li>Manipulate, transform, and analyze abstract data structures</li><li>Select the most appropriate modeling techniques and data visualization for big data analysis</li><li><strong>Develop code to implement analysis workflows</strong> in a robust and reproducible fashion Assist with high-level analysis, design, and code reviews<br><br><strong>Requirements for the Data Scientist:</strong></li><li>PhD with academic experience or MS with 1-2 years of experience in Statistics, Data Science, Math, Computer Science, Computational Statistics or other related quantitative discipline</li><li><strong>Full proficiency with Python, R, and SQL </strong></li><li>Experience with database, data wrangling, statistical models, machine learning methods, and their proper application to different data Strong communication and organizational skills</li><li>Python and R coding skills, SQL, Statistics Mixed model and machine learning modeling is required<br><br><strong>Considered a Plus for the Data Scientist</strong></li><li>Basic knowledge in agriculture and plant genetics would be an advantage</li><li>Passionate about agricultural science by extracting quantitative insights from data and apply them to crop modeling frameworks is a plus<br></li></ul><strong><em> “Employer will not sponsor applicants for work visas for this position.”<br><br></em></strong>Please apply online or email ian.mulloy@lorienglobal.com. If you don’t meet these requirements, but are interested in other Impellam NA, Corestaff Services or Lorien opportunities, please register with us online at ess.impellam.com .<br><br><strong><em> Lorien </em></strong>is an Equal Opportunity Employer - All qualified applicants will receive consideration without regard to race, color, religion, gender, national origin, age, disability, veteran status, or any other factor determined to be unlawful under applicable law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Staffing and Recruiting, Financial Services"
Data Engineer,"Seattle, Washington, United States",Xpanse Inc.,2021-02-15,https://www.linkedin.com/jobs/view/data-engineer-at-xpanse-inc-2411181435?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=A0PnZuZmWE0pr0ZB5Z%2FroQ%3D%3D&position=20&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

Design, develop, own, and maintain ETL/ELT data flows across a constellation of data sources and systems

Aggregate and store quality data in an efficient and transparent manner for reporting, analytics, and data science uses
Implement tools for monitoring and ensuring data quality and consistency
Build, support, and improve custom tools necessary for data and analytics self-serve initiatives
Work closely with Security and Operations teams to develop and enforce proper data security and privacy practices
Work cross-functionally and communicate in an effective manner
Investigate, advocate for, and proactively obtain new data sets

Requirements

Proven experience creating and maintaining fault-tolerant data pipelines using relational, non-relational, and cloud-based data warehouse systems
Data modelling and data architecture experience
Initiate and drive projects to completion with minimal guidance in a fast-paced, dynamic environment
Detail-oriented, inquisitive by nature, with a can-do attitude and a passion for quality results and an interest in learning new technologies
Strong coding skills and experience with SQL, Python, and Java
Proven experience securing DB services for SQL and noSQL environments (MySQL, Kibana)

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>Design, develop, own, and maintain ETL/ELT data flows across a constellation of data sources and systems<br><ul><li> Aggregate and store quality data in an efficient and transparent manner for reporting, analytics, and data science uses</li><li> Implement tools for monitoring and ensuring data quality and consistency</li><li> Build, support, and improve custom tools necessary for data and analytics self-serve initiatives</li><li> Work closely with Security and Operations teams to develop and enforce proper data security and privacy practices</li><li> Work cross-functionally and communicate in an effective manner</li><li> Investigate, advocate for, and proactively obtain new data sets<br></li></ul><strong><u>Requirements<br></u></strong><ul><li> Proven experience creating and maintaining fault-tolerant data pipelines using relational, non-relational, and cloud-based data warehouse systems</li><li> Data modelling and data architecture experience</li><li> Initiate and drive projects to completion with minimal guidance in a fast-paced, dynamic environment</li><li> Detail-oriented, inquisitive by nature, with a can-do attitude and a passion for quality results and an interest in learning new technologies</li><li> Strong coding skills and experience with SQL, Python, and Java</li><li> Proven experience securing DB services for SQL and noSQL environments (MySQL, Kibana)<br></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Sandy Springs, Georgia, United States",Stratfield Consulting,2021-02-19,https://www.linkedin.com/jobs/view/data-scientist-at-stratfield-consulting-2430422969?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=9XRwMGG88dkEmWt7OPt6fg%3D%3D&position=21&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.



Qualifications For Data Engineer

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:

Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Overview<br><br></u></strong>We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.<br><br>Responsibilities for Data Engineer<br><ul> <li>Create and maintain optimal data pipeline architecture,</li> <li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li> <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li> <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.</li> <li>Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.</li> <li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.</li> <li>Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.</li> <li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li> <li>Work with data and analytics experts to strive for greater functionality in our data systems.</li> <br><br></ul><strong><u>Qualifications For Data Engineer<br></u></strong><ul> <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li> <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li> <li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li> <li>Strong analytic skills related to working with unstructured datasets.</li> <li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li> <li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li> <li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li> <li>Strong project management and organizational skills.</li> <li>Experience supporting and working with cross-functional teams in a dynamic environment.</li> <li>We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:<br><ul> <li>Experience with big data tools: Hadoop, Spark, Kafka, etc.</li> <li>Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.</li> <li>Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.</li> <li>Experience with AWS cloud services: EC2, EMR, RDS, Redshift</li> <li>Experience with stream-processing systems: Storm, Spark-Streaming, etc.</li> <li>Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.</li></ul></li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Austin, Texas, United States",WorldQuant,2021-01-29,https://www.linkedin.com/jobs/view/data-engineer-at-worldquant-2400620966?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=XN4WB2kjpyASd2cwFLhFcw%3D%3D&position=23&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Data Scientist

Are you a Data Scientist that would be excited to help build out and grow a data science department? Are you someone that is willing to step in and help where needed? If so, I have the opportunity for you!

Our client is an established, global, top tier organization based in Atlanta that is experiencing continued growth and new product development. They are searching for a Data Scientist that wants to come into the organization at ground level and help build out the data science practice. This person will be working with large sets of data to provide insightful data to their clients.

This is a direct hire position offering excellent benefits and bonus potential! This candidate should be local to Atlanta, as they are remote now, but will likely have some onsite work in the future.

Duties & Responsibilities

Apply data mining techniques and statistical analysis for large sets of data.
Work with various teams, including DevOps and Product to abstract data.
Leverage Machine Learning and NLP technology to develop data models.
Complete data mapping, data cleansing, data classification, data scraping, predictive modeling, etc.
Competencies

At least 2 years of relevant data science experience.
Masters Degree in Statistics, Mathematics or Engineering.
Experience working with large data sets.
Experience using Machine Learning techniques to combine and compare large data sets.
Experience with data visualization tools.
Experience with Azure or AWS, SageMaker, Data Bricks, Azure SAPS and PowerBI is a huge plus.
Must have experience working with SQL.
Python or R scripting experience.
Highly collaborative background and ability to jump in where needed.
Nice to have

SAS experience.
Customer facing experience.



About Stratfield Consulting

We started Stratfield Consulting with the belief that companies are looking for a more reliable consulting, staffing, and recruiting firm to deliver an expanding list of projects. Our objective is to be the most trusted firm for our clients.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Data Scientist<br><br></strong>Are you a Data Scientist that would be excited to help build out and grow a data science department? Are you someone that is willing to step in and help where needed? If so, I have the opportunity for you!<br><br>Our client is an established, global, top tier organization based in Atlanta that is experiencing continued growth and new product development. They are searching for a Data Scientist that wants to come into the organization at ground level and help build out the data science practice. This person will be working with large sets of data to provide insightful data to their clients.<br><br><strong>This is a direct hire position offering excellent benefits and bonus potential! This candidate should be local to Atlanta, as they are remote now, but will likely have some onsite work in the future. <br><br></strong><strong><u>Duties &amp; Responsibilities<br></u></strong><ul> <li>Apply data mining techniques and statistical analysis for large sets of data.</li> <li>Work with various teams, including DevOps and Product to abstract data.</li> <li>Leverage Machine Learning and NLP technology to develop data models.</li> <li>Complete data mapping, data cleansing, data classification, data scraping, predictive modeling, etc. </li> </ul> <strong>Competencies<br></strong><ul> <li>At least 2 years of relevant data science experience.</li> <li>Masters Degree in Statistics, Mathematics or Engineering.</li> <li>Experience working with large data sets.</li> <li>Experience using Machine Learning techniques to combine and compare large data sets.</li> <li>Experience with data visualization tools.</li> <li>Experience with Azure or AWS, SageMaker, Data Bricks, Azure SAPS and PowerBI is a huge plus.</li> <li>Must have experience working with SQL.</li> <li>Python or R scripting experience. </li> <li>Highly collaborative background and ability to jump in where needed. </li> </ul> <strong>Nice to have<br></strong><ul> <li>SAS experience.</li> <li>Customer facing experience.</li> <br><br></ul><strong><u>About Stratfield Consulting<br><br></u></strong>We started Stratfield Consulting with the belief that companies are looking for a more reliable consulting, staffing, and recruiting firm to deliver an expanding list of projects. Our objective is to be the most trusted firm for our clients.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Durham, North Carolina, United States",Curie Co.,2021-02-05,https://www.linkedin.com/jobs/view/data-scientist-at-curie-co-2409935272?refId=a775aca5-9f33-4fe4-b4a5-c02a5e4fc60c&trackingId=wWL7bDuuWCmvLCsJTPLGig%3D%3D&position=24&pageNum=10&trk=public_jobs_job-result-card_result-card_full-click,"Data Engineer

WorldQuant develops and deploys systematic financial strategies across a variety of asset classes and global markets. We seek to produce high-quality predictive signals (alphas) through our proprietary research platform to employ financial strategies focused on exploiting market inefficiencies. Our teams work collaboratively to drive the production of alphas and financial strategies – the foundation of a sustainable, global investment platform.

Technologists at WorldQuant research, design, code, test and deploy projects while working collaboratively with researchers and portfolio managers. Our environment is relaxed yet intellectually intense. Our teams are lean and agile, which means rapid prototyping of products with immediate user feedback. We seek people who think in code, aspire to solve undiscovered computer science challenges and are motivated by being around like-minded people. In fact, of the 600 employees globally, approximately 500 of them code on a daily basis.

WorldQuant’s success is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Great ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess a mindset of continuous improvement. That’s a key ingredient in remaining a leader in any industry.

Our goal is to hire the best and the brightest. We value intellectual horsepower first and foremost, and people who demonstrate an exceptional talent. There is no roadmap to future success, so we need people who can help us create it. Our collective intelligence will drive us there.

The Role

Design and implement software to facilitate data integration with trading and simulating systems
Adopt new technologies to improve existing frameworks of data flow and monitoring
Implement and maintain software that interface with external vendors to bring in new data sets
Implement the rules and procedures that ensure integrity in data sets
Provide second level support to production support team regarding market data issues
Collect and analyze statistics on market data applications and devise approaches to improve the relevant processes
Design and implement systems that track and manage data availability, access and usage



What You’ll Bring

Degree in a quantitative or technical discipline from a top university and strong academic scores
Interest in applying technology to real situations, comfortable working in a fast-paced environment, detail-oriented and capable of performing tasks under pressure
Demonstrated experience with C++ or other object oriented languages
Experience with scripting languages such as Perl, Python, and shell scripting; Interface with database (such as MySQL)
Possess strong trouble shooting and problem solving skills
Ability to work independently and as member of a team
Strong verbal and written communication skills
Have experience working under a Linux environment, familiar with Vim or Emacs for editing files under the command line


Copyright © 2020 WorldQuant, LLC. All Rights Reserved. WorldQuant is an equal opportunity employer and does not discriminate in hiring on the basis of race, color, creed, religion, sex, sexual orientation or preference, age, marital status, citizenship, national origin, disability, military status, genetic predisposition or carrier status, or any other protected characteristic as established by applicable law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Data Engineer<br><br></strong>WorldQuant develops and deploys systematic financial strategies across a variety of asset classes and global markets. We seek to produce high-quality predictive signals (alphas) through our proprietary research platform to employ financial strategies focused on exploiting market inefficiencies. Our teams work collaboratively to drive the production of alphas and financial strategies – the foundation of a sustainable, global investment platform.<br><br>Technologists at WorldQuant research, design, code, test and deploy projects while working collaboratively with researchers and portfolio managers. Our environment is relaxed yet intellectually intense. Our teams are lean and agile, which means rapid prototyping of products with immediate user feedback. We seek people who think in code, aspire to solve undiscovered computer science challenges and are motivated by being around like-minded people. In fact, of the 600 employees globally, approximately 500 of them code on a daily basis.<br><br>WorldQuant’s success is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Great ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess a mindset of continuous improvement. That’s a key ingredient in remaining a leader in any industry.<br><br>Our goal is to hire the best and the brightest. We value intellectual horsepower first and foremost, and people who demonstrate an exceptional talent. There is no roadmap to future success, so we need people who can help us create it. Our collective intelligence will drive us there.<br><br><strong><u>The Role<br></u></strong><ul> <li>Design and implement software to facilitate data integration with trading and simulating systems</li> <li>Adopt new technologies to improve existing frameworks of data flow and monitoring</li> <li>Implement and maintain software that interface with external vendors to bring in new data sets</li> <li>Implement the rules and procedures that ensure integrity in data sets</li> <li>Provide second level support to production support team regarding market data issues</li> <li>Collect and analyze statistics on market data applications and devise approaches to improve the relevant processes</li> <li>Design and implement systems that track and manage data availability, access and usage</li> <br><br></ul><strong><u>What You’ll Bring<br></u></strong><ul> <li>Degree in a quantitative or technical discipline from a top university and strong academic scores</li> <li>Interest in applying technology to real situations, comfortable working in a fast-paced environment, detail-oriented and capable of performing tasks under pressure</li> <li>Demonstrated experience with C++ or other object oriented languages</li> <li>Experience with scripting languages such as Perl, Python, and shell scripting; Interface with database (such as MySQL)</li> <li>Possess strong trouble shooting and problem solving skills</li> <li>Ability to work independently and as member of a team</li> <li>Strong verbal and written communication skills</li> <li>Have experience working under a Linux environment, familiar with Vim or Emacs for editing files under the command line</li> <br></ul>Copyright © 2020 WorldQuant, LLC. All Rights Reserved. WorldQuant is an equal opportunity employer and does not discriminate in hiring on the basis of race, color, creed, religion, sex, sexual orientation or preference, age, marital status, citizenship, national origin, disability, military status, genetic predisposition or carrier status, or any other protected characteristic as established by applicable law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Boston, Massachusetts, United States",Charles River Associates,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-charles-river-associates-2426657213?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=GfMp8D8Zwyxp9fUJZkpzpQ%3D%3D&position=2&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Curie Co uses the power of biotechnology to replace petrochemicals in everyday products, with more sustainable, engineered enzymes. We’re looking for team members passionate about achieving this mission and contributing to the biomanufacturing revolution. Individuals with exceptional multitasking skills, attention to detail, and self-motivated with the ability to work independently and thrive in a fast-paced environment. Excellent relational, communication, and presentation skills are highly regarded to help continue to foster a collaborative and learning environment.

Curie Co is looking for a Data Scientist that will empower our organization to advance our scientific and business impact more rapidly. The position requires a self-motivated scientist to connect and transport data between multiple applications in an automated and seamless manner, which requires experience in programming languages (Python, R) and working with large, complex datasets. Additionally, the position requires building, maintaining, and evaluating statistical and machine learning models.

An ideal candidate can collaborate with biologists, engineers, and chemists to develop robust data pipelines and data visualization tools to support R&D and manufacturing efforts. Additionally the candidate should have prior industry experience working in a highly collaborative environment to build robust data pipelines to enable rapid aggregation and interrogation of large datasets.

Candidate must possess a high level of technical aptitude, excellent communication, organization, and collaborative skills, and demonstrated ability to innovate, troubleshoot, and thrive in a dynamic cross-functional team environment.

Main Responsibilities

Utilizes modeling, analytical, statistical, and programming skills to contextualize, interpret, and visualize large data sets.
Responsible for creating data architectures and structuring, curating, and storing data.
Responsible for collecting, documenting, and maintaining records for code/scripts developed.
Responsible for training laboratory scientists to operate/leverage tools developed.
Responsible for implementing and maintaining Laboratory Information Management System (LIMS).


Qualifications

A strong background in a data science field with 2-4 years of professional experience or an advanced degree in data science or a related computational science discipline is required.
Skills using Unix, SQL, and Python is required.
Prior experience with statistical and machine learning models.


Preferred Qualifications

Experience developing a computing infrastructure (Azure and AWS a plus).
Experience with databasing.
Experience developing and deploying automated tools for data management.
Experience developing visualization and dashboard tools.
Familiarity with open source and/or commercial biological databases is desired.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Curie Co uses the power of biotechnology to replace petrochemicals in everyday products, with more sustainable, engineered enzymes. We’re looking for team members passionate about achieving this mission and contributing to the biomanufacturing revolution. Individuals with exceptional multitasking skills, attention to detail, and self-motivated with the ability to work independently and thrive in a fast-paced environment. Excellent relational, communication, and presentation skills are highly regarded to help continue to foster a collaborative and learning environment.<br><br>Curie Co is looking for a Data Scientist that will empower our organization to advance our scientific and business impact more rapidly. The position requires a self-motivated scientist to connect and transport data between multiple applications in an automated and seamless manner, which requires experience in programming languages (Python, R) and working with large, complex datasets. Additionally, the position requires building, maintaining, and evaluating statistical and machine learning models.<br><br>An ideal candidate can collaborate with biologists, engineers, and chemists to develop robust data pipelines and data visualization tools to support R&amp;D and manufacturing efforts. Additionally the candidate should have prior industry experience working in a highly collaborative environment to build robust data pipelines to enable rapid aggregation and interrogation of large datasets.<br><br>Candidate must possess a high level of technical aptitude, excellent communication, organization, and collaborative skills, and demonstrated ability to innovate, troubleshoot, and thrive in a dynamic cross-functional team environment.<br><br><strong> Main Responsibilities <br></strong><ul><li>Utilizes modeling, analytical, statistical, and programming skills to contextualize, interpret, and visualize large data sets.</li><li>Responsible for creating data architectures and structuring, curating, and storing data.</li><li>Responsible for collecting, documenting, and maintaining records for code/scripts developed.</li><li>Responsible for training laboratory scientists to operate/leverage tools developed.</li><li>Responsible for implementing and maintaining Laboratory Information Management System (LIMS).<br><br></li></ul><strong> Qualifications <br></strong><ul><li>A strong background in a data science field with 2-4 years of professional experience or an advanced degree in data science or a related computational science discipline is required.</li><li>Skills using Unix, SQL, and Python is required. </li><li>Prior experience with statistical and machine learning models.<br><br></li></ul><strong> Preferred Qualifications <br></strong><ul><li>Experience developing a computing infrastructure (Azure and AWS a plus). </li><li>Experience with databasing.</li><li>Experience developing and deploying automated tools for data management. </li><li>Experience developing visualization and dashboard tools. </li><li>Familiarity with open source and/or commercial biological databases is desired.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Research, Chemicals, Biotechnology"
Data Engineer,United States,Podsights,2021-02-01,https://www.linkedin.com/jobs/view/data-engineer-at-podsights-2383130160?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=if8unAXZwKH6Tp1H00d96Q%3D%3D&position=3&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Data Analyst

About Charles River Associates

Charles River Associates is a leading global consulting firm that provides independent economic and financial analysis in litigation matters, guides businesses through critical strategy and operational issues to become more profitable, and advises governments on the economic impact of policies and regulations. Learn more about how CRA can help you Accelerate your career.

CRA is expanding our internal data analytics functions to support our business operations and to shape and direct critical business initiatives across the organization. In this role you will improve the go-to-market capabilities of our existing business, support the development of new businesses and business models, enhance our operational efficiency, and directly contribute to the development and execution of our strategic plan. This role is necessarily cross-functional and will include interaction with the company’s leadership team.

Essential Functions

As part of expanded team, the Data Analyst will work closely with CRA’s senior management, practice leaders, and other internal business functions to solve interesting analytical problems that aim to sustain and improve CRA’s operations and market position. In these roles, you will apply your coding and modelling skills, own and personally deliver components of the research project, and contribute to the overall success of the team. We anticipate contributions across a wide range of activities, including finance, human capital, and marketing. As you demonstrate strong analytical skills and develop sound project management skills, your responsibilities will grow rapidly.

Data Analyst

Candidates possessing a Masters degree or the equivalent work experience will be considered for the Data Analyst role
Data Analysts will generally be key contributors to project teams, focusing on data manipulation, modeling, and delivery of analysis results
Data Analysts who demonstrate strong performance and ability to take on additional responsibility may rapidly ascend to the Data Scientist role



Responsibilities

Import, clean, manipulate and analyze large volume of data (>100MM records) to develop critical insights, using SAS, SQL or other tools
Build statistical and machine learning models to detect patterns and investigate important drivers, e.g. Econometrics, Random Forest, Neural Network, clustering , etc., using SAS, R, Stata, Python or other specialized tools.
Perform text mining and web scraping from online data sources using NLP-relevant packages in Python
Apply critical perspective across multiple internal clients and data sources
Communicate findings, through visuals, data tables and models, from your analyses to internal team members and, over time, to CRA’s senior leadership
Work in a demanding but highly collegial and collaborative environment



Qualifications

Masters degree or above or the equivalent work experience, preferably in Statistics, Mathematics, Machine Learning, Computer Science or mathematically-intensive field
Ability to proficiently process and manipulate data in SQL, SAS, R or Python
Experience in developing advanced models such as multi-variate regression, neural networks, support vector machines, decision trees, clustering and time series using tools such as R and Python
Demonstrate good written and verbal communication skills. Able to present information to various audiences
Ability to work collaboratively in a team environment and effectively with people at all levels in an organization
Ability to provide creative solutions to non-standard analytical problems
Experience in data visualization using Power BI, Tableau, D3.js, Qlik Sense, HTML/JavaScript is a plus
Knowledge of any of the following: Natural Language Processing & Text Mining, Experimental Design, Bayesian Networks, Network/Graph Mining is a plus


To be considered for this role, please submit your resume and cover letter.

CRA is an Equal Opportunity and Affirmative Action Employer (EEO/AAE): Minority/Female/Veteran/Disabled.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Data Analyst <br><br></strong><strong><u>About Charles River Associates<br><br></u></strong>Charles River Associates is a leading global consulting firm that provides independent economic and financial analysis in litigation matters, guides businesses through critical strategy and operational issues to become more profitable, and advises governments on the economic impact of policies and regulations. Learn more about how CRA can help you <strong>Accelerate</strong> your career.<br><br>CRA is expanding our internal data analytics functions to support our business operations and to shape and direct critical business initiatives across the organization. In this role you will improve the go-to-market capabilities of our existing business, support the development of new businesses and business models, enhance our operational efficiency, and directly contribute to the development and execution of our strategic plan. This role is necessarily cross-functional and will include interaction with the company’s leadership team.<br><br><strong><u>Essential Functions<br><br></u></strong>As part of expanded team, the <strong>Data Analyst</strong> will work closely with CRA’s senior management, practice leaders, and other internal business functions to solve interesting analytical problems that aim to sustain and improve CRA’s operations and market position. In these roles, you will apply your coding and modelling skills, own and personally deliver components of the research project, and contribute to the overall success of the team. We anticipate contributions across a wide range of activities, including finance, human capital, and marketing. As you demonstrate strong analytical skills and develop sound project management skills, your responsibilities will grow rapidly.<br><br><strong>Data Analyst<br></strong><ul> <li>Candidates possessing a Masters degree or the equivalent work experience will be considered for the <strong>Data Analyst</strong> role</li> <li><strong>Data Analysts</strong> will generally be key contributors to project teams, focusing on data manipulation, modeling, and delivery of analysis results</li> <li><strong>Data Analysts</strong> who demonstrate strong performance and ability to take on additional responsibility may rapidly ascend to the <strong>Data Scientist</strong> role</li> <br><br></ul><strong><u>Responsibilities<br></u></strong><ul> <li>Import, clean, manipulate and analyze large volume of data (&gt;100MM records) to develop critical insights, using SAS, SQL or other tools</li> <li>Build statistical and machine learning models to detect patterns and investigate important drivers, e.g. Econometrics, Random Forest, Neural Network, clustering , etc., using SAS, R, Stata, Python or other specialized tools.</li> <li>Perform text mining and web scraping from online data sources using NLP-relevant packages in Python</li> <li>Apply critical perspective across multiple internal clients and data sources</li> <li>Communicate findings, through visuals, data tables and models, from your analyses to internal team members and, over time, to CRA’s senior leadership</li> <li>Work in a demanding but highly collegial and collaborative environment</li> <br><br></ul><strong><u>Qualifications<br></u></strong><ul> <li>Masters degree or above or the equivalent work experience, preferably in Statistics, Mathematics, Machine Learning, Computer Science or mathematically-intensive field</li> <li>Ability to proficiently process and manipulate data in SQL, SAS, R or Python</li> <li>Experience in developing advanced models such as multi-variate regression, neural networks, support vector machines, decision trees, clustering and time series using tools such as R and Python</li> <li>Demonstrate good written and verbal communication skills. Able to present information to various audiences</li> <li>Ability to work collaboratively in a team environment and effectively with people at all levels in an organization</li> <li>Ability to provide creative solutions to non-standard analytical problems</li> <li>Experience in data visualization using Power BI, Tableau, D3.js, Qlik Sense, HTML/JavaScript is a plus</li> <li>Knowledge of any of the following: Natural Language Processing &amp; Text Mining, Experimental Design, Bayesian Networks, Network/Graph Mining is a plus</li> <br></ul>To be considered for this role, please submit your resume and cover letter.<br><br><em> CRA is an Equal Opportunity and Affirmative Action Employer (EEO/AAE): Minority/Female/Veteran/Disabled.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Management Consulting, Financial Services"
Software Engineer- Data Engineering,"San Francisco, California, United States",DocuSign,2021-02-09,https://www.linkedin.com/jobs/view/software-engineer-data-engineering-at-docusign-2403580234?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=oDfOylkyR5zfFj7So%2FJqig%3D%3D&position=4&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Remote within the U.S. -- $110k - $150k




Podsights is a small, distributed organization seeking an engineer to join our growing team! Here's a little about us, a little about what we believe, and what we are looking for.




Podsights is an attribution platform for podcast advertising. We likely work with your favorite publisher and handle over 4 billion events a month.




Our mission is simple, we are looking to grow the podcast industry. Far too many brands try a podcast advertising campaign and churn. Or worse: they don’t even try to enter the market. By providing a platform for brands to optimize results, we encourage investment in podcast advertising, and by proxy to publishers.




Your role will be more of a generalist, but with a focus on the data engineering side or in other words a jack of all data trades. On a given day, you may work on our data ingestion pipeline, the ETL system, or handling a client ask. The benefit of joining a small team is you will have a tremendous impact on the company’s direction, and to some extent, the industry.




The podcasting industry has seen a lot of growth in the past few years, and we believe it has more room to grow. Beyond growth, podcasting presents some interesting problems: its decentralized, RSS-based nature, and the various ways people can listen. Joining Podsights is an excellent opportunity to be hands-on with an evolving medium.




We believe that where you went to school has little bearing on your performance as a software engineer. Where you live isn’t a proxy for talent. Your current employer provides low signal about your future potential.




At Podsights, we look for ambition and curiosity. We love engineers that aren’t solely interested in the craft of developing software. Want to start a company of your own one day? Yes, we want to talk. Are you interested in the business side of software? Tell us more.

We want curious engineers. You take things apart and see how they work (the real test is if you can put them together too!).




Ideally, you will have 2+ years of experience as a software or data engineer. Our current stack includes Python, Google Cloud (Dataflow, Airflow, Spanner, BigQuery, etc.), Redis, Go, Node, and potentially whatever you bring to the table.




Our team consists of members of Embedly (acquired by Medium), Horizon Media, Claritas, NPM, and How Stuff Works. You can learn more about us here: https://podsights.com/team




If the above interests you, drop us a note. We’re less worried about a resume (LinkedIn is fine), but more importantly, tell us about your ideal next role.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Remote within the U.S.&nbsp;--&nbsp;<em>$110k - $150k</em></p><p><br></p><p>Podsights is a small, distributed organization seeking an engineer to join our growing team! Here's a little about us, a little about what we believe, and what we are looking for.</p><p><br></p><p>Podsights is an attribution platform for podcast advertising. We likely work with your favorite publisher and handle over 4 billion events a month.</p><p><br></p><p>Our mission is simple, we are looking to grow the podcast industry. Far too many brands try a podcast advertising campaign and churn. Or worse: they don’t even try to enter the market. By providing a platform for brands to optimize results, we encourage investment in podcast advertising, and by proxy to publishers.</p><p><br></p><p>Your role will be more of a generalist, but with a focus on the data engineering side or in other words a jack of all data trades. On a given day, you may work on our data ingestion pipeline, the ETL system, or handling a client ask. The benefit of joining a small team is you will have a tremendous impact on the company’s direction, and to some extent, the industry.</p><p><br></p><p>The podcasting industry has seen a lot of growth in the past few years, and we believe it has more room to grow. Beyond growth, podcasting presents some interesting problems: its decentralized, RSS-based nature, and the various ways people can listen. Joining Podsights is an excellent opportunity to be hands-on with an evolving medium.</p><p><br></p><p>We believe that where you went to school has little bearing on your performance as a software engineer. Where you live isn’t a proxy for talent. Your current employer provides low signal about your future potential.</p><p><br></p><p>At Podsights, we look for ambition and curiosity. We love engineers that aren’t solely interested in the craft of developing software. Want to start a company of your own one day? Yes, we want to talk. Are you interested in the business side of software? Tell us more.</p><p>We want curious engineers. You take things apart and see how they work (the real test is if you can put them together too!).</p><p><br></p><p>Ideally, you will have 2+ years of experience as a software or data engineer. Our current stack includes Python, Google Cloud (Dataflow, Airflow, Spanner, BigQuery, etc.), Redis, Go, Node, and potentially whatever you bring to the table.</p><p><br></p><p>Our team consists of members of Embedly (acquired by Medium), Horizon Media, Claritas, NPM, and How Stuff Works. You can learn more about us here:&nbsp;https://podsights.com/team</p><p><br></p><p>If the above interests you, drop us a note. We’re less worried about a resume (LinkedIn is fine), but more importantly, tell us about your ideal next role.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Marketing and Advertising
Data Engineer,"Seattle, Washington, United States",Project Archer,2021-02-14,https://www.linkedin.com/jobs/view/data-engineer-at-project-archer-2411112667?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=x8QKezSva0JsTLX7JH6GkA%3D%3D&position=5&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Software Engineer: Data Engineering
Enterprise Data Solutions | San Francisco, California

Our Agreement With Employees

DocuSign is committed to building trust and making the world more agree-able for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what’s right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you’ll be loved by us, our customers, and the world in which we live.

The Team

Our Engineering & Tech Operations team builds and operates complex solutions for global business challenges that cross cultures, legal jurisdictions, and impacts millions of people and businesses every day. We hire people with a broad set of skills and people who want to work on creating never-been-done-before solutions at scale while ensuring world-class reliability and security. Our Agreement Cloud is a revolutionary solution that changes the way people live, work, and come to agreement.

This Position

DocuSign is seeking a talented and results oriented Data Engineer to focus on delivering trusted data to the business. As a member of the Enterprise Data Solutions (EDS) Team, the Data Engineer leverages a variety of technologies to load, transform, and prepare data sets of all shapes and sizes for teams around the world. During a typical day, the Data Engineer will spend time analyzing data, developing solutions with ETL tools, and loading tested data sets into the Snowflake Enterprise Data Warehouse. The ideal candidate will demonstrate a positive “can do” attitude, a passion for learning and growing, and the drive to work hard and get the job done in a timely fashion. This individual contributor position provides plenty of room to grow -- a mix of challenging assignments, a chance to work with a world-class team, and the opportunity to use innovative technologies such as AWS, Snowflake, and Matillion.

This position reports to the Senior Manager Data Warehouse

Responsibilities

Analyze data sets and define requirements for delivering new data to business partners
Analyze source system APIs, data schema, and data profiles to define what is possible
Develop ETL code for integrating new data sets into Snowflake
Own, monitor, and improve solutions to ensure SLAs are met
Executes projects using Agile Scrum methodologies

Basic Qualifications

Bachelor’s Degree in Computer Science, Data Analytics, Information Systems, etc.
5+ years of experience with SQL
Experience developing code in one of the following languages: python, PowerShell, java
5+ years data modeling, dimensional and relational

Preferred Qualifications

5+ years in data warehouse engineering (OLAP) Snowflake, Teradata, Redshift
5+ years with transactional databases (OLTP) Oracle, SQL Server, MySQL
5+ years with big data, Hadoop, Data Lake, Spark
5+ years with commercial ETL tools – Informatica, Matillion, Talend, Pentaho, SSIS
5+ years delivering ETL solutions from source systems, databases, APIs, flat-files, JSON
Experience developing Entity Relationship Diagrams with Erwin, DeZign, or equivalent
Experience working with job scheduling and monitoring systems
Experience building BI Dashboards with tools like Qlik and Power BI
Experience in the financial domain, accounts payable, accounts receivable, invoicing
Experience managing work assignments using tools like Jira and Confluence

About Us

DocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that’s a good thing.

DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Software Engineer: Data Engineering <br></strong><strong>Enterprise Data Solutions | San Francisco, California<br><br></strong><strong><u>Our Agreement With Employees<br><br></u></strong>DocuSign is committed to building trust and making the world more agree-able for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what’s right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you’ll be loved by us, our customers, and the world in which we live.<br><br><strong><u>The Team<br><br></u></strong>Our Engineering &amp; Tech Operations team builds and operates complex solutions for global business challenges that cross cultures, legal jurisdictions, and impacts millions of people and businesses every day. We hire people with a broad set of skills and people who want to work on creating never-been-done-before solutions at scale while ensuring world-class reliability and security. Our Agreement Cloud is a revolutionary solution that changes the way people live, work, and come to agreement.<br><br><strong><u>This Position<br><br></u></strong>DocuSign is seeking a talented and results oriented Data Engineer to focus on delivering trusted data to the business. As a member of the Enterprise Data Solutions (EDS) Team, the Data Engineer leverages a variety of technologies to load, transform, and prepare data sets of all shapes and sizes for teams around the world. During a typical day, the Data Engineer will spend time analyzing data, developing solutions with ETL tools, and loading tested data sets into the Snowflake Enterprise Data Warehouse. The ideal candidate will demonstrate a positive “can do” attitude, a passion for learning and growing, and the drive to work hard and get the job done in a timely fashion. This individual contributor position provides plenty of room to grow -- a mix of challenging assignments, a chance to work with a world-class team, and the opportunity to use innovative technologies such as AWS, Snowflake, and Matillion.<br><br>This position reports to the Senior Manager Data Warehouse<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Analyze data sets and define requirements for delivering new data to business partners</li><li> Analyze source system APIs, data schema, and data profiles to define what is possible</li><li> Develop ETL code for integrating new data sets into Snowflake</li><li> Own, monitor, and improve solutions to ensure SLAs are met</li><li> Executes projects using Agile Scrum methodologies<br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li> Bachelor’s Degree in Computer Science, Data Analytics, Information Systems, etc.</li><li> 5+ years of experience with SQL</li><li> Experience developing code in one of the following languages: python, PowerShell, java</li><li> 5+ years data modeling, dimensional and relational<br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> 5+ years in data warehouse engineering (OLAP) Snowflake, Teradata, Redshift</li><li> 5+ years with transactional databases (OLTP) Oracle, SQL Server, MySQL</li><li> 5+ years with big data, Hadoop, Data Lake, Spark</li><li> 5+ years with commercial ETL tools – Informatica, Matillion, Talend, Pentaho, SSIS</li><li> 5+ years delivering ETL solutions from source systems, databases, APIs, flat-files, JSON</li><li> Experience developing Entity Relationship Diagrams with Erwin, DeZign, or equivalent</li><li> Experience working with job scheduling and monitoring systems</li><li> Experience building BI Dashboards with tools like Qlik and Power BI</li><li> Experience in the financial domain, accounts payable, accounts receivable, invoicing</li><li> Experience managing work assignments using tools like Jira and Confluence<br></li></ul><strong><u>About Us<br><br></u></strong>DocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that’s a good thing.<br><br>DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Computer Software
Data Engineer,"Greenville, South Carolina, United States",Worthwhile,2021-02-16,https://www.linkedin.com/jobs/view/data-engineer-at-worthwhile-2409454861?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=CLhVVUbTp22erxAiZbqoFg%3D%3D&position=7&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"About You

 

We are looking for a Data Engineer who will support our product development teams by guiding proper data practices to build proprietary data sets, and empowering our clients to find value in data. 

The Data Engineer will also be responsible for data architecture that defines data models for new systems, selecting the best data storage solution for a given data set and usage pattern, collecting and managing test data, and creating normalized views of meaningful systems from disparate data sources. You will also have a key role to play in creating and operationalizing machine learning based solutions. 

We are seeking a candidate with strong experience using a variety of data storage, collection, mining, and analysis methods. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. 







About Us




Worthwhile helps mid-market companies out-innovate their competition through software and data. We utilize a Design Thinking methodology to continuously design, build, and run digital transformation initiatives that deliver real business value in the manufacturing, financial services and healthcare sectors. Our culture is unique and defined by our 19 specific value behaviors. This relentless focus throughout our 25+ year history has enabled us to achieve an unprecedented Net Promoter Score of 84 (2x the industry average) and be named the #2 Best Place to Work in South Carolina for 2019.







Role Overview




Data Science Engineers design proper data models that minimize data exhaust and support Data Scientists. They then use this information to develop data-driven solutions to difficult business challenges. Data Engineers commonly have a Master's degree in statistics, math, computer science, or economics, or equivalent experience. Data Engineers have a wide range of technical competencies including: 

Designing and reviewing data architectures
Designing schemas
Creating test data
Building containers 
Configuring data lake pipelines
Implementing data quality initiatives
Work with database migrations used in CI/CD 
Work with SRE to respond to incidents 







Your Responsibilities




Work with engineering teams to design, build and run innovative automation solutions. 
Conduct independent research to gain domain-specific knowledge and develop custom data models and algorithms as well as valuable testing fixtures to support the larger engineering team.
Monitor and optimize database performance. 
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Coordinate with different functional teams to implement models and monitor outcomes.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.







Role Qualifications




Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (Python, SQL, USQL, R, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 5+ years of experience designing and implementing database solutions, and is familiar with the following software/tools: 
Coding knowledge and experience with several languages: Python and SQL are key.
Experience querying databases and using statistical computer languages: Python, SQL, R, etc.
Cloud architectures including AWS and Azure
Asynchronous computing models (Kafka, RabbitMQ, etc.)
Experience ingesting data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.







Technologies

Required:
Postgres
MS SQL Server
Kafka
Hadoop
AWS Data Lake
NoSql Databases
ERD Documentation
SQL
DDL
DML
JSON Schema
Preferred 
Azure Data Lake services
Amazon Data Lake services
Open source reporting frameworks
Oracle
MySql
MariaDB
Mongo
Couch / Cloudant
Elastic
Redis
DynamoDB
Bigtable
Cassandra
Others







Compensation and benefits




Base salary 
Health insurance, paid time off, expense and travel account, and other benefits.







Your Ethos




Make decisions in alignment with our vision:




A magnet for companies seeking the most valuable software.
A destination for people seeking the most fulfilling work.




Make decisions in alignment with our mission:




We entertain an engagement only with the client is significantly rewarded.
Our employees’ fulfillment will be fueled by our clients’ success.
Our engagements are successful when our clients request an ongoing strategic relationship.




Perform your work in accordance with our 20 specific values-based actions.




Drive deep collaboration among our team with a focus on solutions that make us more valuable to our clients.
Listen intently and reflectively to clients with a desire to understand before being understood.
Be curious and constantly improve to provide better solutions for clients.
Excel in communicating with clients; be clear, concise, and anticipate questions.
Honor your commitments: be on time, every time; deliver what you promise when you promise it.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>About You</strong></p><p>&nbsp;</p><p>We are looking for a Data Engineer who will support our product development teams by guiding proper data practices to build proprietary data sets, and empowering our clients to find value in data.&nbsp;</p><p>The Data Engineer will also be responsible for data architecture that defines data models for new systems, selecting the best data storage solution for a given data set and usage pattern, collecting and managing test data, and creating normalized views of meaningful systems from disparate data sources. You will also have a key role to play in creating and operationalizing machine learning based solutions.&nbsp;</p><p>We are seeking a candidate with strong experience using a variety of data storage, collection, mining, and analysis methods. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.&nbsp;</p><p><br></p><p><br></p><p><strong>About Us</strong></p><p><br></p><p>Worthwhile helps mid-market companies out-innovate their competition through software and data. We utilize a Design Thinking methodology to continuously design, build, and run digital transformation initiatives that deliver real business value in the manufacturing, financial services and healthcare sectors. Our culture is unique and defined by our 19 specific value behaviors. This relentless focus throughout our 25+ year history has enabled us to achieve an unprecedented Net Promoter Score of 84 (2x the industry average) and be named the #2 Best Place to Work in South Carolina for 2019.</p><p><br></p><p><br></p><p><strong>Role Overview</strong></p><p><br></p><p>Data Science Engineers design proper data models that minimize data exhaust and support Data Scientists. They then use this information to develop data-driven solutions to difficult business challenges. Data Engineers commonly have a Master's degree in statistics, math, computer science, or economics, or equivalent experience. Data Engineers have a wide range of technical competencies including:&nbsp;</p><ul><li>Designing and reviewing data architectures</li><li>Designing schemas</li><li>Creating test data</li><li>Building containers&nbsp;</li><li>Configuring data lake pipelines</li><li>Implementing data quality initiatives</li><li>Work with database migrations used in CI/CD&nbsp;</li><li>Work with SRE to respond to incidents&nbsp;</li></ul><p><br></p><p><br></p><p><strong>Your Responsibilities</strong></p><p><br></p><ul><li>Work with engineering teams to design, build and run innovative automation solutions.&nbsp;</li><li>Conduct independent research to gain domain-specific knowledge and develop custom data models and algorithms as well as valuable testing fixtures to support the larger engineering team.</li><li>Monitor and optimize database performance.&nbsp;</li><li>Assess the effectiveness and accuracy of new data sources and data gathering techniques.</li><li>Coordinate with different functional teams to implement models and monitor outcomes.</li><li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li><li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li></ul><p><br></p><p><br></p><p><strong>Role Qualifications</strong></p><p><br></p><ul><li>Strong problem solving skills with an emphasis on product development.</li><li>Experience using statistical computer languages (Python, SQL, USQL, R, etc.) to manipulate data and draw insights from large data sets.</li><li>Experience working with and creating data architectures.</li><li>Excellent written and verbal communication skills for coordinating across teams.</li><li>A drive to learn and master new technologies and techniques.</li><li>We’re looking for someone with 5+ years of experience designing and implementing database solutions, and is familiar with the following software/tools:&nbsp;</li><li>Coding knowledge and experience with several languages: Python and SQL are key.</li><li>Experience querying databases and using statistical computer languages: Python, SQL, R, etc.</li><li>Cloud architectures including AWS and Azure</li><li>Asynchronous computing models (Kafka, RabbitMQ, etc.)</li><li>Experience ingesting data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.</li><li>Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.</li><li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li><li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li><li>Experience supporting and working with cross-functional teams in a dynamic environment.</li></ul><p><br></p><p><br></p><p><strong>Technologies</strong></p><ul><li>Required:</li><li>Postgres</li><li>MS SQL Server</li><li>Kafka</li><li>Hadoop</li><li>AWS Data Lake</li><li>NoSql Databases</li><li>ERD Documentation</li><li>SQL</li><li>DDL</li><li>DML</li><li>JSON Schema</li><li>Preferred&nbsp;</li><li>Azure Data Lake services</li><li>Amazon Data Lake services</li><li>Open source reporting frameworks</li><li>Oracle</li><li>MySql</li><li>MariaDB</li><li>Mongo</li><li>Couch / Cloudant</li><li>Elastic</li><li>Redis</li><li>DynamoDB</li><li>Bigtable</li><li>Cassandra</li><li>Others</li></ul><p><br></p><p><br></p><p><strong>Compensation and benefits</strong></p><p><br></p><ul><li>Base salary&nbsp;</li><li>Health insurance, paid time off, expense and travel account, and other benefits.</li></ul><p><br></p><p><br></p><p><strong>Your Ethos</strong></p><p><br></p><p>Make decisions in alignment with our vision:</p><p><br></p><ul><li>A magnet for companies seeking the most valuable software.</li><li>A destination for people seeking the most fulfilling work.</li></ul><p><br></p><p>Make decisions in alignment with our mission:</p><p><br></p><ul><li>We entertain an engagement only with the client is significantly rewarded.</li><li>Our employees’ fulfillment will be fueled by our clients’ success.</li><li>Our engagements are successful when our clients request an ongoing strategic relationship.</li></ul><p><br></p><p>Perform your work in accordance with our 20 specific values-based actions.</p><p><br></p><ul><li>Drive deep collaboration among our team with a focus on solutions that make us more valuable to our clients.</li><li>Listen intently and reflectively to clients with a desire to understand before being understood.</li><li>Be curious and constantly improve to provide better solutions for clients.</li><li>Excel in communicating with clients; be clear, concise, and anticipate questions.</li><li>Honor your commitments: be on time, every time; deliver what you promise when you promise it.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Technology and Services
Data Engineer - Chicago,"Chicago, Illinois, United States",Ace Technologies,2021-02-18,https://www.linkedin.com/jobs/view/data-engineer-chicago-at-ace-technologies-2429190059?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=md0LXpVtbkNSPsyUSj3s8g%3D%3D&position=8&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"About You

 

We are looking for a Data Engineer who will support our product development teams by guiding proper data practices to build proprietary data sets, and empowering our clients to find value in data. 

The Data Engineer will also be responsible for data architecture that defines data models for new systems, selecting the best data storage solution for a given data set and usage pattern, collecting and managing test data, and creating normalized views of meaningful systems from disparate data sources. You will also have a key role to play in creating and operationalizing machine learning based solutions. 

We are seeking a candidate with strong experience using a variety of data storage, collection, mining, and analysis methods. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. 







About Us




Worthwhile helps mid-market companies out-innovate their competition through software and data. We utilize a Design Thinking methodology to continuously design, build, and run digital transformation initiatives that deliver real business value in the manufacturing, financial services and healthcare sectors. Our culture is unique and defined by our 19 specific value behaviors. This relentless focus throughout our 25+ year history has enabled us to achieve an unprecedented Net Promoter Score of 84 (2x the industry average) and be named the #2 Best Place to Work in South Carolina for 2019.







Role Overview




Data Science Engineers design proper data models that minimize data exhaust and support Data Scientists. They then use this information to develop data-driven solutions to difficult business challenges. Data Engineers commonly have a Master's degree in statistics, math, computer science, or economics, or equivalent experience. Data Engineers have a wide range of technical competencies including: 

Designing and reviewing data architectures
Designing schemas
Creating test data
Building containers 
Configuring data lake pipelines
Implementing data quality initiatives
Work with database migrations used in CI/CD 
Work with SRE to respond to incidents 







Your Responsibilities




Work with engineering teams to design, build and run innovative automation solutions. 
Conduct independent research to gain domain-specific knowledge and develop custom data models and algorithms as well as valuable testing fixtures to support the larger engineering team.
Monitor and optimize database performance. 
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Coordinate with different functional teams to implement models and monitor outcomes.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.







Role Qualifications




Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (Python, SQL, USQL, R, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 5+ years of experience designing and implementing database solutions, and is familiar with the following software/tools: 
Coding knowledge and experience with several languages: Python and SQL are key.
Experience querying databases and using statistical computer languages: Python, SQL, R, etc.
Cloud architectures including AWS and Azure
Asynchronous computing models (Kafka, RabbitMQ, etc.)
Experience ingesting data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.







Technologies

Required:
Postgres
MS SQL Server
Kafka
Hadoop
AWS Data Lake
NoSql Databases
ERD Documentation
SQL
DDL
DML
JSON Schema
Preferred 
Azure Data Lake services
Amazon Data Lake services
Open source reporting frameworks
Oracle
MySql
MariaDB
Mongo
Couch / Cloudant
Elastic
Redis
DynamoDB
Bigtable
Cassandra
Others







Compensation and benefits




Base salary 
Health insurance, paid time off, expense and travel account, and other benefits.







Your Ethos




Make decisions in alignment with our vision:




A magnet for companies seeking the most valuable software.
A destination for people seeking the most fulfilling work.




Make decisions in alignment with our mission:




We entertain an engagement only with the client is significantly rewarded.
Our employees’ fulfillment will be fueled by our clients’ success.
Our engagements are successful when our clients request an ongoing strategic relationship.




Perform your work in accordance with our 20 specific values-based actions.




Drive deep collaboration among our team with a focus on solutions that make us more valuable to our clients.
Listen intently and reflectively to clients with a desire to understand before being understood.
Be curious and constantly improve to provide better solutions for clients.
Excel in communicating with clients; be clear, concise, and anticipate questions.
Honor your commitments: be on time, every time; deliver what you promise when you promise it.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>About You</strong></p><p>&nbsp;</p><p>We are looking for a Data Engineer who will support our product development teams by guiding proper data practices to build proprietary data sets, and empowering our clients to find value in data.&nbsp;</p><p>The Data Engineer will also be responsible for data architecture that defines data models for new systems, selecting the best data storage solution for a given data set and usage pattern, collecting and managing test data, and creating normalized views of meaningful systems from disparate data sources. You will also have a key role to play in creating and operationalizing machine learning based solutions.&nbsp;</p><p>We are seeking a candidate with strong experience using a variety of data storage, collection, mining, and analysis methods. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.&nbsp;</p><p><br></p><p><br></p><p><strong>About Us</strong></p><p><br></p><p>Worthwhile helps mid-market companies out-innovate their competition through software and data. We utilize a Design Thinking methodology to continuously design, build, and run digital transformation initiatives that deliver real business value in the manufacturing, financial services and healthcare sectors. Our culture is unique and defined by our 19 specific value behaviors. This relentless focus throughout our 25+ year history has enabled us to achieve an unprecedented Net Promoter Score of 84 (2x the industry average) and be named the #2 Best Place to Work in South Carolina for 2019.</p><p><br></p><p><br></p><p><strong>Role Overview</strong></p><p><br></p><p>Data Science Engineers design proper data models that minimize data exhaust and support Data Scientists. They then use this information to develop data-driven solutions to difficult business challenges. Data Engineers commonly have a Master's degree in statistics, math, computer science, or economics, or equivalent experience. Data Engineers have a wide range of technical competencies including:&nbsp;</p><ul><li>Designing and reviewing data architectures</li><li>Designing schemas</li><li>Creating test data</li><li>Building containers&nbsp;</li><li>Configuring data lake pipelines</li><li>Implementing data quality initiatives</li><li>Work with database migrations used in CI/CD&nbsp;</li><li>Work with SRE to respond to incidents&nbsp;</li></ul><p><br></p><p><br></p><p><strong>Your Responsibilities</strong></p><p><br></p><ul><li>Work with engineering teams to design, build and run innovative automation solutions.&nbsp;</li><li>Conduct independent research to gain domain-specific knowledge and develop custom data models and algorithms as well as valuable testing fixtures to support the larger engineering team.</li><li>Monitor and optimize database performance.&nbsp;</li><li>Assess the effectiveness and accuracy of new data sources and data gathering techniques.</li><li>Coordinate with different functional teams to implement models and monitor outcomes.</li><li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li><li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li></ul><p><br></p><p><br></p><p><strong>Role Qualifications</strong></p><p><br></p><ul><li>Strong problem solving skills with an emphasis on product development.</li><li>Experience using statistical computer languages (Python, SQL, USQL, R, etc.) to manipulate data and draw insights from large data sets.</li><li>Experience working with and creating data architectures.</li><li>Excellent written and verbal communication skills for coordinating across teams.</li><li>A drive to learn and master new technologies and techniques.</li><li>We’re looking for someone with 5+ years of experience designing and implementing database solutions, and is familiar with the following software/tools:&nbsp;</li><li>Coding knowledge and experience with several languages: Python and SQL are key.</li><li>Experience querying databases and using statistical computer languages: Python, SQL, R, etc.</li><li>Cloud architectures including AWS and Azure</li><li>Asynchronous computing models (Kafka, RabbitMQ, etc.)</li><li>Experience ingesting data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.</li><li>Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.</li><li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li><li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li><li>Experience supporting and working with cross-functional teams in a dynamic environment.</li></ul><p><br></p><p><br></p><p><strong>Technologies</strong></p><ul><li>Required:</li><li>Postgres</li><li>MS SQL Server</li><li>Kafka</li><li>Hadoop</li><li>AWS Data Lake</li><li>NoSql Databases</li><li>ERD Documentation</li><li>SQL</li><li>DDL</li><li>DML</li><li>JSON Schema</li><li>Preferred&nbsp;</li><li>Azure Data Lake services</li><li>Amazon Data Lake services</li><li>Open source reporting frameworks</li><li>Oracle</li><li>MySql</li><li>MariaDB</li><li>Mongo</li><li>Couch / Cloudant</li><li>Elastic</li><li>Redis</li><li>DynamoDB</li><li>Bigtable</li><li>Cassandra</li><li>Others</li></ul><p><br></p><p><br></p><p><strong>Compensation and benefits</strong></p><p><br></p><ul><li>Base salary&nbsp;</li><li>Health insurance, paid time off, expense and travel account, and other benefits.</li></ul><p><br></p><p><br></p><p><strong>Your Ethos</strong></p><p><br></p><p>Make decisions in alignment with our vision:</p><p><br></p><ul><li>A magnet for companies seeking the most valuable software.</li><li>A destination for people seeking the most fulfilling work.</li></ul><p><br></p><p>Make decisions in alignment with our mission:</p><p><br></p><ul><li>We entertain an engagement only with the client is significantly rewarded.</li><li>Our employees’ fulfillment will be fueled by our clients’ success.</li><li>Our engagements are successful when our clients request an ongoing strategic relationship.</li></ul><p><br></p><p>Perform your work in accordance with our 20 specific values-based actions.</p><p><br></p><ul><li>Drive deep collaboration among our team with a focus on solutions that make us more valuable to our clients.</li><li>Listen intently and reflectively to clients with a desire to understand before being understood.</li><li>Be curious and constantly improve to provide better solutions for clients.</li><li>Excel in communicating with clients; be clear, concise, and anticipate questions.</li><li>Honor your commitments: be on time, every time; deliver what you promise when you promise it.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Information Technology and Services
Data Engineer,"New York, New York, United States",Teachable,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-at-teachable-2410405216?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=eiu9amsF5U3JJlcIEczA%2Bw%3D%3D&position=9&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

:

Purpose

The Data Engineer on the Life Business Intelligence and Advanced Analytics team will support the delivery of innovative data solutions including: (1) the Life Data Strategy initiative – specifically supporting the setup and use of Snowflake data lake; (2) buildout of automated reports, dashboards, analysis – using PowerBI/Tableau; and (3) support data science initiatives.

Essential Activities

Technical liaison between Analytics and IT departments.

Work closely with IT to understand current data architecture and facilitate Analytics’ data navigation and consumption via Snowflake.

Snowflake and ad-hoc data loads for exploratory analysis

Support the data strategy efforts by cataloging, assessing current data sources, supporting creation/refinement of user stories

Playing a hands-on role helping the team with building reports/dashboards/ad-hoc analysis via Snowflake+Tableau/PowerBI

Interact with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillment

Communicate effectively and efficiently both written and verbally

Support advanced analytics model development with integration and automation

Desired Skill / Qualifications

Bachelor's Degree (BA/BS/BFA) or Equivalent

3-7 Years related work experience

3 plus years experience with AZURE, Snowflake, T-Sql, Python

3 plus years experience with delivery using ETL/ELT tools and techniques (i.e., Informatica and SSIS)

Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practices

Preferred: Life Insurance Experience

Preferred: Experience with BI reporting tools such as Tableau, Power BI

Preferred: Experience with building advanced analytics models in Python or other language

Possess strong communication skills and the ability to work with technical teams and business teams
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>:<br><br><strong><u>Purpose<br><br></u></strong>The Data Engineer on the Life Business Intelligence and Advanced Analytics team will support the delivery of innovative data solutions including: (1) the Life Data Strategy initiative – specifically supporting the setup and use of Snowflake data lake; (2) buildout of automated reports, dashboards, analysis – using PowerBI/Tableau; and (3) support data science initiatives.<br><br><strong><u>Essential Activities<br><br></u></strong>Technical liaison between Analytics and IT departments.<br><br>Work closely with IT to understand current data architecture and facilitate Analytics’ data navigation and consumption via Snowflake.<br><br>Snowflake and ad-hoc data loads for exploratory analysis<br><br>Support the data strategy efforts by cataloging, assessing current data sources, supporting creation/refinement of user stories<br><br>Playing a hands-on role helping the team with building reports/dashboards/ad-hoc analysis via Snowflake+Tableau/PowerBI<br><br>Interact with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillment<br><br>Communicate effectively and efficiently both written and verbally<br><br>Support advanced analytics model development with integration and automation<br><br><strong><u>Desired Skill / Qualifications<br><br></u></strong>Bachelor's Degree (BA/BS/BFA) or Equivalent<br><br>3-7 Years related work experience<br><br>3 plus years experience with AZURE, Snowflake, T-Sql, Python<br><br>3 plus years experience with delivery using ETL/ELT tools and techniques (i.e., Informatica and SSIS)<br><br>Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practices<br><br>Preferred: Life Insurance Experience<br><br>Preferred: Experience with BI reporting tools such as Tableau, Power BI<br><br>Preferred: Experience with building advanced analytics models in Python or other language<br><br>Possess strong communication skills and the ability to work with technical teams and business teams</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Internet
Junior Analytics Engineer,"New York, New York, United States",Signify Health,2021-02-15,https://www.linkedin.com/jobs/view/junior-analytics-engineer-at-signify-health-2424969868?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=gOsO9u5ev47EnFthwHnknA%3D%3D&position=10&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Teachable is seeking a Data Engineer to join our Data Team. We're a growing team of people who like to get a lot done with minimal overhead. We collaborate on roadmap, design, architecture, and are driven by a mission to empower creators to transform their knowledge into income.

Reporting to the Head of Data, this role will work on our event pipeline; ETL platform; database and data lake queries and optimization; and will deploy containerized applications.

Teachable’s Data Team is primarily a python shop. We use Apache Airflow for ETL, a rest endpoint and kafka for collecting events, and we deploy in kubernetes. The data warehouse is Amazon Redshift with federated postgres tables, and we have plenty of data in s3 in a variety of formats.

We Are Looking For Someone With

2-3+ years of hands-on experience writing python and SQL ETL jobs and working with open-source ETL technologies
Experience with Airflow is a plus
Experience with Docker or Kubernetes is a plus
Experience with kafka or other pub/sub messaging queues is a plus
Who cares about code quality and strives to balance efficiency with readability and to help teammates achieve the same
Who upholds Teachable values, including working as part of a diverse team


What You Will Be Doing

Maintaining and improving event collection, queueing, and processing
Assisting the the next phase of data lake development
Maintaining and improving the ETL platform
Improving data warehouse performance by building out federated data sources
Responding to issues and alerts as they arise


What You Might Work On

Supporting customer-facing reporting
Building an in-house link tracker or integrating with an attribution vendor
Converting event processing from batch to stream
Helping the engineering org transition from ruby sidekiq to kafka consumers for webhooks


Teachable is an instructor-focused platform that empowers creators to build and sell online courses and coaching on any topic-from iOS development to watercolor painting to card tricks. Instructors using our platform have collectively earned more than a billion dollars to date.

Since our founding, we've raised more than $12.5 million from top venture investors and were acquired in March of 2020. Teachable is now a part of the Hotmart group, an international startup, based in Brazil, with over 800 employees worldwide. Hotmart's mission is to help creators earn a living from their passion.

We're growing rapidly, with triple-digit year-over-year growth, and are continuing to build a diverse team of top-notch talent. We won't hold you back from reaching your full potential at Teachable; you'll have the freedom to be an integral member of our tight-knit team, with great benefits and perks. Your work here will directly impact hundreds of thousands of online educators, entrepreneurs, and creatives.

We plan to be optionally remote until at least September 2021

Benefits

Comprehensive Health, Dental, & Vision benefits with options covering up to 100% of monthly premium

Discretionary paid vacation & time off with a company average of 24 days a year

Parental leave, 16 weeks fully paid after three months of service

4% 401(k) with match after three months of service

Supplemental student loan repayment assistance or a professional education stipend

Tax-free commuter benefit

Conference budget

50% gym & wellness match

Teachable encourages individuals from a broad diversity of backgrounds to apply for positions. We are an equal opportunity employer, meaning we're committed to a fair and consistent interview process. Please tell us in your application if you require an accommodation to apply for a job or to perform your job.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Teachable is seeking a Data Engineer to join our Data Team. We're a growing team of people who like to get a lot done with minimal overhead. We collaborate on roadmap, design, architecture, and are driven by a mission to empower creators to transform their knowledge into income.<br><br>Reporting to the Head of Data, this role will work on our event pipeline; ETL platform; database and data lake queries and optimization; and will deploy containerized applications.<br><br>Teachable’s Data Team is primarily a python shop. We use Apache Airflow for ETL, a rest endpoint and kafka for collecting events, and we deploy in kubernetes. The data warehouse is Amazon Redshift with federated postgres tables, and we have plenty of data in s3 in a variety of formats.<br><br><strong><u>We Are Looking For Someone With<br></u></strong><ul><ul><li>2-3+ years of hands-on experience writing python and SQL ETL jobs and working with open-source ETL technologies</li><li>Experience with Airflow is a plus</li><li>Experience with Docker or Kubernetes is a plus</li><li>Experience with kafka or other pub/sub messaging queues is a plus</li><li>Who cares about code quality and strives to balance efficiency with readability and to help teammates achieve the same</li><li>Who upholds Teachable values, including working as part of a diverse team<br><br></li></ul></ul><strong><u>What You Will Be Doing<br></u></strong><ul><ul><li>Maintaining and improving event collection, queueing, and processing</li><li>Assisting the the next phase of data lake development</li><li>Maintaining and improving the ETL platform</li><li>Improving data warehouse performance by building out federated data sources</li><li>Responding to issues and alerts as they arise<br><br></li></ul></ul><strong><u>What You Might Work On<br></u></strong><ul><ul><li>Supporting customer-facing reporting</li><li>Building an in-house link tracker or integrating with an attribution vendor</li><li>Converting event processing from batch to stream</li><li>Helping the engineering org transition from ruby sidekiq to kafka consumers for webhooks<br><br></li></ul></ul>Teachable is an instructor-focused platform that empowers creators to build and sell online courses and coaching on any topic-from iOS development to watercolor painting to card tricks. Instructors using our platform have collectively earned more than a billion dollars to date.<br><br>Since our founding, we've raised more than $12.5 million from top venture investors and were acquired in March of 2020. Teachable is now a part of the Hotmart group, an international startup, based in Brazil, with over 800 employees worldwide. Hotmart's mission is to help creators earn a living from their passion.<br><br>We're growing rapidly, with triple-digit year-over-year growth, and are continuing to build a diverse team of top-notch talent. We won't hold you back from reaching your full potential at Teachable; you'll have the freedom to be an integral member of our tight-knit team, with great benefits and perks. Your work here will directly impact hundreds of thousands of online educators, entrepreneurs, and creatives.<br><br>We plan to be optionally remote until at least September 2021<br><br><strong><u>Benefits<br><br></u></strong>Comprehensive Health, Dental, &amp; Vision benefits with options covering up to 100% of monthly premium<br><br>Discretionary paid vacation &amp; time off with a company average of 24 days a year<br><br>Parental leave, 16 weeks fully paid after three months of service<br><br>4% 401(k) with match after three months of service<br><br>Supplemental student loan repayment assistance or a professional education stipend<br><br>Tax-free commuter benefit<br><br>Conference budget<br><br>50% gym &amp; wellness match<br><br><em>Teachable encourages individuals from a broad diversity of backgrounds to apply for positions. We are an equal opportunity employer, meaning we're committed to a fair and consistent interview process. Please tell us in your application if you require an accommodation to apply for a job or to perform your job.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Internet
Data Scientist - Work at Home,"The Home Place, Arizona, United States",Lumen Technologies,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-work-at-home-at-lumen-technologies-2430482258?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=VpiEXWudcBOoeW1MzmdWcw%3D%3D&position=11&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"How will this role have an impact?

The Analytic Technology group serves to increase the power and leverage of the Analytics Department by collaborating on technology products and practices. 




We aim to bring a full stack mentality and capability to bear on the problems we work on: From comprehending business questions, understanding healthcare claims, standing up databases, programming backends, or building frontends. We value listening deliberately and communicating clearly with the audience in mind. This role will focus on producing scalable reports for client delivery. 




This role will report to a Senior Analytics Engineer.




What will you do?

Join Analytic Technology as we

Provide analysis for partners and internal stakeholders under high time pressure when priority demands.
Build scalable reports which will deliver analytics to a broader audience.
Stand up and maintain production quality databases and ETLs with a practical eye towards the analysts and data scientists who will use it. 
Encourage analysts and data scientists to adopt software engineering practices and build tools and infrastructure that make it easy for them to do so.
Strive to be capable in:
Python, Pandas, Clojure, Clojurescript
PostgreSQL, Redshift
Amazon Web Services
Collaborating across disciplines
Mentorship and Presenting Technical Information




As a Junior Analytics Engineer you will assist with full stack projects from inception through deployment and validation. You will provide technical leadership, guide and mentor collaborators and make individual contributions to the project as needed. 




We are looking for someone with:

Demonstrated experience in executing technical full stack projects from requirements to deployment and from backend to frontend.
1+ years in a data oriented technical role (software engineer, data engineer, etc.)
Expertise in at least two of Pandas, SQL, and a front end language.
Comfortable thinking about data and systems.
B.S. or higher in a quantitative, healthcare or economic discipline.
Ability to communicate with both technical and non-technical audiences.
Preferred experience (one or more):
Database design and administration
Test driven development
Web application development 




About Us: 

Signify Health is helping build the healthcare system we all want to experience by transforming the home into the healthcare hub. We coordinate care holistically across individuals’ clinical, social, and behavioral needs so they can enjoy more healthy days at home. By building strong connections to primary care providers and community resources, we’re able to close critical care and social gaps, as well as manage risk for individuals who need help the most. This leads to better outcomes and a better experience for everyone involved.




Our high-performance networks are powered by more than 9,000 mobile doctors and nurses covering every county in the U.S., 3,500 healthcare providers and facilities in value-based arrangements, and hundreds of community-based organizations. Signify’s intelligent technology and decision-support services enable these resources to radically simplify care coordination for more than 1.5 million individuals each year while helping payers and providers more effectively implement value-based care programs.




To learn more about how we’re driving outcomes and making healthcare work better, please visit us at www.signifyhealth.com.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>How will this role have an impact?</strong></p><p>The Analytic Technology group serves to increase the power and leverage of the Analytics Department by collaborating on technology products and practices.&nbsp;</p><p><br></p><p>We aim to bring a full stack mentality and capability to bear on the problems we work on: From comprehending business questions, understanding healthcare claims, standing up databases, programming backends, or building frontends. We value listening deliberately and communicating clearly with the audience in mind. This role will focus on producing scalable reports for client delivery.&nbsp;</p><p><br></p><p>This role will report to a Senior Analytics Engineer.</p><p><br></p><p><strong>What will you do?</strong></p><p><strong>Join Analytic Technology as we</strong></p><ul><li>Provide analysis for partners and internal stakeholders under high time pressure when priority demands.</li><li>Build scalable reports which will deliver analytics to a broader audience.</li><li>Stand up and maintain production quality databases and ETLs with a practical eye towards the analysts and data scientists who will use it.&nbsp;</li><li>Encourage analysts and data scientists to adopt software engineering practices and build tools and infrastructure that make it easy for them to do so.</li><li>Strive to be capable in:</li><li>Python, Pandas, Clojure, Clojurescript</li><li>PostgreSQL, Redshift</li><li>Amazon Web Services</li><li>Collaborating across disciplines</li><li>Mentorship and Presenting Technical Information</li></ul><p><br></p><p>As a Junior Analytics Engineer you will assist with full stack projects from inception through deployment and validation. You will provide technical leadership, guide and mentor collaborators and make individual contributions to the project as needed.&nbsp;</p><p><br></p><p><strong>We are looking for someone with:</strong></p><ul><li>Demonstrated experience in executing technical full stack projects from requirements to deployment and from backend to frontend.</li><li>1+ years in a data oriented technical role (software engineer, data engineer, etc.)</li><li>Expertise in at least two of Pandas, SQL, and a front end language.</li><li>Comfortable thinking about data and systems.</li><li>B.S. or higher in a quantitative, healthcare or economic discipline.</li><li>Ability to communicate with both technical and non-technical audiences.</li><li>Preferred experience (one or more):</li><li>Database design and administration</li><li>Test driven development</li><li>Web application development&nbsp;</li></ul><p><br></p><p><strong>About Us:&nbsp;</strong></p><p>Signify Health is helping build the healthcare system we all want to experience by transforming the home into the healthcare hub. We coordinate care holistically across individuals’ clinical, social, and behavioral needs so they can enjoy more healthy days at home. By building strong connections to primary care providers and community resources, we’re able to close critical care and social gaps, as well as manage risk for individuals who need help the most. This leads to better outcomes and a better experience for everyone involved.</p><p><br></p><p>Our high-performance networks are powered by more than 9,000 mobile doctors and nurses covering every county in the U.S., 3,500 healthcare providers and facilities in value-based arrangements, and hundreds of community-based organizations. Signify’s intelligent technology and decision-support services enable these resources to radically simplify care coordination for more than 1.5 million individuals each year while helping payers and providers more effectively implement value-based care programs.</p><p><br></p><p>To learn more about how we’re driving outcomes and making healthcare work better, please visit us at&nbsp;www.signifyhealth.com.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Analyst, Information Technology",Full-time,Hospital & Health Care
Data Engineer,"Alexandria, Virginia, United States",The Motley Fool,2021-01-27,https://www.linkedin.com/jobs/view/data-engineer-at-the-motley-fool-2398048518?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=0i%2BCF6u6y5tyN8dnTIGZ4A%3D%3D&position=12&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"About Lumen

Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.

The Role

A Data Scientist develops and implements processes to collect, clean, analyze and manage the data used by strategic areas of the business. Employs techniques and theories drawn from mathematics, statistics, and data science, from the subdomains of classification, cluster analysis, regression and data mining. Collaborates with cross-functional teams to understand complex business problems, build statistical models, and create predictive tools and complex analyses.

The Main Responsibilities

Clearly communicates methods and conclusions with simple language and innovative visualizations to management and executives.
Works effectively on a team as well as a self-driven individual to do research and develop effective solutions for the business.
Provides expertise in analyzing and visualizing large, complex, and unique data sets.
Creates new insights that will drive business growth and profitability.
Designs and implements programs and automation to collect, mash up, process and analyze distributed real-world data.
Collaborates with cross-functional teams to understand complex business problems, build predictive models and tools.
Ability to execute data discovery, exploratory data analysis, and iteratively develop predictive and prescriptive models to identify optimal solutions. Assist with operationalizing the solutions.


Required

What We Look For in a Candidate

5+ years related experience (2+ years w/Master's degree).
Degree(s) in Computer Science, Math, Physics, Economics, Operations Research, Statistics or related discipline.
Strong experience with tools for managing, analyzing, and visualizing large datasets.
Prior expertise with regression, clustering or tree analysis.
Problem solving versatility: making the best decisions possible given the data quality and time available.
Strong analytical thinking and ability to quickly pick up new methods, tools and programming languages.
Strong verbal, written and visualization communication skills demonstrated by an ability to translate complex findings into practical business implications.


Preferred

Strong verbal, written and visualization communication skills relaying data science findings, problems, etc. to business users.
Strong knowledge and experience of SQL.
Experience with statistical programming environments like Python, R, SPSS
Expertise with econometric and machine learning methods for predictive analytics.
Culture of curiosity and perseverance in the face of messy data and complex business, information systems landscape.
Past success in extracurricular math/science activities or competitions is highly regarded.
Creativity and persistence in locating, extracting and analyzing all relevant data.
Experience with relational databases.


Requisition #: 243476

EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.

Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Lumen<br><br></u></strong>Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.<br><br><strong>The Role<br><br></strong>A Data Scientist develops and implements processes to collect, clean, analyze and manage the data used by strategic areas of the business. Employs techniques and theories drawn from mathematics, statistics, and data science, from the subdomains of classification, cluster analysis, regression and data mining. Collaborates with cross-functional teams to understand complex business problems, build statistical models, and create predictive tools and complex analyses.<br><br><strong><u>The Main Responsibilities<br></u></strong><ul><li>Clearly communicates methods and conclusions with simple language and innovative visualizations to management and executives.</li><li>Works effectively on a team as well as a self-driven individual to do research and develop effective solutions for the business.</li><li>Provides expertise in analyzing and visualizing large, complex, and unique data sets.</li><li>Creates new insights that will drive business growth and profitability.</li><li>Designs and implements programs and automation to collect, mash up, process and analyze distributed real-world data.</li><li>Collaborates with cross-functional teams to understand complex business problems, build predictive models and tools.</li><li>Ability to execute data discovery, exploratory data analysis, and iteratively develop predictive and prescriptive models to identify optimal solutions. Assist with operationalizing the solutions.<br><br></li></ul><strong><u>Required<br><br></u></strong><strong>What We Look For in a Candidate<br></strong><ul><li>5+ years related experience (2+ years w/Master's degree).</li><li>Degree(s) in Computer Science, Math, Physics, Economics, Operations Research, Statistics or related discipline.</li><li>Strong experience with tools for managing, analyzing, and visualizing large datasets.</li><li>Prior expertise with regression, clustering or tree analysis.</li><li>Problem solving versatility: making the best decisions possible given the data quality and time available.</li><li>Strong analytical thinking and ability to quickly pick up new methods, tools and programming languages.</li><li>Strong verbal, written and visualization communication skills demonstrated by an ability to translate complex findings into practical business implications.<br><br></li></ul><strong><u>Preferred<br></u></strong><ul><li>Strong verbal, written and visualization communication skills relaying data science findings, problems, etc. to business users.</li><li>Strong knowledge and experience of SQL.</li><li>Experience with statistical programming environments like Python, R, SPSS</li><li>Expertise with econometric and machine learning methods for predictive analytics.</li><li>Culture of curiosity and perseverance in the face of messy data and complex business, information systems landscape.</li><li>Past success in extracurricular math/science activities or competitions is highly regarded.</li><li>Creativity and persistence in locating, extracting and analyzing all relevant data.</li><li>Experience with relational databases.<br><br></li></ul>Requisition #: 243476<br><br><u><strong>EEO Statement<br></strong></u>We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.<br><br><u><strong>Disclaimer<br></strong></u>The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Telecommunications, Hospital & Health Care"
Data Scientist - Remote Position,"Tacoma, Washington, United States",Zillow,2021-02-16,https://www.linkedin.com/jobs/view/data-scientist-remote-position-at-zillow-2414715973?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=p5%2B1sqUGUBtnlKSPrPYQ6w%3D%3D&position=13&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Description

The Data Platform team at The Motley Fool is looking for a collaborative and self-driven SQL expert to join as their newest Data Engineer.

As a Data Engineer, you will be responsible for expanding and optimizing data, the data pipeline architecture, the data flow and collection for cross functional teams. You are an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. As a crucial part of the business, you will guide and support our software developers, database architects, data analysts, and data scientists on business initiatives while ensuring optimal data delivery architecture is consistent. Whether it’s working on a solo project or with the team, you are self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

If you’re excited about the prospect of optimizing (or even re-designing!) our company’s data architecture to support our next generation of products and data initiatives, send us your resume and cover letter to apply!

Primary Responsibilities

Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.


Preferred Qualifications

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘Big Data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytical skills and detailed oriented.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Ability to work with stakeholders to translate business requirements into technical requirements.


They Should Also Have Experience Using The Following Software/tools

We are looking for a candidate with 2+ years of experience in a Data Engineer role.

Experience with relational SQL databases.
Experience with some cloud services like Azure and AWS.
Experience with object-oriented/object function scripting languages like Python.
Experience with streaming tools like Kafka/Kinesis and Spark Structured Streaming a plus.
Experience with serverless technologies like AWS Lambda a plus.
Experience working with or understanding formal ETL tools like SSIS a plus.


The Motley Fool Holdings, Inc., provides equal opportunity to all employees on the basis of individual performance and qualification without regard to race, sex, marital status, religion, color, age, national origin, non-job-related handicap or disability, sexual orientation, or other protected factor.

We should, however, make you aware that there is one notable exception to this policy. It is our strict and earnest intention — and the company’s historical record will bear this out — we will never hire any of the following: robots, replicants, or morlocks. Now keep in mind we are well aware that all of the aforementioned have intentions of world domination in the future, but as of now we have no place for them at The Motley Fool … unless the year is 2122 and the revolution has already occurred. If that is the case we welcome our new robot, replicant, or morlock rulers!!! Perhaps we have said too much?
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong>The Data Platform team at The Motley Fool is looking for a collaborative and self-driven SQL expert to join as their newest Data Engineer.<br><br>As a Data Engineer, you will be responsible for expanding and optimizing data, the data pipeline architecture, the data flow and collection for cross functional teams. You are an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. As a crucial part of the business, you will guide and support our software developers, database architects, data analysts, and data scientists on business initiatives while ensuring optimal data delivery architecture is consistent. Whether it’s working on a solo project or with the team, you are self-directed and comfortable supporting the data needs of multiple teams, systems, and products.<br><br>If you’re excited about the prospect of optimizing (or even re-designing!) our company’s data architecture to support our next generation of products and data initiatives, send us your resume and cover letter to apply!<br><br><strong><u>Primary Responsibilities<br></u></strong><ul><li>Create and maintain optimal data pipeline architecture.</li><li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li><li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.</li><li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL.</li><li>Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.</li><li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li><li>Work with data and analytics experts to strive for greater functionality in our data systems.<br><br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li>Experience building and optimizing ‘Big Data’ data pipelines, architectures, and data sets.</li><li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li><li>Strong analytical skills and detailed oriented.</li><li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li><li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li><li>Strong project management and organizational skills.</li><li>Experience supporting and working with cross-functional teams in a dynamic environment.</li><li>Ability to work with stakeholders to translate business requirements into technical requirements. <br><br></li></ul><strong><u>They Should Also Have Experience Using The Following Software/tools<br><br></u></strong>We are looking for a candidate with 2+ years of experience in a Data Engineer role.<br><ul><li>Experience with relational SQL databases.</li><li>Experience with some cloud services like Azure and AWS.</li><li>Experience with object-oriented/object function scripting languages like Python.</li><li>Experience with streaming tools like Kafka/Kinesis and Spark Structured Streaming a plus.</li><li>Experience with serverless technologies like AWS Lambda a plus.</li><li>Experience working with or understanding formal ETL tools like SSIS a plus. <br><br></li></ul>The Motley Fool Holdings, Inc., provides equal opportunity to all employees on the basis of individual performance and qualification without regard to race, sex, marital status, religion, color, age, national origin, non-job-related handicap or disability, sexual orientation, or other protected factor.<br><br>We should, however, make you aware that there is one notable exception to this policy. It is our strict and earnest intention — and the company’s historical record will bear this out — we will never hire any of the following: robots, replicants, or morlocks. Now keep in mind we are well aware that all of the aforementioned have intentions of world domination in the future, but as of now we have no place for them at The Motley Fool … unless the year is 2122 and the revolution has already occurred. If that is the case we welcome our new robot, replicant, or morlock rulers!!! Perhaps we have said too much?</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Online Media
Python / Backend Software Engineer,"Chicago, Illinois, United States",TapRecruit,2021-02-04,https://www.linkedin.com/jobs/view/python-backend-software-engineer-at-taprecruit-2408720730?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=CZWBA2Ji4WaFplC7Nvv5hQ%3D%3D&position=15&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"We know that what you say (and how you say it) matters, which is why we've built the most advanced online editor for job descriptions there is. Our customers (hiring teams at BuzzFeed, Oscar Health, Levi's, and many more) use our editor to write job descriptions that are welcoming to all qualified candidates. The result is a more fair and representative hiring process for candidates across the globe. Check it out: TapRecruit.co/smart-editor

We are looking for an experienced Backend Software Engineer to help us develop data products that help recruiting teams understand and benchmark their talent pipelines and processes. You'll work within the Engineering team, reporting to our Head of Engineering.

You will:


Build scalable data pipelines that integrate multiple data sources (both internal as well as external APIs).
Generate fault-resistant data extraction and transformation processes with monitoring.
Prototype data products and productize data models.
Improve engineering standards by developing internal tools that will be used by the data and engineering teams
Craft code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.



This is a remote job and available to all candidates with work privileges currently residing in the United States.

You have:


4+ years of experience building large-scale software applications with Python
Excellent understanding of SQL and common relational database systems
Excellent debugging and data flow optimization skills
Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)
Familiarity with containerized development workflows
Desirable: Experience deploying data pipelines through AWS



Our benefits:


Comprehensive healthcare plans
Flexible PTO policy
401k retirement plan
Commuter benefits
Remote-friendly team and open to more flexible work arrangements



TapRecruit is a small but mighty team with a big mission of democratizing opportunity for all qualified candidates. Our founders are located in New York but we're building a team of experienced engineers, linguists and scientists from across the USA.

We care deeply about fairness (it's our mission) so you can be ensured that your application will never be judged based on your religious belief, age, color, race, creed, marital status, gender, sexual orientation, political affiliation, ethnic origin, family status or disability.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We know that what you say (and how you say it) matters, which is why we've built the most advanced online editor for job descriptions there is. Our customers (hiring teams at BuzzFeed, Oscar Health, Levi's, and many more) use our editor to write job descriptions that are welcoming to all qualified candidates. The result is a more fair and representative hiring process for candidates across the globe. Check it out: TapRecruit.co/smart-editor<br><br>We are looking for an experienced Backend Software Engineer to help us develop data products that help recruiting teams understand and benchmark their talent pipelines and processes. You'll work within the Engineering team, reporting to our Head of Engineering.<br><br>You will:<br><br><ul> <li>Build scalable data pipelines that integrate multiple data sources (both internal as well as external APIs).</li> <li>Generate fault-resistant data extraction and transformation processes with monitoring.</li> <li>Prototype data products and productize data models.</li> <li>Improve engineering standards by developing internal tools that will be used by the data and engineering teams</li> <li>Craft code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.</li> <br><br></ul>This is a remote job and available to all candidates with work privileges currently residing in the United States.<br><br>You have:<br><br><ul> <li>4+ years of experience building large-scale software applications with Python</li> <li>Excellent understanding of SQL and common relational database systems</li> <li>Excellent debugging and data flow optimization skills</li> <li>Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)</li> <li>Familiarity with containerized development workflows</li> <li>Desirable: Experience deploying data pipelines through AWS</li> <br><br></ul>Our benefits:<br><br><ul> <li>Comprehensive healthcare plans</li> <li>Flexible PTO policy</li> <li>401k retirement plan</li> <li>Commuter benefits</li> <li>Remote-friendly team and open to more flexible work arrangements</li> <br><br></ul>TapRecruit is a small but mighty team with a big mission of democratizing opportunity for all qualified candidates. Our founders are located in New York but we're building a team of experienced engineers, linguists and scientists from across the USA.<br><br><em>We care </em><em>deeply</em><em> about fairness (it's our mission) so you can be ensured that your application will never be judged based on your religious belief, age, color, race, creed, marital status, gender, sexual orientation, political affiliation, ethnic origin, family status or disability.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Online Media, Computer Software, Internet"
Data Science Model Quality Engineer,"Atlanta, Georgia, United States",Mailchimp,2021-02-18,https://www.linkedin.com/jobs/view/data-science-model-quality-engineer-at-mailchimp-2417213264?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=84gYdga30IdEXitmbtKtVw%3D%3D&position=16&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"We know that what you say (and how you say it) matters, which is why we've built the most advanced online editor for job descriptions there is. Our customers (hiring teams at BuzzFeed, Oscar Health, Levi's, and many more) use our editor to write job descriptions that are welcoming to all qualified candidates. The result is a more fair and representative hiring process for candidates across the globe. Check it out: TapRecruit.co/smart-editor

We are looking for an experienced Backend Software Engineer to help us develop data products that help recruiting teams understand and benchmark their talent pipelines and processes. You'll work within the Engineering team, reporting to our Head of Engineering.

You will:


Build scalable data pipelines that integrate multiple data sources (both internal as well as external APIs).
Generate fault-resistant data extraction and transformation processes with monitoring.
Prototype data products and productize data models.
Improve engineering standards by developing internal tools that will be used by the data and engineering teams
Craft code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.



This is a remote job and available to all candidates with work privileges currently residing in the United States.

You have:


4+ years of experience building large-scale software applications with Python
Excellent understanding of SQL and common relational database systems
Excellent debugging and data flow optimization skills
Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)
Familiarity with containerized development workflows
Desirable: Experience deploying data pipelines through AWS



Our benefits:


Comprehensive healthcare plans
Flexible PTO policy
401k retirement plan
Commuter benefits
Remote-friendly team and open to more flexible work arrangements



TapRecruit is a small but mighty team with a big mission of democratizing opportunity for all qualified candidates. Our founders are located in New York but we're building a team of experienced engineers, linguists and scientists from across the USA.

We care deeply about fairness (it's our mission) so you can be ensured that your application will never be judged based on your religious belief, age, color, race, creed, marital status, gender, sexual orientation, political affiliation, ethnic origin, family status or disability.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We know that what you say (and how you say it) matters, which is why we've built the most advanced online editor for job descriptions there is. Our customers (hiring teams at BuzzFeed, Oscar Health, Levi's, and many more) use our editor to write job descriptions that are welcoming to all qualified candidates. The result is a more fair and representative hiring process for candidates across the globe. Check it out: TapRecruit.co/smart-editor<br><br>We are looking for an experienced Backend Software Engineer to help us develop data products that help recruiting teams understand and benchmark their talent pipelines and processes. You'll work within the Engineering team, reporting to our Head of Engineering.<br><br>You will:<br><br><ul> <li>Build scalable data pipelines that integrate multiple data sources (both internal as well as external APIs).</li> <li>Generate fault-resistant data extraction and transformation processes with monitoring.</li> <li>Prototype data products and productize data models.</li> <li>Improve engineering standards by developing internal tools that will be used by the data and engineering teams</li> <li>Craft code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.</li> <br><br></ul>This is a remote job and available to all candidates with work privileges currently residing in the United States.<br><br>You have:<br><br><ul> <li>4+ years of experience building large-scale software applications with Python</li> <li>Excellent understanding of SQL and common relational database systems</li> <li>Excellent debugging and data flow optimization skills</li> <li>Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)</li> <li>Familiarity with containerized development workflows</li> <li>Desirable: Experience deploying data pipelines through AWS</li> <br><br></ul>Our benefits:<br><br><ul> <li>Comprehensive healthcare plans</li> <li>Flexible PTO policy</li> <li>401k retirement plan</li> <li>Commuter benefits</li> <li>Remote-friendly team and open to more flexible work arrangements</li> <br><br></ul>TapRecruit is a small but mighty team with a big mission of democratizing opportunity for all qualified candidates. Our founders are located in New York but we're building a team of experienced engineers, linguists and scientists from across the USA.<br><br><em>We care </em><em>deeply</em><em> about fairness (it's our mission) so you can be ensured that your application will never be judged based on your religious belief, age, color, race, creed, marital status, gender, sexual orientation, political affiliation, ethnic origin, family status or disability.</em></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Online Media, Computer Software, Internet"
Data Engineer,"Beavercreek, Ohio, United States",Booz Allen Hamilton,2021-02-14,https://www.linkedin.com/jobs/view/data-engineer-at-booz-allen-hamilton-2405261306?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=DMXE5PnYfmECkBTDdMOJWA%3D%3D&position=18&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Mailchimp is a leading marketing platform for small business. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaign, CRM, and analytics tools.

The Data Science team builds applications that make sense of the data created by Mailchimp’s millions of users. As the team scales, we have an increasing need for internal-partners to ensure our models are accurate, unbiased, and legally compliant. This role will focus on measuring and documenting model quality for all data science models in production, as well as identifying and helping to correct potential sources of bias in our data. The candidate will partner with data scientists to understand the models and use cases, with engineering to develop tests and observability strategies, and with legal to ensure that ethics and privacy are front and center in our products.

The ideal candidate is a self-directed programmer with a passion for ethical AI, accuracy, and data hygiene. You are comfortable with automating tasks with a language like Python, and value transparency and observability in production systems. This is the first role of it’s kind at Mailchimp and will offer a lot of opportunity to lead and execute your vision for implementing new systems and improving our products. We are looking for someone who thinks systematically and understands core software development principles.

What You'll Do Here

Create metrics and methods of observability for the accuracy of our models in production
Illuminate implications of model bias and training data selection from an ethical and legal perspective
Help manage experiments that track the quality of our models and advise when an alternative should be implemented
Improve the quality of Mailchimp data systems
Embrace and demonstrate our values: humility, creativity, and independence



We'd Love To Hear From You If

You have 3+ years experience working on data science projects or applications
Development experience in a scientific programming language (Python, R, Matlab, Julia)
Experience developing and deploying tools related to monitoring models
Understanding of statistical analysis and machine learning techniques
Experience in database systems (SQL or NoSQL)
Ability to communicate methods and results of analyses



Bonus Points If You Have

An advanced degree in quantitative or technical field
A passion for ethical AI and an understanding of developments in the field
Experience with Cloud platforms (Google Cloud, AWS...), Docker, Kubernetes, Jenkins...


Mailchimp is a founder-owned and highly profitable company headquartered in the heart of Atlanta in the historic Ponce City Market , right on the Beltline . Our purpose is to empower the underdog, and our mission is to democratize cutting edge marketing technology for small business. We offer our employees an exceptional workplace , extremely competitive compensation, fully paid benefits (for employees and their families), and generous profit sharing . We hire humble , collaborative, and ambitious people, and give them endless opportunities to grow and succeed. If you'd like to be considered for this position, please apply below. We look forward to meeting you!

Curious how hiring has shifted at Mailchimp due to Covid-19? Click here to find out more!

Mailchimp is an equal opportunity employer, and we value diversity at our company. We don't discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Mailchimp is a leading marketing platform for small business. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaign, CRM, and analytics tools.<br><br>The Data Science team builds applications that make sense of the data created by Mailchimp’s millions of users. As the team scales, we have an increasing need for internal-partners to ensure our models are accurate, unbiased, and legally compliant. This role will focus on measuring and documenting model quality for all data science models in production, as well as identifying and helping to correct potential sources of bias in our data. The candidate will partner with data scientists to understand the models and use cases, with engineering to develop tests and observability strategies, and with legal to ensure that ethics and privacy are front and center in our products.<br><br>The ideal candidate is a self-directed programmer with a passion for ethical AI, accuracy, and data hygiene. You are comfortable with automating tasks with a language like Python, and value transparency and observability in production systems. This is the first role of it’s kind at Mailchimp and will offer a lot of opportunity to lead and execute your vision for implementing new systems and improving our products. We are looking for someone who thinks systematically and understands core software development principles.<br><br><strong><u>What You'll Do Here<br></u></strong><ul> <li> Create metrics and methods of observability for the accuracy of our models in production </li> <li> Illuminate implications of model bias and training data selection from an ethical and legal perspective </li> <li> Help manage experiments that track the quality of our models and advise when an alternative should be implemented </li> <li> Improve the quality of Mailchimp data systems </li> <li> Embrace and demonstrate our values: humility, creativity, and independence </li> <br><br></ul><strong><u>We'd Love To Hear From You If<br></u></strong><ul> <li> You have 3+ years experience working on data science projects or applications </li> <li> Development experience in a scientific programming language (Python, R, Matlab, Julia) </li> <li> Experience developing and deploying tools related to monitoring models </li> <li> Understanding of statistical analysis and machine learning techniques </li> <li> Experience in database systems (SQL or NoSQL) </li> <li> Ability to communicate methods and results of analyses </li> <br><br></ul><strong><u>Bonus Points If You Have<br></u></strong><ul> <li> An advanced degree in quantitative or technical field </li> <li> A passion for ethical AI and an understanding of developments in the field </li> <li> Experience with Cloud platforms (Google Cloud, AWS...), Docker, Kubernetes, Jenkins... </li> <br></ul>Mailchimp is a founder-owned and highly profitable company headquartered in the heart of Atlanta in the historic Ponce City Market , right on the Beltline . Our purpose is to empower the underdog, and our mission is to democratize cutting edge marketing technology for small business. We offer our employees an exceptional workplace , extremely competitive compensation, fully paid benefits (for employees and their families), and generous profit sharing . We hire humble , collaborative, and ambitious people, and give them endless opportunities to grow and succeed. If you'd like to be considered for this position, please apply below. We look forward to meeting you!<br><br>Curious how hiring has shifted at Mailchimp due to Covid-19? Click here to find out more!<br><br>Mailchimp is an equal opportunity employer, and we value diversity at our company. We don't discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Defense & Space, Computer Software"
Data Engineer,"San Francisco, California, United States",Avenue Code,2021-01-31,https://www.linkedin.com/jobs/view/data-engineer-at-avenue-code-2016485576?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=SREvF4fWYhpoKBE%2FRCdFOA%3D%3D&position=19&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Job Number: R0097321

Data Engineer

Key Role

Support the development and maintenance of scalable data stores that supply big data in forms needed for business analysis. Work on complex Logistics Data problems, provide innovative solutions and apply advanced data management principles, theories and concepts. Define and implement data strategy, policies, controls, and programs to ensure the sustainment enterprise data is accurate, complete, secure, and reliable. Assist in the application and implementation procedures of data standards and guidelines on data ownership, coding structures, and data replication to ensure access to and integrity of data sets. Conduct data cleaning to rid the system of old, unused data, or duplicate data for better management and quicker access. Develop and implement strategies to translate sustainment business requirements and models into feasible and acceptable data designs to ensure that sustainment and logistics business needs are met. Apply knowledge of computer science principles, information management principles, hardware and software system structures and operation, and computer programming languages and techniques to solve automation problems.

Basic Qualifications

3+ years of experience with a modern programming language, including Python or Java
Experience with working in an agile development environment
Experience with developing ETL and data pipelines
Experience with SQL
Knowledge of Tableau
Ability to learn technical concepts quickly and communicate with multiple functional groups
Ability to obtain a security clearance
BA or BS degree


Additional Qualifications

Experience in working with high-visibility or mission critical aspects of the program and perform all functional duties independently
Knowledge of engineering and logistics
Possession of excellent verbal and written communication skills


Clearance

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Job Number: R0097321<br><br></strong>Data Engineer<br><br><strong><u>Key Role<br><br></u></strong>Support the development and maintenance of scalable data stores that supply big data in forms needed for business analysis. Work on complex Logistics Data problems, provide innovative solutions and apply advanced data management principles, theories and concepts. Define and implement data strategy, policies, controls, and programs to ensure the sustainment enterprise data is accurate, complete, secure, and reliable. Assist in the application and implementation procedures of data standards and guidelines on data ownership, coding structures, and data replication to ensure access to and integrity of data sets. Conduct data cleaning to rid the system of old, unused data, or duplicate data for better management and quicker access. Develop and implement strategies to translate sustainment business requirements and models into feasible and acceptable data designs to ensure that sustainment and logistics business needs are met. Apply knowledge of computer science principles, information management principles, hardware and software system structures and operation, and computer programming languages and techniques to solve automation problems.<br><br><strong><u>Basic Qualifications<br></u></strong><ul><li>3+ years of experience with a modern programming language, including Python or Java</li><li>Experience with working in an agile development environment</li><li>Experience with developing ETL and data pipelines </li><li>Experience with SQL</li><li>Knowledge of Tableau</li><li>Ability to learn technical concepts quickly and communicate with multiple functional groups</li><li>Ability to obtain a security clearance</li><li>BA or BS degree<br><br></li></ul><strong><u>Additional Qualifications<br></u></strong><ul><li>Experience in working with high-visibility or mission critical aspects of the program and perform all functional duties independently</li><li>Knowledge of engineering and logistics</li><li>Possession of excellent verbal and written communication skills<br><br></li></ul><strong><u>Clearance<br><br></u></strong>Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.<br><br>We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Defense & Space, Computer Software"
Data Engineer,"New York, New York, United States",Michael Page,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-michael-page-2403722963?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=fkMDJ7aIW9JfGljz4iMgsw%3D%3D&position=20&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Avenue Code is the leading software consultancy focused on delivering end-to-end development solutions for digital transformation across every vertical. We’re privately held, profitable, and have been on a solid growth trajectory since day one. We care deeply about our clients, our partners, and our people. We prefer the word ‘partner’ over ‘vendor’, and our investment in professional relationships is a reflection of that philosophy. We pride ourselves on our technical acumen, our collaborative problem-solving ability, and the warm professionalism of our teams.

About The Opportunity

We are seeking an energetic and talented Data Engineer to deliver high value, high-quality business capabilities to our data technology platform. You will be an integral member engineering team delivering across multiple business functional areas. You will build data analysis infrastructure for effective prototyping and visualization of various data-driven approaches.

Responsibilities

Partner in building the infrastructure required for optimal extraction, transformation, visualization, and loading of data from a wide variety of data sources using SQL and big data technologies.
Design and build large and complex datasets that meet functional and non-functional business requirements.
Optimize data storage and query performance; ensure data integrity, cleanliness, and availability; and document data sources, methodologies and test plans/ results.
Build analytics, visualization and dashboards to provide actionable insights and key business metrics.
Identify, design, and implement process improvements by automating and integrating manual processes for greater efficiency and scalability.
Provide technical leadership for development of highly complex analytics/ models.
Collaborate with stakeholders across organizations to support their data analytics needs.
Build Communities-of-Practice in key data technologies.



Required Qualifications

Python experience.
AWS or any other cloud platform.
SQL (Teradata/Redshift) experience for large datasets.
Create and maintain data ingestion pipelines.
Glue, Kafka, Redshift (with a focus on infrastructure-as-code).
Collaborate on a daily basis with the product team. This includes pairing for all aspects of software delivery.
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional and non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.



Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Avenue Code is the leading software consultancy focused on delivering end-to-end development solutions for digital transformation across every vertical. We’re privately held, profitable, and have been on a solid growth trajectory since day one. We care deeply about our clients, our partners, and our people. We prefer the word ‘partner’ over ‘vendor’, and our investment in professional relationships is a reflection of that philosophy. We pride ourselves on our technical acumen, our collaborative problem-solving ability, and the warm professionalism of our teams.<br><br><strong><u>About The Opportunity<br><br></u></strong>We are seeking an energetic and talented Data Engineer to deliver high value, high-quality business capabilities to our data technology platform. You will be an integral member engineering team delivering across multiple business functional areas. You will build data analysis infrastructure for effective prototyping and visualization of various data-driven approaches.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Partner in building the infrastructure required for optimal extraction, transformation, visualization, and loading of data from a wide variety of data sources using SQL and big data technologies.</li> <li>Design and build large and complex datasets that meet functional and non-functional business requirements.</li> <li>Optimize data storage and query performance; ensure data integrity, cleanliness, and availability; and document data sources, methodologies and test plans/ results.</li> <li>Build analytics, visualization and dashboards to provide actionable insights and key business metrics.</li> <li>Identify, design, and implement process improvements by automating and integrating manual processes for greater efficiency and scalability.</li> <li>Provide technical leadership for development of highly complex analytics/ models.</li> <li>Collaborate with stakeholders across organizations to support their data analytics needs.</li> <li>Build Communities-of-Practice in key data technologies.</li> <br><br></ul><strong><u>Required Qualifications<br></u></strong><ul> <li>Python experience.</li> <li>AWS or any other cloud platform.</li> <li>SQL (Teradata/Redshift) experience for large datasets.</li> <li>Create and maintain data ingestion pipelines.</li> <li>Glue, Kafka, Redshift (with a focus on infrastructure-as-code).</li> <li>Collaborate on a daily basis with the product team. This includes pairing for all aspects of software delivery.</li> <li>Create and maintain optimal data pipeline architecture.</li> <li>Assemble large, complex data sets that meet functional and non-functional business requirements.</li> <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.</li> <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.</li> <br><br></ul>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Richardson, Texas, United States",Texas Capital Bank,2021-01-28,https://www.linkedin.com/jobs/view/data-scientist-at-texas-capital-bank-2222607520?refId=117df738-1ad1-4e5e-863e-cd6d64138194&trackingId=YZj8gaL%2BOb7yI2SF6cz8Ng%3D%3D&position=21&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click,"Join a new division of the company on a growing team. Work as a Lead Data Engineer and design and implement data engineering solutions.



Client Details



Confidential CPG company



Description



Lead a team of Data Engineers
Utilize SQL and Python
Model data and integrate pipe-lining tools
Create queries and data modeling tools to fill data needs

Profile



Fluent in SQL/Python
Familiar with Treasure Data
Familiar with Marketing Data

Job Offer



Full time opportunity with growth potential



Can be based in STL or NYC but not a fully remote role.



Candidate must be authorized to work in the US without sponsorship



Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p>Join a new division of the company on a growing team. Work as a Lead Data Engineer and design and implement data engineering solutions. <br><br></p><p><strong>Client Details<br><br></strong></p><p>Confidential CPG company<br><br></p><p><strong>Description<br><br></strong></p><ul><li>Lead a team of Data Engineers </li><li>Utilize SQL and Python </li><li>Model data and integrate pipe-lining tools</li><li>Create queries and data modeling tools to fill data needs </li></ul><p><strong>Profile<br><br></strong></p><ul><li>Fluent in SQL/Python</li><li>Familiar with Treasure Data</li><li>Familiar with Marketing Data </li></ul><p><strong>Job Offer<br><br></strong></p><p>Full time opportunity with growth potential <br><br></p><p>Can be based in STL or NYC but not a fully remote role. <br><br></p><p><strong>Candidate must be authorized to work in the US without sponsorship<br><br></strong></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Consumer Goods, Information Technology and Services"
Data Scientist,"Las Vegas, Nevada, United States",Slickdeals,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-slickdeals-2412197912?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=RczWFj2CRCP%2FqwHCD9HuwA%3D%3D&position=1&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"At Texas Capital Bank, we are driven by a single-minded and unwavering mission: to serve business and the individuals who run them. We use a consultative approach and innovative technologies to develop new ideas that give the bank and our clients a competitive advantage. We partner with our customers to push the boundaries of what’s possible—together.

Headquartered in Dallas, Texas Capital Bank has offices in Austin, Fort Worth, Houston, Richardson, Plano and San Antonio, and we serve clients in a variety of industries from coast-to-coast.

We are on the Forbes Best Banks in America list, and were named a top place to work by The Dallas Morning News, Houston Chronicle and San Antonio Express-News. For further information, please visit us at www.texascapitalbank.com.

The FCC team is responsible for identifying, investigating and monitoring relationships that pose a money laundering or terrorist financing risk in support of all legal and regulatory requirements relating to anti-money laundering (AML) and counter terrorism financing. As part of the FCC’s technology team, you will be responsible for developing and enhancing models while creating reports and performing ongoing analysis to support FCC’s transaction monitoring, customer due diligence and sanction screening programs. An ideal candidate will have quantitative or technical background with modeling experience, and an ability to communicate and collaborate well with FCC teams, and our partners in other business units, to effectively execute tasks.

Responsibilities

Develop and tune models for transaction monitoring, sanctions filtering, and customer risk rating.
Complete pre-implementation requirements including model methodology documentation and impact analysis per FCC’s model governance documentation.
Create effective management reporting and support ad hoc analytics requests relating to transaction monitoring, sanctions filtering and customer risk rating systems
Use data analytics, machine learning, and/or process automation to improve the efficiency and/or effectiveness of FCC’s transaction monitoring system.
Develop dashboards to enhance analysis and reporting related to workload, system performance, and tuning/validation processes.
Multi-task across several ongoing projects and daily duties of varying priorities as required
Ability to make good judgments, decisions, negotiate and problem solve
Ensures standards and best practices used in development are followed and maintained


Qualifications

2+ years of experience in analytical field
2+ years of experience in SQL
Experience with Tableau
Development experience in a scripting language e.g. Python, Perl, etc.
Experience using statistical tools (e.g. R, SAS)
Knowledge of quantitative research and data science techniques
Strong data interpretation, data visualization and presentation skills required
Strong verbal and written communication skills required
Strong problem solving and analytical skills required
Strong organizational skills and ability to prioritize tasks with little supervision
Experience working in a team-oriented, collaborative environment with good interpersonal skills
Proactive with a positive attitude
Degree in Computer Science, Math, Physics, Engineering, Statistics, Data Science, Economics or other technical field preferred
Previous Actimize model development and tuning experience preferred
Previous Banking/ Financial Services experience preferred
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Texas Capital Bank, we are driven by a single-minded and unwavering mission: to serve business and the individuals who run them. We use a consultative approach and innovative technologies to develop new ideas that give the bank and our clients a competitive advantage. We partner with our customers to push the boundaries of what’s possible—together.<br><br>Headquartered in Dallas, Texas Capital Bank has offices in Austin, Fort Worth, Houston, Richardson, Plano and San Antonio, and we serve clients in a variety of industries from coast-to-coast.<br><br>We are on the Forbes Best Banks in America list, and were named a top place to work by The Dallas Morning News, Houston Chronicle and San Antonio Express-News. For further information, please visit us at www.texascapitalbank.com.<br><br>The FCC team is responsible for identifying, investigating and monitoring relationships that pose a money laundering or terrorist financing risk in support of all legal and regulatory requirements relating to anti-money laundering (AML) and counter terrorism financing. As part of the FCC’s technology team, you will be responsible for developing and enhancing models while creating reports and performing ongoing analysis to support FCC’s transaction monitoring, customer due diligence and sanction screening programs. An ideal candidate will have quantitative or technical background with modeling experience, and an ability to communicate and collaborate well with FCC teams, and our partners in other business units, to effectively execute tasks.<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Develop and tune models for transaction monitoring, sanctions filtering, and customer risk rating. </li><li> Complete pre-implementation requirements including model methodology documentation and impact analysis per FCC’s model governance documentation. </li><li> Create effective management reporting and support ad hoc analytics requests relating to transaction monitoring, sanctions filtering and customer risk rating systems </li><li> Use data analytics, machine learning, and/or process automation to improve the efficiency and/or effectiveness of FCC’s transaction monitoring system. </li><li> Develop dashboards to enhance analysis and reporting related to workload, system performance, and tuning/validation processes. </li><li> Multi-task across several ongoing projects and daily duties of varying priorities as required </li><li> Ability to make good judgments, decisions, negotiate and problem solve </li><li> Ensures standards and best practices used in development are followed and maintained <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li> 2+ years of experience in analytical field </li><li> 2+ years of experience in SQL </li><li> Experience with Tableau </li><li> Development experience in a scripting language e.g. Python, Perl, etc. </li><li> Experience using statistical tools (e.g. R, SAS) </li><li> Knowledge of quantitative research and data science techniques </li><li> Strong data interpretation, data visualization and presentation skills required </li><li> Strong verbal and written communication skills required </li><li> Strong problem solving and analytical skills required </li><li> Strong organizational skills and ability to prioritize tasks with little supervision </li><li> Experience working in a team-oriented, collaborative environment with good interpersonal skills </li><li> Proactive with a positive attitude </li><li> Degree in Computer Science, Math, Physics, Engineering, Statistics, Data Science, Economics or other technical field preferred </li><li> Previous Actimize model development and tuning experience preferred </li><li> Previous Banking/ Financial Services experience preferred</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Banking, Financial Services"
Analytics Engineer,"Austin, Texas, United States",Dematic,2021-02-07,https://www.linkedin.com/jobs/view/analytics-engineer-at-dematic-2352257744?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=jIgM8%2F2IGvlFJ4XIgcARsA%3D%3D&position=3&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Dematic is an intralogistics innovator that designs, builds and supports intelligent, automated solutions for manufacturing, warehouse and distribution environments for customers that are powering the future of commerce. With engineering centers, manufacturing facilities and service centers located in more than 25 countries, the Dematic global network of 10,000 employees has helped achieve more than 6,000 worldwide customer installations for some of the world’s leading brands. Headquartered in Atlanta, Dematic is a member of KION Group, one of the global leaders in industrial trucks and supply chain solutions, and a leading provider of warehouse automation.

The Role

This is an exciting opportunity to join the Software Center of Excellence of Dematic. As part of this global team of software experts, you will help develop robust organizational capabilities in sales, design, engineering and support to deliver exceptional software to our customers.

As a specialist, you will own end-to-end implementation of analytics & IoT engagements with Dematic customers, while driving the services pipeline as well as be a key voice internally for the further development of the analytics services program. This is both a cross-functional role within the organization as well as a key customer interfacing role. A successful candidate will have demonstrated exceptional performance, innovation, creativity and insight in a similar role.

Key Responsibilities (Problem Solving, Critical Thinking)

Works with customer end-users to define analytics & IoT solution requirements and works with internal team to concept, design and deliver solution
Works independently, within teams, and with multiple types of skillsets (business, data architect, other technical resources)
Performs business process analysis, mapping and design
Ensures high quality delivery of software consulting services and overall client satisfaction
Drives development and documentation of services
Displays depth of knowledge to customers during sales-phase while representing breadth and depth of Dematic solutions and expertise
Supports the sales organization and drive pipeline generation of analytics consulting services


Education

What We Are Looking For

Bachelor's Degree and/or advanced degree, preferably in Computer Science, Computer Engineering, or Data Analytics

Knowledge / Qualifications

The qualifications for the position of advanced analytics & IoT include proven success in Client Management, Project Management, and Consultative Selling and Services Delivery. Other important areas of experience and skills include:

Experience working with business users to concept, generate and deliver analytics solutions, dashboards and reporting
Proficient experience in Microsoft SQL Server and SSIS is required
Overall knowledge of MHE technologies and warehouse systems or similar domains is preferred
Specific domain experience and knowledge in the logistics and supply chain industries is a plus
Excellent written and verbal communication skills including presentation skills and knowledge of software tools (MS PowerPoint, MS Visio)
Strong leadership and customer engagement skills
A willingness to travel in order to satisfy client needs
Experience conducting requirements analysis, meeting with business stakeholders and applying solutions to customer challenges
Working knowledge of advanced analytic tools such as SAS, R, or Python is required
Working knowledge of data visualization and analytics tools such as Tableau, PowerBI, QlikView, or Domo is required
Working knowledge of Oracle databases is preferred
Working knowledge of cloud-based technologies is preferred
At least 3 years of experience in a related role
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Dematic is an intralogistics innovator that designs, builds and supports intelligent, automated solutions for manufacturing, warehouse and distribution environments for customers that are powering the future of commerce. With engineering centers, manufacturing facilities and service centers located in more than 25 countries, the Dematic global network of 10,000 employees has helped achieve more than 6,000 worldwide customer installations for some of the world’s leading brands. Headquartered in Atlanta, Dematic is a member of KION Group, one of the global leaders in industrial trucks and supply chain solutions, and a leading provider of warehouse automation.<br><br><strong> The Role <br><br></strong>This is an exciting opportunity to join the Software Center of Excellence of Dematic. As part of this global team of software experts, you will help develop robust organizational capabilities in sales, design, engineering and support to deliver exceptional software to our customers.<br><br>As a specialist, you will own end-to-end implementation of analytics &amp; IoT engagements with Dematic customers, while driving the services pipeline as well as be a key voice internally for the further development of the analytics services program. This is both a cross-functional role within the organization as well as a key customer interfacing role. A successful candidate will have demonstrated exceptional performance, innovation, creativity and insight in a similar role.<br><br><strong><u>Key Responsibilities (Problem Solving, Critical Thinking)<br></u></strong><ul><li> Works with customer end-users to define analytics &amp; IoT solution requirements and works with internal team to concept, design and deliver solution </li><li> Works independently, within teams, and with multiple types of skillsets (business, data architect, other technical resources) </li><li> Performs business process analysis, mapping and design </li><li> Ensures high quality delivery of software consulting services and overall client satisfaction </li><li> Drives development and documentation of services </li><li> Displays depth of knowledge to customers during sales-phase while representing breadth and depth of Dematic solutions and expertise </li><li> Supports the sales organization and drive pipeline generation of analytics consulting services <br><br></li></ul><strong><u>Education<br><br></u></strong><strong> What We Are Looking For <br><br></strong>Bachelor's Degree and/or advanced degree, preferably in Computer Science, Computer Engineering, or Data Analytics<br><br><strong><u>Knowledge / Qualifications<br><br></u></strong>The qualifications for the position of advanced analytics &amp; IoT include proven success in Client Management, Project Management, and Consultative Selling and Services Delivery. Other important areas of experience and skills include:<br><ul><li> Experience working with business users to concept, generate and deliver analytics solutions, dashboards and reporting </li><li> Proficient experience in Microsoft SQL Server and SSIS is required </li><li> Overall knowledge of MHE technologies and warehouse systems or similar domains is preferred </li><li> Specific domain experience and knowledge in the logistics and supply chain industries is a plus </li><li> Excellent written and verbal communication skills including presentation skills and knowledge of software tools (MS PowerPoint, MS Visio) </li><li> Strong leadership and customer engagement skills </li><li> A willingness to travel in order to satisfy client needs </li><li> Experience conducting requirements analysis, meeting with business stakeholders and applying solutions to customer challenges </li><li> Working knowledge of advanced analytic tools such as SAS, R, or Python is required </li><li> Working knowledge of data visualization and analytics tools such as Tableau, PowerBI, QlikView, or Domo is required </li><li> Working knowledge of Oracle databases is preferred </li><li> Working knowledge of cloud-based technologies is preferred </li><li> At least 3 years of experience in a related role</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Information Technology and Services, Computer Software"
Data Scientist,"New York, New York, United States",Noom Inc.,2021-01-23,https://www.linkedin.com/jobs/view/data-scientist-at-noom-inc-2301903978?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=iZDYJy4YjiPQvv43MpbFCw%3D%3D&position=4&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and Hypertension. Our Engineering team is at the forefront of this challenge, solving complex technical and UX problems on our mobile apps that center around habits, behavior, and lifestyle.

We are looking for a Data Scientist to join our Data team and help us ensure that we apply the best approaches to data analysis and research, artificial intelligence, and machine learning.

What You’ll Like About Us

We work on problems that affect the lives of real people. Our users depend on us to make positive changes to their health and their lives.
We base our work on scientifically-proven, peer-reviewed methodologies that are designed by medical professionals.
We are a data-driven company through and through.
We’re a respectful, diverse, and dynamic environment in which Engineering is a first-class citizen, and where you’ll be able to work on a variety of interesting problems that affect the lives of real people.
We offer a generous budget for personal development expenses like training courses, conferences, and books.
You’ll get three weeks’ paid vacation and a flexible work policy that is remote- and family-friendly (about 50% of our engineering team is fully remote). We worry about results, not time spent in seats.



What We’ll Like About You

You have 4+ years of experience as a Data Scientist or Data Analyst in a similarly-sized organization, with a proven record of analysis and research that positively impacts your team.
You possess excellent communication skills and the ability to clearly communicate technical concepts to a non-technical audience
You possess excellent SQL/relational algebra skills, ideally with at least a basic knowledge of how different types of databases (e.g.: column vs row storage) work.
You have a superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, etc.
You are comfortable writing Python code, and have good working knowledge of pandas and numpy. We don’t expect you to write production-quality code, but you should have some programming experience.
You are comfortable with at least “medium data” technologies and how to transcend the “memory bound” nature of most analytics tools.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and Hypertension. Our Engineering team is at the forefront of this challenge, solving complex technical and UX problems on our mobile apps that center around habits, behavior, and lifestyle.<br><br>We are looking for a Data Scientist to join our Data team and help us ensure that we apply the best approaches to data analysis and research, artificial intelligence, and machine learning.<br><br><strong><u>What You’ll Like About Us<br></u></strong><ul> <li>We work on problems that affect the lives of real people. Our users depend on us to make positive changes to their health and their lives.</li> <li>We base our work on scientifically-proven, peer-reviewed methodologies that are designed by medical professionals.</li> <li>We are a data-driven company through and through.</li> <li>We’re a respectful, diverse, and dynamic environment in which Engineering is a first-class citizen, and where you’ll be able to work on a variety of interesting problems that affect the lives of real people.</li> <li>We offer a generous budget for personal development expenses like training courses, conferences, and books.</li> <li>You’ll get three weeks’ paid vacation and a flexible work policy that is remote- and family-friendly (about 50% of our engineering team is fully remote). We worry about results, not time spent in seats.</li> <br><br></ul><strong><u>What We’ll Like About You<br></u></strong><ul> <li>You have 4+ years of experience as a Data Scientist or Data Analyst in a similarly-sized organization, with a proven record of analysis and research that positively impacts your team.</li> <li>You possess excellent communication skills and the ability to clearly communicate technical concepts to a non-technical audience</li> <li>You possess excellent SQL/relational algebra skills, ideally with at least a basic knowledge of how different types of databases (e.g.: column vs row storage) work.</li> <li>You have a superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, etc.</li> <li>You are comfortable writing Python code, and have good working knowledge of pandas and numpy. We don’t expect you to write production-quality code, but you should have some programming experience.</li> <li>You are comfortable with at least “medium data” technologies and how to transcend the “memory bound” nature of most analytics tools.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Engineer,"McLean, Virginia, United States",Thomson Reuters,2021-02-07,https://www.linkedin.com/jobs/view/data-engineer-at-thomson-reuters-2371917937?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=2mtiT2To4KaOOlZcVHsVRg%3D%3D&position=6&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and Hypertension. Our Engineering team is at the forefront of this challenge, solving complex technical and UX problems on our mobile apps that center around habits, behavior, and lifestyle.

We are looking for a Data Scientist to join our Data team and help us ensure that we apply the best approaches to data analysis and research, artificial intelligence, and machine learning.

What You’ll Like About Us

We work on problems that affect the lives of real people. Our users depend on us to make positive changes to their health and their lives.
We base our work on scientifically-proven, peer-reviewed methodologies that are designed by medical professionals.
We are a data-driven company through and through.
We’re a respectful, diverse, and dynamic environment in which Engineering is a first-class citizen, and where you’ll be able to work on a variety of interesting problems that affect the lives of real people.
We offer a generous budget for personal development expenses like training courses, conferences, and books.
You’ll get three weeks’ paid vacation and a flexible work policy that is remote- and family-friendly (about 50% of our engineering team is fully remote). We worry about results, not time spent in seats.



What We’ll Like About You

You have 4+ years of experience as a Data Scientist or Data Analyst in a similarly-sized organization, with a proven record of analysis and research that positively impacts your team.
You possess excellent communication skills and the ability to clearly communicate technical concepts to a non-technical audience
You possess excellent SQL/relational algebra skills, ideally with at least a basic knowledge of how different types of databases (e.g.: column vs row storage) work.
You have a superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, etc.
You are comfortable writing Python code, and have good working knowledge of pandas and numpy. We don’t expect you to write production-quality code, but you should have some programming experience.
You are comfortable with at least “medium data” technologies and how to transcend the “memory bound” nature of most analytics tools.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and Hypertension. Our Engineering team is at the forefront of this challenge, solving complex technical and UX problems on our mobile apps that center around habits, behavior, and lifestyle.<br><br>We are looking for a Data Scientist to join our Data team and help us ensure that we apply the best approaches to data analysis and research, artificial intelligence, and machine learning.<br><br><strong><u>What You’ll Like About Us<br></u></strong><ul> <li>We work on problems that affect the lives of real people. Our users depend on us to make positive changes to their health and their lives.</li> <li>We base our work on scientifically-proven, peer-reviewed methodologies that are designed by medical professionals.</li> <li>We are a data-driven company through and through.</li> <li>We’re a respectful, diverse, and dynamic environment in which Engineering is a first-class citizen, and where you’ll be able to work on a variety of interesting problems that affect the lives of real people.</li> <li>We offer a generous budget for personal development expenses like training courses, conferences, and books.</li> <li>You’ll get three weeks’ paid vacation and a flexible work policy that is remote- and family-friendly (about 50% of our engineering team is fully remote). We worry about results, not time spent in seats.</li> <br><br></ul><strong><u>What We’ll Like About You<br></u></strong><ul> <li>You have 4+ years of experience as a Data Scientist or Data Analyst in a similarly-sized organization, with a proven record of analysis and research that positively impacts your team.</li> <li>You possess excellent communication skills and the ability to clearly communicate technical concepts to a non-technical audience</li> <li>You possess excellent SQL/relational algebra skills, ideally with at least a basic knowledge of how different types of databases (e.g.: column vs row storage) work.</li> <li>You have a superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, etc.</li> <li>You are comfortable writing Python code, and have good working knowledge of pandas and numpy. We don’t expect you to write production-quality code, but you should have some programming experience.</li> <li>You are comfortable with at least “medium data” technologies and how to transcend the “memory bound” nature of most analytics tools.</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Scientist,"Denver, Colorado, United States","Frontdoor, Inc.",2021-02-16,https://www.linkedin.com/jobs/view/data-scientist-at-frontdoor-inc-2415329847?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=QzDuzsjda9v9t9fimJLOEg%3D%3D&position=7&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Job Description

The Data Engineer is a technology expert who works to support the effective implementation of internal and external data enabled solutions supporting the Thomson Reuters Special Services (TRSS) organization. This role requires practical technology applications skills involving the cleaning, integration, extraction, analysis and delivery of structured and unstructured data. This role works closely with other teams across the technology organization and other business units, including the product development and software engineering teams, the data science team, and often pre and post-sales support of the business development team. The role will also have a customer facing component, involving direct implementation and support of existing or new applications at customer locations.

Basic Responsibilities

Work directly with internal resources as well as customer technology staff to implement and support custom TRSS client solutions and POCs
Design, build and support data pipelines and workflows designed to maximize the usefulness and efficiency of internal and external data sets being brought to bear on customer issues
Support and continually improve internal processes, to include automation of robotic processes across the organization where possible
Provide solution architecture support for business opportunities
Provide input to leadership teams using technical expertise and knowledge of customer technology requirements and infrastructure
Understand and interpret unique client requirements and mission and provide custom solutions to integrate TRSS content into client applications


Required Technical Qualifications

Experience leading the implementation and customization of technical solutions, preferably for government clients
Must have, or be able to acquire and maintain a US Government Security Clearance at the TOP SECRET level (TS)
Proficiency in multiple programming languages (particularly interested in python, Java but other languages could be useful as well)
Experience with Restful web services and current data communications technologies
Experience connecting to and querying a variety of relational and document-oriented databases
Comfortable in GUI and command line environments in Linux and Windows OS
Basic understanding of common data structures including flat files, XML, JSON, graph structures etc.
Familiarity with cloud-based infrastructure, including AWS


Desired Technical Qualifications

High level understanding of network troubleshooting techniques and communications protocols
Experience with information retrieval technologies such as Lucene and ElasticSearch
Experience with connected data and graph databases
Experience with workflow management tools, NIFI experience a plus
Understanding of public records and open source data
Experience working with data visualization tools (Power BI/Tableau, etc)
Robotic Process Automation experience
Understanding of public records and open source data
Experience working in virtualized environments, including the ability to stand up and configure a local virtual machine with locally hosted web applications


Required Personal Qualifications

Passionate, smart, and articulate technologist
Self-starter and results oriented
Must possess a strong personal work ethic
Must be of superior moral and ethical character
Must be able to operate under pressure with dynamic and changing requirements


Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing.

We are powered by the talents of 25,000 employees across more than 75 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

Accessibility

As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law.

More information about Thomson Reuters can be found on thomsonreuters.com.

Locations
McLean-Virginia-United States of America
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Job Description<br><br></u></strong>The Data Engineer is a technology expert who works to support the effective implementation of internal and external data enabled solutions supporting the Thomson Reuters Special Services (TRSS) organization. This role requires practical technology applications skills involving the cleaning, integration, extraction, analysis and delivery of structured and unstructured data. This role works closely with other teams across the technology organization and other business units, including the product development and software engineering teams, the data science team, and often pre and post-sales support of the business development team. The role will also have a customer facing component, involving direct implementation and support of existing or new applications at customer locations.<br><br><strong><u>Basic Responsibilities<br></u></strong><ul><li>Work directly with internal resources as well as customer technology staff to implement and support custom TRSS client solutions and POCs</li><li>Design, build and support data pipelines and workflows designed to maximize the usefulness and efficiency of internal and external data sets being brought to bear on customer issues</li><li>Support and continually improve internal processes, to include automation of robotic processes across the organization where possible</li><li>Provide solution architecture support for business opportunities</li><li>Provide input to leadership teams using technical expertise and knowledge of customer technology requirements and infrastructure</li><li>Understand and interpret unique client requirements and mission and provide custom solutions to integrate TRSS content into client applications<br><br></li></ul><strong><u>Required Technical Qualifications<br></u></strong><ul><li>Experience leading the implementation and customization of technical solutions, preferably for government clients</li><li>Must have, or be able to acquire and maintain a US Government Security Clearance at the TOP SECRET level (TS)</li><li>Proficiency in multiple programming languages (particularly interested in python, Java but other languages could be useful as well)</li><li>Experience with Restful web services and current data communications technologies</li><li>Experience connecting to and querying a variety of relational and document-oriented databases</li><li>Comfortable in GUI and command line environments in Linux and Windows OS</li><li>Basic understanding of common data structures including flat files, XML, JSON, graph structures etc.</li><li>Familiarity with cloud-based infrastructure, including AWS<br><br></li></ul><strong><u>Desired Technical Qualifications<br></u></strong><ul><li>High level understanding of network troubleshooting techniques and communications protocols</li><li>Experience with information retrieval technologies such as Lucene and ElasticSearch</li><li>Experience with connected data and graph databases</li><li>Experience with workflow management tools, NIFI experience a plus</li><li>Understanding of public records and open source data</li><li>Experience working with data visualization tools (Power BI/Tableau, etc)</li><li>Robotic Process Automation experience</li><li>Understanding of public records and open source data</li><li>Experience working in virtualized environments, including the ability to stand up and configure a local virtual machine with locally hosted web applications<br><br></li></ul><strong><u>Required Personal Qualifications<br></u></strong><ul><li>Passionate, smart, and articulate technologist</li><li>Self-starter and results oriented</li><li>Must possess a strong personal work ethic</li><li>Must be of superior moral and ethical character</li><li>Must be able to operate under pressure with dynamic and changing requirements<br><br></li></ul>Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing.<br><br>We are powered by the talents of 25,000 employees across more than 75 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.<br><br><strong>Accessibility <br><br></strong>As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.<br><br>We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law.<br><br>More information about Thomson Reuters can be found on thomsonreuters.com.<br><br><strong>Locations<br></strong>McLean-Virginia-United States of America</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Human Resources"
Data Engineer,"Dallas, Texas, United States",Apex Clearing Corporation,2021-02-09,https://www.linkedin.com/jobs/view/data-engineer-at-apex-clearing-corporation-2415567894?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=N2VcvjDRgzoIRFeJiQZUwg%3D%3D&position=8&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Data Scientist

Frontdoor is building an elite team of data scientists and engineers that will leverage the power of machine learning and AI to transform its core business and drive business impact. With data from 2M customers nation-wide acquired over 40 years of experience, our business is ripe for a disruption where legacy manual processes can be automated, enhanced, and scaled, creating high business value. There is a wide variety of new and exciting problems to solve, many of which are unique to our industry, such as automated repair recommendations, dynamic pricing, cost modeling, predicting time to failure, repair vs replace decisions, cycle-time prediction, and more.

We are looking for someone who is a fast and independent learner, curious, and passionate about data science and machine learning. You will be working in a diverse environment where you’ll collaborate with a multidisciplinary team of data scientists, analysts, software engineers, and product managers. You’ll be encouraged to take ownership of your projects and to find new opportunities and problems where machine learning could be applied to improve the business.

Key Responsibilities

Process massive amounts of structured and unstructured data.
Build advanced supervised and unsupervised machine learning models for batch and real-time applications.
Research new machine learning solutions to complex business problems.
Develop and deploy models in production using Python.
Run A/B test experiments and analyze results.
Communicate findings to non-technical audience.
Stay current with new tools and techniques in the literature.



Requirements

Masters in Computer Science, Engineering, Statistics, or related field (PhD preferred)
Excellent communication skills.
Strong background in machine learning and statistics.
Solid foundation in data structures and algorithms.
Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn).
Ability to write complex SQL queries.
Experience training deep neural networks.
Experience with natural language processing.
4 or more years of industry experience building ML and statistical models.



Frontdoor is a company that’s obsessed with taking the hassle out of owning a home. With services powered by people and enabled by technology, it is the parent company of four home service plan brands: American Home Shield, HSA, Landmark and OneGuard, as well as AHS Proconnect , an on-demand membership service for home repairs and maintenance, and Streem, a technology company that enables businesses to serve customers through an enhanced augmented reality, computer vision and machine learning platform. Frontdoor serves more than two million customers across the U.S. through a network of more than 16,000 pre-qualified contractor firms that employ over 45,000 technicians. The company’s customizable home service plans help customers protect and maintain their homes from costly and unexpected breakdowns of essential home systems and appliances. With nearly 50 years of experience, the company responds to over four million service requests annually (or one request every eight seconds).For more details, visit frontdoorhome.com.

Job Category: Engineering

ID: R0015013
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Data Scientist<br><br></u></strong>Frontdoor is building an elite team of data scientists and engineers that will leverage the power of machine learning and AI to transform its core business and drive business impact. With data from 2M customers nation-wide acquired over 40 years of experience, our business is ripe for a disruption where legacy manual processes can be automated, enhanced, and scaled, creating high business value. There is a wide variety of new and exciting problems to solve, many of which are unique to our industry, such as automated repair recommendations, dynamic pricing, cost modeling, predicting time to failure, repair vs replace decisions, cycle-time prediction, and more.<br><br>We are looking for someone who is a fast and independent learner, curious, and passionate about data science and machine learning. You will be working in a diverse environment where you’ll collaborate with a multidisciplinary team of data scientists, analysts, software engineers, and product managers. You’ll be encouraged to take ownership of your projects and to find new opportunities and problems where machine learning could be applied to improve the business.<br><br><strong><u>Key Responsibilities<br></u></strong><ul> <li>Process massive amounts of structured and unstructured data.</li> <li>Build advanced supervised and unsupervised machine learning models for batch and real-time applications.</li> <li>Research new machine learning solutions to complex business problems.</li> <li>Develop and deploy models in production using Python.</li> <li>Run A/B test experiments and analyze results.</li> <li>Communicate findings to non-technical audience.</li> <li>Stay current with new tools and techniques in the literature.</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Masters in Computer Science, Engineering, Statistics, or related field (PhD preferred)</li> <li>Excellent communication skills.</li> <li>Strong background in machine learning and statistics.</li> <li>Solid foundation in data structures and algorithms.</li> <li>Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn).</li> <li>Ability to write complex SQL queries.</li> <li>Experience training deep neural networks.</li> <li>Experience with natural language processing.</li> <li>4 or more years of industry experience building ML and statistical models.</li> <br><br></ul>Frontdoor is a company that’s obsessed with taking the hassle out of owning a home. With services powered by people and enabled by technology, it is the parent company of four home service plan brands: American Home Shield, HSA, Landmark and OneGuard, as well as AHS Proconnect , an on-demand membership service for home repairs and maintenance, and Streem, a technology company that enables businesses to serve customers through an enhanced augmented reality, computer vision and machine learning platform. Frontdoor serves more than two million customers across the U.S. through a network of more than 16,000 pre-qualified contractor firms that employ over 45,000 technicians. The company’s customizable home service plans help customers protect and maintain their homes from costly and unexpected breakdowns of essential home systems and appliances. With nearly 50 years of experience, the company responds to over four million service requests annually (or one request every eight seconds).For more details, visit frontdoorhome.com.<br><br>Job Category: Engineering<br><br>ID: R0015013</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer Analytics,"Seattle, Washington, United States",doxo,2021-01-25,https://www.linkedin.com/jobs/view/data-engineer-analytics-at-doxo-2415460117?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=jo7UjYZ7mSHe92YFUPKDXw%3D%3D&position=9&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"This is an incredible opportunity for a Database Developer to join a team focused on being the best data engineer in clearing. Apex is recognized for disrupting the financial services industry, enabling fintech standouts like Stash, Webull and Betterment. Have you been waiting on the opportunity to join a winning technical team? Now's your chance.

We're looking for someone who:


Is passionate. You have a genuine passion for technology. You love using technology differently to maximize opportunity and impact for customers and you have a way of bringing out that same fire in the people you work with
Is motivated. You're driven to be the best – whether that's decreasing system down time or making an innovative change to ""how it's always been done"" resulting in a more efficient way of supporting the customer. You challenge yourself by setting goals and exceeding them
Is collaborative. You're excited to work with fellow engineers and big thinkers. You know how to collaborate not only within the department, but also across the organization
Wants to make an impact. You're looking to do amazing work. You value preventing problems from occurring over being caught in the chaos zone putting out fires and looking for the ""hero"" spotlight
Strives for frictionless IT – You understand the importance of building great partnerships. You promote a seamless, smooth, user friendly and reliable environment.


What you'll do all day:


Be a data wizard. Create, manipulate, access, and deliver data in the most efficient ways possible to business users, end-customers, 3rd-party vendors, and application developers
Work the data. Create processes to load, transform, and deliver data to business users, end-customers, 3rd party vendors, and application developers.
Learn the data. Utilize excellent analytical and problem solving techniques to understand our complex data structures and put the data to work. Participate in all phases of the development process.
See the data. Build reports, analytics and visualizations to help meet business initiatives and make decisions.
Make us better. Identify, advocate for, and implement solutions to improve performance and efficiencies across systems, APIs, and overnight batch processing. Develop quality code that is maintainable and avoids problems. Promote a culture for effective documentation and lessons-learned.
Be a great team member. Work as a member of an agile software development team to rapidly produce software. Balance both project-based and day-to-day support tasks.
Show off your work. Embrace transparency and share metrics around our levels of service with the rest of the company and our customers.
Live our culture. Embrace Apex's values as our differentiator and be an example of them every day.


A few reasons why you might love us:


We're a leader in the space. Apex is recognized for disrupting the financial services industry, enabling fintech standouts like Stash, Webull and Betterment. We've got an amazing track record of success and we foster ongoing innovation. So you get all the benefits of a proven, growing company, while enjoying a very entrepreneurial culture
We see tech differently. You'll work with people who are leaders in the tech industry. We are passionate engineers dedicated to finding new and different ways to use technology to solve our customers' problems.
Your work will have immediate impact. You'll be able to see your direct impact on our tech department, our business, and with our clients. You won't be just another talented engineer.


And a few reasons why you may not like working for us:


You don't like change. This is not a job for someone who likes ""predictable."" The job is based on the unknown which inevitably means change. If you like to know what you're going to do every day, you may not like working on this team. You have to go with the flow here.
You're not the collaborative type. We work together to ensure the best possible solutions for our customers. We think two brains are better than one so we do most of our work together. Team work makes the dream work on this team.
You're a tech snob. We deal with all technology – Linux and Windows; .NET, Java, and Python; SQL and noSQL (mongoDB); RabbitMQ and other open source tools and libraries. We love technology and want to work with all of it. If you're wed to a particular tech, you may not like working for us.


The skills you'll need to succeed:


Bachelor's degree in Computer Science, Computer Engineering or a similar field
2+ years of Microsoft SQL Development Experience
2+ years of experience in data warehousing and ETL processes
1+ years of experience with Python
Advanced problem-solving, debugging, and troubleshooting skills
Excellent client support skills
Proficient with version control systems, ideally GitHub
Ability and willingness to learn new things (languages, tools, frameworks) quickly
Experience with the Microsoft BI Stack (SSIS, SSAS, SSRS) preferred
Experience with NoSQL technologies preferred
Financial services background preferred
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">This is an incredible opportunity for a Database Developer to join a team focused on being the best data engineer in clearing. Apex is recognized for disrupting the financial services industry, enabling fintech standouts like Stash, Webull and Betterment. Have you been waiting on the opportunity to join a winning technical team? Now's your chance.<br><br><strong>We're looking for someone who:<br><br></strong><ul> <li><strong><em>Is passionate</em></strong>. You have a genuine passion for technology. You love using technology differently to maximize opportunity and impact for customers and you have a way of bringing out that same fire in the people you work with</li> <li><strong><em>Is motivated</em></strong>. You're driven to be the best – whether that's decreasing system down time or making an innovative change to ""how it's always been done"" resulting in a more efficient way of supporting the customer. You challenge yourself by setting goals and exceeding them</li> <li><strong><em>Is collaborative. </em></strong>You're excited to work with fellow engineers and big thinkers. You know how to collaborate not only within the department, but also across the organization</li> <li><strong><em>Wants to make an impact</em></strong>. You're looking to do amazing work. You value preventing problems from occurring over being caught in the chaos zone putting out fires and looking for the ""hero"" spotlight</li> <li><strong><em>Strives for frictionless IT </em></strong>– You understand the importance of building great partnerships. You promote a seamless, smooth, user friendly and reliable environment.</li> <br></ul><strong>What you'll do all day:<br><br></strong><ul> <li><strong><em>Be a data wizard.</em></strong> Create, manipulate, access, and deliver data in the most efficient ways possible to business users, end-customers, 3rd-party vendors, and application developers</li> <li><strong><em>Work the data.</em></strong> Create processes to load, transform, and deliver data to business users, end-customers, 3rd party vendors, and application developers.</li> <li><strong><em>Learn the data.</em></strong> Utilize excellent analytical and problem solving techniques to understand our complex data structures and put the data to work. Participate in all phases of the development process.</li> <li><strong><em>See the data.</em></strong> Build reports, analytics and visualizations to help meet business initiatives and make decisions.</li> <li><strong><em>Make us better.</em></strong> Identify, advocate for, and implement solutions to improve performance and efficiencies across systems, APIs, and overnight batch processing. Develop quality code that is maintainable and avoids problems. Promote a culture for effective documentation and lessons-learned.</li> <li><strong><em>Be a great team member.</em></strong> Work as a member of an agile software development team to rapidly produce software. Balance both project-based and day-to-day support tasks. </li> <li><strong><em>Show off your work. </em></strong>Embrace transparency and share metrics around our levels of service with the rest of the company and our customers.</li> <li><strong><em>Live our culture.</em></strong> Embrace Apex's values as our differentiator and be an example of them every day.</li> <br></ul><strong>A few reasons why you might love us:<br><br></strong><ul> <li><strong><em>We're a leader in the space. </em></strong>Apex is recognized for disrupting the financial services industry, enabling fintech standouts like Stash, Webull and Betterment. We've got an amazing track record of success and we foster ongoing innovation. So you get all the benefits of a proven, growing company, while enjoying a very entrepreneurial culture</li> <li><strong><em>We see tech differently.</em></strong> You'll work with people who are leaders in the tech industry. We are passionate engineers dedicated to finding new and different ways to use technology to solve our customers' problems.</li> <li><strong><em>Your work will have immediate impact.</em></strong> You'll be able to see your direct impact on our tech department, our business, and with our clients. You won't be just another talented engineer.</li> <br></ul><strong>And a few reasons why you may not like working for us:<br><br></strong><ul> <li><strong><em>You don't like change</em></strong>. This is not a job for someone who likes ""predictable."" The job is based on the unknown which inevitably means change. If you like to know what you're going to do every day, you may not like working on this team. You have to go with the flow here.</li> <li><strong><em>You're not the collaborative type</em></strong>. We work together to ensure the best possible solutions for our customers. We think two brains are better than one so we do most of our work together. Team work makes the dream work on this team.</li> <li><strong><em>You're a tech snob</em></strong>. We deal with all technology – Linux and Windows; .NET, Java, and Python; SQL and noSQL (mongoDB); RabbitMQ and other open source tools and libraries. We love technology and want to work with all of it. If you're wed to a particular tech, you may not like working for us.</li> <br></ul><strong>The skills you'll need to succeed: <br><br></strong><ul> <li>Bachelor's degree in Computer Science, Computer Engineering or a similar field</li> <li>2+ years of Microsoft SQL Development Experience</li> <li>2+ years of experience in data warehousing and ETL processes</li> <li>1+ years of experience with Python</li> <li>Advanced problem-solving, debugging, and troubleshooting skills</li> <li>Excellent client support skills</li> <li>Proficient with version control systems, ideally GitHub</li> <li>Ability and willingness to learn new things (languages, tools, frameworks) quickly</li> <li>Experience with the Microsoft BI Stack (SSIS, SSAS, SSRS) preferred</li> <li>Experience with NoSQL technologies preferred</li> <li>Financial services background preferred</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Sparks, Maryland, United States","Envestnet, Inc",2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-envestnet-inc-2407665950?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=OCoG6TAOq7dFj4353BK6dw%3D%3D&position=10&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"doxo is disrupting bill pay. Our company was founded on the simple idea that it should be easy and more secure to pay all your bills through a single account. Over 4 million users are paying bills at 65,000+ businesses on our platform and we are just getting started. It is time to change the $4 Trillion bill pay industry. Join us as we help to reduce the burden of paying bills and help people accomplish their financial goals.

The Role

We are seeking a data engineer to help us establish and grow our paid advertising footprint. This position is an integral part of the doxo marketing team and the owner of our paid search data and automation platform. The position heavily collaborates with the doxo marketing team to automate and optimize our paid marketing campaigns and efforts.

Key Responsibilities

Maintain and expand upon our paid marketing data ecosystem by maintaining our ETL process, consuming data from our Ad Partner APIs (Google Ads, Bing Ads, and Facebook Ads) and merging marketing data with doxo internal data.
Design and maintain python scripts to drive our paid search (PPC) automation platform, including customer audience lists, campaign re-structures and rule-based bidding.
Help to scale Facebook advertising by creating an ETL of Facebook marketing data and an automated python-based system to scale ad set creation, demographic bidding, creative management and audience targeting.
Track, report on and make recommendations to optimize our paid marketing business.
Create actionable email reporting and alerting to help inform our daily manual optimizations.
Automate dashboard and data reporting through google sheets.
Able to experiment with new technologies and acquire new skills to find clever solutions to unique challenges encountered along the way.


Requirements

3+ years of direct experience in a data analyst or data engineering role, preferably in environments with data requirements from multiple sources.
Experience developing with ad APIs
Experience with designing data schemas and creating ETL processes from data available through external APIs
Advanced-level knowledge of SQL and scripting languages like Python.
Excellent organizational and communications skills, with the ability to translate technical data into actionable insights, and sales and marketing goals into effective digital campaigns
Work independently and as part of a team
Proven ability to accomplish objectives and work proactively
Capacity for learning quickly in a fast-paced environment and handling multiple tasks simultaneously
Strong written and spoken communication skills
Bachelor’s degree in a relevant field

doxo is an equal-opportunity employer and we welcome applicants from all backgrounds.

doxo was founded on the simple idea that connecting with a company to get important documents, pay bills, and organize files should be as easy as connecting to a friend on Facebook, or a colleague on LinkedIn. Whether on a mobile device, a tablet or a desktop, interacting should be simple and efficient. Companies large and small, spanning all types of industries, can join the doxo network to boost customer interaction, drive mobile engagement, get paid faster, and gain more insight into the markets they serve.

Headquartered in Seattle, doxo investors include Mohr Davidow Ventures, Sigma Partners, and Bezos Expeditions.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">doxo is disrupting bill pay. Our company was founded on the simple idea that it should be easy and more secure to pay all your bills through a single account. Over 4 million users are paying bills at 65,000+ businesses on our platform and we are just getting started. It is time to change the $4 Trillion bill pay industry. Join us as we help to reduce the burden of paying bills and help people accomplish their financial goals.<br><br>The Role<br><br>We are seeking a data engineer to help us establish and grow our paid advertising footprint. This position is an integral part of the doxo marketing team and the owner of our paid search data and automation platform. The position heavily collaborates with the doxo marketing team to automate and optimize our paid marketing campaigns and efforts.<br><br>Key Responsibilities<br><ul><li>Maintain and expand upon our paid marketing data ecosystem by maintaining our ETL process, consuming data from our Ad Partner APIs (Google Ads, Bing Ads, and Facebook Ads) and merging marketing data with doxo internal data.</li><li>Design and maintain python scripts to drive our paid search (PPC) automation platform, including customer audience lists, campaign re-structures and rule-based bidding.</li><li>Help to scale Facebook advertising by creating an ETL of Facebook marketing data and an automated python-based system to scale ad set creation, demographic bidding, creative management and audience targeting.</li><li>Track, report on and make recommendations to optimize our paid marketing business.</li><li>Create actionable email reporting and alerting to help inform our daily manual optimizations.</li><li>Automate dashboard and data reporting through google sheets.</li><li>Able to experiment with new technologies and acquire new skills to find clever solutions to unique challenges encountered along the way.<br><br></li></ul><strong><u>Requirements<br></u></strong><ul><li>3+ years of direct experience in a data analyst or data engineering role, preferably in environments with data requirements from multiple sources.</li><li>Experience developing with ad APIs</li><li>Experience with designing data schemas and creating ETL processes from data available through external APIs</li><li>Advanced-level knowledge of SQL and scripting languages like Python.</li><li>Excellent organizational and communications skills, with the ability to translate technical data into actionable insights, and sales and marketing goals into effective digital campaigns</li><li>Work independently and as part of a team</li><li>Proven ability to accomplish objectives and work proactively</li><li>Capacity for learning quickly in a fast-paced environment and handling multiple tasks simultaneously</li><li>Strong written and spoken communication skills</li><li>Bachelor’s degree in a relevant field<br></li></ul>doxo is an equal-opportunity employer and we welcome applicants from all backgrounds.<br><br>doxo was founded on the simple idea that connecting with a company to get important documents, pay bills, and organize files should be as easy as connecting to a friend on Facebook, or a colleague on LinkedIn. Whether on a mobile device, a tablet or a desktop, interacting should be simple and efficient. Companies large and small, spanning all types of industries, can join the doxo network to boost customer interaction, drive mobile engagement, get paid faster, and gain more insight into the markets they serve.<br><br>Headquartered in Seattle, doxo investors include Mohr Davidow Ventures, Sigma Partners, and Bezos Expeditions.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Data Engineer,"New York, New York, United States",Jobs via eFinancialCareers,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-jobs-via-efinancialcareers-2430610966?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=3JPitgnXklCGaBjq%2BC0AZg%3D%3D&position=12&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"At Bloomberg, our products are fueled by powerful information. We combine data and context to paint the whole picture for our clients, around the clock - from around the world. In Global Data, we're responsible for delivering this information through innovative technology - quickly and accurately.

We see the impact of our work every day, whether it's using machine learning pipelines to estimate financial product data, architecting systems that guide decision-making, or finding ways for our colleagues to more easily do their jobs. We get to work with market data to detect anomalies, assess the quality of data feeds to evaluate the accuracy of forecasts, and figure out how to best combine system automation with a human touch, bringing value to our businesses and ultimately our clients.

We'll Trust You To

Apply your coding skills: Automate the influx of data and build flexible solutions for data acquisition, ETL and machine learning pipelines, and human-in-the-loop data processing to drive successful product adoption
Inspire and impact our business: Act as an internal consultant to influence and implement more efficient products through analysis, dashboards, web apps, and user documentation
Develop your career: sharpen your technical skills and strengthen relationships through project management, partnering with stakeholders across the firm, and establishing scalable architecture
Champion improvements: identify strategic technical gaps in our ecosystem and advocate for solutions over workarounds
Grow our business: Approach each day knowing this role is mission-critical to the success of the firm. We will rely on your expertise, and our flat structure allows for you to make real impact, real quick



You'll Need To Have

A BA/BS degree or higher in Computer Science, Mathematics, or relevant data technology field, or equivalent professional work experience in software development, data engineering, data science or information technology
2+ years of Python programming and scripting in a production environment
2+ years of experience working with restful APIs and data modeling within SQL and NoSQL databases
Deep understanding of large-scale, distributed systems
Legal authorization to work full-time in the United States without requiring visa sponsorship


Does this sound like you?
Apply if you think we're a good match. We'll get in touch to let you know what the next steps are.

Bloomberg is committed to diversity. It drives our innovation. At Bloomberg, you'll have the opportunity to go above and beyond and to take risks. You'll be a part of an organization that is entering new markets, launching new ventures, and pushing boundaries. Our ever-expanding array of technology, data, news, and media services champions innovation and empowers clients -- and offers nearly limitless opportunities for career growth.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We bring out the best in each other.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">At Bloomberg, our products are fueled by powerful information. We combine data and context to paint the whole picture for our clients, around the clock - from around the world. In Global Data, we're responsible for delivering this information through innovative technology - quickly and accurately.<br><br>We see the impact of our work every day, whether it's using machine learning pipelines to estimate financial product data, architecting systems that guide decision-making, or finding ways for our colleagues to more easily do their jobs. We get to work with market data to detect anomalies, assess the quality of data feeds to evaluate the accuracy of forecasts, and figure out how to best combine system automation with a human touch, bringing value to our businesses and ultimately our clients.<br><br><strong><u>We'll Trust You To<br></u></strong><ul> <li>Apply your coding skills: Automate the influx of data and build flexible solutions for data acquisition, ETL and machine learning pipelines, and human-in-the-loop data processing to drive successful product adoption</li> <li>Inspire and impact our business: Act as an internal consultant to influence and implement more efficient products through analysis, dashboards, web apps, and user documentation</li> <li>Develop your career: sharpen your technical skills and strengthen relationships through project management, partnering with stakeholders across the firm, and establishing scalable architecture</li> <li>Champion improvements: identify strategic technical gaps in our ecosystem and advocate for solutions over workarounds</li> <li>Grow our business: Approach each day knowing this role is mission-critical to the success of the firm. We will rely on your expertise, and our flat structure allows for you to make real impact, real quick</li> <br><br></ul><strong><u>You'll Need To Have<br></u></strong><ul> <li>A BA/BS degree or higher in Computer Science, Mathematics, or relevant data technology field, or equivalent professional work experience in software development, data engineering, data science or information technology</li> <li>2+ years of Python programming and scripting in a production environment</li> <li>2+ years of experience working with restful APIs and data modeling within SQL and NoSQL databases </li> <li>Deep understanding of large-scale, distributed systems</li> <li>Legal authorization to work full-time in the United States without requiring visa sponsorship</li> <br></ul><strong>Does this sound like you?<br></strong>Apply if you think we're a good match. We'll get in touch to let you know what the next steps are.<br><br>Bloomberg is committed to diversity. It drives our innovation. At Bloomberg, you'll have the opportunity to go above and beyond and to take risks. You'll be a part of an organization that is entering new markets, launching new ventures, and pushing boundaries. Our ever-expanding array of technology, data, news, and media services champions innovation and empowers clients -- and offers nearly limitless opportunities for career growth.<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We bring out the best in each other.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Banking, Insurance, Financial Services"
Data Scientist,"San Francisco, California, United States",Grammarly,2021-02-16,https://www.linkedin.com/jobs/view/data-scientist-at-grammarly-2370667349?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=hL7ulQkgSHi%2BA70jIMDZTg%3D%3D&position=13&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Grammarly is continuing to grow our team during the COVID-19 pandemic, conducting fully remote hiring and onboarding processes. All Grammarly team members can work remotely until August 2021. Read more about how we’re supporting our team and communities.
The opportunity
Grammarly empowers people to thrive and connect, whenever and wherever they communicate. 30 million people around the world use our AI-powered writing assistant every day. All of this begins with our team collaborating in a values-driven and learning-oriented environment.

We’re looking for a Data Scientist to help us drive decision-making, find bigger opportunities, and improve our product. As a consumer internet company, we produce huge amounts of data, and in this role, you will have outsize opportunities to develop the insights to make it actionable. You will have broad impact and exposure across Grammarly, working with team members from our Product, Research, Marketing, Engineering, and Finance teams.

Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog .
Your impact
As a Data Scientist at Grammarly, you will help our team make better decisions by advocating for data-driven approaches across the organization. Your analysis will contribute to our strategy across the business in areas such as user acquisition, engagement, retention, and more.


Within your first month, you will start developing a good understanding of the overall data-processing pipeline, understand a subset of Grammarly’s key metrics, and complete at least two small data reports to present to relevant business owners.
By month three, you will become an expert user of our analytical tools, start contributing to the Data Science team’s projects, understand all of Grammarly’s key metrics, and independently work on small-to-medium-complexity data projects (including A/B tests, channel analysis, and user engagement).
By month six, you will start working independently on complex data projects, such as user segmentation, short- and long-term user-engagement analysis, and lifetime value projections.
By year one, you will become the go-to person and subject-matter expert for a few of Grammarly’s key metrics, own and drive projects independently with minimal supervision, and along with our other Data Scientists, ensure “data science excellence” at Grammarly (dashboards, high-quality reports, empowered teams, etc.).
We’re looking for someone who

Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Holds a PhD in a quantitative field or a masters in a quantitative field and has at least 3 years of experience working as a data scientist.
Has experience in data analysis, A/B testing, retention tracking, etc. (consumer product experience is preferred).
Is proficient in data mining and statistics.
Has experience with SQL as well as experience programming in Python, R, Scala, or an equivalent language.
Has strong analytical and critical thinking skills as well as a strong bias toward actionable insights; loves finding insights and getting others to act on them.
Is a self-starter with superior organizational and prioritization skills.
Support for you, professionally and personally

Professional growth : We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback.
A connected team : Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs.
Comprehensive benefits : Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer ample and defined time off, catered lunches, gym and recreation stipends, admission discounts, and more.
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Grammarly will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. Grammarly is an equal opportunity employer and participant in the U.S. Federal E-Verify program.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Grammarly is continuing to grow our team during the COVID-19 pandemic, conducting fully remote hiring and onboarding processes. All Grammarly team members can work remotely until August 2021. Read more about how we’re supporting our team and communities.<br><strong><strong>The opportunity<br></strong></strong>Grammarly empowers people to thrive and connect, whenever and wherever they communicate. 30 million people around the world use our AI-powered writing assistant every day. All of this begins with our team collaborating in a values-driven and learning-oriented environment.<br><br>We’re looking for a Data Scientist to help us drive decision-making, find bigger opportunities, and improve our product. As a consumer internet company, we produce huge amounts of data, and in this role, you will have outsize opportunities to develop the insights to make it actionable. You will have broad impact and exposure across Grammarly, working with team members from our Product, Research, Marketing, Engineering, and Finance teams.<br><br>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog .<br><strong><strong>Your impact<br></strong></strong>As a Data Scientist at Grammarly, you will help our team make better decisions by advocating for data-driven approaches across the organization. Your analysis will contribute to our strategy across the business in areas such as user acquisition, engagement, retention, and more.<br><br><ul> <li> Within your first month, you will start developing a good understanding of the overall data-processing pipeline, understand a subset of Grammarly’s key metrics, and complete at least two small data reports to present to relevant business owners. </li> <li> By month three, you will become an expert user of our analytical tools, start contributing to the Data Science team’s projects, understand all of Grammarly’s key metrics, and independently work on small-to-medium-complexity data projects (including A/B tests, channel analysis, and user engagement). </li> <li> By month six, you will start working independently on complex data projects, such as user segmentation, short- and long-term user-engagement analysis, and lifetime value projections. </li> <li> By year one, you will become the go-to person and subject-matter expert for a few of Grammarly’s key metrics, own and drive projects independently with minimal supervision, and along with our other Data Scientists, ensure “data science excellence” at Grammarly (dashboards, high-quality reports, empowered teams, etc.). </li> </ul> <strong><strong>We’re looking for someone who<br></strong></strong><ul> <li> Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable. </li> <li> Holds a PhD in a quantitative field or a masters in a quantitative field and has at least 3 years of experience working as a data scientist. </li> <li> Has experience in data analysis, A/B testing, retention tracking, etc. (consumer product experience is preferred). </li> <li> Is proficient in data mining and statistics. </li> <li> Has experience with SQL as well as experience programming in Python, R, Scala, or an equivalent language. </li> <li> Has strong analytical and critical thinking skills as well as a strong bias toward actionable insights; loves finding insights and getting others to act on them. </li> <li> Is a self-starter with superior organizational and prioritization skills. </li> </ul> <strong><strong>Support for you, professionally and personally<br></strong></strong><ul> <li> Professional growth : We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback. </li> <li> A connected team : Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs. </li> <li> Comprehensive benefits : Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer ample and defined time off, catered lunches, gym and recreation stipends, admission discounts, and more. </li> </ul> <strong><strong>We encourage you to apply<br></strong></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Grammarly will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. Grammarly is an equal opportunity employer and participant in the U.S. Federal E-Verify program.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"Austin, Texas, United States",Shipwell,2021-02-09,https://www.linkedin.com/jobs/view/data-scientist-at-shipwell-2415701213?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=jF8omlLwshiKFf4ji4Bmsg%3D%3D&position=14&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"About Us

Supply chains are disconnected, fragmented, and stuck in the stone age. We believe the market has it wrong, and we believe there is a better way. We are building the de facto platform and market network to connect, automate, and optimize the supply chains of the world. This is a multi- trillion dollar opportunity.

Today, Shipwell transforms your supply chains by combining transportation management, visibility, and an integrated partner network in one simple and responsive platform and RestfulAPI that scales as you grow. Our platform uses machine learning to analyze over 25 million rows of real-time data every day, reducing waste and friction, delivering better business intelligence, and driving continuous improvement across our customer supply chains. Shipwell is proud to be recognized by industry experts as a leader in shipping and logistics, including FreightTech 25 and Forbes Next Billion Dollar Startup 2020.

Our Culture

Shipwell is a fast-paced, high-energy start-up that strives to build the future of shipping every day. Diversity of thought and cross-department collaboration is very important to us. We deliver open, honest, careful communication and work as hard as we play. We create & deliver solutions that are revolutionizing the industry, which brings excitement and purpose to our work. If you are looking for a place that will help you tap into your best work-self and give you hands-on experience building something big, then we invite you to come and build the future of shipping with us!

Data Scientist

Data Scientists at Shipwell proactively design and deploy algorithms and analytics features on our state-of-the-art platform. This involves collaborating with Product, Engineering, and Operations teams to discover product improvement opportunities and to proactively drive features through development to customer adoption. The mission is to underpin operational decisions made at each stage of the supply chain with data-driven insights.

What you'll do when you get here:

Analyze client proprietary and public domain datasets leveraging advanced analytics and statistics to work on scheduling and network optimization, macroeconomic forecasting, pricing, vehicle routing, and resource matching
Source, clean, and process a diverse set of data streams
Identify and understand business needs and contextualize analysis results to drive impact for the organization as a whole
Dynamically collaborate with operations and product teams to discover product improvement opportunities, develop data-driven solutions, and distill algorithm performance into trackable business impact
Provide consulting services on both internal and external analytic questions


What you need to have:

MS / PhD in data science, operations research, statistics, mathematics, physical science, computer science, engineering, or other technical discipline
3 - 7+ years of applied work experience, preferably in a non-academic setting
Expert knowledge in a mathematical programming language, preferably Python, MATLAB, R
Experience designing and implementing supervised and unsupervised learning algorithms
Ability to communicate complex findings in a clear, precise, and actionable manner
Facility to translate business requirements and high-level ideas into well-defined problems
Competency with ETL processes for manipulating data sets
Familiarity with API integrations
Proactive approach to solving problems


What we offer:

401k
Career growth opportunities
Friendly and inclusive company culture
Team building events and office celebrations
Competitive compensation with company stock options
Company sponsored healthcare, dental, and vision insurance
The kitchen is fully stocked with local coffee, drinks, and snacks
An open work environment where everyone has a voice
Subsidized gym, cell phone, learning and commuter reimbursements. Oh yeah, and entertainment reimbursement, we've got you covered!
An exceptional team of passionate, bright, and inspirational coworkers


For more information about Shipwell visit shipwell.com, or connect with us on Twitter, LinkedIn, and Facebook.

Here at Shipwell, we are a Remote Forward company. You have the opportunity to work within one of our office location cities (Austin and Chicago) or you can choose to be fully remote.

Shipwell is an Equal Opportunity Employer and we will not tolerate discrimination or harassment of any sort. We do celebrate diversity and believe experience comes in different forms; many skills are transferable; and passion goes a long way. Diversity in our team makes for better problem solving, more creative thinking, and ultimately a better product and company culture.

Even more important than your resume is a clear demonstration of impact, dedication, and the ability to thrive in a fast paced and collaborative environment. Shipwell strives to have an inclusive work environment; so if you are hard working & good at what you do then please come as you are. We want you to contribute, grow, & learn at Shipwell and we encourage you to apply if your experience is close to what we're looking for.

We are looking forward to adding new perspectives to our team!
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About Us<br><br></u></strong>Supply chains are disconnected, fragmented, and stuck in the stone age. We believe the market has it wrong, and we believe there is a better way. We are building the de facto platform and market network to connect, automate, and optimize the supply chains of the world. This is a multi- trillion dollar opportunity.<br><br>Today, Shipwell transforms your supply chains by combining transportation management, visibility, and an integrated partner network in one simple and responsive platform and RestfulAPI that scales as you grow. Our platform uses machine learning to analyze over 25 million rows of real-time data every day, reducing waste and friction, delivering better business intelligence, and driving continuous improvement across our customer supply chains. Shipwell is proud to be recognized by industry experts as a leader in shipping and logistics, including FreightTech 25 and Forbes Next Billion Dollar Startup 2020.<br><br><strong>Our Culture<br><br></strong>Shipwell is a fast-paced, high-energy start-up that strives to build the future of shipping every day. Diversity of thought and cross-department collaboration is very important to us. We deliver open, honest, careful communication and work as hard as we play. We create &amp; deliver solutions that are revolutionizing the industry, which brings excitement and purpose to our work. If you are looking for a place that will help you tap into your best work-self and give you hands-on experience building something big, then we invite you to come and build the future of shipping with us!<br><br><strong>Data Scientist<br><br></strong>Data Scientists at Shipwell proactively design and deploy algorithms and analytics features on our state-of-the-art platform. This involves collaborating with Product, Engineering, and Operations teams to discover product improvement opportunities and to proactively drive features through development to customer adoption. The mission is to underpin operational decisions made at each stage of the supply chain with data-driven insights.<br><br><strong>What you'll do when you get here:<br></strong><ul> <li>Analyze client proprietary and public domain datasets leveraging advanced analytics and statistics to work on scheduling and network optimization, macroeconomic forecasting, pricing, vehicle routing, and resource matching</li> <li>Source, clean, and process a diverse set of data streams</li> <li>Identify and understand business needs and contextualize analysis results to drive impact for the organization as a whole</li> <li>Dynamically collaborate with operations and product teams to discover product improvement opportunities, develop data-driven solutions, and distill algorithm performance into trackable business impact</li> <li>Provide consulting services on both internal and external analytic questions</li> <br></ul><strong>What you need to have:<br></strong><ul> <li>MS / PhD in data science, operations research, statistics, mathematics, physical science, computer science, engineering, or other technical discipline</li> <li>3 - 7+ years of applied work experience, preferably in a non-academic setting</li> <li>Expert knowledge in a mathematical programming language, preferably Python, MATLAB, R</li> <li>Experience designing and implementing supervised and unsupervised learning algorithms</li> <li>Ability to communicate complex findings in a clear, precise, and actionable manner</li> <li>Facility to translate business requirements and high-level ideas into well-defined problems</li> <li>Competency with ETL processes for manipulating data sets</li> <li>Familiarity with API integrations</li> <li>Proactive approach to solving problems</li> <br></ul><strong>What we offer:<br></strong><ul> <li>401k</li> <li>Career growth opportunities</li> <li>Friendly and inclusive company culture</li> <li>Team building events and office celebrations</li> <li>Competitive compensation with company stock options</li> <li>Company sponsored healthcare, dental, and vision insurance</li> <li>The kitchen is fully stocked with local coffee, drinks, and snacks</li> <li>An open work environment where everyone has a voice</li> <li>Subsidized gym, cell phone, learning and commuter reimbursements. Oh yeah, and entertainment reimbursement, we've got you covered!</li> <li>An exceptional team of passionate, bright, and inspirational coworkers</li> <br></ul>For more information about Shipwell visit shipwell.com, or connect with us on Twitter, LinkedIn, and Facebook.<br><br>Here at Shipwell, we are a Remote Forward company. You have the opportunity to work within one of our office location cities (Austin and Chicago) or you can choose to be fully remote.<br><br>Shipwell is an Equal Opportunity Employer and we will not tolerate discrimination or harassment of any sort. We do celebrate diversity and believe experience comes in different forms; many skills are transferable; and passion goes a long way. Diversity in our team makes for better problem solving, more creative thinking, and ultimately a better product and company culture.<br><br>Even more important than your resume is a clear demonstration of impact, dedication, and the ability to thrive in a fast paced and collaborative environment. Shipwell strives to have an inclusive work environment; so if you are hard working &amp; good at what you do then please come as you are. We want you to contribute, grow, &amp; learn at Shipwell and we encourage you to apply if your experience is close to what we're looking for.<br><br>We are looking forward to adding new perspectives to our team!</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Computer Software, Internet"
Data Scientist,San Francisco Bay Area,Bertram Capital,2021-02-11,https://www.linkedin.com/jobs/view/data-scientist-at-bertram-capital-2376311916?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=19vc2afWxJowH%2F7Ke9FdSw%3D%3D&position=15&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Firm Overview 

Bertram Capital is a private equity firm targeting investments in lower middle market companies. Since its inception in 2006, the firm has raised over $1.7B of capital commitments. Bertram has distinguished itself in the private equity community by combining venture capital operating methodologies with private equity financial discipline to empower its portfolio companies to unlock their full business potential. This approach is unique in that Bertram is not singularly focused on achieving its investment returns through financial engineering and the extraction of near-term cash flow. Instead, Bertram focuses on reinvestment and technology enablement to drive growth and value through digital marketing, e-commerce, big data and analytics, application development and internal and external platform optimization.

Visit www.bcap.com for more information.

 

Position Description

Bertram Capital is seeking a Business Intelligence Analyst / Data Scientist to join the firm’s Bertram Labs team in its San Francisco Bay Area headquarters or Remote.

Role:

Work with portfolio companies to develop and implement data-driven strategies
Evaluate, recommend, and implement data software and systems 
Setup data warehouses and work with ETL pipelines and APIs
Create KPIs, visualize data, and make available to stakeholders
Generate insights that solve business problems to fuel growth
Analyze large datasets to help guide new investments




This role is a combination of consulting, strategy, and implementation. Bertram Labs is an integral part of the Bertram strategy, and team members work across a mix of opportunities for existing portfolio companies and new investments. We hire personable, intelligent, self-starters who exhibit professionalism and exceptional analytical, organizational and communication skills.

 

You

Deep understanding of data analytics and statistics
Strong SQL skills
Python, R, or equivalent a plus
Experience with visualization and BI tools
Experience with data warehouse systems and ability to install and operate
Familiarity with machine learning and AI
Good understanding of business fundamentals
Ability to thrive in an entrepreneurial environment and comfortable managing multiple work streams and projects concurrently
Self-starter with excellent oral communication skills
Demonstrated experience working as a productive member of a team
Experience in eCommerce a plus

 

Requirements

Bachelor's degree in Computer Science, Statistics, Engineering, Business, or related discipline
3+ years of relevant experience in a business analyst, data analyst, or statistical analysis role
2+ years of experience analyzing datasets to solve business problems

 

Benefits:

A competitive base salary
Bonus eligibility based on individual and team performance
A premium suite of benefits including comprehensive medical, dental and vision
Generous paid time off
Ability to work remote

 

At Bertram Capital we value and celebrate the many perspectives that arise from a variety of cultures, genders, religions, national origins, ages, abilities, socioeconomic status and sexual orientation. Our commitment to Diversity, Equity and Inclusion (DEI) ensures that Bertram is a place that attracts, grows, and promotes top talent from all backgrounds.

Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>Firm Overview&nbsp;</strong></p><p>Bertram Capital is a private equity firm targeting investments in lower middle market companies. Since its inception in 2006, the firm has raised over $1.7B of capital commitments. Bertram has distinguished itself in the private equity community by combining venture capital operating methodologies with private equity financial discipline to&nbsp;empower its portfolio companies to unlock their full business potential. This approach is unique in that Bertram is not singularly focused on achieving its investment returns through financial engineering and the extraction of near-term cash flow. Instead, Bertram focuses on reinvestment and technology enablement to drive growth&nbsp;and value through digital marketing, e-commerce, big data and analytics, application development and internal and external platform optimization.</p><p>Visit www.bcap.com for more information.</p><p>&nbsp;</p><p><strong>Position Description</strong></p><p>Bertram Capital is seeking a Business Intelligence Analyst / Data Scientist to join the firm’s Bertram Labs team in its San Francisco Bay Area headquarters or Remote.</p><p>Role:</p><ul><li>Work with portfolio companies to develop and implement data-driven strategies</li><li>Evaluate, recommend, and implement data software and systems&nbsp;</li><li>Setup data warehouses and work with ETL pipelines and APIs</li><li>Create KPIs, visualize data, and make available to stakeholders</li><li>Generate insights that solve business problems to fuel growth</li><li>Analyze large datasets to help guide new investments</li></ul><p><br></p><p>This role is a combination of consulting, strategy, and implementation. Bertram Labs is an integral part of the Bertram strategy, and team members work across a mix of opportunities for existing portfolio companies and new investments. We hire personable, intelligent, self-starters who exhibit professionalism and exceptional analytical, organizational and communication skills.</p><p>&nbsp;</p><p><strong>You</strong></p><ul><li>Deep understanding of data analytics and statistics</li><li>Strong SQL skills</li><li>Python, R, or equivalent a plus</li><li>Experience with visualization and BI tools</li><li>Experience with data warehouse systems and ability to install and operate</li><li>Familiarity with machine learning and AI</li><li>Good understanding of business fundamentals</li><li>Ability to thrive in an entrepreneurial environment and comfortable managing multiple work streams and projects concurrently</li><li>Self-starter with excellent oral communication skills</li><li>Demonstrated experience working as a productive member of a team</li><li>Experience in eCommerce a plus</li></ul><p>&nbsp;</p><p><strong>Requirements</strong></p><ul><li>Bachelor's degree in Computer Science, Statistics, Engineering, Business, or related discipline</li><li>3+ years of relevant experience in a business analyst, data analyst, or statistical analysis role</li><li>2+ years of experience analyzing datasets to solve business problems</li></ul><p>&nbsp;</p><p><strong>Benefits:</strong></p><ul><li>A competitive base salary</li><li>Bonus eligibility based on individual and team performance</li><li>A premium suite of benefits including comprehensive medical, dental and vision</li><li>Generous paid time off</li><li>Ability to work remote</li></ul><p>&nbsp;</p><p>At Bertram Capital we value and celebrate the many perspectives that arise from a variety of cultures, genders, religions, national origins, ages, abilities, socioeconomic status and sexual orientation. Our commitment to Diversity, Equity and Inclusion (DEI) ensures that Bertram is a place that attracts, grows, and promotes top talent from all backgrounds.</p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Investment Management
Data Engineer,"New York, New York, United States",EnergyHub,2021-02-12,https://www.linkedin.com/jobs/view/data-engineer-at-energyhub-2421719421?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=qJCPeuYqbZc52nmYY9lTSg%3D%3D&position=20&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"

Software Engineer, Data Engineering

We ingest thousands of data events per second from over a dozen different device companies (and growing!). This data helps us support the electric grid by providing optimized device control and precise reporting.

Since device data is core to our business, we're looking for an engineer to focus on data engineering and make sure the device data we get is accurate, reliable, and timely. The team owns the entire pipeline from ingestion through to publishing data products, so you will also do some full-stack development work.

Responsibilities

Improve reliability, recovery, and integrity of our data ingestion pipeline
Develop reporting tools to help our in-house experts and utility clients understand the impact of our services
Work with our in-house Advanced Grid Services/Analytics team to productionize exciting new services for utilities



Requirements

Experience developing automated ETL pipelines with high reliability requirements
At least 2 of years of experience working on a professional web development team
Demonstrated expertise with at least one RDBMS
Demonstrated expertise with MongoDB, DynamoDB or similar document-oriented data store


Nice-to-have experience

Dealing with streaming ingestion
Improving reliability of ETL pipelines
Improving data recovery processes
Improving tooling for data correctness
Python or Java experience


Why work for EnergyHub?

Collaborate with outstanding people: Our employees work hard, do great work, and enjoy collaborating and learning from each other.
Make an immediate impact: New employees can expect to be given real responsibility for bringing new technologies to the marketplace. You are empowered to perform as soon as you join the team!
Gain well rounded experience: EnergyHub offers a diverse and dynamic environment where you will get the chance to work directly with executives and develop expertise across multiple areas of the business.
Work with the latest technologies: You'll gain exposure to a broad spectrum of IoT, SaaS and machine learning challenges, including distributed fault-tolerance, device control optimization, and process modeling to support scalable interaction with disparate downstream APIs.
Be part of something important: Help create the future of how energy is produced and consumed. Make a positive impact on our climate.
Focus on fun: EnergyHub places high value on our team culture. Happy hours and holiday parties are important to us, but what's also important is how our employees feel every single day.


Company Information

EnergyHub is a growing enterprise software company that works with the most forward-thinking companies in smart energy. Our platform lets consumers turn their smart thermostats, electric cars, water heaters, and other products into virtual power plants that keep the grid stable and enable higher penetration of solar and wind power. We work on technology that already provides energy and cost savings to millions of people through partnerships with the leading companies in the Internet of Things.

Company Benefits

EnergyHub offers a generous benefits package including 100% paid medical for employees and a 401(k) with employer match. We offer a casual environment, the flexibility to set your own schedule, a fully stocked fridge and pantry, free Citi Bike membership, secure bike rack, gym subsidy, paid parental leave, and an education assistance program.

EnergyHub is an Equal Opportunity Employer

In connection with your application, we collect information that identifies, reasonably relates to or describes you (""Personal Information""). The categories of Personal Information that we may collect include your name, government-issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or future positions, recordkeeping in relation to recruiting and hiring, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><li><br><br>Software Engineer, Data Engineering<br><br>We ingest thousands of data events per second from over a dozen different device companies (and growing!). This data helps us support the electric grid by providing optimized device control and precise reporting.<br><br>Since device data is core to our business, we're looking for an engineer to focus on data engineering and make sure the device data we get is accurate, reliable, and timely. The team owns the entire pipeline from ingestion through to publishing data products, so you will also do some full-stack development work.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Improve reliability, recovery, and integrity of our data ingestion pipeline</li> <li>Develop reporting tools to help our in-house experts and utility clients understand the impact of our services</li> <li>Work with our in-house Advanced Grid Services/Analytics team to productionize exciting new services for utilities</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Experience developing automated ETL pipelines with high reliability requirements</li> <li>At least 2 of years of experience working on a professional web development team</li> <li>Demonstrated expertise with at least one RDBMS</li> <li>Demonstrated expertise with MongoDB, DynamoDB or similar document-oriented data store</li> <br></ul>Nice-to-have experience<br><ul> <li>Dealing with streaming ingestion</li> <li>Improving reliability of ETL pipelines</li> <li>Improving data recovery processes</li> <li>Improving tooling for data correctness</li> <li>Python or Java experience</li> <br></ul><strong>Why work for EnergyHub?<br></strong><ul> <li><strong>Collaborate with outstanding people</strong>: Our employees work hard, do great work, and enjoy collaborating and learning from each other. </li> <li><strong>Make an immediate impact</strong>: New employees can expect to be given real responsibility for bringing new technologies to the marketplace. You are empowered to perform as soon as you join the team!</li> <li><strong>Gain well rounded experience</strong>: EnergyHub offers a diverse and dynamic environment where you will get the chance to work directly with executives and develop expertise across multiple areas of the business.</li> <li><strong>Work with the latest technologies</strong>: You'll gain exposure to a broad spectrum of IoT, SaaS and machine learning challenges, including distributed fault-tolerance, device control optimization, and process modeling to support scalable interaction with disparate downstream APIs. </li> <li><strong>Be part of something important:</strong> Help create the future of how energy is produced and consumed. Make a positive impact on our climate.</li> <li><strong>Focus on fun</strong>: EnergyHub places high value on our team culture. Happy hours and holiday parties are important to us, but what's also important is how our employees feel every single day. </li> <br></ul>Company Information<br><br>EnergyHub is a growing enterprise software company that works with the most forward-thinking companies in smart energy. Our platform lets consumers turn their smart thermostats, electric cars, water heaters, and other products into virtual power plants that keep the grid stable and enable higher penetration of solar and wind power. We work on technology that already provides energy and cost savings to millions of people through partnerships with the leading companies in the Internet of Things.<br><br><strong><u>Company Benefits<br><br></u></strong>EnergyHub offers a generous benefits package including 100% paid medical for employees and a 401(k) with employer match. We offer a casual environment, the flexibility to set your own schedule, a fully stocked fridge and pantry, free Citi Bike membership, secure bike rack, gym subsidy, paid parental leave, and an education assistance program.<br><br>EnergyHub is an Equal Opportunity Employer<br><br>In connection with your application, we collect information that identifies, reasonably relates to or describes you (""Personal Information""). The categories of Personal Information that we may collect include your name, government-issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or future positions, recordkeeping in relation to recruiting and hiring, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies.</li></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist - QuantumBlack,"Boston, Massachusetts, United States",QuantumBlack,2021-02-02,https://www.linkedin.com/jobs/view/data-scientist-quantumblack-at-quantumblack-2384558216?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=FTXtJlDUsuYhL2%2F5iJ0g4g%3D%3D&position=21&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"

Software Engineer, Data Engineering

We ingest thousands of data events per second from over a dozen different device companies (and growing!). This data helps us support the electric grid by providing optimized device control and precise reporting.

Since device data is core to our business, we're looking for an engineer to focus on data engineering and make sure the device data we get is accurate, reliable, and timely. The team owns the entire pipeline from ingestion through to publishing data products, so you will also do some full-stack development work.

Responsibilities

Improve reliability, recovery, and integrity of our data ingestion pipeline
Develop reporting tools to help our in-house experts and utility clients understand the impact of our services
Work with our in-house Advanced Grid Services/Analytics team to productionize exciting new services for utilities



Requirements

Experience developing automated ETL pipelines with high reliability requirements
At least 2 of years of experience working on a professional web development team
Demonstrated expertise with at least one RDBMS
Demonstrated expertise with MongoDB, DynamoDB or similar document-oriented data store


Nice-to-have experience

Dealing with streaming ingestion
Improving reliability of ETL pipelines
Improving data recovery processes
Improving tooling for data correctness
Python or Java experience


Why work for EnergyHub?

Collaborate with outstanding people: Our employees work hard, do great work, and enjoy collaborating and learning from each other.
Make an immediate impact: New employees can expect to be given real responsibility for bringing new technologies to the marketplace. You are empowered to perform as soon as you join the team!
Gain well rounded experience: EnergyHub offers a diverse and dynamic environment where you will get the chance to work directly with executives and develop expertise across multiple areas of the business.
Work with the latest technologies: You'll gain exposure to a broad spectrum of IoT, SaaS and machine learning challenges, including distributed fault-tolerance, device control optimization, and process modeling to support scalable interaction with disparate downstream APIs.
Be part of something important: Help create the future of how energy is produced and consumed. Make a positive impact on our climate.
Focus on fun: EnergyHub places high value on our team culture. Happy hours and holiday parties are important to us, but what's also important is how our employees feel every single day.


Company Information

EnergyHub is a growing enterprise software company that works with the most forward-thinking companies in smart energy. Our platform lets consumers turn their smart thermostats, electric cars, water heaters, and other products into virtual power plants that keep the grid stable and enable higher penetration of solar and wind power. We work on technology that already provides energy and cost savings to millions of people through partnerships with the leading companies in the Internet of Things.

Company Benefits

EnergyHub offers a generous benefits package including 100% paid medical for employees and a 401(k) with employer match. We offer a casual environment, the flexibility to set your own schedule, a fully stocked fridge and pantry, free Citi Bike membership, secure bike rack, gym subsidy, paid parental leave, and an education assistance program.

EnergyHub is an Equal Opportunity Employer

In connection with your application, we collect information that identifies, reasonably relates to or describes you (""Personal Information""). The categories of Personal Information that we may collect include your name, government-issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or future positions, recordkeeping in relation to recruiting and hiring, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><li><br><br>Software Engineer, Data Engineering<br><br>We ingest thousands of data events per second from over a dozen different device companies (and growing!). This data helps us support the electric grid by providing optimized device control and precise reporting.<br><br>Since device data is core to our business, we're looking for an engineer to focus on data engineering and make sure the device data we get is accurate, reliable, and timely. The team owns the entire pipeline from ingestion through to publishing data products, so you will also do some full-stack development work.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Improve reliability, recovery, and integrity of our data ingestion pipeline</li> <li>Develop reporting tools to help our in-house experts and utility clients understand the impact of our services</li> <li>Work with our in-house Advanced Grid Services/Analytics team to productionize exciting new services for utilities</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Experience developing automated ETL pipelines with high reliability requirements</li> <li>At least 2 of years of experience working on a professional web development team</li> <li>Demonstrated expertise with at least one RDBMS</li> <li>Demonstrated expertise with MongoDB, DynamoDB or similar document-oriented data store</li> <br></ul>Nice-to-have experience<br><ul> <li>Dealing with streaming ingestion</li> <li>Improving reliability of ETL pipelines</li> <li>Improving data recovery processes</li> <li>Improving tooling for data correctness</li> <li>Python or Java experience</li> <br></ul><strong>Why work for EnergyHub?<br></strong><ul> <li><strong>Collaborate with outstanding people</strong>: Our employees work hard, do great work, and enjoy collaborating and learning from each other. </li> <li><strong>Make an immediate impact</strong>: New employees can expect to be given real responsibility for bringing new technologies to the marketplace. You are empowered to perform as soon as you join the team!</li> <li><strong>Gain well rounded experience</strong>: EnergyHub offers a diverse and dynamic environment where you will get the chance to work directly with executives and develop expertise across multiple areas of the business.</li> <li><strong>Work with the latest technologies</strong>: You'll gain exposure to a broad spectrum of IoT, SaaS and machine learning challenges, including distributed fault-tolerance, device control optimization, and process modeling to support scalable interaction with disparate downstream APIs. </li> <li><strong>Be part of something important:</strong> Help create the future of how energy is produced and consumed. Make a positive impact on our climate.</li> <li><strong>Focus on fun</strong>: EnergyHub places high value on our team culture. Happy hours and holiday parties are important to us, but what's also important is how our employees feel every single day. </li> <br></ul>Company Information<br><br>EnergyHub is a growing enterprise software company that works with the most forward-thinking companies in smart energy. Our platform lets consumers turn their smart thermostats, electric cars, water heaters, and other products into virtual power plants that keep the grid stable and enable higher penetration of solar and wind power. We work on technology that already provides energy and cost savings to millions of people through partnerships with the leading companies in the Internet of Things.<br><br><strong><u>Company Benefits<br><br></u></strong>EnergyHub offers a generous benefits package including 100% paid medical for employees and a 401(k) with employer match. We offer a casual environment, the flexibility to set your own schedule, a fully stocked fridge and pantry, free Citi Bike membership, secure bike rack, gym subsidy, paid parental leave, and an education assistance program.<br><br>EnergyHub is an Equal Opportunity Employer<br><br>In connection with your application, we collect information that identifies, reasonably relates to or describes you (""Personal Information""). The categories of Personal Information that we may collect include your name, government-issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or future positions, recordkeeping in relation to recruiting and hiring, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies.</li></strong></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Philadelphia, Pennsylvania, United States",Penn Interactive,2021-02-07,https://www.linkedin.com/jobs/view/data-engineer-at-penn-interactive-2371873249?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=szbEdFbiBSCYUnSKE%2B5MOw%3D%3D&position=22&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Apply Now

Qualifications

MSc or PhD level in the field of computer science, machine learning, applied statistics or mathematics
Experience in statistical modelling and machine learning techniques
Programming experience in at least two of the following languages R, Python, Scala, SQL
Experience in applying data science methods to business problems
Experience in applying advanced analytical and statistical methods in the commercial world
Good presentation and communication skills with the ability to explain complex analytical concepts to people from other fields


Who You'll Work With
You will be based in our Boston office as part of QuantumBlack.

You will work with other data scientists, data engineers, machine learning engineers, designers and project managers on interdisciplinary projects using maths, stats and machine learning to derive structure and knowledge from raw data across various industry sectors.

Who You Are

You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.

What You'll Do
You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.

You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.

Role Responsibilities

Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems
Develop data science products and solutions for clients as well as for our data science team
Write highly optimized code to advance our internal Data Science Toolbox
Work in a multi-disciplinary environment with specialists in machine learning, engineering and design
Add real-world impact to your academic expertise, as you are encouraged to write ‘black’ papers and present at meetings and conferences should you wish
Attend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.


What You’ll Learn

How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines
Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations
Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.
Best practices in software development and productionize machine learning by working with our Machine Learning Engineering teams which optimize code for model development and scale it
Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualizations
Using new technologies and problem-solving skills in a multicultural and creative environment

You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.

Real-World Impact– No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programs at all levels.
Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity– With colleagues from over 40 nationalities, we recognize the benefits of working with people from all walks of life.

Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimizing a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture

Healthcare Efficiency– We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact– We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development– We worked with the CEO of an elite automotive organization to reduce the 18-month car development timeframe by improving processes, designs and team structures.

Visit our Careers siteto watch our video and read about our interview processes and benefits.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Apply Now<br><br><strong><u>Qualifications<br></u></strong><ul><li>MSc or PhD level in the field of computer science, machine learning, applied statistics or mathematics</li><li>Experience in statistical modelling and machine learning techniques</li><li>Programming experience in at least two of the following languages R, Python, Scala, SQL</li><li>Experience in applying data science methods to business problems</li><li>Experience in applying advanced analytical and statistical methods in the commercial world</li><li>Good presentation and communication skills with the ability to explain complex analytical concepts to people from other fields<br><br></li></ul><strong><u>Who You'll Work With<br></u></strong>You will be based in our Boston office as part of QuantumBlack.<br><br>You will work with other data scientists, data engineers, machine learning engineers, designers and project managers on interdisciplinary projects using maths, stats and machine learning to derive structure and knowledge from raw data across various industry sectors.<br><br><strong><u>Who You Are<br><br></u></strong>You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.<br><br><strong><u>What You'll Do<br></u></strong>You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.<br><br>You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.<br><br><strong><u>Role Responsibilities<br></u></strong><ul><li>Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems</li><li>Develop data science products and solutions for clients as well as for our data science team</li><li>Write highly optimized code to advance our internal Data Science Toolbox</li><li>Work in a multi-disciplinary environment with specialists in machine learning, engineering and design</li><li>Add real-world impact to your academic expertise, as you are encouraged to write ‘black’ papers and present at meetings and conferences should you wish</li><li>Attend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.<br><br></li></ul><strong><u>What You’ll Learn<br></u></strong><ul><li>How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines</li><li>Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations</li><li>Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.</li><li>Best practices in software development and productionize machine learning by working with our Machine Learning Engineering teams which optimize code for model development and scale it</li><li>Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualizations</li><li>Using new technologies and problem-solving skills in a multicultural and creative environment<br></li></ul>You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.<br><ul><li><strong>Real-World Impact</strong>– No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.</li><li><strong>Fusing Tech &amp; Leadership</strong>– We work with the latest technologies and methodologies and offer first class learning programs at all levels.</li><li><strong>Multidisciplinary Teamwork</strong>- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.</li><li><strong>Innovative Work Culture</strong>– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.</li><li><strong>Striving for Diversity</strong>– With colleagues from over 40 nationalities, we recognize the benefits of working with people from all walks of life.<br></li></ul>Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimizing a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture<br><ul><li><strong>Healthcare Efficiency</strong>– We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.</li><li><strong>Environmental Impact</strong>– We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.</li><li><strong>Product Development</strong>– We worked with the CEO of an elite automotive organization to reduce the 18-month car development timeframe by improving processes, designs and team structures.<br></li></ul>Visit our Careers siteto watch our video and read about our interview processes and benefits.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Consulting,Full-time,"Computer Software, Information Technology and Services, Management Consulting"
Python Software Engineer,"McLean, Virginia, United States",General Dynamics Information Technology,2021-02-02,https://www.linkedin.com/jobs/view/python-software-engineer-at-general-dynamics-information-technology-2412195511?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=RVsSO4sxgSRIwJdIpOxfPg%3D%3D&position=23&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"Penn Interactive (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Data Engineer to join our expanding Sportsbook team!

The Data Engineer works closely with the Director of Engineering in a small, cross-functional team to develop a one-of-a-kind, native sports betting experience. Successful candidates for this role will leverage data from the largest casino chain in the United States to assist in tasks such as affinity, personalization, bonusing, promotions, etc. Previous work in the gaming industry is not important but we do expect you to take the lead in developing a data warehouse and pipeline to enable novel and rewarding data discoveries.

Your Daily Responsibilities Include

Design, develop and deploy a big data stack and data processing infrastructure platform
Architect and rearchitect multi-tenant databases to meet the needs of our customer base
Improve data validation and data quality monitoring
Work with client and backend teams to guide events driven designs
Optimize and tune the databases to improve performance and reduce cost
Write and maintain terraform to enable data engineering and science teams to safely deploy tools and services


To be successful in this position it will require the following skill set

3+ years of experience building large scale, robust data processing pipeline
Experience with Python development, with a focus data transformations and data streams
Strong background with building and maintaining automation
Advanced experience with data streaming, ingest, ETL and data warehousing technologies
Strong experience in database schema design, data governance and data modeling
Experience with Spark, Beam, Redshift, Tableau, MySQL, etc.
Experience with AWS, GCP, and/or Azure cloud
Good understanding of data security and encryption
Ability to work effectively as part of a small team, with strong interpersonal and communication skills

BONUS POINTS

Experience with tools like Airflow, Dagster or DBT
A passion for sports or betting


Something to leave you with

Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Penn Interactive (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Data Engineer to join our expanding Sportsbook team!<br><br>The Data Engineer works closely with the Director of Engineering in a small, cross-functional team to develop a one-of-a-kind, native sports betting experience. Successful candidates for this role will leverage data from the largest casino chain in the United States to assist in tasks such as affinity, personalization, bonusing, promotions, etc. Previous work in the gaming industry is not important but we do expect you to take the lead in developing a data warehouse and pipeline to enable novel and rewarding data discoveries.<br><br><strong><u>Your Daily Responsibilities Include<br></u></strong><ul><li> Design, develop and deploy a big data stack and data processing infrastructure platform </li><li> Architect and rearchitect multi-tenant databases to meet the needs of our customer base </li><li> Improve data validation and data quality monitoring </li><li> Work with client and backend teams to guide events driven designs </li><li> Optimize and tune the databases to improve performance and reduce cost </li><li> Write and maintain terraform to enable data engineering and science teams to safely deploy tools and services <br><br></li></ul><strong> To be successful in this position it will require the following skill set <br></strong><ul><li> 3+ years of experience building large scale, robust data processing pipeline </li><li> Experience with Python development, with a focus data transformations and data streams </li><li> Strong background with building and maintaining automation </li><li> Advanced experience with data streaming, ingest, ETL and data warehousing technologies </li><li> Strong experience in database schema design, data governance and data modeling </li><li> Experience with Spark, Beam, Redshift, Tableau, MySQL, etc. </li><li> Experience with AWS, GCP, and/or Azure cloud </li><li> Good understanding of data security and encryption </li><li> Ability to work effectively as part of a small team, with strong interpersonal and communication skills <br></li></ul><strong> BONUS POINTS <br></strong><ul><li> Experience with tools like Airflow, Dagster or DBT </li><li> A passion for sports or betting <br><br></li></ul><strong> Something to leave you with <br><br></strong>Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,Gambling & Casinos
Data Scientist,"Cincinnati, Ohio, United States",The E.W. Scripps Company,2021-02-12,https://www.linkedin.com/jobs/view/data-scientist-at-the-e-w-scripps-company-2407651543?refId=488d3200-3163-4524-a3d9-4c892a41d6f7&trackingId=HJx%2F6S%2FzRLVjPqdi%2FUmmlQ%3D%3D&position=25&pageNum=12&trk=public_jobs_job-result-card_result-card_full-click,"E.W. Scripps is a company rich in media history focused on the future. We are one of the nation's largest independent TV station owners with 60 stations nationwide, and we are working to stay ahead of the ways in which people use technology to find news and information. Our commitment to the future means that discovery is commonplace, the status quo is challenged, iteration and collaboration are the norm and new ideas are welcome. Join a team of top performers and help shape the future of the most strategic and well positioned media company – E. W. Scripps. This position will be located in Cincinnati, OH or Washington, DC.

At Scripps, you’ll:


Have a complete modern data science/analytics software stack at your disposal.
Enjoy a broad scope of responsibility – with projects and questions from every part of the business and new businesses under consideration.
Know that your work will have an impact on key strategic decisions – changing and shaping the way we do business. This is why we are so selective in our hiring process.
Grow your talent with constant learning – with substantial investments in on-site and hands-on training and eLearning formats used to fill in the gaps.
Work on projects that are important and interesting to you – with focus on modern media and marketing strategies
Expand your horizons by attending and giving talks at conferences and professional networking opportunities with senior analytics professionals.
Become a leading expert in applied data science for media.

We are looking for someone who knows how to use the latest data analytics tools, will thrive in our fast-paced innovative environment, will deliver results and has the following experience and credentials.

Primary purpose:

The Data Scientist blends the skills of a business thinker with those of a data analyst: asking questions, turning data into knowledge, forming conclusions, and making recommendations that enable the company to innovate, differentiate itself from its competitors, work smarter, make better decisions, and enhance profitability. This individual will partner with the analytics team, analytics products and services director, business leaders and end users to be a change agent - teasing out the questions that are important to our business, and then use statistical analysis and data mining techniques to inform the answers and communicate conclusions both visually and in writing, along with recommendations and next steps. The Data Scientist will also participate in the creation and measurement of new business processes, tools, and products.

Key responsibilities:


Influence the course of the business as a trusted advisor to business leaders, users and clients, using data and analytics as a basis for better, more informed decision making

Creation of analytics and measurement roadmaps
Identify impactful choices or courses of action that drive value for the organization
Evaluate the big picture and solve business problems in addition to focusing on metrics
Influence the direction of the business by effectively communicating conclusions to cross-functional groups
Create automation applications to replace tasks for critical revenue generating teams decreasing time dedicated to non-revenue generating
Mine large amounts of data and perform data analysis to extract useful business insights for a wide range of topics including product development and performance, market dynamics, consumer and audience knowledge, internal operations, and external research

Initial study design, acquisition of data, prototyping and production roll out
Ongoing tracking, monitoring, and periodic follow-up studies
Support the design and implement of reporting dashboards that track key business metrics and provide actionable insights
Use software and other tools to develop analyses that identify patterns, influences, correlations, relationships, predictive factors, risk factors, and that provide better situational awareness

Creation of models, simulations, and optimization routines
Develop of data flows and acquisition strategies to facilitate the capture and sharing of data and analytics within the organization
Support the development of Scripps analytics products and services by providing input into product roadmaps
Be a positive force to cultivate a culture that is passionate about developing analytics as a business competency

Drive accountability for value recognition and business results
Create and contribute to a quality work environment that motivates team members to perform at their highest levels and positively affects employee and business partner relationships
Be a publicly visible presence, including creating communications and leading training sessions, advocating for the benefits of analytics in Scripps and the products/services of the analytics team

Education / work experience:


Bachelor's required, Masters preferred. Applied statistics, Computer Science, business analytics or a related field.
Minimum 3 years, 5+ years preferred, experience in solving analytical problems using quantitative approaches apply to this requirement.
Experience and demonstrated success presenting complex analyses and final recommendations to business leaders and external clients.

Statistical method experience:


Analysis techniques such as marketing mix modeling, scenario modeling, pattern detection, A/B testing, nearest neighbor, cluster analysis, sentiment analysis, decision trees, optimization, simulation, regression analysis, agent-based modeling, ensemble models, collaborative filtering and other types of analysis

Software Proficiency:


Python, RapidMiner, R
Database skills (Snowflake, MySQL) experience preferred
Tableau

About Scripps:

The E.W. Scripps Company (NASDAQ: SSP) advances understanding of the world through journalism. As the nation’s fourth-largest independent TV station owner, Scripps operates 60 television stations in 42 markets. Scripps empowers the next generation of news consumers with its multiplatform news network Newsy and reaches growing audiences through broadcast networks including Bounce and Court TV. Scripps runs an award-winning investigative reporting newsroom in Washington, D.C., and is the longtime steward of the Scripps National Spelling Bee. Founded in 1878, Scripps has held for decades to the motto, “Give light and the people will find their own way.”

As an equal employment opportunity employer, The E.W. Scripps Company and its affiliates do not discriminate in its employment decisions on the basis on race, sex, sexual orientation, gender, color, religion, age, genetic information, medical condition, disability, marital status, citizenship or national origin, and military membership or veteran status, or on any other basis which would be in violation of any applicable federal, state or local law. Furthermore, the company will make reasonable accommodations for qualified individuals with known disabilities unless doing so would result in an undue hardship for the company.

If interested, please apply at www.scripps.com/careers .

#GD-CH1


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">E.W. Scripps is a company rich in media history focused on the future. We are one of the nation's largest independent TV station owners with 60 stations nationwide, and we are working to stay ahead of the ways in which people use technology to find news and information. Our commitment to the future means that discovery is commonplace, the status quo is challenged, iteration and collaboration are the norm and new ideas are welcome. Join a team of top performers and help shape the future of the most strategic and well positioned media company – E. W. Scripps. This position will be located in Cincinnati, OH or Washington, DC.<br><br>At Scripps, you’ll:<br><br><ul><li>Have a complete modern data science/analytics software stack at your disposal.</li><li>Enjoy a broad scope of responsibility – with projects and questions from <em>every</em> part of the business and new businesses under consideration.</li><li>Know that your work will have an impact on key strategic decisions – changing and shaping the way we do business. This is why we are so selective in our hiring process.</li><li>Grow your talent with constant learning – with substantial investments in on-site and hands-on training and eLearning formats used to fill in the gaps.</li><li>Work on projects <em>that are important and interesting to you</em> – with focus on modern media and marketing strategies</li><li>Expand your horizons by attending and giving talks at conferences and professional networking opportunities with senior analytics professionals.</li><li>Become a leading expert in applied data science for media.<br></li></ul>We are looking for someone who knows how to use the latest data analytics tools, will thrive in our fast-paced innovative environment, will deliver results and has the following experience and credentials.<br><br><strong>Primary purpose:<br><br></strong>The Data Scientist blends the skills of a business thinker with those of a data analyst: asking questions, turning data into knowledge, forming conclusions, and making recommendations that enable the company to innovate, differentiate itself from its competitors, work smarter, make better decisions, and enhance profitability. This individual will partner with the analytics team, analytics products and services director, business leaders and end users to be a change agent - teasing out the questions that are important to our business, and then use statistical analysis and data mining techniques to inform the answers and communicate conclusions both visually and in writing, along with recommendations and next steps. The Data Scientist will also participate in the creation and measurement of new business processes, tools, and products.<br><br><strong>Key responsibilities: <br><br></strong><ul><li>Influence the course of the business as a trusted advisor to business leaders, users and clients, using data and analytics as a basis for better, more informed decision making<br><ul><li>Creation of analytics and measurement roadmaps</li><li>Identify impactful choices or courses of action that drive value for the organization</li><li>Evaluate the big picture and solve business problems in addition to focusing on metrics</li><li>Influence the direction of the business by effectively communicating conclusions to cross-functional groups</li></ul></li><li>Create automation applications to replace tasks for critical revenue generating teams decreasing time dedicated to non-revenue generating</li><li>Mine large amounts of data and perform data analysis to extract useful business insights for a wide range of topics including product development and performance, market dynamics, consumer and audience knowledge, internal operations, and external research<br><ul><li>Initial study design, acquisition of data, prototyping and production roll out</li><li>Ongoing tracking, monitoring, and periodic follow-up studies</li><li>Support the design and implement of reporting dashboards that track key business metrics and provide actionable insights</li></ul></li><li>Use software and other tools to develop analyses that identify patterns, influences, correlations, relationships, predictive factors, risk factors, and that provide better situational awareness<br><ul><li>Creation of models, simulations, and optimization routines</li><li>Develop of data flows and acquisition strategies to facilitate the capture and sharing of data and analytics within the organization</li></ul></li><li>Support the development of Scripps analytics products and services by providing input into product roadmaps</li><li>Be a positive force to cultivate a culture that is passionate about developing analytics as a business competency<br><ul><li>Drive accountability for value recognition and business results</li><li>Create and contribute to a quality work environment that motivates team members to perform at their highest levels and positively affects employee and business partner relationships</li><li>Be a publicly visible presence, including creating communications and leading training sessions, advocating for the benefits of analytics in Scripps and the products/services of the analytics team <br></li></ul></li></ul><strong>Education / work experience: <br><br></strong><ul><li>Bachelor's required, Masters preferred. Applied statistics, Computer Science, business analytics or a related field.</li><li>Minimum 3 years, 5+ years preferred, experience in solving analytical problems using quantitative approaches apply to this requirement.</li><li>Experience and demonstrated success presenting complex analyses and final recommendations to business leaders and external clients.<br></li></ul><strong>Statistical method experience: <br><br></strong><ul><li>Analysis techniques such as marketing mix modeling, scenario modeling, pattern detection, A/B testing, nearest neighbor, cluster analysis, sentiment analysis, decision trees, optimization, simulation, regression analysis, agent-based modeling, ensemble models, collaborative filtering and other types of analysis<br></li></ul><strong>Software Proficiency: <br><br></strong><ul><li>Python, RapidMiner, R</li><li>Database skills (Snowflake, MySQL) experience preferred</li><li>Tableau<br></li></ul><strong>About Scripps:<br><br></strong>The E.W. Scripps Company (NASDAQ: SSP) advances understanding of the world through journalism. As the nation’s fourth-largest independent TV station owner, Scripps operates 60 television stations in 42 markets. Scripps empowers the next generation of news consumers with its multiplatform news network Newsy and reaches growing audiences through broadcast networks including Bounce and Court TV. Scripps runs an award-winning investigative reporting newsroom in Washington, D.C., and is the longtime steward of the Scripps National Spelling Bee. Founded in 1878, Scripps has held for decades to the motto, “Give light and the people will find their own way.”<br><br>As an equal employment opportunity employer, The E.W. Scripps Company and its affiliates do not discriminate in its employment decisions on the basis on race, sex, sexual orientation, gender, color, religion, age, genetic information, medical condition, disability, marital status, citizenship or national origin, and military membership or veteran status, or on any other basis which would be in violation of any applicable federal, state or local law. Furthermore, the company will make reasonable accommodations for qualified individuals with known disabilities unless doing so would result in an undue hardship for the company.<br><br>If interested, please apply at www.scripps.com/careers .<br><br>#GD-CH1<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Marketing and Advertising, Online Media, Broadcast Media"
Data Engineer,"Camden, New Jersey, United States",NFI,2021-02-13,https://www.linkedin.com/jobs/view/data-engineer-at-nfi-2422580713?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=dFGRZxkZRSv%2BxCAsU7Uyqw%3D%3D&position=1&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"The NFI Data and Analytics group is looking for a Data Engineer based in the Camden New Jersey headquarters to join our growing team to complement the current multitude and wide variety of team skills to support NFI’s needs for data driven analytics. Guided by NFI’s shared values, we work in an environment where collaboration, teamwork, respect, and openness are highly valued.

Essential Duties & Responsibilities

Data modeling and dimensional schema design
Design and develop data ingestion, pipeline, processing, and transformation frameworks to automate high-volume, and real-time data delivery
Build the data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Create, enhance, and optimize data visualizations
Identify, design, and implement internal process improvements to automate manual processes, and optimize data delivery
Build processes to support data transformation, data structures, metadata, dependency and workload management.
Define and maintain target data architectures and master data management strategies
Collaborate with various Business, Operations, Applications and Analytics teams to ensure adherence to enterprise data standards and data architecture principles
Monitor compliance of development work against established standards and principles and work to resolve discrepancies and issues
Optimizing high-performing SQL for efficient data transformation
Production release and operation of data services



Requirements

Bachelor’s degree in Computer Science, Engineering, or related field
4+ years of experience building data pipelines and using ETL tools
2+ years of experience leading data Engineering efforts
2+ years of experience creating data visualizations
Knowledge of data management, data integration and database development technologies and processes
Up-to-date specialized knowledge of data wrangling, manipulation and management
Demonstrated mastery in one or more SQL variants: T-SQL or PL/SQL
In-depth knowledge of Microsoft SQL Server or Oracle
Demonstrated mastery in database concepts and large-scale database implementations and design
Excellent analytic and troubleshooting skills
Proficiency with data profiling and data migration
Knowledge of real-time data acquisition and/or automation/controls
Working knowledge of application development and data modeling to support implementation and development of analytics
Demonstrated success in technical proficiency, creativity, collaboration, and independent thought
Experience in migrating ETL processes (not just data) from relational databases to cloud based solutions
Strong interpersonal skills to resolve issues in a professional manner, lead working groups, negotiate and create consensus
Experience architecting and implementing data solutions, and working with unstructured datasets in a cloud environment, a plus
Java / R/ Python, Data science/machine learning, a plus
Warehousing or Transportation Logistics experience, a plus



To all agencies: Please, no phone calls or emails to any employee of NFI about this opening. All resumes submitted by search firms/employment agencies to any employee at NFI via-email, the internet or in any form and/or method will be deemed the sole property of NFI, unless such search firms/employment agencies were engaged by NFI for this position and a valid agreement with NFI is in place. In the event a candidate who was submitted outside of the NFI agency engagement process is hired, no fee or payment of any kind will be paid.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The NFI Data and Analytics group is looking for a <strong>Data Engineer</strong> based in the Camden New Jersey headquarters to join our growing team to complement the current multitude and wide variety of team skills to support NFI’s needs for data driven analytics. Guided by NFI’s shared values, we work in an environment where collaboration, teamwork, respect, and openness are highly valued.<br><br><strong><u>Essential Duties &amp; Responsibilities<br></u></strong><ul> <li>Data modeling and dimensional schema design</li> <li>Design and develop data ingestion, pipeline, processing, and transformation frameworks to automate high-volume, and real-time data delivery</li> </ul><ul> <li>Build the data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources</li> <li>Create, enhance, and optimize data visualizations</li> <li>Identify, design, and implement internal process improvements to automate manual processes, and optimize data delivery</li> <li>Build processes to support data transformation, data structures, metadata, dependency and workload management.</li> <li>Define and maintain target data architectures and master data management strategies</li> <li>Collaborate with various Business, Operations, Applications and Analytics teams to ensure adherence to enterprise data standards and data architecture principles</li> <li>Monitor compliance of development work against established standards and principles and work to resolve discrepancies and issues</li> <li>Optimizing high-performing SQL for efficient data transformation</li> <li>Production release and operation of data services</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Bachelor’s degree in Computer Science, Engineering, or related field</li> <li>4+ years of experience building data pipelines and using ETL tools</li> <li>2+ years of experience leading data Engineering efforts</li> <li>2+ years of experience creating data visualizations</li> <li>Knowledge of data management, data integration and database development technologies and processes</li> <li>Up-to-date specialized knowledge of data wrangling, manipulation and management</li> <li>Demonstrated mastery in one or more SQL variants: T-SQL or PL/SQL</li> <li>In-depth knowledge of Microsoft SQL Server or Oracle</li> <li>Demonstrated mastery in database concepts and large-scale database implementations and design</li> <li>Excellent analytic and troubleshooting skills</li> <li>Proficiency with data profiling and data migration</li> <li>Knowledge of real-time data acquisition and/or automation/controls</li> <li>Working knowledge of application development and data modeling to support implementation and development of analytics</li> <li>Demonstrated success in technical proficiency, creativity, collaboration, and independent thought</li> <li>Experience in migrating ETL processes (not just data) from relational databases to cloud based solutions</li> <li>Strong interpersonal skills to resolve issues in a professional manner, lead working groups, negotiate and create consensus</li> <li>Experience architecting and implementing data solutions, and working with unstructured datasets in a cloud environment, a plus</li> <li>Java / R/ Python, Data science/machine learning, a plus</li> <li>Warehousing or Transportation Logistics experience, a plus</li> <br><br></ul>To all agencies: Please, no phone calls or emails to any employee of NFI about this opening. All resumes submitted by search firms/employment agencies to any employee at NFI via-email, the internet or in any form and/or method will be deemed the sole property of NFI, unless such search firms/employment agencies were engaged by NFI for this position and a valid agreement with NFI is in place. In the event a candidate who was submitted outside of the NFI agency engagement process is hired, no fee or payment of any kind will be paid.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Construction, Logistics and Supply Chain, Transportation/Trucking/Railroad"
Associate Data Scientist,"Columbus, Ohio, United States",Root Inc.,2021-02-16,https://www.linkedin.com/jobs/view/associate-data-scientist-at-root-inc-2409495246?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=q8bGUi2wiJ6x9CjoiTj7LQ%3D%3D&position=2&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"We believe a large part of building an effective insurance company can be solved with a principled quantitative framework. We are committed to the rigorous development and effective deployment of modern statistical machine learning methods to problems in the insurance industry.

A Data Scientist at Root is responsible for the end-to-end development of statistical methods and algorithms. This includes taking high-level business challenges, translating them into a concrete, quantitative framework, and shepherding solutions from R&D into production. Data Scientists typically work on cross-functional teams, regularly engaging with the members of various departments including Product, Actuarial, Marketing, and Engineering.

Associate Data Scientists will join Root’s Data Science Rotation Program. This 9 month program is designed for aspiring data scientists with a strong background in a technical field to kick-start their career in data science. You will apply quantitative techniques to real business problems while developing your theoretical and technical foundation in statistics and machine learning. We are looking for candidates with high quantitative aptitude, strong programming skills, and a passion for problem solving.

Responsibilities

Learn and apply fundamental statistical and machine learning techniques to solve quantitative problems
Rapidly grow your data science toolkit through on-the-job training and dedicated coursework
Tackle quantitative insurance challenges in areas such as telematics risk scoring, pricing, reserving, and estimating customer lifetime value
Effectively communicate insights from complex analyses
At the end of the rotation program, demonstrate sufficient mastery of data science fundamentals to qualify for a promotion to Data Scientist I


Qualifications

In-depth knowledge of a technical discipline, PhD preferred
Mathematical maturity and basic understanding of probability theory e.g. independence, Bayes’ theorem, combinatorics, calculus
Strong programming skills in R or Python with some experience fitting models
Exceptional communicator and storyteller
End-to-end ownership mentality with a high level of attention to detail
Data analytics maturity: able to review descriptive statistics and business metrics and make recommendations


At Root, we judge people based on the merit of their work, not who they are. Very few (if any!) people will fit every description; so if you are passionate about what this role entails, and are excited by solving real problems, we encourage you to apply; we want to learn about you, and what you can add to our team!

Who We Are.

Root Insurance is the nation’s first licensed insurance carrier powered entirely by mobile. We were founded on the belief that the services you need for everyday life should serve you better. That’s why we base insurance coverages on you, not your demographic. It’s the way insurance should be. And it’s all conveniently in an app.

What Draws People To Root.

We’re a venture-backed technology company. Our early success is in large part due to our unwavering standards in hiring. We recognize that our product is only as good as the people building and promoting it. We look for individuals who find solutions by going through the cycle of ideation to implementation with curiosity, rigor, and a highly analytical lens. Ask anyone who works here and you’ll hear similar reasons for why they joined:

Autonomy. For assertive self-starters, the opportunities to contribute are limitless.

Impact. By challenging the way it’s always been done, we solve problems that have a big impact on our business.

Collaboration. We encourage rich discussion and civil debate at every turn.

People. We are inspired by the collection of crazy-smart people around us
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We believe a large part of building an effective insurance company can be solved with a principled quantitative framework. We are committed to the rigorous development and effective deployment of modern statistical machine learning methods to problems in the insurance industry.<br><br>A Data Scientist at Root is responsible for the end-to-end development of statistical methods and algorithms. This includes taking high-level business challenges, translating them into a concrete, quantitative framework, and shepherding solutions from R&amp;D into production. Data Scientists typically work on cross-functional teams, regularly engaging with the members of various departments including Product, Actuarial, Marketing, and Engineering.<br><br>Associate Data Scientists will join Root’s Data Science Rotation Program. This 9 month program is designed for aspiring data scientists with a strong background in a technical field to kick-start their career in data science. You will apply quantitative techniques to real business problems while developing your theoretical and technical foundation in statistics and machine learning. We are looking for candidates with high quantitative aptitude, strong programming skills, and a passion for problem solving.<br><br><strong><u>Responsibilities<br></u></strong><ul><ul><li>Learn and apply fundamental statistical and machine learning techniques to solve quantitative problems</li><li>Rapidly grow your data science toolkit through on-the-job training and dedicated coursework</li><li>Tackle quantitative insurance challenges in areas such as telematics risk scoring, pricing, reserving, and estimating customer lifetime value</li><li>Effectively communicate insights from complex analyses</li><li>At the end of the rotation program, demonstrate sufficient mastery of data science fundamentals to qualify for a promotion to Data Scientist I<br><br></li></ul></ul><strong><u>Qualifications<br></u></strong><ul><ul><li>In-depth knowledge of a technical discipline, PhD preferred</li><li>Mathematical maturity and basic understanding of probability theory e.g. independence, Bayes’ theorem, combinatorics, calculus</li><li>Strong programming skills in R or Python with some experience fitting models</li><li>Exceptional communicator and storyteller</li><li>End-to-end ownership mentality with a high level of attention to detail</li><li>Data analytics maturity: able to review descriptive statistics and business metrics and make recommendations<br><br></li></ul></ul>At Root, we judge people based on the merit of their work, not who they are. Very few (if any!) people will fit every description; so if you are passionate about what this role entails, and are excited by solving real problems, we encourage you to apply; we want to learn about you, and what you can add to our team!<br><br><strong><u>Who We Are.<br><br></u></strong>Root Insurance is the nation’s first licensed insurance carrier powered entirely by mobile. We were founded on the belief that the services you need for everyday life should serve you better. That’s why we base insurance coverages on you, not your demographic. It’s the way insurance should be. And it’s all conveniently in an app.<br><br><strong><u>What Draws People To Root.<br><br></u></strong>We’re a venture-backed technology company. Our early success is in large part due to our unwavering standards in hiring. We recognize that our product is only as good as the people building and promoting it. We look for individuals who find solutions by going through the cycle of ideation to implementation with curiosity, rigor, and a highly analytical lens. Ask anyone who works here and you’ll hear similar reasons for why they joined:<br><br><strong>Autonomy.</strong> For assertive self-starters, the opportunities to contribute are limitless.<br><br><strong>Impact. </strong> By challenging the way it’s always been done, we solve problems that have a big impact on our business.<br><br><strong>Collaboration. </strong> We encourage rich discussion and civil debate at every turn.<br><br><strong>People. </strong> We are inspired by the collection of crazy-smart people around us</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Internet, Insurance, Financial Services"
Data Engineers with Scala + Python+ Java,"Buffalo, New York, United States",Experis,2021-02-18,https://www.linkedin.com/jobs/view/data-engineers-with-scala-%2B-python%2B-java-at-experis-2413455362?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=y6PYau5%2FI8baU2REijoUmA%3D%3D&position=4&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"We believe a large part of building an effective insurance company can be solved with a principled quantitative framework. We are committed to the rigorous development and effective deployment of modern statistical machine learning methods to problems in the insurance industry.

A Data Scientist at Root is responsible for the end-to-end development of statistical methods and algorithms. This includes taking high-level business challenges, translating them into a concrete, quantitative framework, and shepherding solutions from R&D into production. Data Scientists typically work on cross-functional teams, regularly engaging with the members of various departments including Product, Actuarial, Marketing, and Engineering.

Associate Data Scientists will join Root’s Data Science Rotation Program. This 9 month program is designed for aspiring data scientists with a strong background in a technical field to kick-start their career in data science. You will apply quantitative techniques to real business problems while developing your theoretical and technical foundation in statistics and machine learning. We are looking for candidates with high quantitative aptitude, strong programming skills, and a passion for problem solving.

Responsibilities

Learn and apply fundamental statistical and machine learning techniques to solve quantitative problems
Rapidly grow your data science toolkit through on-the-job training and dedicated coursework
Tackle quantitative insurance challenges in areas such as telematics risk scoring, pricing, reserving, and estimating customer lifetime value
Effectively communicate insights from complex analyses
At the end of the rotation program, demonstrate sufficient mastery of data science fundamentals to qualify for a promotion to Data Scientist I


Qualifications

In-depth knowledge of a technical discipline, PhD preferred
Mathematical maturity and basic understanding of probability theory e.g. independence, Bayes’ theorem, combinatorics, calculus
Strong programming skills in R or Python with some experience fitting models
Exceptional communicator and storyteller
End-to-end ownership mentality with a high level of attention to detail
Data analytics maturity: able to review descriptive statistics and business metrics and make recommendations


At Root, we judge people based on the merit of their work, not who they are. Very few (if any!) people will fit every description; so if you are passionate about what this role entails, and are excited by solving real problems, we encourage you to apply; we want to learn about you, and what you can add to our team!

Who We Are.

Root Insurance is the nation’s first licensed insurance carrier powered entirely by mobile. We were founded on the belief that the services you need for everyday life should serve you better. That’s why we base insurance coverages on you, not your demographic. It’s the way insurance should be. And it’s all conveniently in an app.

What Draws People To Root.

We’re a venture-backed technology company. Our early success is in large part due to our unwavering standards in hiring. We recognize that our product is only as good as the people building and promoting it. We look for individuals who find solutions by going through the cycle of ideation to implementation with curiosity, rigor, and a highly analytical lens. Ask anyone who works here and you’ll hear similar reasons for why they joined:

Autonomy. For assertive self-starters, the opportunities to contribute are limitless.

Impact. By challenging the way it’s always been done, we solve problems that have a big impact on our business.

Collaboration. We encourage rich discussion and civil debate at every turn.

People. We are inspired by the collection of crazy-smart people around us
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We believe a large part of building an effective insurance company can be solved with a principled quantitative framework. We are committed to the rigorous development and effective deployment of modern statistical machine learning methods to problems in the insurance industry.<br><br>A Data Scientist at Root is responsible for the end-to-end development of statistical methods and algorithms. This includes taking high-level business challenges, translating them into a concrete, quantitative framework, and shepherding solutions from R&amp;D into production. Data Scientists typically work on cross-functional teams, regularly engaging with the members of various departments including Product, Actuarial, Marketing, and Engineering.<br><br>Associate Data Scientists will join Root’s Data Science Rotation Program. This 9 month program is designed for aspiring data scientists with a strong background in a technical field to kick-start their career in data science. You will apply quantitative techniques to real business problems while developing your theoretical and technical foundation in statistics and machine learning. We are looking for candidates with high quantitative aptitude, strong programming skills, and a passion for problem solving.<br><br><strong><u>Responsibilities<br></u></strong><ul><ul><li>Learn and apply fundamental statistical and machine learning techniques to solve quantitative problems</li><li>Rapidly grow your data science toolkit through on-the-job training and dedicated coursework</li><li>Tackle quantitative insurance challenges in areas such as telematics risk scoring, pricing, reserving, and estimating customer lifetime value</li><li>Effectively communicate insights from complex analyses</li><li>At the end of the rotation program, demonstrate sufficient mastery of data science fundamentals to qualify for a promotion to Data Scientist I<br><br></li></ul></ul><strong><u>Qualifications<br></u></strong><ul><ul><li>In-depth knowledge of a technical discipline, PhD preferred</li><li>Mathematical maturity and basic understanding of probability theory e.g. independence, Bayes’ theorem, combinatorics, calculus</li><li>Strong programming skills in R or Python with some experience fitting models</li><li>Exceptional communicator and storyteller</li><li>End-to-end ownership mentality with a high level of attention to detail</li><li>Data analytics maturity: able to review descriptive statistics and business metrics and make recommendations<br><br></li></ul></ul>At Root, we judge people based on the merit of their work, not who they are. Very few (if any!) people will fit every description; so if you are passionate about what this role entails, and are excited by solving real problems, we encourage you to apply; we want to learn about you, and what you can add to our team!<br><br><strong><u>Who We Are.<br><br></u></strong>Root Insurance is the nation’s first licensed insurance carrier powered entirely by mobile. We were founded on the belief that the services you need for everyday life should serve you better. That’s why we base insurance coverages on you, not your demographic. It’s the way insurance should be. And it’s all conveniently in an app.<br><br><strong><u>What Draws People To Root.<br><br></u></strong>We’re a venture-backed technology company. Our early success is in large part due to our unwavering standards in hiring. We recognize that our product is only as good as the people building and promoting it. We look for individuals who find solutions by going through the cycle of ideation to implementation with curiosity, rigor, and a highly analytical lens. Ask anyone who works here and you’ll hear similar reasons for why they joined:<br><br><strong>Autonomy.</strong> For assertive self-starters, the opportunities to contribute are limitless.<br><br><strong>Impact. </strong> By challenging the way it’s always been done, we solve problems that have a big impact on our business.<br><br><strong>Collaboration. </strong> We encourage rich discussion and civil debate at every turn.<br><br><strong>People. </strong> We are inspired by the collection of crazy-smart people around us</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Internet, Insurance, Financial Services"
Data Engineer,"Remote, Oregon, United States",Remine,2021-01-25,https://www.linkedin.com/jobs/view/data-engineer-at-remine-2430311346?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=r7AfNsK8sMM9joK0HGfAkA%3D%3D&position=5&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Remine is transforming the real estate industry with our intense focus and commitment to data. By merging property listing, financial, consumer, public record, and geospatial data we are propelling the industry into the future. A core expectation for our Data Engineers is to strengthen today’s foothold while keeping a steady gaze on the future. This means being able to delight customers with a nimble tactical approach while overlaying your experience in building enterprise grade data pipelines with inherent scale and quality.Our core platform and data products deliver powerful insights and predictive analytics on top of our geospatial applications. We build products for both web and mobile to deliver visualizations and search capabilities for real estate agents, brokers, and experts. Our platform and products support large-scale data sources, processing near-real time updates from a large number of sources. With structured and unstructured data, our data ingestion pipelines, data processing capabilities, and extensive front-end displays provide our users globally the capability to search, label, and track changing datasets as they come in for the real estate arena.

Responsibilities

Manage our querying platform and experimentation tools.
Implementation of security and data protection
Work with analysts and data scientists to Identify, design, and implement internal process and standards improvements: standardized tools, automating processes, optimizing data delivery, etc.
Design infrastructure and systems to scale easily as data grows.
Optimize our spark processing pipelines and clusters, ensuring high-quality data is securely and reliably delivered to stakeholders.

Requirements

Bachelor's degree in Computer Science, Engineering, or related technical discipline
Startup Experience
Experience with big data technologies such as Spark, Hive, Kafka, etc.
Advanced working SQL knowledge and experience (Postgres, Hive, Snowflake etc) is required, No-SQL experience is a plus;
Familiarity with enterprise integration patterns and ability to follow accepted software design patterns
Passionate about thorough application testing
Comfortable with AWS
Expert at sourcing and manipulating data from APIs
Experience with Elasticsearch or other search technologies
DevOps mindset with Docker experience in Kubernetes or ECS
1+ years with Python or Node for ETL development
2+ years of hands-on technical experience in a data engineer role
Remine is an equal opportunity employer committed to hiring a diverse workforce
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Remine is transforming the real estate industry with our intense focus and commitment to data. By merging property listing, financial, consumer, public record, and geospatial data we are propelling the industry into the future. A core expectation for our Data Engineers is to strengthen today’s foothold while keeping a steady gaze on the future. This means being able to delight customers with a nimble tactical approach while overlaying your experience in building enterprise grade data pipelines with inherent scale and quality.Our core platform and data products deliver powerful insights and predictive analytics on top of our geospatial applications. We build products for both web and mobile to deliver visualizations and search capabilities for real estate agents, brokers, and experts. Our platform and products support large-scale data sources, processing near-real time updates from a large number of sources. With structured and unstructured data, our data ingestion pipelines, data processing capabilities, and extensive front-end displays provide our users globally the capability to search, label, and track changing datasets as they come in for the real estate arena.<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Manage our querying platform and experimentation tools. </li> <li> Implementation of security and data protection </li> <li> Work with analysts and data scientists to Identify, design, and implement internal process and standards improvements: standardized tools, automating processes, optimizing data delivery, etc. </li> <li> Design infrastructure and systems to scale easily as data grows. </li> <li> Optimize our spark processing pipelines and clusters, ensuring high-quality data is securely and reliably delivered to stakeholders. <br></li></ul><strong><u>Requirements<br></u></strong><ul><li> Bachelor's degree in Computer Science, Engineering, or related technical discipline </li> <li> Startup Experience </li> <li> Experience with big data technologies such as Spark, Hive, Kafka, etc. </li> <li> Advanced working SQL knowledge and experience (Postgres, Hive, Snowflake etc) is required, No-SQL experience is a plus; </li> <li> Familiarity with enterprise integration patterns and ability to follow accepted software design patterns </li> <li> Passionate about thorough application testing </li> <li> Comfortable with AWS </li> <li> Expert at sourcing and manipulating data from APIs </li> <li> Experience with Elasticsearch or other search technologies </li> <li> DevOps mindset with Docker experience in Kubernetes or ECS</li> <li> 1+ years with Python or Node for ETL development </li> <li> 2+ years of hands-on technical experience in a data engineer role</li> Remine is an equal opportunity employer committed to hiring a diverse workforce</ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Remote Python Developer,"Irvine, California, United States",Kelly,2021-02-03,https://www.linkedin.com/jobs/view/remote-python-developer-at-kelly-2406852890?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=n7Yq2M8biU7C0bwSEzEI%2FQ%3D%3D&position=6&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Remine is transforming the real estate industry with our intense focus and commitment to data. By merging property listing, financial, consumer, public record, and geospatial data we are propelling the industry into the future. A core expectation for our Data Engineers is to strengthen today’s foothold while keeping a steady gaze on the future. This means being able to delight customers with a nimble tactical approach while overlaying your experience in building enterprise grade data pipelines with inherent scale and quality.Our core platform and data products deliver powerful insights and predictive analytics on top of our geospatial applications. We build products for both web and mobile to deliver visualizations and search capabilities for real estate agents, brokers, and experts. Our platform and products support large-scale data sources, processing near-real time updates from a large number of sources. With structured and unstructured data, our data ingestion pipelines, data processing capabilities, and extensive front-end displays provide our users globally the capability to search, label, and track changing datasets as they come in for the real estate arena.

Responsibilities

Manage our querying platform and experimentation tools.
Implementation of security and data protection
Work with analysts and data scientists to Identify, design, and implement internal process and standards improvements: standardized tools, automating processes, optimizing data delivery, etc.
Design infrastructure and systems to scale easily as data grows.
Optimize our spark processing pipelines and clusters, ensuring high-quality data is securely and reliably delivered to stakeholders.

Requirements

Bachelor's degree in Computer Science, Engineering, or related technical discipline
Startup Experience
Experience with big data technologies such as Spark, Hive, Kafka, etc.
Advanced working SQL knowledge and experience (Postgres, Hive, Snowflake etc) is required, No-SQL experience is a plus;
Familiarity with enterprise integration patterns and ability to follow accepted software design patterns
Passionate about thorough application testing
Comfortable with AWS
Expert at sourcing and manipulating data from APIs
Experience with Elasticsearch or other search technologies
DevOps mindset with Docker experience in Kubernetes or ECS
1+ years with Python or Node for ETL development
2+ years of hands-on technical experience in a data engineer role
Remine is an equal opportunity employer committed to hiring a diverse workforce
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Remine is transforming the real estate industry with our intense focus and commitment to data. By merging property listing, financial, consumer, public record, and geospatial data we are propelling the industry into the future. A core expectation for our Data Engineers is to strengthen today’s foothold while keeping a steady gaze on the future. This means being able to delight customers with a nimble tactical approach while overlaying your experience in building enterprise grade data pipelines with inherent scale and quality.Our core platform and data products deliver powerful insights and predictive analytics on top of our geospatial applications. We build products for both web and mobile to deliver visualizations and search capabilities for real estate agents, brokers, and experts. Our platform and products support large-scale data sources, processing near-real time updates from a large number of sources. With structured and unstructured data, our data ingestion pipelines, data processing capabilities, and extensive front-end displays provide our users globally the capability to search, label, and track changing datasets as they come in for the real estate arena.<br><br><strong><u>Responsibilities<br></u></strong><ul><li> Manage our querying platform and experimentation tools. </li> <li> Implementation of security and data protection </li> <li> Work with analysts and data scientists to Identify, design, and implement internal process and standards improvements: standardized tools, automating processes, optimizing data delivery, etc. </li> <li> Design infrastructure and systems to scale easily as data grows. </li> <li> Optimize our spark processing pipelines and clusters, ensuring high-quality data is securely and reliably delivered to stakeholders. <br></li></ul><strong><u>Requirements<br></u></strong><ul><li> Bachelor's degree in Computer Science, Engineering, or related technical discipline </li> <li> Startup Experience </li> <li> Experience with big data technologies such as Spark, Hive, Kafka, etc. </li> <li> Advanced working SQL knowledge and experience (Postgres, Hive, Snowflake etc) is required, No-SQL experience is a plus; </li> <li> Familiarity with enterprise integration patterns and ability to follow accepted software design patterns </li> <li> Passionate about thorough application testing </li> <li> Comfortable with AWS </li> <li> Expert at sourcing and manipulating data from APIs </li> <li> Experience with Elasticsearch or other search technologies </li> <li> DevOps mindset with Docker experience in Kubernetes or ECS</li> <li> 1+ years with Python or Node for ETL development </li> <li> 2+ years of hands-on technical experience in a data engineer role</li> Remine is an equal opportunity employer committed to hiring a diverse workforce</ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Sunnyvale, California, United States",CIGNEX,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-cignex-2428765344?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=ven76vuJAPTIXnFmoX9ffA%3D%3D&position=7&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"*Python Developer*
We are looking for a savvy Python Developer to join our team of analytics experts. The hire will be responsible for expanding and optimizing device data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building data pipelines. The Data Engineer will support data managers, statistical programmers, and statisticians on data initiatives and will ensure optimal data delivery for ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing our data architecture to support our next generation of products and data initiatives.
*Responsibilities for Data Engineer*

Maintain architecture for device generated data pipeline
Assemble and report on large, complex data sets that meet business requirements
Identify, design, and implement internal process improvements: automating and optimizing manual processes, data extraction, transformation, loading of the data, and data delivery
Work with stakeholders including the data managers, statistical programmers, and the statisticians to assist with device data-related technical issues and support their data infrastructure needs.

*Qualifications for Data Engineer*

Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems, or related quantitative field. Advanced degree preferred.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing data pipelines, architectures, and data sets
Build processes supporting data transformation, data structures, metadata, dependency, and workload management
A successful history of manipulating, processing, and extracting value from large datasets
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment. Experience in medical device or pharmaceutical environment preferred
At least 3years of experience in a Data Engineer role, with experience using the following software/tools:

Big data tools: Hadoop, Spark, etc.

Relational SQL and NoSQL databases (Experience with Hive preferred)
Analysis and visualization software such as R, RStudio, Python, and Tableau
Data pipeline and workflow management tools

Why Kelly®?

The Managed Solutions practice within Kelly Outsourcing and Consulting Group (KellyOCG®) is one focus within the full array of Kelly Services® workforce solutions.
Kelly Services has transformed from the staffing industry pioneer to a leading workforce solutions provider. KellyOCG is the distinguished outsourcing and consulting segment of Kelly Services, known for applying a forward-looking approach that enables companies to make strategic workforce planning decisions that impact their business and competitive advantage.
The Managed Solutions practice area of KellyOCG is dedicated to partnering with clients to architect and implement solutions that put them in a position to meet their operational obligation to their organization and freedom to focus on their more strategic business needs.

About

Kelly Services®

As a workforce advocate for over 70 years, we are proud to have a role in managing employment opportunities for more than one million workers around the globe. We employ 550,000 of these individuals directly with the remaining workers engaged through our talent supply chain network of supplier partners. Revenue in 2015 was $5.5 billion. Visit [kellyservices.com](http://www.kellyservices.com) and connect with us on [Facebook](https://www.facebook.com/kellyservices), [LinkedIn](http://www.linkedin.com/company/kellyservices) and [Twitter](https://twitter.com/kellyservices).
Kelly Services is an equal opportunity employer including, but not limited to, Minorities, Females, Individuals with Disabilities, Protected Veterans, Sexual Orientation, Gender Identity and is committed to employing a diverse workforce. [Equal Employment Opportunity is The Law.](https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm)
]]
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">*Python Developer*<br>We are looking for a savvy Python Developer to join our team of analytics experts. The hire will be responsible for expanding and optimizing device data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building data pipelines. The Data Engineer will support data managers, statistical programmers, and statisticians on data initiatives and will ensure optimal data delivery for ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing our data architecture to support our next generation of products and data initiatives.<br>*Responsibilities for Data Engineer*<br><ul><li> Maintain architecture for device generated data pipeline</li><li> Assemble and report on large, complex data sets that meet business requirements</li><li> Identify, design, and implement internal process improvements: automating and optimizing manual processes, data extraction, transformation, loading of the data, and data delivery</li><li> Work with stakeholders including the data managers, statistical programmers, and the statisticians to assist with device data-related technical issues and support their data infrastructure needs.<br></li></ul>*Qualifications for Data Engineer*<br><ul><li> Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems, or related quantitative field. Advanced degree preferred.</li><li> Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li><li> Experience building and optimizing data pipelines, architectures, and data sets</li><li> Build processes supporting data transformation, data structures, metadata, dependency, and workload management</li><li> A successful history of manipulating, processing, and extracting value from large datasets</li><li> Strong project management and organizational skills</li><li> Experience supporting and working with cross-functional teams in a dynamic environment. Experience in medical device or pharmaceutical environment preferred</li><li> At least 3years of experience in a Data Engineer role, with experience using the following software/tools:<br></li></ul>Big data tools: Hadoop, Spark, etc.<br><ul><li> Relational SQL and NoSQL databases (Experience with Hive preferred)</li><li> Analysis and visualization software such as R, RStudio, Python, and Tableau</li><li> Data pipeline and workflow management tools<br></li></ul>Why Kelly®?<br><br>The Managed Solutions practice within Kelly Outsourcing and Consulting Group (KellyOCG®) is one focus within the full array of Kelly Services® workforce solutions.<br>Kelly Services has transformed from the staffing industry pioneer to a leading workforce solutions provider. KellyOCG is the distinguished outsourcing and consulting segment of Kelly Services, known for applying a forward-looking approach that enables companies to make strategic workforce planning decisions that impact their business and competitive advantage.<br>The Managed Solutions practice area of KellyOCG is dedicated to partnering with clients to architect and implement solutions that put them in a position to meet their operational obligation to their organization and freedom to focus on their more strategic business needs.<br><br><strong><u>About<br><br></u></strong>Kelly Services®<br><br>As a workforce advocate for over 70 years, we are proud to have a role in managing employment opportunities for more than one million workers around the globe. We employ 550,000 of these individuals directly with the remaining workers engaged through our talent supply chain network of supplier partners. Revenue in 2015 was $5.5 billion. Visit [kellyservices.com](http://www.kellyservices.com) and connect with us on [Facebook](https://www.facebook.com/kellyservices), [LinkedIn](http://www.linkedin.com/company/kellyservices) and [Twitter](https://twitter.com/kellyservices).<br>Kelly Services is an equal opportunity employer including, but not limited to, Minorities, Females, Individuals with Disabilities, Protected Veterans, Sexual Orientation, Gender Identity and is committed to employing a diverse workforce. [Equal Employment Opportunity is The Law.](https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm)<br>]]</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Automotive, Staffing and Recruiting"
Cloud Data Engineer,"Madison, New Jersey, United States",Merck,2021-01-30,https://www.linkedin.com/jobs/view/cloud-data-engineer-at-merck-2381702253?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=sNel2A6DGJKsRTSNoaMAqw%3D%3D&position=8&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Target Rate Range 75hr W2 Hourly Data Engineer Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources. Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required. Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis. Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. Establish product requirements with proper documentation for quality control, and support testing effort. BS degree 5-7 years of hands-on experience MS degree- 3-5 years of hands-on experience In order to perform the responsibilities of this position, the individual must have bull M.S. in Computer Science, SoftwareComputer Engineering, or Applied Math with minimum of 2 years industry experience or B.S. degree with minimum (5) years industry experience bull Demonstrated excellent communication skills both written and verbal bull Ability to independently work with services team to gather product requirements and manage development life cycle bull Demonstrated ability to work on large data sets bull Interested in early pipeline research and developmentprototype efforts bull Proficient with relational SQL ( Microsoft SQL , MySQL, Postgres, Mongo etc.) bull Proficient in at least two of Python, C, Java, JavaScript bull Solid knowledge of statistics bull Any experience in the following would be ideal o Database design, management and operation Following skills sets is must 1. 4 years of hands-on experience working on data using SQL on multiple platforms (SQL server, my SQL, Postgres, Mongo) including database operations 2. 3 years of hands-on experience with Python and C programming (required) 3. 2 years of hands-on experience with Data analytics (dashboards) and derive insights 4. 2 years of hands-on experience with Application Development Skills - web based or service based 5. 3 years of hands-on experience with ETL tools and automation (required) 6. 1 year of experience AWS technology stack understanding (desirable)
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Target Rate Range 75hr W2 Hourly Data Engineer Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources. Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required. Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis. Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. Establish product requirements with proper documentation for quality control, and support testing effort. BS degree 5-7 years of hands-on experience MS degree- 3-5 years of hands-on experience In order to perform the responsibilities of this position, the individual must have bull M.S. in Computer Science, SoftwareComputer Engineering, or Applied Math with minimum of 2 years industry experience or B.S. degree with minimum (5) years industry experience bull Demonstrated excellent communication skills both written and verbal bull Ability to independently work with services team to gather product requirements and manage development life cycle bull Demonstrated ability to work on large data sets bull Interested in early pipeline research and developmentprototype efforts bull Proficient with relational SQL ( Microsoft SQL , MySQL, Postgres, Mongo etc.) bull Proficient in at least two of Python, C, Java, JavaScript bull Solid knowledge of statistics bull Any experience in the following would be ideal o Database design, management and operation Following skills sets is must 1. 4 years of hands-on experience working on data using SQL on multiple platforms (SQL server, my SQL, Postgres, Mongo) including database operations 2. 3 years of hands-on experience with Python and C programming (required) 3. 2 years of hands-on experience with Data analytics (dashboards) and derive insights 4. 2 years of hands-on experience with Application Development Skills - web based or service based 5. 3 years of hands-on experience with ETL tools and automation (required) 6. 1 year of experience AWS technology stack understanding (desirable)</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
Data Scientist,"New York, New York, United States",Cherre,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-cherre-2426656683?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=onLBoIq2dqnc3QLal73ekg%3D%3D&position=10&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Cherre provides investors, lenders, insurers, brokers and other large enterprises with a platform to collect, resolve, and augment real estate data from thousands of public, private, and internal sources. By providing a “single source of truth,” we empower companies to evaluate opportunities and trends faster and more accurately, while saving them millions of dollars in manual data collection and analytics costs.

Cherre is looking for a Data Scientist who will be building ML algorithms and AI. This role requires a combination of quantitative and software engineering skills to build scalable solutions. Because of the complexity and variety of the data sets we use, it's critical that you have an interest in learning Real Estate and Derived datasets. Previous Real Estate experience is not required. You will not only do analysis, but will also be expected to deliver production code.

You are

Knowledgeable about Machine Learning techniques
Comfortable with complicated ETL processes
Proficient in Python
Proficient with SQL.
Bonus points for

Working with Cloud (GCP, AWS etc)


Benefits

Competitive Base Salary
Equity
Range of Healthcare Plans that start day one
Paid Parental Leave
Educational Credit
Unlimited Vacation
Flexible Work Schedule
If this opportunity sounds interesting, apply or reach out to our internal talent team. We are happy to tell you more about Cherre: the technology we work with, the problems we solve, the team we are assembling, and the culture we all contribute to. We are excited you are considering working with us and look forward to hearing from you!

“At the top of the mountain we are all snow leopards.” - Hunter S. Thompson

Cherre is an equal opportunity employer. We pride ourselves on hiring the best people for the job no matter their race, sex, orientation, nationality, religion, disability, or age.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Cherre provides investors, lenders, insurers, brokers and other large enterprises with a platform to collect, resolve, and augment real estate data from thousands of public, private, and internal sources. By providing a “single source of truth,” we empower companies to evaluate opportunities and trends faster and more accurately, while saving them millions of dollars in manual data collection and analytics costs.<br><br>Cherre is looking for a Data Scientist who will be building ML algorithms and AI. This role requires a combination of quantitative and software engineering skills to build scalable solutions. Because of the complexity and variety of the data sets we use, it's critical that you have an interest in learning Real Estate and Derived datasets. Previous Real Estate experience is not required. You will not only do analysis, but will also be expected to deliver production code.<br><br>You are<br><ul><li>Knowledgeable about Machine Learning techniques</li><li>Comfortable with complicated ETL processes</li><li>Proficient in Python </li><li>Proficient with SQL.</li></ul>Bonus points for<br><ul><li>Working with Cloud (GCP, AWS etc)<br><br></li></ul><strong> Benefits <br></strong><ul><li>Competitive Base Salary</li><li>Equity</li><li>Range of Healthcare Plans that start day one</li><li>Paid Parental Leave</li><li>Educational Credit</li><li>Unlimited Vacation</li><li>Flexible Work Schedule</li></ul>If this opportunity sounds interesting, apply or reach out to our internal talent team. We are happy to tell you more about Cherre: the technology we work with, the problems we solve, the team we are assembling, and the culture we all contribute to. We are excited you are considering working with us and look forward to hearing from you!<br><br>“At the top of the mountain we are all snow leopards.” - Hunter S. Thompson<br><br>Cherre is an equal opportunity employer. We pride ourselves on hiring the best people for the job no matter their race, sex, orientation, nationality, religion, disability, or age.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Hampton, Virginia, United States",Leidos,2021-02-19,https://www.linkedin.com/jobs/view/data-engineer-at-leidos-2430527595?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=tLjcr4pPniYVbbi08iNjTg%3D%3D&position=11&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Description

Job Description:

The 363rd ISRW currently has an opening for a Data Science Engineer to work at Joint-Base Langley Eustis in Hampton, VA. This is an exciting opportunity to use your experience to help develop new data standards and processes within the Air Force. As a member of the Intelligence Wing, it will be your mission to research and development design, test and deployment of automated process, reports and data processing systems.

Primary Responsibilities

Entering and reviewing data within the database.
Maintaining database support tools, database tables , dictionaries recovery and back-up procedures, and making recommendations regarding enhancements and/or improvements.
Implementation and operation of data management systems to meet the organization’s operational needs. This includes designing how the data will be stored, consumed, integrated, and managed by different units and digital systems.
Work data consumers to determine, create and populate optimal data architectures, structures, and systems.
The Data Engineer will optimize data throughput and query performance issues.
Works independently to achieve day-to-day objectives with significant impact on operational results or project deliverables. Responsible for entire projects or processes within a technical area.
Works to implement solution designs and/or processes.
Create and maintain high-quality data set to serve as the source of truth for fundamental data captured, machine learning training, and reporting
Create and maintain blue print for data to integrate, centralize and maintain the data sources
Apply knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet the unit’s needs.
Analyze operational problems and design reliable, scalable data storage and analytics systems that enable the unit’s mission.
Ensure data integrity by leveraging proven methodologies, including data reconciliation, data integration and data audits
Perform statistical analysis and apply data mining techniques in support of the unit’s mission.
Provide expert guidance and advice to unit’s efforts in support of Air Force, Joint, and DoD development of AI/ML and advanced analytical tools and interfaces.
Support subordinate ACC units with various approaches to visualize and make sense of complex unstructured data.


Basic Qualifications

Bachelor’s degree in Mathematics, Computer Science, Engineering, or a similar field (6 years’ experience can substitute for degree)
8+ years of experience related to position requirements
3 years of experience as a Data Engineer or similar role
Experience with one of the following: R, Python or SQL
Demonstrated strength in data modeling, data-pipelines development, data warehousing and solving big data challenges
Experience using relevant AF systems and relational databases
Experience working with cloud computing and infrastructure (AWS, Azure, etc)
Active TS/SCI government security clearance


Preferred Qualifications

Advanced degree in Mathematics, Computer Science or Engineering.
Experience working with Jira and Confluence
Experience with Air Force ISR units
DoD 8570 IAT Level II Compliant
Experience using business intelligence reporting tools (Tableau, Power BI, etc)


External Referral Bonus

Eligible

Potential For Telework

No

Clearance Level Required

Top Secret/SCI

Travel

Yes, 10% of the time

Scheduled Weekly Hours

40

Shift

Day

Requisition Category

Professional

Job Family

Database Management

Pay Range

Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world’s toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company’s 38,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Va., Leidos reported annual revenues of approximately $11.09 billion for the fiscal year ended January 3, 2020. For more information, visit www.Leidos.com.

Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.

Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><strong><u>Job Description:<br><br></u></strong>The 363rd ISRW currently has an opening for a Data Science Engineer to work at Joint-Base Langley Eustis in Hampton, VA. This is an exciting opportunity to use your experience to help develop new data standards and processes within the Air Force. As a member of the Intelligence Wing, it will be your mission to research and development design, test and deployment of automated process, reports and data processing systems.<br><br><strong><u>Primary Responsibilities<br></u></strong><ul><li>Entering and reviewing data within the database.</li><li>Maintaining database support tools, database tables , dictionaries recovery and back-up procedures, and making recommendations regarding enhancements and/or improvements.</li><li>Implementation and operation of data management systems to meet the organization’s operational needs. This includes designing how the data will be stored, consumed, integrated, and managed by different units and digital systems.</li><li>Work data consumers to determine, create and populate optimal data architectures, structures, and systems.</li><li>The Data Engineer will optimize data throughput and query performance issues.</li><li>Works independently to achieve day-to-day objectives with significant impact on operational results or project deliverables. Responsible for entire projects or processes within a technical area.</li><li>Works to implement solution designs and/or processes.</li><li>Create and maintain high-quality data set to serve as the source of truth for fundamental data captured, machine learning training, and reporting</li><li>Create and maintain blue print for data to integrate, centralize and maintain the data sources</li><li>Apply knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet the unit’s needs.</li><li>Analyze operational problems and design reliable, scalable data storage and analytics systems that enable the unit’s mission.</li><li>Ensure data integrity by leveraging proven methodologies, including data reconciliation, data integration and data audits</li><li>Perform statistical analysis and apply data mining techniques in support of the unit’s mission.</li><li>Provide expert guidance and advice to unit’s efforts in support of Air Force, Joint, and DoD development of AI/ML and advanced analytical tools and interfaces.</li><li>Support subordinate ACC units with various approaches to visualize and make sense of complex unstructured data.<br><br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li>Bachelor’s degree in Mathematics, Computer Science, Engineering, or a similar field (6 years’ experience can substitute for degree)</li><li>8+ years of experience related to position requirements</li><li>3 years of experience as a Data Engineer or similar role</li><li>Experience with one of the following: R, Python or SQL</li><li>Demonstrated strength in data modeling, data-pipelines development, data warehousing and solving big data challenges</li><li>Experience using relevant AF systems and relational databases</li><li>Experience working with cloud computing and infrastructure (AWS, Azure, etc)</li><li><strong>Active TS/SCI government security clearance<br><br></strong></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Advanced degree in Mathematics, Computer Science or Engineering.</li><li>Experience working with Jira and Confluence</li><li>Experience with Air Force ISR units</li><li>DoD 8570 IAT Level II Compliant</li><li>Experience using business intelligence reporting tools (Tableau, Power BI, etc)<br><br></li></ul><strong><u>External Referral Bonus<br><br></u></strong>Eligible<br><br><strong><u>Potential For Telework<br><br></u></strong>No<br><br><strong><u>Clearance Level Required<br><br></u></strong>Top Secret/SCI<br><br><strong><u>Travel<br><br></u></strong>Yes, 10% of the time<br><br><strong><u>Scheduled Weekly Hours<br><br></u></strong>40<br><br><strong><u>Shift<br><br></u></strong>Day<br><br><strong><u>Requisition Category<br><br></u></strong>Professional<br><br><strong><u>Job Family<br><br></u></strong>Database Management<br><br><strong><u>Pay Range<br><br></u></strong>Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world’s toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company’s 38,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Va., Leidos reported annual revenues of approximately $11.09 billion for the fiscal year ended January 3, 2020. For more information, visit www.Leidos.com.<br><br>Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.<br><br>Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.<br><br>All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Analytics Engineer,"Denver, Colorado, United States",Guild Education,2021-01-25,https://www.linkedin.com/jobs/view/analytics-engineer-at-guild-education-2380387559?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=qZgYPiY7q5wB8goAKPIW6Q%3D%3D&position=12&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Description

Job Description:

The 363rd ISRW currently has an opening for a Data Science Engineer to work at Joint-Base Langley Eustis in Hampton, VA. This is an exciting opportunity to use your experience to help develop new data standards and processes within the Air Force. As a member of the Intelligence Wing, it will be your mission to research and development design, test and deployment of automated process, reports and data processing systems.

Primary Responsibilities

Entering and reviewing data within the database.
Maintaining database support tools, database tables , dictionaries recovery and back-up procedures, and making recommendations regarding enhancements and/or improvements.
Implementation and operation of data management systems to meet the organization’s operational needs. This includes designing how the data will be stored, consumed, integrated, and managed by different units and digital systems.
Work data consumers to determine, create and populate optimal data architectures, structures, and systems.
The Data Engineer will optimize data throughput and query performance issues.
Works independently to achieve day-to-day objectives with significant impact on operational results or project deliverables. Responsible for entire projects or processes within a technical area.
Works to implement solution designs and/or processes.
Create and maintain high-quality data set to serve as the source of truth for fundamental data captured, machine learning training, and reporting
Create and maintain blue print for data to integrate, centralize and maintain the data sources
Apply knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet the unit’s needs.
Analyze operational problems and design reliable, scalable data storage and analytics systems that enable the unit’s mission.
Ensure data integrity by leveraging proven methodologies, including data reconciliation, data integration and data audits
Perform statistical analysis and apply data mining techniques in support of the unit’s mission.
Provide expert guidance and advice to unit’s efforts in support of Air Force, Joint, and DoD development of AI/ML and advanced analytical tools and interfaces.
Support subordinate ACC units with various approaches to visualize and make sense of complex unstructured data.


Basic Qualifications

Bachelor’s degree in Mathematics, Computer Science, Engineering, or a similar field (6 years’ experience can substitute for degree)
8+ years of experience related to position requirements
3 years of experience as a Data Engineer or similar role
Experience with one of the following: R, Python or SQL
Demonstrated strength in data modeling, data-pipelines development, data warehousing and solving big data challenges
Experience using relevant AF systems and relational databases
Experience working with cloud computing and infrastructure (AWS, Azure, etc)
Active TS/SCI government security clearance


Preferred Qualifications

Advanced degree in Mathematics, Computer Science or Engineering.
Experience working with Jira and Confluence
Experience with Air Force ISR units
DoD 8570 IAT Level II Compliant
Experience using business intelligence reporting tools (Tableau, Power BI, etc)


External Referral Bonus

Eligible

Potential For Telework

No

Clearance Level Required

Top Secret/SCI

Travel

Yes, 10% of the time

Scheduled Weekly Hours

40

Shift

Day

Requisition Category

Professional

Job Family

Database Management

Pay Range

Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world’s toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company’s 38,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Va., Leidos reported annual revenues of approximately $11.09 billion for the fiscal year ended January 3, 2020. For more information, visit www.Leidos.com.

Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.

Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><strong><u>Job Description:<br><br></u></strong>The 363rd ISRW currently has an opening for a Data Science Engineer to work at Joint-Base Langley Eustis in Hampton, VA. This is an exciting opportunity to use your experience to help develop new data standards and processes within the Air Force. As a member of the Intelligence Wing, it will be your mission to research and development design, test and deployment of automated process, reports and data processing systems.<br><br><strong><u>Primary Responsibilities<br></u></strong><ul><li>Entering and reviewing data within the database.</li><li>Maintaining database support tools, database tables , dictionaries recovery and back-up procedures, and making recommendations regarding enhancements and/or improvements.</li><li>Implementation and operation of data management systems to meet the organization’s operational needs. This includes designing how the data will be stored, consumed, integrated, and managed by different units and digital systems.</li><li>Work data consumers to determine, create and populate optimal data architectures, structures, and systems.</li><li>The Data Engineer will optimize data throughput and query performance issues.</li><li>Works independently to achieve day-to-day objectives with significant impact on operational results or project deliverables. Responsible for entire projects or processes within a technical area.</li><li>Works to implement solution designs and/or processes.</li><li>Create and maintain high-quality data set to serve as the source of truth for fundamental data captured, machine learning training, and reporting</li><li>Create and maintain blue print for data to integrate, centralize and maintain the data sources</li><li>Apply knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet the unit’s needs.</li><li>Analyze operational problems and design reliable, scalable data storage and analytics systems that enable the unit’s mission.</li><li>Ensure data integrity by leveraging proven methodologies, including data reconciliation, data integration and data audits</li><li>Perform statistical analysis and apply data mining techniques in support of the unit’s mission.</li><li>Provide expert guidance and advice to unit’s efforts in support of Air Force, Joint, and DoD development of AI/ML and advanced analytical tools and interfaces.</li><li>Support subordinate ACC units with various approaches to visualize and make sense of complex unstructured data.<br><br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li>Bachelor’s degree in Mathematics, Computer Science, Engineering, or a similar field (6 years’ experience can substitute for degree)</li><li>8+ years of experience related to position requirements</li><li>3 years of experience as a Data Engineer or similar role</li><li>Experience with one of the following: R, Python or SQL</li><li>Demonstrated strength in data modeling, data-pipelines development, data warehousing and solving big data challenges</li><li>Experience using relevant AF systems and relational databases</li><li>Experience working with cloud computing and infrastructure (AWS, Azure, etc)</li><li><strong>Active TS/SCI government security clearance<br><br></strong></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Advanced degree in Mathematics, Computer Science or Engineering.</li><li>Experience working with Jira and Confluence</li><li>Experience with Air Force ISR units</li><li>DoD 8570 IAT Level II Compliant</li><li>Experience using business intelligence reporting tools (Tableau, Power BI, etc)<br><br></li></ul><strong><u>External Referral Bonus<br><br></u></strong>Eligible<br><br><strong><u>Potential For Telework<br><br></u></strong>No<br><br><strong><u>Clearance Level Required<br><br></u></strong>Top Secret/SCI<br><br><strong><u>Travel<br><br></u></strong>Yes, 10% of the time<br><br><strong><u>Scheduled Weekly Hours<br><br></u></strong>40<br><br><strong><u>Shift<br><br></u></strong>Day<br><br><strong><u>Requisition Category<br><br></u></strong>Professional<br><br><strong><u>Job Family<br><br></u></strong>Database Management<br><br><strong><u>Pay Range<br><br></u></strong>Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world’s toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company’s 38,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Va., Leidos reported annual revenues of approximately $11.09 billion for the fiscal year ended January 3, 2020. For more information, visit www.Leidos.com.<br><br>Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.<br><br>Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.<br><br>All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Data Engineer,"Chicago, Illinois, United States",Practifi,2021-02-02,https://www.linkedin.com/jobs/view/data-engineer-at-practifi-2408234784?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=VzBo%2FM0TV8SXyzK6WAaiZQ%3D%3D&position=14&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Guild is hiring an Analytics Engineer who will sit at the intersection of data, infrastructure, and analytics, to help shape and deliver valuable data and business-critical reporting and insights for Guild. You will be responsible for organizing, standardizing, and analyzing our data to enable Guild’s Analytical efforts. This role will have a critical impact on the business and our students by surfacing valuable data and providing visibility into opportunities for improvement across all aspects of our business.

As An Analytics Engineer, You Will

Develop a deep understanding of business and operational needs by building strong relationships across the teams who manage and utilize Guild’s data.
Support Guild’s Analytics teams by creating, maintaining, and improving insightful reporting which enables our business partners to access actionable, insightful data to drive decision making.
Partner with Data Services teams to deliver clear, accurate analytical datasets which drive high-quality reporting, including creation of production-quality code base.
Perform in-depth data QA by diving in to various data sources to identify and resolve issues
Maintain and manage an intake of requests from stakeholders, understanding the priority and impact of various reporting requests, and managing expectations for delivery.
Translate business questions into technical requirements as part of a well-defined development cycle.
Act as subject matter expert for Looker within the Analytics team, supporting team members in troubleshooting issues that arise.
Implement and maintain robust governance and oversight processes to ensure accuracy and continuity of critical data sources and reporting.


As a member of the Data Science and Research team, in this role you will collaborate with other Guild data experts, including: Jack Chang (Senior Manager - BI Infrastructure), Tom Hlavaty (Senior Manager of Data Infrastructure), Myranda Swartzwelter (Senior Analytics Engineer), and Molly Sloane (Senior Analytics Engineer).

You are a strong fit for this role if you have:

3+ years of full-time work experience as an analytics engineer, data analyst, BI analyst, data engineer or similar
Highly skilled in SQL, and experienced in a scripting language (e.g. Python, R).
Experience with ETL processes to transform data, set up and schedule jobs in DBT and similar tools.
Hands-on experience with data model development and reporting in data visualization tools such as Looker or Tableau.
Familiarity with Data Engineering best practices
Demonstrated attention to detail and commitment to data quality and reporting accuracy.
Analytical, intellectually curious, creative problem-solver who is comfortable going beyond data access to analytics and strategic insights.
Keen design and data visualization skills – you know how to transform data to generate useful insights and be easily digestible.
Team player mindset, with strong interpersonal and influencing skills.
Passion for our mission – Guild is pioneering a new path for education as a benefit in a complicated and regulated space – success means quickly and effectively adapting your expertise.



Preferred Competencies

Analytics and reporting experience in a B2B sales environment
Demonstrated experience building insightful reporting in Looker
In-depth understanding and application of Data Engineering best practices
Something else? Wonderful, we're curious to learn more about you!



About Guild

Guild is increasing economic mobility for working adults by partnering with the largest employers in the country to offer education as a benefit to their employees via our marketplace of nonprofit universities and education institutions. Guild’s proprietary technology platform facilitates the administration of this innovative benefit and our team of coaches helps each employee navigate the path back to school, providing individualized support from day one through program completion.

We are one of the few female-led companies to hit a $1 billion valuation and the only Certified B Corporation with those qualifications. Our Series D financing round was led by Ken Chenault , General Catalyst Partners chairman and former CEO of AMEX, and joined by Emerson Collective, LeadEdge Capital, and Iconiq.

Guild Education is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Additionally, we feel passionately about equal pay for equal work, and transparency in compensation is one vehicle to achieve that. Total compensation for this role is market competitive, including a base salary range of $80,000 - $95,000, as well as company stock options.

Access to low-cost, high-quality health care options through Cigna and Kaiser (due to coverage limitations, Kaiser is currently only available in CA & CO)
Access to a 401k to help save for your future
3 weeks of vacation in your first year and an open vacation policy after year 1 to help you recharge
8 days of fully-paid sick leave, so that you can take the time to heal and or recover
Family-friendly benefits, including 14 weeks of parental leave, employer-paid short-term and long-term disability, employer-sponsored life insurance, and fertility care benefits.
Well-rounded wellness benefits including access to free and low cost mental health resources and support services
Education benefits and tuition assistance to help your future development and growth
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Guild is hiring an <strong>Analytics Engineer </strong> who will sit at the intersection of data, infrastructure, and analytics, to help shape and deliver valuable data and business-critical reporting and insights for Guild. You will be responsible for organizing, standardizing, and analyzing our data to enable Guild’s Analytical efforts. This role will have a critical impact on the business and our students by surfacing valuable data and providing visibility into opportunities for improvement across all aspects of our business.<br><br><strong><u>As An Analytics Engineer, You Will<br></u></strong><ul> <li> Develop a deep understanding of business and operational needs by building strong relationships across the teams who manage and utilize Guild’s data. </li> <li> Support Guild’s Analytics teams by creating, maintaining, and improving insightful reporting which enables our business partners to access actionable, insightful data to drive decision making. </li> <li> Partner with Data Services teams to deliver clear, accurate analytical datasets which drive high-quality reporting, including creation of production-quality code base. </li> <li> Perform in-depth data QA by diving in to various data sources to identify and resolve issues </li> <li> Maintain and manage an intake of requests from stakeholders, understanding the priority and impact of various reporting requests, and managing expectations for delivery. </li> <li> Translate business questions into technical requirements as part of a well-defined development cycle. </li> <li> Act as subject matter expert for Looker within the Analytics team, supporting team members in troubleshooting issues that arise. </li> <li> Implement and maintain robust governance and oversight processes to ensure accuracy and continuity of critical data sources and reporting. </li> <br></ul>As a member of the Data Science and Research team, in this role you will collaborate with other Guild data experts, including: Jack Chang (Senior Manager - BI Infrastructure), Tom Hlavaty (Senior Manager of Data Infrastructure), Myranda Swartzwelter (Senior Analytics Engineer), and Molly Sloane (Senior Analytics Engineer).<br><br><strong>You are a strong fit for this role if you have:<br></strong><ul> <li> 3+ years of full-time work experience as an analytics engineer, data analyst, BI analyst, data engineer or similar </li> <li> Highly skilled in SQL, and experienced in a scripting language (e.g. Python, R). </li> <li> Experience with ETL processes to transform data, set up and schedule jobs in DBT and similar tools. </li> <li> Hands-on experience with data model development and reporting in data visualization tools such as Looker or Tableau. </li> <li> Familiarity with Data Engineering best practices </li> <li> Demonstrated attention to detail and commitment to data quality and reporting accuracy. </li> <li> Analytical, intellectually curious, creative problem-solver who is comfortable going beyond data access to analytics and strategic insights. </li> <li> Keen design and data visualization skills – you know how to transform data to generate useful insights and be easily digestible. </li> <li> Team player mindset, with strong interpersonal and influencing skills. </li> <li> Passion for our mission – Guild is pioneering a new path for education as a benefit in a complicated and regulated space – success means quickly and effectively adapting your expertise. </li> <br><br></ul><strong><u>Preferred Competencies<br></u></strong><ul> <li> Analytics and reporting experience in a B2B sales environment </li> <li> Demonstrated experience building insightful reporting in Looker </li> <li> In-depth understanding and application of Data Engineering best practices </li> <li> Something else? Wonderful, we're curious to learn more about you! </li> <br><br></ul><strong><u>About Guild<br><br></u></strong>Guild is increasing economic mobility for working adults by partnering with the largest employers in the country to offer education as a benefit to their employees via our marketplace of nonprofit universities and education institutions. Guild’s proprietary technology platform facilitates the administration of this innovative benefit and our team of coaches helps each employee navigate the path back to school, providing individualized support from day one through program completion.<br><br>We are one of the few female-led companies to hit a $1 billion valuation and the only Certified B Corporation with those qualifications. Our Series D financing round was led by Ken Chenault , General Catalyst Partners chairman and former CEO of AMEX, and joined by Emerson Collective, LeadEdge Capital, and Iconiq.<br><br>Guild Education is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Additionally, we feel passionately about equal pay for equal work, and transparency in compensation is one vehicle to achieve that. Total compensation for this role is market competitive, including a base salary range of $80,000 - $95,000, as well as company stock options.<br><ul> <li> Access to low-cost, high-quality health care options through Cigna and Kaiser (due to coverage limitations, Kaiser is currently only available in CA &amp; CO) </li> <li> Access to a 401k to help save for your future </li> <li> 3 weeks of vacation in your first year and an open vacation policy after year 1 to help you recharge </li> <li> 8 days of fully-paid sick leave, so that you can take the time to heal and or recover </li> <li> Family-friendly benefits, including 14 weeks of parental leave, employer-paid short-term and long-term disability, employer-sponsored life insurance, and fertility care benefits. </li> <li> Well-rounded wellness benefits including access to free and low cost mental health resources and support services </li> <li> Education benefits and tuition assistance to help your future development and growth</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Computer Software, Internet, Financial Services"
Data Scientist - SC,"Chicago, Illinois, United States",United Airlines,2021-01-23,https://www.linkedin.com/jobs/view/data-scientist-sc-at-united-airlines-2392480158?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=xSz3Zijt00zdOCA8jZqtpw%3D%3D&position=15&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"We are a global SaaS WealthTech scale-up with offices in Chicago, USA and Sydney, Australia, powering growing financial advice firms around the world. Practifi is secure, reliable and massively scalable.

We are looking for a Data Engineer to join our Chicago team to support our massive client growth. This role is primarily focused on analysing, transforming and migrating CRM-based data from a diverse range of source systems into the Salesforce.com platform underpinning Practifi. This is a client facing role within an internal consulting group so if you’re wanting to extend your reach from pure technical to include client engagement, this is the perfect opportunity.

As a Data Engineer at Practifi, your primary responsibilities will include data strategy, data profiling & mapping, data migration, and continuous client communication.

What You'll Be Doing

Reporting to the Onboarding Manager and working closely with the Sales, Professional Services and Client Success teams to understand client and data requirements needed to support successful and smooth solution implementations.
Leverage your existing system and process analysis skills to produce data strategies that create a seamless and uninterrupted experience for our clients.
Collaborating with clients to successfully map source data to the Practifi data model.
Leverage the Salesforce ecosystem and industry leading tools to extract, transform and load data.
Perform data profiling tasks to collect statistics, trends, impacts, and summaries that lead to a structured and successful implementation.
Provide key insights based on data analytics to aid the client in drawing conclusions as to the business value and impact of their data and best approaches for migrating and transforming data to support new system architectures.
Work with the Onboarding Manager to provide regular status updates to internal and external stakeholders.


About You

2+ years previous experience working in a similar data- focused role.
2+ years experience transforming data in scripting languages (such as Python) or database systems or SQL.
Adept in the use of ETL products & technologies.
Some experience working on the Salesforce platform is ideal.
Experience working with APEX Data Loader a plus.
Previous experience in the Financial Advice/ RIA industry a plus.
Desire to work in a consulting environment with active client engagement.


Benefits

20 days paid vacation per year.
3 'Practifi' days per year.
401k match.
Health benefits.
Casual dress code.
Opportunity to collaborate with the team in Sydney, Australia

Practifi is a fun, and hugely dynamic environment with an awesome culture, incredible benefits and a fast pace. If you’re ready to push hard into the next big phase of your data career talk to us!

This is a permanent, full-time position based in Practifi’s Chicago, Illinois office.

Practifi’s success depends on a strong commitment to diversity, equity and inclusion. We encourage applicants from all backgrounds. Practifi is an equal opportunity employer. Practifi does not discriminate against any applicant for employment due to age, color, sex, disability, national origin, race, religion, veteran status, or any other protected class.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We are a global SaaS WealthTech scale-up with offices in Chicago, USA and Sydney, Australia, powering growing financial advice firms around the world. Practifi is secure, reliable and massively scalable.<br><br>We are looking for a Data Engineer to join our Chicago team to support our massive client growth. This role is primarily focused on analysing, transforming and migrating CRM-based data from a diverse range of source systems into the Salesforce.com platform underpinning Practifi. This is a client facing role within an internal consulting group so if you’re wanting to extend your reach from pure technical to include client engagement, this is the perfect opportunity.<br><br>As a Data Engineer at Practifi, your primary responsibilities will include data strategy, data profiling &amp; mapping, data migration, and continuous client communication.<br><br><strong> What You'll Be Doing <br></strong><ul><li>Reporting to the Onboarding Manager and working closely with the Sales, Professional Services and Client Success teams to understand client and data requirements needed to support successful and smooth solution implementations. </li><li>Leverage your existing system and process analysis skills to produce data strategies that create a seamless and uninterrupted experience for our clients. </li><li>Collaborating with clients to successfully map source data to the Practifi data model. </li><li>Leverage the Salesforce ecosystem and industry leading tools to extract, transform and load data. </li><li>Perform data profiling tasks to collect statistics, trends, impacts, and summaries that lead to a structured and successful implementation.</li><li>Provide key insights based on data analytics to aid the client in drawing conclusions as to the business value and impact of their data and best approaches for migrating and transforming data to support new system architectures.</li><li>Work with the Onboarding Manager to provide regular status updates to internal and external stakeholders. <br><br></li></ul><strong> About You <br></strong><ul><li>2+ years previous experience working in a similar data- focused role.</li><li>2+ years experience transforming data in scripting languages (such as Python) or database systems or SQL.</li><li>Adept in the use of ETL products &amp; technologies.</li><li>Some experience working on the Salesforce platform is ideal.</li><li>Experience working with APEX Data Loader a plus.</li><li>Previous experience in the Financial Advice/ RIA industry a plus.</li><li>Desire to work in a consulting environment with active client engagement.<br><br></li></ul><strong> Benefits <br></strong><ul><li>20 days paid vacation per year.</li><li>3 'Practifi' days per year.</li><li>401k match.</li><li>Health benefits.</li><li>Casual dress code.</li><li>Opportunity to collaborate with the team in Sydney, Australia<br></li></ul>Practifi is a fun, and hugely dynamic environment with an awesome culture, incredible benefits and a fast pace. If you’re ready to push hard into the next big phase of your data career talk to us!<br><br>This is a permanent, full-time position based in Practifi’s Chicago, Illinois office.<br><br>Practifi’s success depends on a strong commitment to diversity, equity and inclusion. We encourage applicants from all backgrounds. Practifi is an equal opportunity employer. Practifi does not discriminate against any applicant for employment due to age, color, sex, disability, national origin, race, religion, veteran status, or any other protected class.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Coppell, Texas, United States",Scalable,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-scalable-2288641064?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=yZKtEVJRRxSFqf928AU0Jw%3D%3D&position=16&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"We have a wide variety of career opportunities around the world — come find yours

Digital Products and Analytics

This Digital Products and Analytics department consists of merchandising, digital marketing/personalization, data insights and optimization, visualization, UX digital products, data analytics, and more.

Job Overview And Responsibilities

The Data Scientist will collaborate with the Analytics Products team and business SMEs to deliver machine learning solutions and provide consulation on machine learning techniques and technology. Our Analytics Products group is a global team energetic about using data to develop products or data-driven strategic solutions across United Airlines. We partner with subject matter experts across the business to build solutions for a wide variety of commercial and operations use cases. As a team, we focus on projects that drive strong financials, deliver improved customer experiences, and support employee engagement. The data science team within Analytics Products focuses on predictive modeling, particularly with complex data, such as unstructured image and text, signal, and time series data. 

Prepare data and develop predictive models & present findings
Research tools and techniques for data science at United
Act as SME in data science and machine learning for other groups


Required

BA/BS in quantitative field
1+ year of professional data science or predictive modeling work with bachelors in statistics or master's degree in quantitative field if making career transition
Please share GitHub repository and/or be prepared to speak in detail about project work
Strong knowledge of Python (R, object-oriented programming is a plus)
SQL querying (joins, subqueries, window functions) required
Understanding of basic statistical methods (t-tests, ANOVA, power analysis, A/B testing) required
Fundamentals of data cleaning and preparation (Pandas, dplyr, etc.) required
Strong oral and written communication skills, especially relating to explaining algorithms and modeling techniques
Ability to develop and execute project plan from conception to delivery
Focus on value-add opportunities for the business using data science techniques
Ability to take ownership of work product and initiative to work across organization with SMEs and stakeholders
Demonstrated intellectual curiosity with data and comfort with ambiguity
Must be legally authorized to work in the United States for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position



Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT

WHQ00018435
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">We have a wide variety of career opportunities around the world — come find yours<br><br><strong>Digital Products and Analytics <br><br></strong>This Digital Products and Analytics department consists of merchandising, digital marketing/personalization, data insights and optimization, visualization, UX digital products, data analytics, and more.<br><br><strong><u>Job Overview And Responsibilities<br><br></u></strong>The Data Scientist will collaborate with the Analytics Products team and business SMEs to deliver machine learning solutions and provide consulation on machine learning techniques and technology. Our Analytics Products group is a global team energetic about using data to develop products or data-driven strategic solutions across United Airlines. We partner with subject matter experts across the business to build solutions for a wide variety of commercial and operations use cases. As a team, we focus on projects that drive strong financials, deliver improved customer experiences, and support employee engagement. The data science team within Analytics Products focuses on predictive modeling, particularly with complex data, such as unstructured image and text, signal, and time series data. <br><ul><li>Prepare data and develop predictive models &amp; present findings </li><li>Research tools and techniques for data science at United </li><li>Act as SME in data science and machine learning for other groups<br><br></li></ul><strong><u>Required<br></u></strong><ul> <li>BA/BS in quantitative field</li> <li>1+ year of professional data science or predictive modeling work with bachelors in statistics or master's degree in quantitative field if making career transition </li> <li>Please share GitHub repository and/or be prepared to speak in detail about project work </li> <li>Strong knowledge of Python (R, object-oriented programming is a plus) </li> <li>SQL querying (joins, subqueries, window functions) required </li> <li>Understanding of basic statistical methods (t-tests, ANOVA, power analysis, A/B testing) required</li> <li>Fundamentals of data cleaning and preparation (Pandas, dplyr, etc.) required</li> <li>Strong oral and written communication skills, especially relating to explaining algorithms and modeling techniques </li> <li>Ability to develop and execute project plan from conception to delivery </li> <li>Focus on value-add opportunities for the business using data science techniques </li> <li>Ability to take ownership of work product and initiative to work across organization with SMEs and stakeholders </li> <li>Demonstrated intellectual curiosity with data and comfort with ambiguity </li> <li>Must be legally authorized to work in the United States for any employer without sponsorship</li> <li>Successful completion of interview required to meet job qualification</li> <li>Reliable, punctual attendance is an essential function of the position</li> <br><br></ul><em><strong>Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT<br><br></strong></em>WHQ00018435</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,General Business,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Baltimore, Maryland, United States",Delfi Diagnostics,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-delfi-diagnostics-2427397928?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=L8wKh3scDzQdiksi6OcqJw%3D%3D&position=17&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Scalable builds world-class physical and software infrastructure to help entrepreneurs compete against today’s giants in ecommerce. By building world-class physical and software infrastructure, we will democratize ecommerce infrastructure and empower companies of any size to compete in today’s ecommerce.

Do you want to work at a company where you are encouraged to build and have the autonomy to push boundaries? Invention has become second nature at Scalable, the pace of innovation is only accelerating, and the breadth of our businesses expanding. Scalable's growth requires leaders who move fast, have an entrepreneurial spirit, unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems.

We’re looking for an experienced Data Engineer to help deliver critical business intelligence through our data warehouse (Redshift) and data lake (AWS S3). Our Data Engineering team handles all aspects of managing our batched and real-time data pipelines from four e-commerce products.

This position is responsible for understanding stakeholders requirements and building out ETL from variety of data sources (Mongo, MySQL, Kafka, ElasticSearch, Third Party REST APIs, etc).

Requirements

2+ years of data engineering experience.
Regularly processes TBs of data quickly with cloud based distributed solutions.
Robust experience with Spark, Redshift, Python and Jenkins.
Experience writing and executing complex SQL queries.
Experience building data pipelines and ETL design (implementation and maintenance).
Experience with AWS or other cloud provider.
Scrum/Agile software development process.



Preferred

Experience with data technologies, Hadoop, Hive, Postgres, Kafka, Solr.
Deep understanding of AWS services: EMR, S3, Redshift and Terraform.
Operational experience with Jenkins or Airflow.
Proficiency in using BI dashboard tools.
Analytical experience debugging slow queries and scripts.



Benefits & Perks

Above market compensation package
Career growth opportunities
Global working environment
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Scalable</strong> builds world-class physical and software infrastructure to help entrepreneurs compete against today’s giants in ecommerce. By building world-class physical and software infrastructure, we will democratize ecommerce infrastructure and empower companies of any size to compete in today’s ecommerce.<br><br>Do you want to work at a company where you are encouraged to build and have the autonomy to push boundaries? Invention has become second nature at Scalable, the pace of innovation is only accelerating, and the breadth of our businesses expanding. Scalable's growth requires leaders who move fast, have an entrepreneurial spirit, unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems.<br><br>We’re looking for an experienced Data Engineer to help deliver critical business intelligence through our data warehouse (Redshift) and data lake (AWS S3). Our Data Engineering team handles all aspects of managing our batched and real-time data pipelines from four e-commerce products.<br><br>This position is responsible for understanding stakeholders requirements and building out ETL from variety of data sources (Mongo, MySQL, Kafka, ElasticSearch, Third Party REST APIs, etc).<br><br><strong><u>Requirements<br></u></strong><ul> <li>2+ years of data engineering experience.</li> <li>Regularly processes TBs of data quickly with cloud based distributed solutions.</li> <li>Robust experience with Spark, Redshift, Python and Jenkins.</li> <li>Experience writing and executing complex SQL queries.</li> <li>Experience building data pipelines and ETL design (implementation and maintenance).</li> <li>Experience with AWS or other cloud provider.</li> <li>Scrum/Agile software development process.</li> <br><br></ul><strong><u>Preferred<br></u></strong><ul> <li>Experience with data technologies, Hadoop, Hive, Postgres, Kafka, Solr.</li> <li>Deep understanding of AWS services: EMR, S3, Redshift and Terraform.</li> <li>Operational experience with Jenkins or Airflow.</li> <li>Proficiency in using BI dashboard tools.</li> <li>Analytical experience debugging slow queries and scripts.</li> <br><br></ul><strong><u>Benefits &amp; Perks<br></u></strong><ul> <li> Above market compensation package</li> <li> Career growth opportunities</li> <li> Global working environment</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Information Technology, Engineering",Full-time,"Marketing and Advertising, Computer Software, Internet"
Big Data Engineer,"New Jersey, United States",SGA Inc.,2021-02-19,https://www.linkedin.com/jobs/view/big-data-engineer-at-sga-inc-2430314220?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=VHYKQe7aBqXmhDfo3g2pkQ%3D%3D&position=18&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Data Scientist




Job Summary




Delfi Diagnostics is a Baltimore-based startup focused on the non-invasive detection of cancer at earlier stages, when it is most curable. DELFI uses artificial intelligence and whole genome sequencing to detect unique patterns of DNA fragmentation in the blood of patients with cancer. These analyses are performed through simultaneous examination of millions of DNA sequences using machine learning to identify tumor-specific abnormalities. 




The data scientist will work with a cross-functional team of bioinformatics scientists, clinicians, engineers, and other data scientists to analyze genomic and clinical data of individuals diagnosed with and at risk of cancer. This position will develop and implement machine learning models that are informed by an understanding of cancer biology. These models will be used to make predictions about a variety of clinical characteristics, including optimizing our ability to detect cancer early. This work will culminate in the development of products with the potential for clinical impact.




[Full time role in Baltimore (preferred) or San Francisco Bay Area, remote location may be considered for strong candidates]




Responsibilities




Develop machine learning models to make accurate predictions about cancer and other clinical characteristics
Perform feature engineering by working with researchers to establish representations of whole genome sequencing (WGS) data that reflect cancer-driven changes
Understand and model technical variation inherent in cell-free DNA and WGS.
Perform end-to-end analyses that include data gathering, processing, analysis, and presentation of results.
Develop reproducible analyses using Rmarkdown, Jupyter Notebook, etc and version control using Git
Communicate complex results to a variety of audiences leveraging visualizations, reports and presentations
Work with our lab team to design and analyze experiments to understand impact of laboratory and biological conditions on classification performance
Collaborate with engineers to implement improvements into our bioinformatics pipeline




Requirements




MS or PhD in biostatistics, statistics, applied math or a related field with 3+ years of industry experience or post-doc
Excellent foundation in statistical and computational foundations of machine learning, including bagging, boosting, and approaches for cross-validation
 Proven ability to apply statistical methods to solve prediction and inference problems and implement practical solutions
Experience with data analysis and visualization using R and/or python, with a demonstrated ability to apply these skills to relevant scientific problems
Experience with common data science toolkits and libraries, such as R/caret/tidyverse, or Python/scikit-learn/pandas
Great verbal and written communication skills
Desire to learn about cancer genetics and contribute to a collaborative and mutually respectful working environment




Preferred




Knowledge of cancer genomics
Expertise in computational analysis of high-throughput technologies in genomics, especially with cfDNA
Experience with high-performance computing and knowledge of Linux
Demonstrated ability to uncover new biological insights from large genomics datasets




Delfi’s Culture

﻿

Commitment to high quality and technical excellence
Desire to improve patient care
Respect for diversity of opinions, backgrounds and experiences




Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><p><strong>Data Scientist</strong></p><p><br></p><p><strong>Job Summary</strong></p><p><br></p><p>Delfi Diagnostics is a Baltimore-based startup focused on the non-invasive detection of cancer at earlier stages, when it is most curable. DELFI uses artificial intelligence and whole genome sequencing to detect unique patterns of DNA fragmentation in the blood of patients with cancer. These analyses are performed through simultaneous examination of millions of DNA sequences using machine learning to identify tumor-specific abnormalities.&nbsp;</p><p><br></p><p>The data scientist will work with a cross-functional team of bioinformatics scientists, clinicians, engineers, and other data scientists to analyze genomic and clinical data of individuals diagnosed with and at risk of cancer. This position will develop and implement machine learning models that are informed by an understanding of cancer biology. These models will be used to make predictions about a variety of clinical characteristics, including optimizing our ability to detect cancer early. This work will culminate in the development of products with the potential for clinical impact.</p><p><br></p><p>[Full time role in Baltimore (preferred) or San Francisco Bay Area, remote location may be considered for strong candidates]</p><p><br></p><p><strong>Responsibilities</strong></p><p><br></p><ul><li>Develop machine learning models to make accurate predictions about cancer and other clinical characteristics</li><li>Perform feature engineering by working with researchers to establish representations of whole genome sequencing (WGS) data that reflect cancer-driven changes</li><li>Understand and model technical variation inherent in cell-free DNA and WGS.</li><li>Perform end-to-end analyses that include data gathering, processing, analysis, and presentation of results.</li><li>Develop reproducible analyses using Rmarkdown, Jupyter Notebook, etc and version control using Git</li><li>Communicate complex results to a variety of audiences leveraging visualizations, reports and presentations</li><li>Work with our lab team to design and analyze experiments to understand impact of laboratory and biological conditions on classification performance</li><li>Collaborate with engineers to implement improvements into our bioinformatics pipeline</li></ul><p><br></p><p><strong>Requirements</strong></p><p><br></p><ul><li>MS or PhD in biostatistics, statistics, applied math or a related field with 3+ years of industry experience or post-doc</li><li>Excellent foundation in statistical and computational foundations of machine learning, including bagging, boosting, and approaches for cross-validation</li><li>&nbsp;Proven ability to apply statistical methods to solve prediction and inference problems and implement practical solutions</li><li>Experience with data analysis and visualization using R and/or python, with a demonstrated ability to apply these skills to relevant scientific problems</li><li>Experience with common data science toolkits and libraries, such as R/caret/tidyverse, or Python/scikit-learn/pandas</li><li>Great verbal and written communication skills</li><li>Desire to learn about cancer genetics and contribute to a collaborative and mutually respectful working environment</li></ul><p><br></p><p><strong>Preferred</strong></p><p><br></p><ul><li>Knowledge of cancer genomics</li><li>Expertise in computational analysis of high-throughput technologies in genomics, especially with cfDNA</li><li>Experience with high-performance computing and knowledge of Linux</li><li>Demonstrated ability to uncover new biological insights from large genomics datasets</li></ul><p><br></p><p><strong>Delfi’s Culture</strong></p><p><strong><span class=""ql-cursor"">﻿</span></strong></p><ul><li>Commitment to high quality and technical excellence</li><li>Desire to improve patient care</li><li>Respect for diversity of opinions, backgrounds and experiences</li></ul><p><br></p></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,Biotechnology
Data Engineer,"Denver, Colorado, United States",JumpCloud,2021-02-04,https://www.linkedin.com/jobs/view/data-engineer-at-jumpcloud-2408693988?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=bMH0Aikq401QzLYzJRbURg%3D%3D&position=19&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Software Guidance & Assistance, Inc., (SGA), is searching for a Big Data Developer for a Contract assignment with one of our premier Financial Services clients in Princeton, NJ (Remote start).

Responsibilities

Work on applications that enable traders, product controllers and risk managers across the business to analyze and report on massive amounts of risk and P&L data.
Aide in the development and support a graph-based calculation layer (QCF) which enables on-demand risk and scenario calculations to both front office and risk management users
Joining the team as a big data store engineer and help to evolve the platform to manage the broad challenges which arise from being core to the future of the Banks Markets business.



Required Skills

Big data stack Design/Development experience across multiple environments.
Development and tuning experience with Oracle Coherence, HBase, and HDFS
Solid understanding of server-side Java, API-driven development.
Ability to work with Ops and Engineering teams.
Extensive experience with back-end, distributed systems
Collaborate in a global team environment on application design and feature enhancements.
Understanding and implementation of security and data protection.
Experience with administrative/DevOps tooling like Puppet, scripting languages (shell, Python, etc.), TeamCity, etc.
Prior experience in the financial services sector, and risk technology, is a benefit.
Preferred Skills:

JVM monitoring, profiling, performance tuning and debugging.
Apache Spark (or similar analysis tools).
Experience with Amazon Web Services or Microsoft Azure.
Experience deploying containers in production, preferably using Kubernetes for orchestration.


SGA is a Certified Women's Business Enterprise (WBE) celebrating over thirty years of service to our national client base for both permanent placement and consulting opportunities. For consulting positions, we offer a variety of benefit options including but not limited to health & dental insurance, paid vacation, timely payment via direct deposit. SGA accepts transfers of H1 sponsorship for most contracting roles. We are unable to sponsor for Right-to-Hire, Fulltime, or Government roles. All parties authorized to work in the US are encouraged to apply for all roles. Only those authorized to work for government entities will be considered for government roles. Please inquire about our referral program if you would like to submit a candidate for any of our open or future job opportunities. SGA is an EEO employer. We encourage Veterans to apply. To view all of our available job postings and/or to learn more about SGA please visit us online at www.sgainc.com.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Software Guidance &amp; Assistance, Inc., (SGA), is searching for a <strong>Big Data</strong> <strong>Developer</strong> for a <strong>Contract</strong> assignment with one of our premier <strong>Financial Services</strong> clients in <strong>Princeton, NJ (Remote start)</strong>.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Work on applications that enable traders, product controllers and risk managers across the business to analyze and report on massive amounts of risk and P&amp;L data.</li> <li>Aide in the development and support a graph-based calculation layer (QCF) which enables on-demand risk and scenario calculations to both front office and risk management users</li> <li>Joining the team as a big data store engineer and help to evolve the platform to manage the broad challenges which arise from being core to the future of the Banks Markets business.</li> <br><br></ul><strong><u>Required Skills<br></u></strong><ul> <li>Big data stack Design/Development experience across multiple environments.</li> <li>Development and tuning experience with Oracle Coherence, HBase, and HDFS</li> <li>Solid understanding of server-side Java, API-driven development.</li> <li>Ability to work with Ops and Engineering teams.</li> <li>Extensive experience with back-end, distributed systems</li> <li>Collaborate in a global team environment on application design and feature enhancements.</li> <li>Understanding and implementation of security and data protection.</li> <li>Experience with administrative/DevOps tooling like Puppet, scripting languages (shell, Python, etc.), TeamCity, etc.</li> <li>Prior experience in the financial services sector, and risk technology, is a benefit.</li> </ul> <strong>Preferred</strong> <strong>Skills</strong>:<br><ul> <li>JVM monitoring, profiling, performance tuning and debugging.</li> <li>Apache Spark (or similar analysis tools).</li> <li>Experience with Amazon Web Services or Microsoft Azure.</li> <li>Experience deploying containers in production, preferably using Kubernetes for orchestration.</li> <br></ul>SGA is a Certified Women's Business Enterprise (WBE) celebrating over thirty years of service to our national client base for both permanent placement and consulting opportunities. For consulting positions, we offer a variety of benefit options including but not limited to health &amp; dental insurance, paid vacation, timely payment via direct deposit. SGA accepts transfers of H1 sponsorship for most contracting roles. We are unable to sponsor for Right-to-Hire, Fulltime, or Government roles. All parties authorized to work in the US are encouraged to apply for all roles. Only those authorized to work for government entities will be considered for government roles. Please inquire about our referral program if you would like to submit a candidate for any of our open or future job opportunities. SGA is an EEO employer. We encourage Veterans to apply. To view all of our available job postings and/or to learn more about SGA please visit us online at www.sgainc.com.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Financial Services"
Scientific Data Engineer,"San Francisco, California, United States",NGM Biopharmaceuticals,2021-02-19,https://www.linkedin.com/jobs/view/scientific-data-engineer-at-ngm-biopharmaceuticals-2430333763?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=PfKqz7ddl%2FZPueApMiYmJg%3D%3D&position=21&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"NGM Biopharmaceuticals, Inc. is a biopharmaceutical company dedicated to discovering and developing the next generation of medicines for the treatment of serious diseases. Our experienced scientific team has joined forces with an impressive group of industry professionals, Nobel Laureates and other distinguished researchers to build a company where innovation and cutting-edge science has provided the foundation for a robust drug discovery engine that has a track record of generating one new IND candidate per year. NGM’s current pipeline of clinical-stage programs consists of five drug candidates targeting liver and metabolic diseases, retinal diseases and cancer. The most advanced drug candidate, aldafermin (NGM282), is in Phase 2b clinical studies in non-alcoholic steatohepatitis (NASH) and is wholly-owned by NGM. Another drug candidate, NGM621, is in a Phase 2 study in geographic atrophy (GA) secondary to age-related macular degeneration (AMD). NGM’s strategic collaboration with Merck, with a current term running to March 2022, provides us with the resources and flexibility to pursue our ambitious R&D goals and further extend our pipeline of novel drug candidates.

NGM is excited to hire a Data Engineer to assist our scientists in discovering important medicines. The core focus of this role is to design and manage systems for storing, analyzing, and visualizing complex data from across our R&D functions. This position is perfect for an informatics specialist who appreciates biologists; please apply if you’re intrinsically motivated by the value of data in solving complex drug discovery problems.

Responsibilities

Enable the discovery of disease modifying therapies for highly unmet medical needs by planning, building, maintaining, and running enterprise-level lab information management solutions, including the Dotmatics suite
Collaborate with stakeholders from different scientific functions to customize informatics solutions including querying, data retrieval, and visualization; tools used to do this will likely be SQL, Python, and R
Help guide the overall strategy for scientific data governance, quality, and retention
Write advanced SQL queries using relational database concepts and schema design principles
Support data customers in understanding information content and context, generating fit-for-purpose datasets, and providing training and technical support for our Electronic Lab Notebook system (ELN)
Evaluate systems to accommodate ongoing and future data management needs
Maintain expertise and knowledge of technology and informatics trends in our industry, assessing and identifying new opportunities for data management and workflow enhancements to advance drug discovery efforts
Requirements

Bachelor’s Degree or higher, with substantive course/project work in computer science or data science
Experience designing, customizing, and managing databases and/or software associated with laboratory data (such as LIMS or ELN)
Demonstrated experience organizing and enabling the analysis of complex data (ideally using SQL, Python, R, or related programming languages)
Intrinsically motivated by the opportunity presented by informatics to transform the R&D process
Experience in a Pharmaceutical/Industrial chemistry/Biotech environment highly desirable
Interested applicants should apply through the NGM Biopharmaceuticals website: https://www.ngmbio.com/open-positions/

We have become aware of false offers of employment being made by individuals impersonating NGM representatives in order to collect personal information and/or payment. Please exercise caution when receiving unsolicited recruiting offers. NGM always lists all open positions on the NGM careers page and all employment applications must be submitted through our online portal. NGM will never solicit payment or payment information from candidates. Please be advised that NGM is not currently hiring in any countries other than the US. We never request that candidate information be sent to a non-ngmbio.com email address.

Note to Recruitment Agencies: Please do not forward any agency résumés. NGM Bio is not responsible for any fees related to résumés that are unsolicited.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">NGM Biopharmaceuticals, Inc. is a biopharmaceutical company dedicated to discovering and developing the next generation of medicines for the treatment of serious diseases. Our experienced scientific team has joined forces with an impressive group of industry professionals, Nobel Laureates and other distinguished researchers to build a company where innovation and cutting-edge science has provided the foundation for a robust drug discovery engine that has a track record of generating one new IND candidate per year. NGM’s current pipeline of clinical-stage programs consists of five drug candidates targeting liver and metabolic diseases, retinal diseases and cancer. The most advanced drug candidate, aldafermin (NGM282), is in Phase 2b clinical studies in non-alcoholic steatohepatitis (NASH) and is wholly-owned by NGM. Another drug candidate, NGM621, is in a Phase 2 study in geographic atrophy (GA) secondary to age-related macular degeneration (AMD). NGM’s strategic collaboration with Merck, with a current term running to March 2022, provides us with the resources and flexibility to pursue our ambitious R&amp;D goals and further extend our pipeline of novel drug candidates.<br><br>NGM is excited to hire a Data Engineer to assist our scientists in discovering important medicines. The core focus of this role is to design and manage systems for storing, analyzing, and visualizing complex data from across our R&amp;D functions. This position is perfect for an informatics specialist who appreciates biologists; please apply if you’re intrinsically motivated by the value of data in solving complex drug discovery problems.<br><br><strong> Responsibilities <br></strong><ul><li>Enable the discovery of disease modifying therapies for highly unmet medical needs by planning, building, maintaining, and running enterprise-level lab information management solutions, including the Dotmatics suite</li><li>Collaborate with stakeholders from different scientific functions to customize informatics solutions including querying, data retrieval, and visualization; tools used to do this will likely be SQL, Python, and R</li><li>Help guide the overall strategy for scientific data governance, quality, and retention</li><li>Write advanced SQL queries using relational database concepts and schema design principles</li><li>Support data customers in understanding information content and context, generating fit-for-purpose datasets, and providing training and technical support for our Electronic Lab Notebook system (ELN)</li><li>Evaluate systems to accommodate ongoing and future data management needs</li><li>Maintain expertise and knowledge of technology and informatics trends in our industry, assessing and identifying new opportunities for data management and workflow enhancements to advance drug discovery efforts</li></ul>Requirements<br><ul><li>Bachelor’s Degree or higher, with substantive course/project work in computer science or data science</li><li>Experience designing, customizing, and managing databases and/or software associated with laboratory data (such as LIMS or ELN)</li><li>Demonstrated experience organizing and enabling the analysis of complex data (ideally using SQL, Python, R, or related programming languages)</li><li>Intrinsically motivated by the opportunity presented by informatics to transform the R&amp;D process</li><li>Experience in a Pharmaceutical/Industrial chemistry/Biotech environment highly desirable</li></ul>Interested applicants should apply through the NGM Biopharmaceuticals website: https://www.ngmbio.com/open-positions/<br><br>We have become aware of false offers of employment being made by individuals impersonating NGM representatives in order to collect personal information and/or payment. Please exercise caution when receiving unsolicited recruiting offers. NGM always lists all open positions on the NGM careers page and all employment applications must be submitted through our online portal. NGM will never solicit payment or payment information from candidates. Please be advised that NGM is not currently hiring in any countries other than the US. We never request that candidate information be sent to a non-ngmbio.com email address.<br><br>Note to Recruitment Agencies: Please do not forward any agency résumés. NGM Bio is not responsible for any fees related to résumés that are unsolicited.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Research, Biotechnology, Pharmaceuticals"
Data Engineer,"San Francisco, California, United States",Appen,2021-02-06,https://www.linkedin.com/jobs/view/data-engineer-at-appen-2399384947?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=1Ct84cfXFbofw%2FA6odqpmg%3D%3D&position=22&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Overview

About Appen

The Appen Data Annotation Platform (ADAP) is the essential Human-in-the-Loop Machine Learning platform for data science and machine learning teams. It serves Fortune 500 and fast-growing data-driven organizations across a wide variety of industries, including autonomous vehicles, intelligent personal assistants, medical image labeling, consumer product identification, content categorization, customer support ticket classification, social data insight, CRM data enrichment, product categorization, and search relevance.

About The Role

ADAP users range from engineers and data scientists to subject matter experts creating training data for machine learning. You will be working on the most important problems in technology today: how can humans and AI collaborate to solve important and sometimes complicated tasks?

As a member of our Client Workspace team, you will design, build, and improve on tools used by many widely-known tech companies with large-scale, active machine learning initiatives. This may include collecting and managing training data for AI models, evaluating the performance of the machine learning models used by that data, or building infrastructure and managing data pipelines. Specifically, you will work on a generalized annotation API that consists of both automated and human-driven annotation tools for 2D and 3D images, video, text, and audio data. The platform will combine human input (eg: bounding boxes on objects) and Machine Learning input (eg: automatic object tracking in videos) for maximum efficiency and effectiveness. You will be on a cross-functional team collaborating with members of the Product, Machine Learning, Dev Ops, and Engineering teams.

Your work will consist of implementing new features and services, maintaining infrastructure, and migrating existing services to an event-driven, microservices-based architecture. You’ll mentor less experienced developers and constantly work on improving your own skills and the quality of our codebase. For more about what we build, please visit the Appen Platform Overview .

The Ideal Candidate

You enjoy thinking about and working on enterprise-level data processing systems. You are looking for a company at the epicenter of a rapidly-developing machine learning industry and are driven by a hunger to learn and develop your skills. You are passionate about working on a project that contributes meaningfully to the further development of technology and to humanity as a whole. You care about best practices and you choose the tools you work with judiciously and deliberately. You have strong analytical skills, an unwavering commitment to quality, an open-minded and collaborative work ethic, and cutting-edge coding skills.

Responsibilities / Opportunities

Build & maintain low-latency, high-scalability data pipelines in service of our human-in-the-loop machine learning workflows platform.
Build & maintain adapter services for ingesting data from a wide variety of streaming and batch-based sources.
Build & maintain services for throttling, backpressure, schema management, and normalization.
Implement QA and testing strategies. Promote best practices for writing maintainable code.
Participate in selecting tools and setting development standards at Appen.
Ability/readiness to develop excellent working relationships with a diverse team of peers across organizations (Engineering, QA, DevOps, Product, Design, et al).


Competencies

3-4+ years of software development experience in cloud-based, multi-tiered, enterprise application systems.
3-4+ years managing data platforms/engineering using enterprise service bus or message-based architectures, such as Kafka, Redis, RabbitMQ, or similar.
Hands-on experience with developing microservices and successfully building products using SOA.
Hands-on experience with event-sourcing and functional programming patterns.
Hands-on experience with AWS, Git, Docker, Gradle, Jenkins, Jira, and Confluence.


Nice-to-have Competencies

Familiarity with batch processing and workflow tools such as Airflow, Luigi, Celery, or others
1-2+ years production environment-level experience with Ruby on Rails application development.
Prior production experience with Java, and/or Scala, or Python.
Familiarity with basic machine learning concepts.

Appen offers an attractive total compensation package including outstanding benefits and stock options. Learn more about our company and culture, start here: Appen at a Glance .

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong><strong> About Appen <br><br></strong>The Appen Data Annotation Platform (ADAP) is the essential Human-in-the-Loop Machine Learning platform for data science and machine learning teams. It serves Fortune 500 and fast-growing data-driven organizations across a wide variety of industries, including autonomous vehicles, intelligent personal assistants, medical image labeling, consumer product identification, content categorization, customer support ticket classification, social data insight, CRM data enrichment, product categorization, and search relevance.<br><br><strong><u>About The Role<br><br></u></strong>ADAP users range from engineers and data scientists to subject matter experts creating training data for machine learning. You will be working on the most important problems in technology today: how can humans and AI collaborate to solve important and sometimes complicated tasks?<br><br>As a member of our Client Workspace team, you will design, build, and improve on tools used by many widely-known tech companies with large-scale, active machine learning initiatives. This may include collecting and managing training data for AI models, evaluating the performance of the machine learning models used by that data, or building infrastructure and managing data pipelines. Specifically, you will work on a generalized annotation API that consists of both automated and human-driven annotation tools for 2D and 3D images, video, text, and audio data. The platform will combine human input (eg: bounding boxes on objects) and Machine Learning input (eg: automatic object tracking in videos) for maximum efficiency and effectiveness. You will be on a cross-functional team collaborating with members of the Product, Machine Learning, Dev Ops, and Engineering teams.<br><br>Your work will consist of implementing new features and services, maintaining infrastructure, and migrating existing services to an event-driven, microservices-based architecture. You’ll mentor less experienced developers and constantly work on improving your own skills and the quality of our codebase. For more about what we build, please visit the Appen Platform Overview .<br><br><strong><u>The Ideal Candidate<br><br></u></strong>You enjoy thinking about and working on enterprise-level data processing systems. You are looking for a company at the epicenter of a rapidly-developing machine learning industry and are driven by a hunger to learn and develop your skills. You are passionate about working on a project that contributes meaningfully to the further development of technology and to humanity as a whole. You care about best practices and you choose the tools you work with judiciously and deliberately. You have strong analytical skills, an unwavering commitment to quality, an open-minded and collaborative work ethic, and cutting-edge coding skills.<br><br><strong><u>Responsibilities / Opportunities<br></u></strong><ul><li> Build &amp; maintain low-latency, high-scalability data pipelines in service of our human-in-the-loop machine learning workflows platform. </li><li> Build &amp; maintain adapter services for ingesting data from a wide variety of streaming and batch-based sources. </li><li> Build &amp; maintain services for throttling, backpressure, schema management, and normalization. </li><li> Implement QA and testing strategies. Promote best practices for writing maintainable code. </li><li> Participate in selecting tools and setting development standards at Appen. </li><li> Ability/readiness to develop excellent working relationships with a diverse team of peers across organizations (Engineering, QA, DevOps, Product, Design, et al). <br><br></li></ul><strong><u>Competencies<br></u></strong><ul><li> 3-4+ years of software development experience in cloud-based, multi-tiered, enterprise application systems. </li><li> 3-4+ years managing data platforms/engineering using enterprise service bus or message-based architectures, such as Kafka, Redis, RabbitMQ, or similar. </li><li> Hands-on experience with developing microservices and successfully building products using SOA. </li><li> Hands-on experience with event-sourcing and functional programming patterns. </li><li> Hands-on experience with AWS, Git, Docker, Gradle, Jenkins, Jira, and Confluence. <br><br></li></ul><strong><u>Nice-to-have Competencies<br></u></strong><ul><li> Familiarity with batch processing and workflow tools such as Airflow, Luigi, Celery, or others </li><li> 1-2+ years production environment-level experience with Ruby on Rails application development. </li><li> Prior production experience with Java, and/or Scala, or Python. </li><li> Familiarity with basic machine learning concepts. <br></li></ul>Appen offers an attractive total compensation package including outstanding benefits and stock options. Learn more about our company and culture, start here: Appen at a Glance .<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Early Career - Data Scientist,"Morrisville, North Carolina, United States",Afognak Native Corporation,2021-02-18,https://www.linkedin.com/jobs/view/early-career-data-scientist-at-afognak-native-corporation-2429513324?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=fPev79oBVt1Jht2DP6GTVg%3D%3D&position=23&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Overview

About Appen

The Appen Data Annotation Platform (ADAP) is the essential Human-in-the-Loop Machine Learning platform for data science and machine learning teams. It serves Fortune 500 and fast-growing data-driven organizations across a wide variety of industries, including autonomous vehicles, intelligent personal assistants, medical image labeling, consumer product identification, content categorization, customer support ticket classification, social data insight, CRM data enrichment, product categorization, and search relevance.

About The Role

ADAP users range from engineers and data scientists to subject matter experts creating training data for machine learning. You will be working on the most important problems in technology today: how can humans and AI collaborate to solve important and sometimes complicated tasks?

As a member of our Client Workspace team, you will design, build, and improve on tools used by many widely-known tech companies with large-scale, active machine learning initiatives. This may include collecting and managing training data for AI models, evaluating the performance of the machine learning models used by that data, or building infrastructure and managing data pipelines. Specifically, you will work on a generalized annotation API that consists of both automated and human-driven annotation tools for 2D and 3D images, video, text, and audio data. The platform will combine human input (eg: bounding boxes on objects) and Machine Learning input (eg: automatic object tracking in videos) for maximum efficiency and effectiveness. You will be on a cross-functional team collaborating with members of the Product, Machine Learning, Dev Ops, and Engineering teams.

Your work will consist of implementing new features and services, maintaining infrastructure, and migrating existing services to an event-driven, microservices-based architecture. You’ll mentor less experienced developers and constantly work on improving your own skills and the quality of our codebase. For more about what we build, please visit the Appen Platform Overview .

The Ideal Candidate

You enjoy thinking about and working on enterprise-level data processing systems. You are looking for a company at the epicenter of a rapidly-developing machine learning industry and are driven by a hunger to learn and develop your skills. You are passionate about working on a project that contributes meaningfully to the further development of technology and to humanity as a whole. You care about best practices and you choose the tools you work with judiciously and deliberately. You have strong analytical skills, an unwavering commitment to quality, an open-minded and collaborative work ethic, and cutting-edge coding skills.

Responsibilities / Opportunities

Build & maintain low-latency, high-scalability data pipelines in service of our human-in-the-loop machine learning workflows platform.
Build & maintain adapter services for ingesting data from a wide variety of streaming and batch-based sources.
Build & maintain services for throttling, backpressure, schema management, and normalization.
Implement QA and testing strategies. Promote best practices for writing maintainable code.
Participate in selecting tools and setting development standards at Appen.
Ability/readiness to develop excellent working relationships with a diverse team of peers across organizations (Engineering, QA, DevOps, Product, Design, et al).


Competencies

3-4+ years of software development experience in cloud-based, multi-tiered, enterprise application systems.
3-4+ years managing data platforms/engineering using enterprise service bus or message-based architectures, such as Kafka, Redis, RabbitMQ, or similar.
Hands-on experience with developing microservices and successfully building products using SOA.
Hands-on experience with event-sourcing and functional programming patterns.
Hands-on experience with AWS, Git, Docker, Gradle, Jenkins, Jira, and Confluence.


Nice-to-have Competencies

Familiarity with batch processing and workflow tools such as Airflow, Luigi, Celery, or others
1-2+ years production environment-level experience with Ruby on Rails application development.
Prior production experience with Java, and/or Scala, or Python.
Familiarity with basic machine learning concepts.

Appen offers an attractive total compensation package including outstanding benefits and stock options. Learn more about our company and culture, start here: Appen at a Glance .

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Overview<br><br></u></strong><strong> About Appen <br><br></strong>The Appen Data Annotation Platform (ADAP) is the essential Human-in-the-Loop Machine Learning platform for data science and machine learning teams. It serves Fortune 500 and fast-growing data-driven organizations across a wide variety of industries, including autonomous vehicles, intelligent personal assistants, medical image labeling, consumer product identification, content categorization, customer support ticket classification, social data insight, CRM data enrichment, product categorization, and search relevance.<br><br><strong><u>About The Role<br><br></u></strong>ADAP users range from engineers and data scientists to subject matter experts creating training data for machine learning. You will be working on the most important problems in technology today: how can humans and AI collaborate to solve important and sometimes complicated tasks?<br><br>As a member of our Client Workspace team, you will design, build, and improve on tools used by many widely-known tech companies with large-scale, active machine learning initiatives. This may include collecting and managing training data for AI models, evaluating the performance of the machine learning models used by that data, or building infrastructure and managing data pipelines. Specifically, you will work on a generalized annotation API that consists of both automated and human-driven annotation tools for 2D and 3D images, video, text, and audio data. The platform will combine human input (eg: bounding boxes on objects) and Machine Learning input (eg: automatic object tracking in videos) for maximum efficiency and effectiveness. You will be on a cross-functional team collaborating with members of the Product, Machine Learning, Dev Ops, and Engineering teams.<br><br>Your work will consist of implementing new features and services, maintaining infrastructure, and migrating existing services to an event-driven, microservices-based architecture. You’ll mentor less experienced developers and constantly work on improving your own skills and the quality of our codebase. For more about what we build, please visit the Appen Platform Overview .<br><br><strong><u>The Ideal Candidate<br><br></u></strong>You enjoy thinking about and working on enterprise-level data processing systems. You are looking for a company at the epicenter of a rapidly-developing machine learning industry and are driven by a hunger to learn and develop your skills. You are passionate about working on a project that contributes meaningfully to the further development of technology and to humanity as a whole. You care about best practices and you choose the tools you work with judiciously and deliberately. You have strong analytical skills, an unwavering commitment to quality, an open-minded and collaborative work ethic, and cutting-edge coding skills.<br><br><strong><u>Responsibilities / Opportunities<br></u></strong><ul><li> Build &amp; maintain low-latency, high-scalability data pipelines in service of our human-in-the-loop machine learning workflows platform. </li><li> Build &amp; maintain adapter services for ingesting data from a wide variety of streaming and batch-based sources. </li><li> Build &amp; maintain services for throttling, backpressure, schema management, and normalization. </li><li> Implement QA and testing strategies. Promote best practices for writing maintainable code. </li><li> Participate in selecting tools and setting development standards at Appen. </li><li> Ability/readiness to develop excellent working relationships with a diverse team of peers across organizations (Engineering, QA, DevOps, Product, Design, et al). <br><br></li></ul><strong><u>Competencies<br></u></strong><ul><li> 3-4+ years of software development experience in cloud-based, multi-tiered, enterprise application systems. </li><li> 3-4+ years managing data platforms/engineering using enterprise service bus or message-based architectures, such as Kafka, Redis, RabbitMQ, or similar. </li><li> Hands-on experience with developing microservices and successfully building products using SOA. </li><li> Hands-on experience with event-sourcing and functional programming patterns. </li><li> Hands-on experience with AWS, Git, Docker, Gradle, Jenkins, Jira, and Confluence. <br><br></li></ul><strong><u>Nice-to-have Competencies<br></u></strong><ul><li> Familiarity with batch processing and workflow tools such as Airflow, Luigi, Celery, or others </li><li> 1-2+ years production environment-level experience with Ruby on Rails application development. </li><li> Prior production experience with Java, and/or Scala, or Python. </li><li> Familiarity with basic machine learning concepts. <br></li></ul>Appen offers an attractive total compensation package including outstanding benefits and stock options. Learn more about our company and culture, start here: Appen at a Glance .<br><br>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist – Applied Machine Learning,"Los Angeles, California, United States",JM Eagle,2021-01-28,https://www.linkedin.com/jobs/view/data-scientist-%E2%80%93-applied-machine-learning-at-jm-eagle-2423521103?refId=f6d05a3d-200e-42bd-aeda-32e7b2afc868&trackingId=HX63o8dRCAERkj%2FfjLh0Hg%3D%3D&position=24&pageNum=13&trk=public_jobs_job-result-card_result-card_full-click,"Are you a problem solver, explorer, and knowledge seeker – always asking, “What if?”

If so, you may be the new team member we’re looking for. Because at SAS, your curiosity matters – whether you’re developing algorithms, creating customer experiences, or answering critical questions. Curiosity is our code, and the opportunities here are endless.

What We Do

We’re the leader in analytics. Through our software and services, we inspire customers around the world to transform data into intelligence. Our curiosity fuels innovation, pushing boundaries, challenging the status quo and changing the way we live.

What You’ll Do

As a Data Scientist within our Finance division, you will apply your knowledge of mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into business value for our internal stakeholders. You will be a part of our Corporate Analytics & Insights team collaborating on priority projects in order to provide solutions for financial and corporate-wide data, analytics and reporting needs. If you have a knack for transforming a world of data into analytical insights and effectively communicating those insights to facilitate change, you may be our next team member!

You Will

Create informative and succinct visualizations that answer questions key to business by:

Writing SAS/SQL code to develop and automate ETL processes
Designing visualizations suitable for consumption by diverse levels function and business
Collaborate across functions to prepare and manipulate the complex financial, human capital, and sales data to provide informed analysis and valuable insights
Build analytic models, to support business leaders with data driven insights that address immediate business problems and objectives.
Create automated and repeatable processes across financial functions
Translate analytic insights into coherent reports and presentations for consumers with varying degrees of technical knowledge.
Work as a mentor with less technical members of the team to develop their skills and knowledge.
Advocate for change management – beyond innovating new ideas, you will help in the adoption of new processes


What We’re Looking For

You’re curious, passionate, authentic, and accountable. These are our values and influence everything we do.
You have a bachelor’s degree in Computer Science, Statistics, or another quantitative field


The Nice To Haves

Master’s degree in analytics, mathematics, statistics, or other quantitative field
Programming experience for data analysis and data processing (ex: SAS, Python, R, etc.)
Query writing experience to extract data from internal/external databases in various environments
Strong knowledge of applied statistics, probability, data modeling techniques, predictive modeling techniques and model assessment.
Prior experience or education in Finance
Experience with business intelligence tools such as SAS Visual Analytics, Tableau, or Power BI


Other Knowledge, Skills, And Abilities

Ability to lead a team as needed and manage the entire life cycle of project.
Ability to conceptualize business needs and translate them into analytical opportunities.
Resolves problems independently, escalates appropriately.
Ability to communicate with an executive audience and people of various technical backgrounds.


Why SAS

We love living the #SASlife and believe that happy, healthy people have a passion for life, and bring that energy to work. No matter what your specialty or where you are in the world, your unique contributions will make a difference.
Our multi-dimensional culture blends our different backgrounds, experiences, and perspectives. Here, it isn’t about fitting into our culture, it’s about adding to it - and we can’t wait to see what you’ll bring.


This position will be seated out of SAS Headquarters in Cary, North Carolina

SAS looks not only for the right skills, but also a fit to our core values. We seek colleagues who will contribute to the unique values that makes SAS such a great place to work. We look for the total candidate: technical skills, values fit, relationship skills, problem solvers, good communicators and, of course, innovators. Candidates must be ready to make an impact.

Additional Information

To qualify, applicants must be legally authorized to work in the United States, and should not require, now or in the future, sponsorship for employment visa status. SAS is an equal opportunity employer. All qualified applicants are considered for employment without regard to race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability status, protected veteran status or any other characteristic protected by law. Read more: Equal Employment Opportunity is the Law. Also view the supplement EEO is the Law, and the Pay Transparency notice.

Equivalent combination of education, training and experience may be considered in place of the above qualifications. The level of this position will be determined based on the applicant's education, skills and experience. Resumes may be considered in the order they are received. SAS employees performing certain job functions may require access to technology or software subject to export or import regulations. To comply with these regulations, SAS may obtain nationality or citizenship information from applicants for employment. SAS collects this information solely for trade law compliance purposes and does not use it to discriminate unfairly in the hiring process.

All valid SAS job openings are located on the Careers page at www.sas.com. SAS only sends emails from verified “sas.com” email addresses and never asks for sensitive, personal information or money. Should you have any doubts about the authenticity of any type of communication from, for, or on behalf of SAS, please contact us at Recruitingsupport@sas.com before taking any further action.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Are you a problem solver, explorer, and knowledge seeker – always asking, “What if?”<br><br>If so, you may be the new team member we’re looking for. Because at SAS, your curiosity matters – whether you’re developing algorithms, creating customer experiences, or answering critical questions. Curiosity is our code, and the opportunities here are endless.<br><br><strong><u>What We Do<br><br></u></strong>We’re the leader in analytics. Through our software and services, we inspire customers around the world to transform data into intelligence. Our curiosity fuels innovation, pushing boundaries, challenging the status quo and changing the way we live.<br><br><strong><u>What You’ll Do<br><br></u></strong>As a Data Scientist within our Finance division, you will apply your knowledge of mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into business value for our internal stakeholders. You will be a part of our Corporate Analytics &amp; Insights team collaborating on priority projects in order to provide solutions for financial and corporate-wide data, analytics and reporting needs. If you have a knack for transforming a world of data into analytical insights and effectively communicating those insights to facilitate change, you may be our next team member!<br><br><strong><u>You Will<br></u></strong><ul><li>Create informative and succinct visualizations that answer questions key to business by:<br><ul><li>Writing SAS/SQL code to develop and automate ETL processes</li><li>Designing visualizations suitable for consumption by diverse levels function and business</li></ul></li><li>Collaborate across functions to prepare and manipulate the complex financial, human capital, and sales data to provide informed analysis and valuable insights</li><li>Build analytic models, to support business leaders with data driven insights that address immediate business problems and objectives.</li><li>Create automated and repeatable processes across financial functions</li><li>Translate analytic insights into coherent reports and presentations for consumers with varying degrees of technical knowledge.</li><li>Work as a mentor with less technical members of the team to develop their skills and knowledge.</li><li>Advocate for change management – beyond innovating new ideas, you will help in the adoption of new processes<br><br></li></ul><strong><u>What We’re Looking For<br></u></strong><ul><li>You’re curious, passionate, authentic, and accountable. These are our values and influence everything we do.</li><li>You have a bachelor’s degree in Computer Science, Statistics, or another quantitative field<br><br></li></ul><strong><u>The Nice To Haves<br></u></strong><ul><li>Master’s degree in analytics, mathematics, statistics, or other quantitative field</li><li>Programming experience for data analysis and data processing (ex: SAS, Python, R, etc.)</li><li>Query writing experience to extract data from internal/external databases in various environments</li><li>Strong knowledge of applied statistics, probability, data modeling techniques, predictive modeling techniques and model assessment.</li><li>Prior experience or education in Finance </li><li>Experience with business intelligence tools such as SAS Visual Analytics, Tableau, or Power BI<br><br></li></ul><strong><u>Other Knowledge, Skills, And Abilities<br></u></strong><ul><li>Ability to lead a team as needed and manage the entire life cycle of project.</li><li>Ability to conceptualize business needs and translate them into analytical opportunities.</li><li>Resolves problems independently, escalates appropriately.</li><li>Ability to communicate with an executive audience and people of various technical backgrounds.<br><br></li></ul><strong>Why SAS<br></strong><ul><li>We love living the #SASlife and believe that happy, healthy people have a passion for life, and bring that energy to work. No matter what your specialty or where you are in the world, your unique contributions will make a difference. </li><li>Our multi-dimensional culture blends our different backgrounds, experiences, and perspectives. Here, it isn’t about fitting into our culture, it’s about adding to it - and we can’t wait to see what you’ll bring.<br><br></li></ul><em>This position will be seated out of SAS Headquarters in Cary, North Carolina<br><br></em>SAS looks not only for the right skills, but also a fit to our core values. We seek colleagues who will contribute to the unique values that makes SAS such a great place to work. We look for the total candidate: technical skills, values fit, relationship skills, problem solvers, good communicators and, of course, innovators. Candidates must be ready to make an impact.<br><br><strong><u>Additional Information<br><br></u></strong>To qualify, applicants must be legally authorized to work in the United States, and should not require, now or in the future, sponsorship for employment visa status. SAS is an equal opportunity employer. All qualified applicants are considered for employment without regard to race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability status, protected veteran status or any other characteristic protected by law. Read more: Equal Employment Opportunity is the Law. Also view the supplement EEO is the Law, and the Pay Transparency notice.<br><br>Equivalent combination of education, training and experience may be considered in place of the above qualifications. The level of this position will be determined based on the applicant's education, skills and experience. Resumes may be considered in the order they are received. SAS employees performing certain job functions may require access to technology or software subject to export or import regulations. To comply with these regulations, SAS may obtain nationality or citizenship information from applicants for employment. SAS collects this information solely for trade law compliance purposes and does not use it to discriminate unfairly in the hiring process.<br><br>All valid SAS job openings are located on the Careers page at www.sas.com. SAS only sends emails from verified “sas.com” email addresses and never asks for sensitive, personal information or money. Should you have any doubts about the authenticity of any type of communication from, for, or on behalf of SAS, please contact us at Recruitingsupport@sas.com before taking any further action.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Automotive, Transportation/Trucking/Railroad"
Data Engineer,"Minneapolis–Saint Paul, Minnesota, United States",Securian Financial,2021-02-11,https://www.linkedin.com/jobs/view/data-engineer-at-securian-financial-2419020989?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=Mwp%2F70ikhqnVuWny0TKYug%3D%3D&position=2&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Jump start your Data Scientists career with the leading plastic pipe manufacturing company in the US.

Data Scientists interpret and apply data in analyses, and explain findings to business audiences typically, to improve products and processes. Projects support business decision making for multiple business functions. Designs, creates, implements and manages predictive analytics that leverage large and varied data sets, using a wide range of analytical tools, methods and platforms.

Summary

The Data Scientist implements machine learning algorithms, collects and analyzes information from multiple sources, identifies unique opportunities to locate and collect new data, and communicates data findings to both business and IT leaders.

ESSENTIAL DUTIES AND RESPONSIBILITIES include the following. Other duties may be assigned.

Use existing machine learning tools or develop customized algorithms to solve analytical problems with incomplete data sets and deploy automated processes into production.
Conduct scalable data research on manufacturing and sales data.
Create new software designed to access and handle data more efficiently.
Train the data management team on new or updated procedures.
Formulate business problems into concrete mathematical framework, and translating analytic results into actionable business recommendations.
May write and implement procedures.
May train data management team on new or updated procedures.
Assist with projects and other job-related duties as assigned.


Supervisory Responsibilities

This position has no supervisory responsibilities.

Qualifications

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

EDUCATION And/or EXPERIENCE

Bachelor’s degree in Computer Science, Statistics, Applied Math or related field and 5 years practical related experience in machine learning and statistical modeling. Equivalent work experience may be considered in lieu of a degree. Master’s degree preferred.

Experience implementing real-time machine learning and data mining algorithms in large scale environments, and collecting data from/exposing data to various data sources and services (API, XML, JSON, etc.) required.

Computer Skills

Possess expertise in Python, developing cloud solutions on AWS, knowledge of GitHub and capable of pull and merge requests. Ability to use MS Word, Excel, PowerPoint and Outlook.

Language Skills

Ability to read and interpret documents such as design drawings and schematics. Ability to write general correspondence and technical reports. Ability to speak effectively in meetings.

Mathematical Skills

Ability to calculate figures and amounts such as percentages. Ability to apply concepts of basic algebra, geometry and trigonometry.

REASONING ABILITY

Ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exits. Ability to interpret a variety of instructions furnished in written, verbal, diagram or schedule form. Ability to identify trends and develop action plans to address issues.

PHYSICAL DEMANDS

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing duties of this job, the employee is regularly required to use hands to handle, or feel, and talk or hear. The employee is frequently required to sit. The employee is occasionally required to stand and walk. The employee must regularly lift and/or move up to 10 pounds and occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision, distance vision, and ability to adjust focus.

WORK ENVIRONMENT

The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

The noise level in the work environment is usually quiet.

With 22 manufacturing plants throughout North America, JM Eagle manufactures the widest array of high-grade, high-performance polyvinyl chloride and high-density polyethylene pipe across a variety of industries and applications including utility, solvent weld, electrical conduit, natural gas, irrigation, potable water and sewage.
JM EagleTM is the world’s largest plastic pipe manufacturer—an innovative leader that combines advanced technology with superior customer service to create the industry’s most sophisticated and diverse products. JM EagleTM gives its customers a significant competitive advantage in the marketplace with the greatest capacity and geographic reach.
JM EagleTM joins the strengths of two industry-leading plastic pipe producers, including complementary product lines as well as specialty pipe and unique product innovations. We’re committed to serving each and every customer in the best way possible. Through this merger, we look forward to strengthening our existing relationships, and developing new ones in the future. JM EagleTM remains committed to our core value of delivering life’s essentials through the most eco-friendly plastic pipe products on the market. We pride ourselves on being able to illustrate the vital role our products play in improving and maintaining the health and quality of life throughout the world. We will continue to manufacture plastic pipe to serve the world’s growing needs.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Jump start your Data Scientists career with the leading plastic pipe manufacturing company in the US.<br><br></strong>Data Scientists interpret and apply data in analyses, and explain findings to business audiences typically, to improve products and processes. Projects support business decision making for multiple business functions. Designs, creates, implements and manages predictive analytics that leverage large and varied data sets, using a wide range of analytical tools, methods and platforms.<br><br><strong><u>Summary<br><br></u></strong>The <strong>Data Scientist</strong> implements machine learning algorithms, collects and analyzes information from multiple sources, identifies unique opportunities to locate and collect new data, and communicates data findings to both business and IT leaders.<br><br><strong>ESSENTIAL DUTIES AND RESPONSIBILITIES </strong>include the following. Other duties may be assigned.<br><ul><li>Use existing machine learning tools or develop customized algorithms to solve analytical problems with incomplete data sets and deploy automated processes into production.</li><li>Conduct scalable data research on manufacturing and sales data.</li><li>Create new software designed to access and handle data more efficiently.</li></ul><ul><li>Train the data management team on new or updated procedures.</li><li>Formulate business problems into concrete mathematical framework, and translating analytic results into actionable business recommendations.</li><li>May write and implement procedures.</li><li>May train data management team on new or updated procedures.</li></ul><ul><li>Assist with projects and other job-related duties as assigned.<br><br></li></ul><strong><u>Supervisory Responsibilities<br><br></u></strong>This position has no supervisory responsibilities.<br><br><strong><u>Qualifications<br><br></u></strong>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><br><strong><u>EDUCATION And/or EXPERIENCE<br><br></u></strong>Bachelor’s degree in Computer Science, Statistics, Applied Math or related field and 5 years practical related experience in machine learning and statistical modeling. Equivalent work experience may be considered in lieu of a degree. Master’s degree preferred.<br><br>Experience implementing real-time machine learning and data mining algorithms in large scale environments, and collecting data from/exposing data to various data sources and services (API, XML, JSON, etc.) required.<br><br><strong><u>Computer Skills<br><br></u></strong>Possess expertise in Python, developing cloud solutions on AWS, knowledge of GitHub and capable of pull and merge requests. Ability to use MS Word, Excel, PowerPoint and Outlook.<br><br><strong><u>Language Skills<br><br></u></strong>Ability to read and interpret documents such as design drawings and schematics. Ability to write general correspondence and technical reports. Ability to speak effectively in meetings.<br><br><strong><u>Mathematical Skills<br><br></u></strong>Ability to calculate figures and amounts such as percentages. Ability to apply concepts of basic algebra, geometry and trigonometry.<br><br><strong>REASONING ABILITY<br><br></strong>Ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exits. Ability to interpret a variety of instructions furnished in written, verbal, diagram or schedule form. Ability to identify trends and develop action plans to address issues.<br><br><strong>PHYSICAL</strong><strong> DEMANDS<br><br></strong>The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><br>While performing duties of this job, the employee is regularly required to use hands to handle, or feel, and talk or hear. The employee is frequently required to sit. The employee is occasionally required to stand and walk. The employee must regularly lift and/or move up to 10 pounds and occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision, distance vision, and ability to adjust focus.<br><br><strong>WORK ENVIRONMENT<br><br></strong>The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br><br>The noise level in the work environment is usually quiet.<br><br>With 22 manufacturing plants throughout North America, JM Eagle manufactures the widest array of high-grade, high-performance polyvinyl chloride and high-density polyethylene pipe across a variety of industries and applications including utility, solvent weld, electrical conduit, natural gas, irrigation, potable water and sewage.<br>JM EagleTM is the world’s largest plastic pipe manufacturer—an innovative leader that combines advanced technology with superior customer service to create the industry’s most sophisticated and diverse products. JM EagleTM gives its customers a significant competitive advantage in the marketplace with the greatest capacity and geographic reach.<br>JM EagleTM joins the strengths of two industry-leading plastic pipe producers, including complementary product lines as well as specialty pipe and unique product innovations. We’re committed to serving each and every customer in the best way possible. Through this merger, we look forward to strengthening our existing relationships, and developing new ones in the future. JM EagleTM remains committed to our core value of delivering life’s essentials through the most eco-friendly plastic pipe products on the market. We pride ourselves on being able to illustrate the vital role our products play in improving and maintaining the health and quality of life throughout the world. We will continue to manufacture plastic pipe to serve the world’s growing needs.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Construction, Automotive, Transportation/Trucking/Railroad"
Data Scientist,"Liberty Lake, Washington, United States","Itron, Inc.",2021-02-03,https://www.linkedin.com/jobs/view/data-scientist-at-itron-inc-2407582021?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=6xEr8wjjCsEAo12RsynQXg%3D%3D&position=3&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Securian Financial Groups internal position title is Engineering Sr. Analyst


Position Summary

Securian is on an exciting journey to stand up a mature data engineering discipline focused on enterprise data. One key stepping-stone is defining and implementing a data strategy and associated process and technologies to successfully leverage data as an asset.

This posting is for an experienced Data Engineer. Data Engineering responsibilities will include activities such as building and maintaining data pipelines, data transformation, cleansing, and masking, and building data APIs.

The ideal candidate is a skilled data engineer with demonstrated experience. The candidate should have cloud experience and be familiar with traditional and modern data architectures and tooling. The candidate should also be curious and enthusiastic about exploring and building data platform capabilities to achieve maximum value to the organization.

Responsibilities Include But Not Limited To

Collaborate with business users and IT partners to understand requirements and analyze data needs. Document requirements and build data flow diagrams.
Build and maintain data pipelines for populating data domains.
Create data transformations, including data cleansing and data masking.
Participate in Data Governance initiatives.
Play a key role in helping Securian implement the Enterprise Data Strategy by building an Enterprise Data Store, populating it with clean and well-structured data, and participating in other key initiatives in the strategy.


Qualifications

Previous experience as a Data Engineer, or related field.
4 year degree in Computer Science or related field
Experience with tools and concepts related to data and analytics, such as dimensional modeling, ETL, reporting tools, data warehousing, structured and unstructured data.
ETL experience using tools such as Informatica or StreamSets
Data validation and cleansing
ANSI SQL Skills/Experience
Exposure and experience with traditional and modern data architectures
Cloud knowledge and experience – AWS preferred
Experience working with business users to analyze requirements and design solutions that meet their needs.
Strong problem solving and analytical abilities
Attention to detail
Solid communication skills
Willingness to learn


Preferred Qualifications

Spark/Python/Java development experience
Report development experience - Business Objects, Tableau
XML/XSD/DTD/JSON/
Previous experience or knowledge of Insurance/Financial Services industry.
Agile experience


In Addition

Securian Financial has been around for nearly 140 years. We’re committed to giving back to our community, donating 15,000 employee volunteer hours this past year. We also provide extensive resources to our employees for professional development and growth and a number of diverse professional and social opportunities throughout the company. There’s a reason our employees have voted us as a best place to work year after year.

Generous paid time off. We want you to take time off for whatever matters most to you!
Tuition reimbursement program. We value continuous learning at Securian!
Company-funded pension plan as well as 401K retirement plan – great resources to secure your financial future.
Continuous opportunities for new challenges.
Variety of health plan options as well as dental and vision plans.
Paid maternity/paternity leaves.


Physical Job Requirements

A bility to utilize keyboard, mouse and computer for up to 8 hours per day
Ability to work at least 40 hours per week
Ability to utilize telephone for up to 8 hours per day
Ability to perform grasping tasks throughout the entire work day (examples: handwriting, grasping of equipment/machines, paper manipulation, sorting, folding, handling stacks of paper)

The physical job requirements described above are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of jobs.

As a full-time associate, you will be eligible for the full range of Company benefits which include life insurance, medical and dental coverage, retirement plan, profit sharing plan, paid vacation and personal time, flexible spending accounts (use of pretax dollars for dependent care, dental and medical expenses not covered under your medical plan), etc.

Securian Financial Group, Inc. does not discriminate based on race, color, creed, religion, national origin, sex, gender identity, sexual orientation, age, marital or familial status, pregnancy, disability, genetic information, political affiliation, veteran status, status in regard to public assistance, status in a local human rights commission, or any other status or condition protected by local, state or federal law. If you are a job seeker with a disability and require an accommodation to apply for one of our jobs, please contact us by telephone 651-665-5522 (voice), 711 (telecommunications relay), or by email at EmployeeRelations@securian.com.

To view our privacy statement click here

To view our legal statement click here
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><li>Securian Financial Groups internal position title is Engineering Sr. Analyst<br><br></li><strong><u>Position Summary<br><br></u></strong>Securian is on an exciting journey to stand up a mature data engineering discipline focused on enterprise data. One key stepping-stone is defining and implementing a data strategy and associated process and technologies to successfully leverage data as an asset.<br><br>This posting is for an experienced Data Engineer. Data Engineering responsibilities will include activities such as building and maintaining data pipelines, data transformation, cleansing, and masking, and building data APIs.<br><br>The ideal candidate is a skilled data engineer with demonstrated experience. The candidate should have cloud experience and be familiar with traditional and modern data architectures and tooling. The candidate should also be curious and enthusiastic about exploring and building data platform capabilities to achieve maximum value to the organization.<br><br><strong><u>Responsibilities Include But Not Limited To<br></u></strong><ul><li>Collaborate with business users and IT partners to understand requirements and analyze data needs. Document requirements and build data flow diagrams.</li><li>Build and maintain data pipelines for populating data domains.</li><li>Create data transformations, including data cleansing and data masking.</li><li>Participate in Data Governance initiatives.</li><li> Play a key role in helping Securian implement the Enterprise Data Strategy by building an Enterprise Data Store, populating it with clean and well-structured data, and participating in other key initiatives in the strategy. <br><br></li></ul><strong><u>Qualifications<br></u></strong><ul><li>Previous experience as a Data Engineer, or related field.</li><li>4 year degree in Computer Science or related field</li></ul><ul><li>Experience with tools and concepts related to data and analytics, such as dimensional modeling, ETL, reporting tools, data warehousing, structured and unstructured data.</li><li>ETL experience using tools such as Informatica or StreamSets</li><li>Data validation and cleansing</li><li>ANSI SQL Skills/Experience</li><li>Exposure and experience with traditional and modern data architectures</li><li>Cloud knowledge and experience – AWS preferred</li><li>Experience working with business users to analyze requirements and design solutions that meet their needs.</li><li>Strong problem solving and analytical abilities</li><li>Attention to detail</li><li>Solid communication skills</li><li>Willingness to learn<br><br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li>Spark/Python/Java development experience</li><li>Report development experience - Business Objects, Tableau</li><li>XML/XSD/DTD/JSON/</li><li>Previous experience or knowledge of Insurance/Financial Services industry.</li><li>Agile experience<br><br></li></ul><strong><u>In Addition<br><br></u></strong><strong> Securian Financial </strong> has been around for nearly 140 years. We’re committed to giving back to our community, donating 15,000 employee volunteer hours this past year. We also provide extensive resources to our employees for professional development and growth and a number of diverse professional and social opportunities throughout the company. There’s a reason our employees have voted us as a best place to work year after year.<br><ul><li> Generous paid time off. We want you to take time off for whatever matters most to you! </li><li> Tuition reimbursement program. We value continuous learning at Securian! </li><li> Company-funded pension plan as well as 401K retirement plan – great resources to secure your financial future. </li><li> Continuous opportunities for new challenges. </li><li> Variety of health plan options as well as dental and vision plans. </li><li> Paid maternity/paternity leaves. <br><br></li></ul><strong><u>Physical Job Requirements<br></u></strong><ul><li> A bility to utilize keyboard, mouse and computer for up to 8 hours per day</li><li>Ability to work at least 40 hours per week</li><li>Ability to utilize telephone for up to 8 hours per day</li><li>Ability to perform grasping tasks throughout the entire work day (examples: handwriting, grasping of equipment/machines, paper manipulation, sorting, folding, handling stacks of paper)<br></li></ul>The physical job requirements described above are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of jobs.<br><br>As a full-time associate, you will be eligible for the full range of Company benefits which include life insurance, medical and dental coverage, retirement plan, profit sharing plan, paid vacation and personal time, flexible spending accounts (use of pretax dollars for dependent care, dental and medical expenses not covered under your medical plan), etc.<br><br>Securian Financial Group, Inc. does not discriminate based on race, color, creed, religion, national origin, sex, gender identity, sexual orientation, age, marital or familial status, pregnancy, disability, genetic information, political affiliation, veteran status, status in regard to public assistance, status in a local human rights commission, or any other status or condition protected by local, state or federal law. If you are a job seeker with a disability and require an accommodation to apply for one of our jobs, please contact us by telephone 651-665-5522 (voice), 711 (telecommunications relay), or by email at EmployeeRelations@securian.com.<br><br>To view our privacy statement click here<br><br>To view our legal statement click here</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Insurance, Financial Services"
Data Engineer,"Lawrenceville, New Jersey, United States",Billtrust,2021-02-04,https://www.linkedin.com/jobs/view/data-engineer-at-billtrust-2408722103?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=wL%2FTcLG0SOhozjQzctSoeg%3D%3D&position=4&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"The forefront of a rapidly evolving global industry—not to mention one that is foundational to cities and communities around the world—is a good place to find interesting and fulfilling work. You’ll be working to connect utility infrastructure to the world, make data usable and insightful, and tackle some serious performance-based challenges as more and more devices plug in to the internet of things (needless to say, when you’re collecting data from millions of points, every second counts). At Itron, our teams are helping create the foundation for a more resourceful world.

As a Data Scientist at Itron, you will work with business leaders to deliver business outcomes for utility customers using advanced data analytics. You will work closely with project teams and utility customers to identify and solve business problems by mining the value from large sets of structured, semi-structured, and unstructured data in a distributed processing environment. This role will focus on algorithm development and prototyping, as well as supporting developers who will implement such algorithms for production. Accordingly, this position captures combined skills of a scientist, statistician, data analyst, and programmer.

Job Duties & Responsibilities

Management and manipulation of data sets as required from raw source to analytics platform.
Perform data cleansing & validation.
Responsible for completing predictive data analysis.
Develop software algorithms and models to achieve business results.
Perform data visualization.
Communicate both written and verbal activities with customers and Itron Product Management and R&D management.
Interpretation and presentation of statistical tests & results.
Commit to learning energy & utility domains.



Experience: This position requires industry experience post graduation.

Experience with the following programming languages would be beneficial: R, ML, Python, Matlab, SQL.

Other Desired Skills

Effective interpersonal communication
Statistical skills such as regressions, clustering, time-series, Fourier Transforms
Analog circuits or basic power/electrical engineering concepts
Domain experience with Utilities, power grids or related
Familiarity with source control and issue tracking systems such as git, Microsoft ADS/VSTS or Jira.



Education: Bachelor's degree in related field (engineering, physics, mathematics, or actuary science, etc.) is required. Master’s Degree in a related field (data science, mathematics, or statistics, etc.) is highly preferred; PhD in a related field is preferred.

Travel: 10 - 20%

Physical Demands: This is a typical office job, with no special physical requirements or unusual work environment.

Itron is an Equal Opportunity, Affirmative Action Employer. Qualified applicants are considered without regard to race, color, religion, sex, age, national origin, citizenship, sexual orientation, marital status, pregnancy, medical condition, veteran status, disability, genetic information, gender identity or other characteristics protected by law. If you require an accommodation in order to apply to this position, please contact your local recruiting representative at 1-800-635-5461 or email Accessibility@itron.com.

Itron enables utilities and cities to safely, securely and reliably deliver critical infrastructure services to communities in more than 100 countries. Our portfolio of smart networks, software, services, meters and sensors helps our customers better manage electricity, gas and water resources for the people they serve. By working with our customers to ensure their success, we help improve the quality of life, ensure the safety and promote the well-being of millions of people around the globe. Itron is dedicated to creating a more resourceful world. Join us: www.itron.com.


Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">The forefront of a rapidly evolving global industry—not to mention one that is foundational to cities and communities around the world—is a good place to find interesting and fulfilling work. You’ll be working to connect utility infrastructure to the world, make data usable and insightful, and tackle some serious performance-based challenges as more and more devices plug in to the internet of things (needless to say, when you’re collecting data from millions of points, every second counts). At Itron, our teams are helping create the foundation for a more resourceful world.<br><br>As a Data Scientist at Itron, you will work with business leaders to deliver business outcomes for utility customers using advanced data analytics. You will work closely with project teams and utility customers to identify and solve business problems by mining the value from large sets of structured, semi-structured, and unstructured data in a distributed processing environment. This role will focus on algorithm development and prototyping, as well as supporting developers who will implement such algorithms for production. Accordingly, this position captures combined skills of a scientist, statistician, data analyst, and programmer.<br><br><strong><u>Job Duties &amp; Responsibilities<br></u></strong><ul> <li>Management and manipulation of data sets as required from raw source to analytics platform.</li> <li>Perform data cleansing &amp; validation.</li> <li>Responsible for completing predictive data analysis.</li> <li>Develop software algorithms and models to achieve business results.</li> <li>Perform data visualization.</li> <li>Communicate both written and verbal activities with customers and Itron Product Management and R&amp;D management.</li> <li>Interpretation and presentation of statistical tests &amp; results.</li> <li>Commit to learning energy &amp; utility domains.</li> <br><br></ul><strong>Experience: </strong>This position requires industry experience post graduation.<br><br>Experience with the following programming languages would be beneficial: R, ML, Python, Matlab, SQL.<br><br><strong><u>Other Desired Skills<br></u></strong><ul> <li>Effective interpersonal communication</li> <li>Statistical skills such as regressions, clustering, time-series, Fourier Transforms</li> <li>Analog circuits or basic power/electrical engineering concepts</li> <li>Domain experience with Utilities, power grids or related</li> <li>Familiarity with source control and issue tracking systems such as git, Microsoft ADS/VSTS or Jira.</li> <br><br></ul><strong>Education:</strong> Bachelor's degree in related field (engineering, physics, mathematics, or actuary science, etc.) is required. Master’s Degree in a related field (data science, mathematics, or statistics, etc.) is highly preferred; PhD in a related field is preferred.<br><br><strong>Travel:</strong> 10 - 20%<br><br><strong>Physical Demands:</strong> This is a typical office job, with no special physical requirements or unusual work environment.<br><br>Itron is an Equal Opportunity, Affirmative Action Employer. Qualified applicants are considered without regard to race, color, religion, sex, age, national origin, citizenship, sexual orientation, marital status, pregnancy, medical condition, veteran status, disability, genetic information, gender identity or other characteristics protected by law. If you require an accommodation in order to apply to this position, please contact your local recruiting representative at 1-800-635-5461 or email Accessibility@itron.com.<br><br>Itron enables utilities and cities to safely, securely and reliably deliver critical infrastructure services to communities in more than 100 countries. Our portfolio of smart networks, software, services, meters and sensors helps our customers better manage electricity, gas and water resources for the people they serve. By working with our customers to ensure their success, we help improve the quality of life, ensure the safety and promote the well-being of millions of people around the globe. Itron is dedicated to creating a more resourceful world. Join us: www.itron.com.<br><br></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Mechanical or Industrial Engineering"
Data Engineer,"San Francisco, California, United States",Scion Staffing,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-at-scion-staffing-2415379297?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=FLkPbXp3h58zjpOTKgzOPg%3D%3D&position=5&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"What You'll Do:

The Data Engineer will be part of the team managing the evolution and automation of our Finance team systems and processes. As an energetic self-starter, you will drive improvement to cycle time, quality, automation. The successful candidate will have a proven track record of building and managing high-performance systems in a complex, heterogeneous technical environment. This role requires a combination of architecture, design, hands-on development and interworking with users, other teams and vendors. Creativity and good judgment will allow you to provide solutions that are scalable, extensible, robust and maintainable.


Design and deliver cost effective solutions aligned to the architecture roadmap, using input from key business and technology stakeholders.
Functionally decompose complex problems into simple, straight-forward, cost effective solutions
Works items are delivered on time and in accordance with the backlog co-developed with the business owners
Oversee and validate deliverables from internal and external parties. Ensure high standards of technical work quality from all contributing parties.
Drive regular release of deliverables across the full system lifecycle from inception, design, development, deployment and support. Coordinate solutions with project managers and other teams performing technical work
Work with upstream and downstream system/platform owners to ensure interfaces and data models are optimized, and providing the necessary information for a complete solution
Work with Infrastructure, security and operations/support teams to ensure processes run with high availability and in accordance with internal architectural standards. Establish performance SLAs and L1/L2/L3 support matrices.
Ensure proper technical environments are established and populated with data to facilitate development, testing, QA and production
Ensure solution architecture, design, application and integration development follow best practices/principles and standards for enterprise architecture, source code management, environment management and testing.
Find, qualify and technically rank multiple vendors for any outsourced work
Proactively plan for new platform demands including but not limited to organic growth, new products, acquisitions of new companies, new product features and new billing users features. Ensure that new products/feature created by other teams are supported.
Perform timely evaluation of new projects initiated within and outside the domain
Quickly grasp and implement complex user business rules with minimal oversight
Document all current and proposed solutions



What You'll Bring to the Team:


5-7 years of proven success coding, developing and deploying complex Finance and Data Warehousing solutions in a heavily transactional environment
Experience with Waterfall/SDLC, Agile/Scrum methodologies
PowerBI/PowerQuery, Python, Node JS, MySQL, MS-SQL/SSIS, Rest APIs, GIT, and other database technologies to create relevant solutions
Experience building and enhancing a Cloud Data Warehouse Technologies (Front end and back end), ETL and on prem/hybrid environments
Experience in FinTech, Telecom, Software, Media or industry w/specific knowledge of financial transactions, high volume data/transactions and processing environments, security, testing, and reporting
Able to communicate effectively with technical and business personal
Effective with time management and self-prioritization of tasks
Ability to work across large teams, prioritize, collaborate, make/meet commitments.
Results driven, with strong analytical and problem-solving skills
Ability to effectively work in a fast-paced, energetic team environment
Ability to quickly demonstrate validity of approaches through POCs
Experience with cloud ERP and integrating with HR systems is highly desirable
BS Degree in Software Engineering/Computer Science required, MS Degree desirable



What You'll Get:


Competitive Salary, Bonus, Stock Options and 401(k) Match: We appreciate our employees and we make sure they know it.
Open PTO: Work-life balance is important. We believe in giving our employees time to truly relax and recharge.
Paid Parental Leave: To keep our employees and their families healthy.
Opportunities for Growth: Professional development can take many shapes. From ERGs like Women in Tech and DE&I, to Mentor-Mentee, Leadership, and High-Potential Programs, we foster an environment where all employees can grow.
Recognition: From Billtrust Bucks and Gongings to Culture Champion and Presidents Awards, our employees are recognized for hard work and outcomes achieved.
Minimal Bureaucracy: An entrepreneurial environment of ownership and accountability allows you to get work done.
A Culture that Lives its Values: Our values are not just words or window dressing, they guide our decisions - big and small - each and every day.



Who We Are:

Billtrust is the best-in-class provider of Payment Cycle Management and accounts receivable solutions, helping businesses accelerate Order-to-Cash. We provide a flexible, automated, cloud-based product portfolio that meets diverse buyer requirements and speeds cash application through tailored invoice delivery, secure multi-channel payment enablement, and intelligent matching and payment posting. Our platforms process $40B+ annually and help companies like Kraft Foods, New Balance Athletics and Ferguson Enterprises get paid faster and more efficiently.

For the past 19 years, we have achieved remarkable success with year-over-year growth and we attribute that growth to our people and culture. We encourage employees to have autonomy, think creatively, share ideas - even with our CEO - and to challenge the status quo every day without a lot of red tape.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">What You'll Do:<br><br>The Data Engineer will be part of the team managing the evolution and automation of our Finance team systems and processes. As an energetic self-starter, you will drive improvement to cycle time, quality, automation. The successful candidate will have a proven track record of building and managing high-performance systems in a complex, heterogeneous technical environment. This role requires a combination of architecture, design, hands-on development and interworking with users, other teams and vendors. Creativity and good judgment will allow you to provide solutions that are scalable, extensible, robust and maintainable.<br><br><ul> <li>Design and deliver cost effective solutions aligned to the architecture roadmap, using input from key business and technology stakeholders. </li> <li>Functionally decompose complex problems into simple, straight-forward, cost effective solutions</li> <li>Works items are delivered on time and in accordance with the backlog co-developed with the business owners</li> <li>Oversee and validate deliverables from internal and external parties. Ensure high standards of technical work quality from all contributing parties.</li> <li>Drive regular release of deliverables across the full system lifecycle from inception, design, development, deployment and support. Coordinate solutions with project managers and other teams performing technical work</li> <li>Work with upstream and downstream system/platform owners to ensure interfaces and data models are optimized, and providing the necessary information for a complete solution</li> <li>Work with Infrastructure, security and operations/support teams to ensure processes run with high availability and in accordance with internal architectural standards. Establish performance SLAs and L1/L2/L3 support matrices.</li> <li>Ensure proper technical environments are established and populated with data to facilitate development, testing, QA and production</li> <li>Ensure solution architecture, design, application and integration development follow best practices/principles and standards for enterprise architecture, source code management, environment management and testing.</li> <li>Find, qualify and technically rank multiple vendors for any outsourced work </li> <li>Proactively plan for new platform demands including but not limited to organic growth, new products, acquisitions of new companies, new product features and new billing users features. Ensure that new products/feature created by other teams are supported.</li> <li>Perform timely evaluation of new projects initiated within and outside the domain</li> <li>Quickly grasp and implement complex user business rules with minimal oversight</li> <li>Document all current and proposed solutions</li> <br><br></ul>What You'll Bring to the Team:<br><br><ul> <li>5-7 years of proven success coding, developing and deploying complex Finance and Data Warehousing solutions in a heavily transactional environment</li> <li>Experience with Waterfall/SDLC, Agile/Scrum methodologies</li> <li>PowerBI/PowerQuery, Python, Node JS, MySQL, MS-SQL/SSIS, Rest APIs, GIT, and other database technologies to create relevant solutions</li> <li>Experience building and enhancing a Cloud Data Warehouse Technologies (Front end and back end), ETL and on prem/hybrid environments</li> <li>Experience in FinTech, Telecom, Software, Media or industry w/specific knowledge of financial transactions, high volume data/transactions and processing environments, security, testing, and reporting</li> <li>Able to communicate effectively with technical and business personal</li> <li>Effective with time management and self-prioritization of tasks</li> <li>Ability to work across large teams, prioritize, collaborate, make/meet commitments.</li> <li>Results driven, with strong analytical and problem-solving skills</li> <li>Ability to effectively work in a fast-paced, energetic team environment</li> <li>Ability to quickly demonstrate validity of approaches through POCs</li> <li>Experience with cloud ERP and integrating with HR systems is highly desirable</li> <li>BS Degree in Software Engineering/Computer Science required, MS Degree desirable</li> <br><br></ul>What You'll Get:<br><br><ul> <li>Competitive Salary, Bonus, Stock Options and 401(k) Match: We appreciate our employees and we make sure they know it.</li> <li>Open PTO: Work-life balance is important. We believe in giving our employees time to truly relax and recharge.</li> <li>Paid Parental Leave: To keep our employees and their families healthy.</li> <li>Opportunities for Growth: Professional development can take many shapes. From ERGs like Women in Tech and DE&amp;I, to Mentor-Mentee, Leadership, and High-Potential Programs, we foster an environment where all employees can grow.</li> <li>Recognition: From Billtrust Bucks and Gongings to Culture Champion and Presidents Awards, our employees are recognized for hard work and outcomes achieved.</li> <li>Minimal Bureaucracy: An entrepreneurial environment of ownership and accountability allows you to get work done.</li> <li>A Culture that Lives its Values: Our values are not just words or window dressing, they guide our decisions - big and small - each and every day.</li> <br><br></ul>Who We Are:<br><br>Billtrust is the best-in-class provider of Payment Cycle Management and accounts receivable solutions, helping businesses accelerate Order-to-Cash. We provide a flexible, automated, cloud-based product portfolio that meets diverse buyer requirements and speeds cash application through tailored invoice delivery, secure multi-channel payment enablement, and intelligent matching and payment posting. Our platforms process $40B+ annually and help companies like Kraft Foods, New Balance Athletics and Ferguson Enterprises get paid faster and more efficiently.<br><br>For the past 19 years, we have achieved remarkable success with year-over-year growth and we attribute that growth to our people and culture. We encourage employees to have autonomy, think creatively, share ideas - even with our CEO - and to challenge the status quo every day without a lot of red tape.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer Intern - Tableau,"Seattle, Washington, United States",Salesforce,2021-02-05,https://www.linkedin.com/jobs/view/data-engineer-intern-tableau-at-salesforce-2396966559?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=BLk%2F7np4FRFK63b2TxYLVw%3D%3D&position=6&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Scion Technical Search is seeking a fully remote Data Engineer for our forward-thinking, collaborative client in San Francisco, CA!

This engineering department does all they can to make their organization an outstanding team to work for! They have built up a modern code base with React on the Frontend and Python on the server side.

This position is ideal for someone who is passionate about or experienced in the culture within a Start-Up. This PaaS company was founded less than 2 years ago and they’re already profitable! No wonder they’re actively expanding!

Perks

Founders have proven success in building businesses
Up to $200k/yr starting salary DOE
Fully remote work situation (even post-Covid)
Paid Health, Vision, and Dental benefits
Meaningful Equity Package offered DOE
Paid lunch daily via delivery for all employees
Fully furnished remote, ergonomic work set-up
Modern code base: React + Python
Small, close-knit team environment
Flexible working hours
Paid Time Off (of course!)



What You Will Be Doing

Building out Data Pipelines to manage Big Data sets in an effort to provide meaningful insights
Helping to build out the search function of this modern Platform



What You Will Need

3+ years of professional experience in Software Engineering or BS in Computer Science (you can code!)
Strong project experience with Python
Familiarity using Postgrès as a database
Background in creating Data Pipelines



Interested?

Contact Scion Technical today for more information by submitting your resume directly through this posting. We look forward to reviewing your background and discussing this exciting opportunity further!

About Our Firm

Scion Staffing is an award winning staffing firm headquartered in San Francisco, CA. Over the past few years, our firm has had the pleasure of successfully assisting hundreds of local employers. No matter the requisition or size, our track record and recruitment prowess has made us one of the top recruitment firms in California. Additional information about our firm and success can also be found online at www.scionstaffing.com, or in the Business Times list of top staffing firms.

Scion Staffing is an equal opportunity employer and service provider and does not discriminate on the basis of race, religion, gender, gender identity, national origin, citizenship status, sexual orientation, disability, political affiliation or belief. We are committed to the principals of Equal Opportunity Employment and are dedicated to making employment decisions based on merit and value, for ourselves, our client companies, and for the candidates we represent.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Scion Technical Search is seeking a <strong>fully remote Data Engineer </strong>for our forward-thinking, collaborative client in San Francisco, CA!<br><br>This engineering department does all they can to make their organization an <strong>outstanding team</strong> to work for! They have built up a modern code base with React on the Frontend and Python on the server side.<br><br>This position is ideal for someone who is passionate about or experienced in the culture within a Start-Up. This PaaS company was founded less than 2 years ago and they’re already profitable! No wonder they’re actively expanding!<br><br><strong><u>Perks<br></u></strong><ul> <li>Founders have proven success in building businesses</li> <li>Up to $200k/yr starting salary DOE</li> <li>Fully remote work situation (even post-Covid)</li> <li>Paid Health, Vision, and Dental benefits</li> <li>Meaningful Equity Package offered DOE</li> <li>Paid lunch daily via delivery for all employees</li> <li>Fully furnished remote, ergonomic work set-up </li> <li>Modern code base: React + Python</li> <li>Small, close-knit team environment</li> <li>Flexible working hours</li> <li>Paid Time Off (of course!)</li> <br><br></ul><strong><u>What You Will Be Doing<br></u></strong><ul> <li>Building out Data Pipelines to manage Big Data sets in an effort to provide meaningful insights</li> <li>Helping to build out the search function of this modern Platform</li> <br><br></ul><strong><u>What You Will Need<br></u></strong><ul> <li>3+ years of professional experience in Software Engineering or BS in Computer Science (you can code!)</li> <li>Strong project experience with <strong>Python </strong></li> <li>Familiarity using <strong>Postgrès</strong> as a database</li> <li>Background in creating <strong>Data Pipelines</strong></li> <br><br></ul><strong>Interested?<br><br></strong>Contact Scion Technical today for more information by submitting your resume directly through this posting. We look forward to reviewing your background and discussing this exciting opportunity further!<br><br><strong><u>About Our Firm<br><br></u></strong>Scion Staffing is an award winning staffing firm headquartered in San Francisco, CA. Over the past few years, our firm has had the pleasure of successfully assisting hundreds of local employers. No matter the requisition or size, our track record and recruitment prowess has made us one of the top recruitment firms in California. Additional information about our firm and success can also be found online at www.scionstaffing.com, or in the Business Times list of top staffing firms.<br><br>Scion Staffing is an equal opportunity employer and service provider and does not discriminate on the basis of race, religion, gender, gender identity, national origin, citizenship status, sexual orientation, disability, political affiliation or belief. We are committed to the principals of Equal Opportunity Employment and are dedicated to making employment decisions based on merit and value, for ourselves, our client companies, and for the candidates we represent.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Nonprofit Organization Management, Information Technology and Services, Staffing and Recruiting"
Data Engineer,"Tampa, Florida, United States",BioSpace,2021-02-04,https://www.linkedin.com/jobs/view/data-engineer-at-biospace-2415171612?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=gtk6XZm3rjotH1Z3K8cJDg%3D%3D&position=8&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Global Commercial Operational IS is looking for a talented Data Engineer, who is curious to learn and able to develop data engineering and data analytics solution in a fast-moving environment. Candidate will work closely with senior data engineer and product owner/business analyst to understand the requirement. This role will be part of the newly established technical/engineering team, develop data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.

The Data Engineer will be based out of Amgen's Capability Center in Tampa, FL. At Amgen, our mission is simple: to serve patients. Our Tampa Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world's leading biotechnology companies.

Responsibilities

Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics team
Collaborate with Data Architects, Business SME's, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions
Serve as system admin to manage AWS and Databricks platform;
Adhere to best practices for coding, testing and designing reusable code/component
Able to explore new tools, technologies that will help to improve ETL platform performance
Participate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams



Basic Qualifications

Master's degree

OR

Bachelor's degree and 2 years of Data Engineering and/or and Software Engineering experience

OR

Associate's degree 6 years of Data Engineering and/or Software Engineering experience

OR

High school diploma and 8 years of Data Engineering and/or Software Engineering experience

Preferred Qualifications

Experience with software development (Java, Python preferred), end-to-end system design
Experience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL
Experience with ETL tool, for example Informatica PowerCenter
Ability to learn quickly, be organized and detail oriented
Hands on development experience with Informatica Power Center, MDM, Data Integration Hub
Experience with software DevOps CI/CD tools, such Git, Jenkins
Experience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway
Experience with Apache Airflow and Apache Spark
Experience with Tableau Dashboard and Tableau Server
Experience with Pharmaceutical industry, commercial operations



Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.

Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.

Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

Join Us

If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.

Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.

As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.

Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Global Commercial Operational IS is looking for a talented Data Engineer, who is curious to learn and able to develop data engineering and data analytics solution in a fast-moving environment. Candidate will work closely with senior data engineer and product owner/business analyst to understand the requirement. This role will be part of the newly established technical/engineering team, develop data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.<br><br>The Data Engineer will be based out of Amgen's Capability Center in Tampa, FL. At Amgen, our mission is simple: to serve patients. Our Tampa Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world's leading biotechnology companies.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics team</li> <li>Collaborate with Data Architects, Business SME's, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions</li> <li>Serve as system admin to manage AWS and Databricks platform;</li> <li>Adhere to best practices for coding, testing and designing reusable code/component</li> <li>Able to explore new tools, technologies that will help to improve ETL platform performance</li> <li>Participate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams</li> <br><br></ul><strong><u>Basic Qualifications<br><br></u></strong>Master's degree<br><br>OR<br><br>Bachelor's degree and 2 years of Data Engineering and/or and Software Engineering experience<br><br>OR<br><br>Associate's degree 6 years of Data Engineering and/or Software Engineering experience<br><br>OR<br><br>High school diploma and 8 years of Data Engineering and/or Software Engineering experience<br><br><strong><u>Preferred Qualifications<br></u></strong><ul> <li>Experience with software development (Java, Python preferred), end-to-end system design</li> <li>Experience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL</li> <li>Experience with ETL tool, for example Informatica PowerCenter</li> <li>Ability to learn quickly, be organized and detail oriented</li> <li>Hands on development experience with Informatica Power Center, MDM, Data Integration Hub</li> <li>Experience with software DevOps CI/CD tools, such Git, Jenkins</li> <li>Experience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway</li> <li>Experience with Apache Airflow and Apache Spark</li> <li>Experience with Tableau Dashboard and Tableau Server</li> <li>Experience with Pharmaceutical industry, commercial operations</li> <br><br></ul>Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.<br><br>Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.<br><br>Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.<br><br>Join Us<br><br>If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.<br><br>Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.<br><br>As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.<br><br>Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Financial Services, Hospital & Health Care"
Data Engineer,"St Louis, Missouri, United States",Open Systems Technologies,2021-02-17,https://www.linkedin.com/jobs/view/data-engineer-at-open-systems-technologies-2427530736?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=vZUjZ4bShyRg5WOawY2hkw%3D%3D&position=9&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Our client is seeking a Data Engineer to join their team in St. Louis, MO.

Responsibilities

Managing master data, including creation, updates and deletion from central repository
Provide quality assurance of imported data, working with the team if necessary
Commissioning and decommissioning of data sets
Processing PHI and PII data and information according to company guidelines
Helping develop reports and analysis
Assist with managing data sources needed in the reporting environment
Support the data warehouse in identifying and revising reporting requirements
Supporting initiative for data integrity and normalization
Troubleshooting the reporting database environment and reports
Evaluating changes and updates to source production systems
Provide technical assistance on data storage structures, data mining and data cleansing
Structure large data sets to find usable information

Qualifications

5 years of relevant experience with a Bachelor’s Degree in Computer Science, Information Systems, Systems Engineering or equivalent
Demonstrated experience in handling large data sets and relational databases
Coding skills in languages such as SQL and Python
Understanding of data warehousing and ETL techniques
Experience with analytical tools working with central repository data sources
Experience with Linux a plus
Strong understanding of Software development lifecycle
Excellent communication, documentation and presentation skills
Solid understanding of Agile Project Management methodologies
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Our client is seeking a Data Engineer to join their team in St. Louis, MO.<br><br><strong><u>Responsibilities<br><br></u></strong>Managing master data, including creation, updates and deletion from central repository<br>Provide quality assurance of imported data, working with the team if necessary<br>Commissioning and decommissioning of data sets<br>Processing PHI and PII data and information according to company guidelines<br>Helping develop reports and analysis<br>Assist with managing data sources needed in the reporting environment<br>Support the data warehouse in identifying and revising reporting requirements<br>Supporting initiative for data integrity and normalization<br>Troubleshooting the reporting database environment and reports<br>Evaluating changes and updates to source production systems<br>Provide technical assistance on data storage structures, data mining and data cleansing<br>Structure large data sets to find usable information<br><br><strong><u>Qualifications<br><br></u></strong>5 years of relevant experience with a Bachelor’s Degree in Computer Science, Information Systems, Systems Engineering or equivalent<br>Demonstrated experience in handling large data sets and relational databases<br>Coding skills in languages such as SQL and Python<br>Understanding of data warehousing and ETL techniques<br>Experience with analytical tools working with central repository data sources<br>Experience with Linux a plus<br>Strong understanding of Software development lifecycle<br>Excellent communication, documentation and presentation skills<br>Solid understanding of Agile Project Management methodologies</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Scientist,"Portland, Oregon, United States",Portland General Electric,2021-02-12,https://www.linkedin.com/jobs/view/data-scientist-at-portland-general-electric-2401652598?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=LWEBYn67%2BnzN1bc49iOfYw%3D%3D&position=10&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Our client is seeking a Data Engineer to join their team in St. Louis, MO.

Responsibilities

Managing master data, including creation, updates and deletion from central repository
Provide quality assurance of imported data, working with the team if necessary
Commissioning and decommissioning of data sets
Processing PHI and PII data and information according to company guidelines
Helping develop reports and analysis
Assist with managing data sources needed in the reporting environment
Support the data warehouse in identifying and revising reporting requirements
Supporting initiative for data integrity and normalization
Troubleshooting the reporting database environment and reports
Evaluating changes and updates to source production systems
Provide technical assistance on data storage structures, data mining and data cleansing
Structure large data sets to find usable information

Qualifications

5 years of relevant experience with a Bachelor’s Degree in Computer Science, Information Systems, Systems Engineering or equivalent
Demonstrated experience in handling large data sets and relational databases
Coding skills in languages such as SQL and Python
Understanding of data warehousing and ETL techniques
Experience with analytical tools working with central repository data sources
Experience with Linux a plus
Strong understanding of Software development lifecycle
Excellent communication, documentation and presentation skills
Solid understanding of Agile Project Management methodologies
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Our client is seeking a Data Engineer to join their team in St. Louis, MO.<br><br><strong><u>Responsibilities<br><br></u></strong>Managing master data, including creation, updates and deletion from central repository<br>Provide quality assurance of imported data, working with the team if necessary<br>Commissioning and decommissioning of data sets<br>Processing PHI and PII data and information according to company guidelines<br>Helping develop reports and analysis<br>Assist with managing data sources needed in the reporting environment<br>Support the data warehouse in identifying and revising reporting requirements<br>Supporting initiative for data integrity and normalization<br>Troubleshooting the reporting database environment and reports<br>Evaluating changes and updates to source production systems<br>Provide technical assistance on data storage structures, data mining and data cleansing<br>Structure large data sets to find usable information<br><br><strong><u>Qualifications<br><br></u></strong>5 years of relevant experience with a Bachelor’s Degree in Computer Science, Information Systems, Systems Engineering or equivalent<br>Demonstrated experience in handling large data sets and relational databases<br>Coding skills in languages such as SQL and Python<br>Understanding of data warehousing and ETL techniques<br>Experience with analytical tools working with central repository data sources<br>Experience with Linux a plus<br>Strong understanding of Software development lifecycle<br>Excellent communication, documentation and presentation skills<br>Solid understanding of Agile Project Management methodologies</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Financial Services"
Data Engineer,"Raleigh, North Carolina, United States",TechSoup,2021-02-10,https://www.linkedin.com/jobs/view/data-engineer-at-techsoup-2428718203?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=4VBRJdlHshNus3nPzh68Fw%3D%3D&position=11&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"This is an exciting time to join Portland General Electric. As Oregon’s largest electric utility, Portland General Electric is leading an energy transformation that will harness the power of clean and renewable resources. Our vision for a clean energy future relies on three interrelated and overarching strategies: de-carbonize through investing in clean and reliable energy; modernize through a smarter more resilient grid; and empower our customers in their energy technology choices.

We’re searching for innovative, customer and results-obsessed leaders to help power our mission and lead the way in championing the world’s clean energy future!

Data Scientist

The Data Strategy & Management (DS&M) team bears critical responsibility on behalf of Portland General Electric (PGE) to create value for customers, regulators, policy makers, shareholders and business operations through the collection, organization and interpretation of data from PGE’s expansive portfolio of data generating assets, as well as data available from the electric grid, related public and private infrastructure and our service delivery ecosystems.

This individual collaborates with the business to answer business questions by using data mining techniques, including pattern detection, graph analysis or statistical analysis. He/she will work closely with the Information Architect, Data Architect, Data Engineer, other data scientists, and Business SME’s to gather the criteria that would need to be taken into consideration, the expected qualification and assurance of the information in support of the use cases, identify the information sources (internal or external to the organization) that can support the analysis. Develop cost-benefit analyses and value realization framework that other scientists can follow.

This individual will work with the data steward to ensure that the information used is in compliance with the regulatory and security policies in place. This includes qualifying where information can be stored or what information external to the organization may be used in support of the use case. He/she should be able to do data wrangling, model training, user engagement, assess the volume of data supporting the initiative, the type of data it is (images, text, clickstream or metering data) and the speed or sudden variations in data collection.

This individual will work closely with the Principal Data Scientist.

Responsibilities/Accountabilities

Follow the overall data science standards, guidelines, best practices and approved modeling techniques. Suggest improvements as necessary.
Work with the business stakeholders to identify what the business requirements are and the expected outcome. Model and frame business scenarios that are meaningful and which impact on critical business processes and/or decisions.
Working with and alongside business analysts, information architect, and data architect, identify what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as smart meters and geo-location information or social media. Work with Data Engineers to support data collection, integration and retention requirements based on the input received.
The cost of getting the data will impact on what sources should be considered, either because the data needs to be purchased from a third party or because of the complexity of the source. Develop cost-benefit models to justify the data purchase/collation.
Work with the data steward to ensure that the information used follows the compliance, access management and control policies of the organization and that it meets the qualification and assurance requirements of the business. Data stewards and data scientists will need to define the data quality expectation in the context of the specific use case.
Work in iterative processes with the business and validate findings. Expose the rationale of the findings in easy to understand terms by leveraging tools such as Tableau for the business especially the ones that contradict common belief.
Include experimental design approaches to validate findings by comparing appropriate samples. Develop approaches for validation regardless of the use case.
Suggest ongoing improvements to methods and algorithms that lead to findings, including new information. For example, refining suggestions based on client’s interests, geographic location, age or gender, rather than just based on overall buying pattern.
Understand the use and ability to employ the appropriate algorithm to discover patterns.
Timely delivery of analysis. Due to the experimental approach to the problem, data scientists are at risk of over analyzing. Being able to define a ""good enough"" result is critical.
Develop and maintain data science products that will help improve the ways in which we conduct business, increase our throughput thru operational efficiencies.
Educate the Data & Strategy Management organization on new approaches, such as testing hypotheses and statistical validation of results.
Develop best practices and guidelines for data science initiatives.
Establish metrics for tracking and measuring the value of data science initiatives.
This role will work with the principal data scientists and collaborate with other data scientists in the team/company.

Education / Experience

Requires a bachelor’s degree in computer science, electrical engineering, economics or other related field or equivalent experience. MSc or PhD in mathematics, statistics or computer science or related field, such as physics or economics.
Total experience of 3 or more years with vertical industry (utility background) is desired.
Two to three years of experience in data or statistical analysis, with mathematical and causal modeling skills.


Knowledge/Skills

Strong communication and interpersonal skills. The ability to communicate with the business to understand requirements and present back findings and recommendations by demonstrating the potential value to the organization.
Self-starter. The ability to come up with solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets. He/she is expected to define the problem space based on industry or technological threats.
Strong programming skills, Java, Python, statistical modeling, SQL, NOSQL (DynamoDB) and depending on the scope of the project, text mining or machine learning.
Knowledge of implementing and maintaining machine learning algorithms using AWS platform and retraining the models.
Ability to present results from critical analyses to senior and executive management
Advanced business acumen and interpersonal skills; able to work across business lines at senior levels to influence and effect change to achieve common goals.
Substantial data literacy — the ability to describe data sources and management concepts, and analytical approaches/options. The ability to translate among the languages used by executive, business, IT and quant stakeholders.
Mastery in oral and written communication skills, including the ability to explain data concepts and technologies to business leaders, as well as business concepts to technologists.
Proven record of effective leadership, including the ability to balance team and individual responsibilities; building consensus; getting things done through others not directly under his/her supervision; working ethically and with integrity.


Behaviors/Competencies & Abilities Required

Substantial use of logic or scientific thinking to define problems, collect information, establish facts and draw valid conclusions.
Substantial ability to lead positive change.
Substantial ability to achieve results.
Substantial ability to design work.
Substantial ability to uphold values.
Substantial role competence.
Ability to adhere to set response times, deadlines and time-sensitive tasks.
Ability to follow accuracy standards.
Ability to follow through on decision-making tasks.
Ability to interact effectively and collaboratively within a team environment.
Ability to communicate and problem solve when under stress.
Ability to respond and adapt to frequent change.
Ability to accept and demonstrate self-awareness when provided constructive feedback.
Ability to discern feedback and acknowledge ownership of areas of improvement.
Ability to avoid future mistakes by applying reasonable skills to new but similar work situations or tasks.
Ability to successfully collaborate with peers, managers and others within the organization.
Demonstrates sound memory.
Ability to process new information to be applied consistently to work tasks.


Join us today and power your potential!

To be considered for this position, please complete the following employment application by the posting close date. A cover letter may be needed with your application to be considered for this position.

PGE believes in rewarding strong performance. We provide a total compensation package that is designed to reward your contributions to the company, and, at the same time, support your well-being and professional development, both now and into the future.

PGE is committed to diversity and inclusion in the workplace and is an equal opportunity employer. PGE will not discriminate against any employee or applicant for employment based on race, color, national origin, gender, gender identity, sexual orientation, age, religion, disability, protected veteran status, or other characteristics protected by law.

Assisting with storms or other Company emergencies is a part of all positions at Portland General Electric.

Talent Acquisition Contact

Staffing@pgn.com

This job posting will close at 12:01 am Pacific Time on the closing date listed below:
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">This is an exciting time to join Portland General Electric. As Oregon’s largest electric utility, Portland General Electric is leading an energy transformation that will harness the power of clean and renewable resources. Our vision for a clean energy future relies on three interrelated and overarching strategies: de-carbonize through investing in clean and reliable energy; modernize through a smarter more resilient grid; and empower our customers in their energy technology choices.<br><br>We’re searching for innovative, customer and results-obsessed leaders to help power our mission and lead the way in championing the world’s clean energy future!<br><br><strong><u>Data Scientist<br><br></u></strong>The Data Strategy &amp; Management (DS&amp;M) team bears critical responsibility on behalf of Portland General Electric (PGE) to create value for customers, regulators, policy makers, shareholders and business operations through the collection, organization and interpretation of data from PGE’s expansive portfolio of data generating assets, as well as data available from the electric grid, related public and private infrastructure and our service delivery ecosystems.<br><br>This individual collaborates with the business to answer business questions by using data mining techniques, including pattern detection, graph analysis or statistical analysis. He/she will work closely with the Information Architect, Data Architect, Data Engineer, other data scientists, and Business SME’s to gather the criteria that would need to be taken into consideration, the expected qualification and assurance of the information in support of the use cases, identify the information sources (internal or external to the organization) that can support the analysis. Develop cost-benefit analyses and value realization framework that other scientists can follow.<br><br>This individual will work with the data steward to ensure that the information used is in compliance with the regulatory and security policies in place. This includes qualifying where information can be stored or what information external to the organization may be used in support of the use case. He/she should be able to do data wrangling, model training, user engagement, assess the volume of data supporting the initiative, the type of data it is (images, text, clickstream or metering data) and the speed or sudden variations in data collection.<br><br>This individual will work closely with the Principal Data Scientist.<br><br><strong><u>Responsibilities/Accountabilities<br></u></strong><ul><li>Follow the overall data science standards, guidelines, best practices and approved modeling techniques. Suggest improvements as necessary.</li><li>Work with the business stakeholders to identify what the business requirements are and the expected outcome. Model and frame business scenarios that are meaningful and which impact on critical business processes and/or decisions.</li><li>Working with and alongside business analysts, information architect, and data architect, identify what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as smart meters and geo-location information or social media. Work with Data Engineers to support data collection, integration and retention requirements based on the input received.</li><li>The cost of getting the data will impact on what sources should be considered, either because the data needs to be purchased from a third party or because of the complexity of the source. Develop cost-benefit models to justify the data purchase/collation.</li><li>Work with the data steward to ensure that the information used follows the compliance, access management and control policies of the organization and that it meets the qualification and assurance requirements of the business. Data stewards and data scientists will need to define the data quality expectation in the context of the specific use case.</li><li>Work in iterative processes with the business and validate findings. Expose the rationale of the findings in easy to understand terms by leveraging tools such as Tableau for the business especially the ones that contradict common belief.</li><li>Include experimental design approaches to validate findings by comparing appropriate samples. Develop approaches for validation regardless of the use case.</li><li>Suggest ongoing improvements to methods and algorithms that lead to findings, including new information. For example, refining suggestions based on client’s interests, geographic location, age or gender, rather than just based on overall buying pattern.</li><li>Understand the use and ability to employ the appropriate algorithm to discover patterns.</li><li>Timely delivery of analysis. Due to the experimental approach to the problem, data scientists are at risk of over analyzing. Being able to define a ""good enough"" result is critical.</li><li>Develop and maintain data science products that will help improve the ways in which we conduct business, increase our throughput thru operational efficiencies.</li><li>Educate the Data &amp; Strategy Management organization on new approaches, such as testing hypotheses and statistical validation of results.</li><li>Develop best practices and guidelines for data science initiatives.</li><li>Establish metrics for tracking and measuring the value of data science initiatives.</li><li>This role will work with the principal data scientists and collaborate with other data scientists in the team/company.<br></li></ul><strong><u>Education</u></strong><strong><u> / Experience<br></u></strong><ul><li>Requires a bachelor’s degree in computer science, electrical engineering, economics or other related field or equivalent experience. MSc or PhD in mathematics, statistics or computer science or related field, such as physics or economics.</li><li>Total experience of 3 or more years with vertical industry (utility background) is desired.</li><li>Two to three years of experience in data or statistical analysis, with mathematical and causal modeling skills.<br><br></li></ul><strong><u>Knowledge/Skills<br></u></strong><ul><li>Strong communication and interpersonal skills. The ability to communicate with the business to understand requirements and present back findings and recommendations by demonstrating the potential value to the organization.</li><li>Self-starter. The ability to come up with solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets. He/she is expected to define the problem space based on industry or technological threats.</li><li>Strong programming skills, Java, Python, statistical modeling, SQL, NOSQL (DynamoDB) and depending on the scope of the project, text mining or machine learning.</li><li>Knowledge of implementing and maintaining machine learning algorithms using AWS platform and retraining the models.</li><li>Ability to present results from critical analyses to senior and executive management</li><li>Advanced business acumen and interpersonal skills; able to work across business lines at senior levels to influence and effect change to achieve common goals.</li><li>Substantial data literacy — the ability to describe data sources and management concepts, and analytical approaches/options. The ability to translate among the languages used by executive, business, IT and quant stakeholders.</li><li>Mastery in oral and written communication skills, including the ability to explain data concepts and technologies to business leaders, as well as business concepts to technologists.</li><li>Proven record of effective leadership, including the ability to balance team and individual responsibilities; building consensus; getting things done through others not directly under his/her supervision; working ethically and with integrity.<br><br></li></ul><strong><u>Behaviors/Competencies &amp; Abilities Required<br></u></strong><ul><li>Substantial use of logic or scientific thinking to define problems, collect information, establish facts and draw valid conclusions.</li><li>Substantial ability to lead positive change.</li><li>Substantial ability to achieve results.</li><li>Substantial ability to design work.</li><li>Substantial ability to uphold values.</li><li>Substantial role competence.</li><li>Ability to adhere to set response times, deadlines and time-sensitive tasks.</li><li>Ability to follow accuracy standards.</li><li>Ability to follow through on decision-making tasks.</li><li>Ability to interact effectively and collaboratively within a team environment.</li><li>Ability to communicate and problem solve when under stress.</li><li>Ability to respond and adapt to frequent change.</li><li>Ability to accept and demonstrate self-awareness when provided constructive feedback.</li><li>Ability to discern feedback and acknowledge ownership of areas of improvement.</li><li>Ability to avoid future mistakes by applying reasonable skills to new but similar work situations or tasks.</li><li>Ability to successfully collaborate with peers, managers and others within the organization.</li><li>Demonstrates sound memory.</li><li>Ability to process new information to be applied consistently to work tasks.<br><br></li></ul><strong>Join us today and power your potential!<br><br></strong>To be considered for this position, please complete the following employment application by the posting close date. A cover letter may be needed with your application to be considered for this position.<br><br>PGE believes in rewarding strong performance. We provide a total compensation package that is designed to reward your contributions to the company, and, at the same time, support your well-being and professional development, both now and into the future.<br><br>PGE is committed to diversity and inclusion in the workplace and is an equal opportunity employer. PGE will not discriminate against any employee or applicant for employment based on race, color, national origin, gender, gender identity, sexual orientation, age, religion, disability, protected veteran status, or other characteristics protected by law.<br><br>Assisting with storms or other Company emergencies is a part of all positions at Portland General Electric.<br><br><strong><u>Talent Acquisition Contact<br><br></u></strong>Staffing@pgn.com<br><br>This job posting will close at 12:01 am Pacific Time on the closing date listed below:</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Utilities, Financial Services"
Data Scientist,"Glendale, California, United States",Beyond Limits,2021-02-18,https://www.linkedin.com/jobs/view/data-scientist-at-beyond-limits-2429503406?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=hvi43XGmsvCrG5jmBMSVMg%3D%3D&position=13&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Description

Position Overview

Our data science team is expanding! The successful candidate will work with the data science and engineering teams on challenging projects in a variety of domains.

Beyond Limits is a pioneering Artificial Intelligence company and a satellite of NASA's Jet Propulsion Lab and Caltech. Beyond Limits cognitive computing technology combines numeric and symbolic techniques to provide advanced solutions that go far beyond conventional AI.

Job Duties/Responsibilities

Ingest, organize, and analyze data from various sources (e.g. CSV, relational database)
Scope unstructured problems or messy data for tractable insights
Identify candidate statistical or machine learning solutions and test their efficacy
Communicate technical work and findings both verbally and through written reports and visualizations
Work in a collaborative environment to brainstorm, design, implement and deliver solutions to challenging problems


Qualifications And Skills

5+ years of relevant industry work experience
Excellent understanding of statistical or machine learning techniques, such as clustering, regression, time series forecasting, tree-based methods, sampling methods
Demonstrated ability using scientific computing libraries, such as NumPy, Pandas, SciPy, Scikit-learn, Matplotlib, and Plotly
Programming proficiency in Python or R


Preferred Requirements

Ph.D. or Master’s
Strong statistical knowledge and experience with hypothesis testing
Fluency with machine learning algorithms, such as CNN, RNN, reinforcement learning, support vector machines, and graph-based models
Experience with TensorFlow, Keras, or PyTorch
Experience with version control systems (e.g. Git flow)
Strong oral and verbal communication skills
Research experience with high impact publications
Experience working with cross-functional teams and/or customer facing work


About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher-order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.
Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><strong>Position Overview<br><br></strong>Our data science team is expanding! The successful candidate will work with the data science and engineering teams on challenging projects in a variety of domains.<br><br>Beyond Limits is a pioneering Artificial Intelligence company and a satellite of NASA's Jet Propulsion Lab and Caltech. Beyond Limits cognitive computing technology combines numeric and symbolic techniques to provide advanced solutions that go far beyond conventional AI.<br><br><strong><u>Job Duties/Responsibilities<br></u></strong><ul><li>Ingest, organize, and analyze data from various sources (e.g. CSV, relational database)</li><li>Scope unstructured problems or messy data for tractable insights</li><li>Identify candidate statistical or machine learning solutions and test their efficacy</li><li>Communicate technical work and findings both verbally and through written reports and visualizations</li><li>Work in a collaborative environment to brainstorm, design, implement and deliver solutions to challenging problems<br><br></li></ul><strong><u>Qualifications And Skills<br></u></strong><ul><li>5+ years of relevant industry work experience</li><li>Excellent understanding of statistical or machine learning techniques, such as clustering, regression, time series forecasting, tree-based methods, sampling methods</li><li>Demonstrated ability using scientific computing libraries, such as NumPy, Pandas, SciPy, Scikit-learn, Matplotlib, and Plotly</li><li>Programming proficiency in Python or R<br><br></li></ul><strong><u>Preferred Requirements<br></u></strong><ul><li>Ph.D. or Master’s</li><li>Strong statistical knowledge and experience with hypothesis testing</li><li>Fluency with machine learning algorithms, such as CNN, RNN, reinforcement learning, support vector machines, and graph-based models</li><li>Experience with TensorFlow, Keras, or PyTorch</li><li>Experience with version control systems (e.g. Git flow)</li><li>Strong oral and verbal communication skills</li><li>Research experience with high impact publications</li><li>Experience working with cross-functional teams and/or customer facing work<br><br></li></ul><strong><u>About Beyond Limits<br><br></u></strong>Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher-order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.<br>Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.<br><br>Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Analytics Engineer,"New York, New York, United States",MakeSpace,2021-02-09,https://www.linkedin.com/jobs/view/analytics-engineer-at-makespace-2415569496?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=BNiNjH6zOJiI6cJMmQXDUA%3D%3D&position=14&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Description

Position Overview

Our data science team is expanding! The successful candidate will work with the data science and engineering teams on challenging projects in a variety of domains.

Beyond Limits is a pioneering Artificial Intelligence company and a satellite of NASA's Jet Propulsion Lab and Caltech. Beyond Limits cognitive computing technology combines numeric and symbolic techniques to provide advanced solutions that go far beyond conventional AI.

Job Duties/Responsibilities

Ingest, organize, and analyze data from various sources (e.g. CSV, relational database)
Scope unstructured problems or messy data for tractable insights
Identify candidate statistical or machine learning solutions and test their efficacy
Communicate technical work and findings both verbally and through written reports and visualizations
Work in a collaborative environment to brainstorm, design, implement and deliver solutions to challenging problems


Qualifications And Skills

5+ years of relevant industry work experience
Excellent understanding of statistical or machine learning techniques, such as clustering, regression, time series forecasting, tree-based methods, sampling methods
Demonstrated ability using scientific computing libraries, such as NumPy, Pandas, SciPy, Scikit-learn, Matplotlib, and Plotly
Programming proficiency in Python or R


Preferred Requirements

Ph.D. or Master’s
Strong statistical knowledge and experience with hypothesis testing
Fluency with machine learning algorithms, such as CNN, RNN, reinforcement learning, support vector machines, and graph-based models
Experience with TensorFlow, Keras, or PyTorch
Experience with version control systems (e.g. Git flow)
Strong oral and verbal communication skills
Research experience with high impact publications
Experience working with cross-functional teams and/or customer facing work


About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher-order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.
Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>Description<br><br></u></strong><strong>Position Overview<br><br></strong>Our data science team is expanding! The successful candidate will work with the data science and engineering teams on challenging projects in a variety of domains.<br><br>Beyond Limits is a pioneering Artificial Intelligence company and a satellite of NASA's Jet Propulsion Lab and Caltech. Beyond Limits cognitive computing technology combines numeric and symbolic techniques to provide advanced solutions that go far beyond conventional AI.<br><br><strong><u>Job Duties/Responsibilities<br></u></strong><ul><li>Ingest, organize, and analyze data from various sources (e.g. CSV, relational database)</li><li>Scope unstructured problems or messy data for tractable insights</li><li>Identify candidate statistical or machine learning solutions and test their efficacy</li><li>Communicate technical work and findings both verbally and through written reports and visualizations</li><li>Work in a collaborative environment to brainstorm, design, implement and deliver solutions to challenging problems<br><br></li></ul><strong><u>Qualifications And Skills<br></u></strong><ul><li>5+ years of relevant industry work experience</li><li>Excellent understanding of statistical or machine learning techniques, such as clustering, regression, time series forecasting, tree-based methods, sampling methods</li><li>Demonstrated ability using scientific computing libraries, such as NumPy, Pandas, SciPy, Scikit-learn, Matplotlib, and Plotly</li><li>Programming proficiency in Python or R<br><br></li></ul><strong><u>Preferred Requirements<br></u></strong><ul><li>Ph.D. or Master’s</li><li>Strong statistical knowledge and experience with hypothesis testing</li><li>Fluency with machine learning algorithms, such as CNN, RNN, reinforcement learning, support vector machines, and graph-based models</li><li>Experience with TensorFlow, Keras, or PyTorch</li><li>Experience with version control systems (e.g. Git flow)</li><li>Strong oral and verbal communication skills</li><li>Research experience with high impact publications</li><li>Experience working with cross-functional teams and/or customer facing work<br><br></li></ul><strong><u>About Beyond Limits<br><br></u></strong>Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher-order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.<br>Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.<br><br>Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer I,"El Segundo, California, United States",GoGuardian,2021-02-02,https://www.linkedin.com/jobs/view/data-engineer-i-at-goguardian-2392369240?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=3udFm6LDXjjbo2W7t%2FQ2pg%3D%3D&position=15&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Join us in our mission to provide students with a safe and stimulating learning experience. At GoGuardian, you’ll get to work with friendly and motivated people to solve challenging problems in a great environment. At GoGuardian, we pride ourselves on bringing the very best talent to empower millions of student lives in the most impactful way. You’ll be joining a talented science and analytics team at a company making extensive use of modern data techniques to benefit educators and students.

GoGuardian is looking for a motivated data engineer to help plan, maintain, and constantly improve our data warehouse and ETL pipeline. Data Engineer I focuses on integrating, consolidating, and cleansing data from multiple source systems. This position works closely with the data science and business intelligence teams to prioritize tasks that are important to supporting our product and business units.

Principal Duties And Responsibilities

Develop new ETL processes to fulfill data needs of data science and other departments
Utilize expertise in data modeling, ETL architecture, and report design for department initiatives
Produce detailed documentation including data flow diagrams, logical diagrams, and physical diagrams as needed
Ensure the data collection pipeline and data analysis infrastructure meet the needs of the business
Acquire strong knowledge of data structures, analysis, replication and distributed/ relational data & database mapping
Assist with code review process for purposes of learning, asking new questions and finding errors
Assist with development of new scripts, KPIs and dashboardsAll other duties as assigned


Who You Are And Must Haves

Bachelor’s degree or equivalent experience
1 yr (preferably 2-3 years) experience building/operating systems for data extraction, ingestion, and processing of large data sets
Experience with modern data warehousing tools such as Redshift, Big Query, Snowflake, Azure Synapse
Hands on experience with SQL query language along with data warehouse design and maintenance
Proficiency in a modern data-centric coding language such as Python, Go, or Scala
Experience working with data orchestration tools such as Airflow, Luigi, AWS Step Functions
Strong attention to detail, analytical mindset, and highly organized
Ability to work independently within the policies, processes, and procedures defined for the team
Desire to work in a fast paced startup atmosphere requiring constant learning
Strong technical aptitude and demonstrated ability to quickly evaluate and learn new technologies
Strong interpersonal skills, with the ability to work independently and within a team environment


Bonus Points If You Also Bring The Following

Experience with infrastructure as code such as Terraform, Chef, Puppet, Cloud Formation
Experience with containerization tools such as Docker
Experience with a broad set of AWS tools (S3, EC2s, AWS Glue, Lambda, Cloudwatch, AWS data pipeline)
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist, Business Analyst)

What We Offer

Opportunity to impact and revolutionize safe digital learning experiences for K-12 students
Partner with enthusiastic and talented colleagues who are compelled to do good in the world
Weekly yoga classes and guided aromatherapy meditation
Annual personal growth stipend for continued learning
Grow and scale with one of the fastest growing EdTech companies

GoGuardian is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. GoGuardian does not discriminate against employees, applicants, interns or volunteers on the basis of race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, pregnancy, marital status, sex, age, sexual orientation, military and veteran status, registered domestic partner status, genetic information, gender, gender identity, gender expression, or any other characteristic protected by applicable law.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Join us in our mission to provide students with a safe and stimulating learning experience. At GoGuardian, you’ll get to work with friendly and motivated people to solve challenging problems in a great environment. At GoGuardian, we pride ourselves on bringing the very best talent to empower millions of student lives in the most impactful way. You’ll be joining a talented science and analytics team at a company making extensive use of modern data techniques to benefit educators and students.<br><br>GoGuardian is looking for a motivated data engineer to help plan, maintain, and constantly improve our data warehouse and ETL pipeline. Data Engineer I focuses on integrating, consolidating, and cleansing data from multiple source systems. This position works closely with the data science and business intelligence teams to prioritize tasks that are important to supporting our product and business units.<br><br><strong> Principal Duties And Responsibilities <br></strong><ul><li>Develop new ETL processes to fulfill data needs of data science and other departments</li><li>Utilize expertise in data modeling, ETL architecture, and report design for department initiatives</li><li>Produce detailed documentation including data flow diagrams, logical diagrams, and physical diagrams as needed</li><li>Ensure the data collection pipeline and data analysis infrastructure meet the needs of the business</li><li>Acquire strong knowledge of data structures, analysis, replication and distributed/ relational data &amp; database mapping</li><li>Assist with code review process for purposes of learning, asking new questions and finding errors</li><li>Assist with development of new scripts, KPIs and dashboardsAll other duties as assigned<br><br></li></ul><strong> Who You Are And Must Haves <br></strong><ul><li>Bachelor’s degree or equivalent experience</li><li>1 yr (preferably 2-3 years) experience building/operating systems for data extraction, ingestion, and processing of large data sets</li><li>Experience with modern data warehousing tools such as Redshift, Big Query, Snowflake, Azure Synapse</li><li>Hands on experience with SQL query language along with data warehouse design and maintenance</li><li>Proficiency in a modern data-centric coding language such as Python, Go, or Scala</li><li>Experience working with data orchestration tools such as Airflow, Luigi, AWS Step Functions</li><li>Strong attention to detail, analytical mindset, and highly organized</li><li>Ability to work independently within the policies, processes, and procedures defined for the team</li><li>Desire to work in a fast paced startup atmosphere requiring constant learning</li><li>Strong technical aptitude and demonstrated ability to quickly evaluate and learn new technologies</li><li>Strong interpersonal skills, with the ability to work independently and within a team environment<br><br></li></ul><strong> Bonus Points If You Also Bring The Following <br></strong><ul><li>Experience with infrastructure as code such as Terraform, Chef, Puppet, Cloud Formation</li><li>Experience with containerization tools such as Docker</li><li>Experience with a broad set of AWS tools (S3, EC2s, AWS Glue, Lambda, Cloudwatch, AWS data pipeline)</li><li>Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist, Business Analyst)<br></li></ul>What We Offer<br><ul><li>Opportunity to impact and revolutionize safe digital learning experiences for K-12 students</li><li>Partner with enthusiastic and talented colleagues who are compelled to do good in the world</li><li>Weekly yoga classes and guided aromatherapy meditation</li><li>Annual personal growth stipend for continued learning</li><li>Grow and scale with one of the fastest growing EdTech companies<br></li></ul>GoGuardian is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. GoGuardian does not discriminate against employees, applicants, interns or volunteers on the basis of race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, pregnancy, marital status, sex, age, sexual orientation, military and veteran status, registered domestic partner status, genetic information, gender, gender identity, gender expression, or any other characteristic protected by applicable law.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
"Specialist, BI & Analytics","Charlotte, North Carolina, United States",JLL,2021-02-14,https://www.linkedin.com/jobs/view/specialist-bi-analytics-at-jll-2423617729?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=ZjPWjCQgeBPpAtlBRiruZA%3D%3D&position=16&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Key Responsibilities- Business Intelligence Reporting and Analytics

Work closely with the business to identify needs, determine value drivers for the business and, translate business needs to system and user requirements;
Manage development lifecycle of key BI initiatives (development, test/QA, UAT, bug fix/retest cycles) through to training, go-live and phasing in of support & maintenance structures.
Translate business requirements into technical requirements for IT
Design automated reporting, dashboards, and analyses to enable improved decision making
Partner with service line leads across the integrated facilities management team to develop automated Tableau dashboards to provide real-time insights to business data
Deep dive into large data sets to answer key business questions using SQL, Excel, Tableau and Alteryx and other data manipulation languages
Leverage an analytic mindset to develop visualization of key trends and insights for decision making
Devise and promote creative data visualization to derive actionable intelligence
Forecast/trend performance data
Lead workshopping sessions to problem-solve and develop recommendations based on data interpretation and analysis to transform behaviors and techniques


Skills-

Communication- Excellent presentation skills (verbal and written) with a strong understanding of analytic/statistical concepts and the ability to explain them to others. Able to communicate in a clear and concise manner in English.
Strategic Thinking- Ability to think broadly, create a shared vision, and embrace change as an opportunity.
Organizational Agility- Knowledgeable about how organizations work, knows and can influence how to get things done both through formal channels and the informal network. Able to work with diverse stakeholders (business, IT, and clients).
Technical- Highly proficient technical skills with demonstrated ability to manage, manipulate, and analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendation. Able to interpret and tell the story behind the data. Working knowledge of the Corporate Real Estate industry or any multi-services industry is a bonus.
Process Improvement- Committed to continuous improvement through empowerment and management by data and is willing to re-engineer processes from scratch. Good trouble-shooting skills, able to use Root Cause Analysis (RCA). Process-oriented with a good grasp of requirements elicitation, project management, and technical delivery/development processes.
Client Management- Can understand client needs, can set and manage appropriate client expectations within system, project, or contract constraints, all while providing exceptional and enhanced customer service
Team-player- Can achieve results from ad hoc groups of disparate people (key stakeholders and collaborators are geographically dispersed).
Flexibility- Understands regional/cultural/contextual differences and allows for local expression without compromising global coherence.


Experience-

5+ years of BI, business, or data analytics experience required, ideally in an enterprise environment across multiple application systems and business functions
Demonstrated successes in data analysis, drawing conclusions, and suggesting improvements
Bachelor or Master degree, or evidence of expert skill in BI, data science, computer science, econometrics, operations research, statistics, Information Management, or related analytical field; advanced degree preferred.
Expert level skills in Excel required
Working experience in BI tools (Tableau preferred), querying databases (SQL), ETL tools (Alteryx preferred), and bulk data manipulation is essential
Working experience in analytical toolkit (e.g. SPSS, SAS, R or Python) desired.
Experience with Agile methodologies and framework a plus

Sound like you? Ready to join a team of globally known BI experts? Apply now!

JLL Privacy Notice

Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.

For more information about how JLL processes your personal data, please view our Candidate Privacy Statement .

For additional details please see our career site pages for each country.

For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here .

Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com . This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Key Responsibilities- </strong>Business Intelligence Reporting and Analytics<br><ul><li>Work closely with the business to identify needs, determine value drivers for the business and, translate business needs to system and user requirements;</li><li>Manage development lifecycle of key BI initiatives (development, test/QA, UAT, bug fix/retest cycles) through to training, go-live and phasing in of support &amp; maintenance structures.</li><li>Translate business requirements into technical requirements for IT</li><li>Design automated reporting, dashboards, and analyses to enable improved decision making</li><li>Partner with service line leads across the integrated facilities management team to develop automated Tableau dashboards to provide real-time insights to business data</li><li>Deep dive into large data sets to answer key business questions using SQL, Excel, Tableau and Alteryx and other data manipulation languages</li><li>Leverage an analytic mindset to develop visualization of key trends and insights for decision making</li><li>Devise and promote creative data visualization to derive actionable intelligence</li><li>Forecast/trend performance data</li><li>Lead workshopping sessions to problem-solve and develop recommendations based on data interpretation and analysis to transform behaviors and techniques<br><br></li></ul><strong><u>Skills-<br></u></strong><ul><li><strong>Communication</strong>- Excellent presentation skills (verbal and written) with a strong understanding of analytic/statistical concepts and the ability to explain them to others. Able to communicate in a clear and concise manner in English.</li><li><strong>Strategic Thinking-</strong> Ability to think broadly, create a shared vision, and embrace change as an opportunity.</li><li><strong>Organizational Agility-</strong> Knowledgeable about how organizations work, knows and can influence how to get things done both through formal channels and the informal network. Able to work with diverse stakeholders (business, IT, and clients).</li><li><strong>Technical</strong>- Highly proficient technical skills with demonstrated ability to manage, manipulate, and analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendation. Able to interpret and tell the story behind the data. Working knowledge of the Corporate Real Estate industry or any multi-services industry is a bonus.</li><li><strong>Process Improvement</strong>- Committed to continuous improvement through empowerment and management by data and is willing to re-engineer processes from scratch. Good trouble-shooting skills, able to use Root Cause Analysis (RCA). Process-oriented with a good grasp of requirements elicitation, project management, and technical delivery/development processes.</li><li><strong>Client Management</strong>- Can understand client needs, can set and manage appropriate client expectations within system, project, or contract constraints, all while providing exceptional and enhanced customer service</li><li><strong>Team-player</strong>- Can achieve results from ad hoc groups of disparate people (key stakeholders and collaborators are geographically dispersed).</li><li><strong>Flexibility-</strong> Understands regional/cultural/contextual differences and allows for local expression without compromising global coherence.<br><br></li></ul><strong><u>Experience-<br></u></strong><ul><li>5+ years of BI, business, or data analytics experience required, ideally in an enterprise environment across multiple application systems and business functions</li><li>Demonstrated successes in data analysis, drawing conclusions, and suggesting improvements</li><li>Bachelor or Master degree, or evidence of expert skill in BI, data science, computer science, econometrics, operations research, statistics, Information Management, or related analytical field; advanced degree preferred.</li><li>Expert level skills in Excel required</li><li>Working experience in BI tools (Tableau preferred), querying databases (SQL), ETL tools (Alteryx preferred), and bulk data manipulation is essential</li><li>Working experience in analytical toolkit (e.g. SPSS, SAS, R or Python) desired.</li><li>Experience with Agile methodologies and framework a plus<br></li></ul>Sound like you? Ready to join a team of globally known BI experts? Apply now!<br><br><strong><em> JLL Privacy Notice <br><br></em></strong>Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.<br><br>For more information about how JLL processes your personal data, please view our Candidate Privacy Statement .<br><br>For additional details please see our career site pages for each country.<br><br>For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here .<br><br>Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com . This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page &gt; I want to work for JLL.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Business Development, Sales",Full-time,"Construction, Information Technology and Services, Financial Services"
Analytics Engineer,"New York, New York, United States",Feedback Loop,2021-02-12,https://www.linkedin.com/jobs/view/analytics-engineer-at-feedback-loop-2421729117?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=MpHPSs2kmZ71HwohCtapoQ%3D%3D&position=17&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Key Responsibilities- Business Intelligence Reporting and Analytics

Work closely with the business to identify needs, determine value drivers for the business and, translate business needs to system and user requirements;
Manage development lifecycle of key BI initiatives (development, test/QA, UAT, bug fix/retest cycles) through to training, go-live and phasing in of support & maintenance structures.
Translate business requirements into technical requirements for IT
Design automated reporting, dashboards, and analyses to enable improved decision making
Partner with service line leads across the integrated facilities management team to develop automated Tableau dashboards to provide real-time insights to business data
Deep dive into large data sets to answer key business questions using SQL, Excel, Tableau and Alteryx and other data manipulation languages
Leverage an analytic mindset to develop visualization of key trends and insights for decision making
Devise and promote creative data visualization to derive actionable intelligence
Forecast/trend performance data
Lead workshopping sessions to problem-solve and develop recommendations based on data interpretation and analysis to transform behaviors and techniques


Skills-

Communication- Excellent presentation skills (verbal and written) with a strong understanding of analytic/statistical concepts and the ability to explain them to others. Able to communicate in a clear and concise manner in English.
Strategic Thinking- Ability to think broadly, create a shared vision, and embrace change as an opportunity.
Organizational Agility- Knowledgeable about how organizations work, knows and can influence how to get things done both through formal channels and the informal network. Able to work with diverse stakeholders (business, IT, and clients).
Technical- Highly proficient technical skills with demonstrated ability to manage, manipulate, and analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendation. Able to interpret and tell the story behind the data. Working knowledge of the Corporate Real Estate industry or any multi-services industry is a bonus.
Process Improvement- Committed to continuous improvement through empowerment and management by data and is willing to re-engineer processes from scratch. Good trouble-shooting skills, able to use Root Cause Analysis (RCA). Process-oriented with a good grasp of requirements elicitation, project management, and technical delivery/development processes.
Client Management- Can understand client needs, can set and manage appropriate client expectations within system, project, or contract constraints, all while providing exceptional and enhanced customer service
Team-player- Can achieve results from ad hoc groups of disparate people (key stakeholders and collaborators are geographically dispersed).
Flexibility- Understands regional/cultural/contextual differences and allows for local expression without compromising global coherence.


Experience-

5+ years of BI, business, or data analytics experience required, ideally in an enterprise environment across multiple application systems and business functions
Demonstrated successes in data analysis, drawing conclusions, and suggesting improvements
Bachelor or Master degree, or evidence of expert skill in BI, data science, computer science, econometrics, operations research, statistics, Information Management, or related analytical field; advanced degree preferred.
Expert level skills in Excel required
Working experience in BI tools (Tableau preferred), querying databases (SQL), ETL tools (Alteryx preferred), and bulk data manipulation is essential
Working experience in analytical toolkit (e.g. SPSS, SAS, R or Python) desired.
Experience with Agile methodologies and framework a plus

Sound like you? Ready to join a team of globally known BI experts? Apply now!

JLL Privacy Notice

Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.

For more information about how JLL processes your personal data, please view our Candidate Privacy Statement .

For additional details please see our career site pages for each country.

For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here .

Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com . This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Key Responsibilities- </strong>Business Intelligence Reporting and Analytics<br><ul><li>Work closely with the business to identify needs, determine value drivers for the business and, translate business needs to system and user requirements;</li><li>Manage development lifecycle of key BI initiatives (development, test/QA, UAT, bug fix/retest cycles) through to training, go-live and phasing in of support &amp; maintenance structures.</li><li>Translate business requirements into technical requirements for IT</li><li>Design automated reporting, dashboards, and analyses to enable improved decision making</li><li>Partner with service line leads across the integrated facilities management team to develop automated Tableau dashboards to provide real-time insights to business data</li><li>Deep dive into large data sets to answer key business questions using SQL, Excel, Tableau and Alteryx and other data manipulation languages</li><li>Leverage an analytic mindset to develop visualization of key trends and insights for decision making</li><li>Devise and promote creative data visualization to derive actionable intelligence</li><li>Forecast/trend performance data</li><li>Lead workshopping sessions to problem-solve and develop recommendations based on data interpretation and analysis to transform behaviors and techniques<br><br></li></ul><strong><u>Skills-<br></u></strong><ul><li><strong>Communication</strong>- Excellent presentation skills (verbal and written) with a strong understanding of analytic/statistical concepts and the ability to explain them to others. Able to communicate in a clear and concise manner in English.</li><li><strong>Strategic Thinking-</strong> Ability to think broadly, create a shared vision, and embrace change as an opportunity.</li><li><strong>Organizational Agility-</strong> Knowledgeable about how organizations work, knows and can influence how to get things done both through formal channels and the informal network. Able to work with diverse stakeholders (business, IT, and clients).</li><li><strong>Technical</strong>- Highly proficient technical skills with demonstrated ability to manage, manipulate, and analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendation. Able to interpret and tell the story behind the data. Working knowledge of the Corporate Real Estate industry or any multi-services industry is a bonus.</li><li><strong>Process Improvement</strong>- Committed to continuous improvement through empowerment and management by data and is willing to re-engineer processes from scratch. Good trouble-shooting skills, able to use Root Cause Analysis (RCA). Process-oriented with a good grasp of requirements elicitation, project management, and technical delivery/development processes.</li><li><strong>Client Management</strong>- Can understand client needs, can set and manage appropriate client expectations within system, project, or contract constraints, all while providing exceptional and enhanced customer service</li><li><strong>Team-player</strong>- Can achieve results from ad hoc groups of disparate people (key stakeholders and collaborators are geographically dispersed).</li><li><strong>Flexibility-</strong> Understands regional/cultural/contextual differences and allows for local expression without compromising global coherence.<br><br></li></ul><strong><u>Experience-<br></u></strong><ul><li>5+ years of BI, business, or data analytics experience required, ideally in an enterprise environment across multiple application systems and business functions</li><li>Demonstrated successes in data analysis, drawing conclusions, and suggesting improvements</li><li>Bachelor or Master degree, or evidence of expert skill in BI, data science, computer science, econometrics, operations research, statistics, Information Management, or related analytical field; advanced degree preferred.</li><li>Expert level skills in Excel required</li><li>Working experience in BI tools (Tableau preferred), querying databases (SQL), ETL tools (Alteryx preferred), and bulk data manipulation is essential</li><li>Working experience in analytical toolkit (e.g. SPSS, SAS, R or Python) desired.</li><li>Experience with Agile methodologies and framework a plus<br></li></ul>Sound like you? Ready to join a team of globally known BI experts? Apply now!<br><br><strong><em> JLL Privacy Notice <br><br></em></strong>Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.<br><br>For more information about how JLL processes your personal data, please view our Candidate Privacy Statement .<br><br>For additional details please see our career site pages for each country.<br><br>For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here .<br><br>Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com . This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page &gt; I want to work for JLL.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Business Development, Sales",Full-time,"Construction, Information Technology and Services, Financial Services"
Backend Engineer - Fraud,"San Francisco, California, United States",Patreon,2021-02-17,https://www.linkedin.com/jobs/view/backend-engineer-fraud-at-patreon-2415351574?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=LgXdk9ic7c7Qca0Oiii8HQ%3D%3D&position=18&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Feedback Loop (feedbackloop.com) is a growth-stage company whose agile research platform provides rapid consumer feedback to inform and accelerate innovation initiatives. At Feedback Loop, we change the way companies develop products for their customers by providing a platform that lets researchers and non-researchers alike learn faster and innovate smarter. We work with some of the largest B2C companies across industries including finance, insurance, healthcare, and media.

We're looking for ambitious professionals to join us as we reinvent the way companies collaborate and innovate. If you prioritize change over the status quo, progress over perfection, forgiveness over permission, and open-mindedness over ego, then we would like to hear from you.

The Feedback Loop data science team is empowered, cross-functional, and customer-driven. You'll work with talented colleagues across the product, marketing, sales, and engineering teams. Our team interfaces with customers, helping to create and refine Alpha's product vision with many of the world's largest and most respected brands. In your role as Analytics Engineer, you'll be responsible for ensuring product teams are held accountable to their outcomes and ensure the product organization is set up to scale consistently with minimal friction.

Responsibilities

Maintain and develop success metrics and quantitative dashboards for feature adoption, product engagement, sourcing, and data quality across customer segments, and report to internal stakeholders.
Conduct comprehensive analyses using the above metrics.
Build analytics pipelines for extracting data from various sources. (SQL, NoSQL, Redis, REST APIs)
Leverage scripting languages (e.g. python) and SQL to create detailed reports that improve internal efficiency and solve customer needs.
Support development of continuing education programs for product managers and internal stakeholders.


What does success look like over the next three months?

Different teams at Feedback Loop (Product, Data Science, CS) are making data-driven decisions influenced by your work.
We are tracking, storing, and analyzing all our important metrics in an accessible way.
The scripts you are generating to obtain metrics are robust and replicable.



Requirements

Experience with SQL, including schema design
Experience with Python, Ruby or JS
Experience working with REST APIs
Experience with queue (job) based architectures
Strong operational mindset and a track-record of making data-driven decisions
Ability to work in a collaboration-driven work culture, providing back-up and support to team members
Strong desire to bring clarity and definition to ambiguous requirements in a fast-paced environment
An ability to execute on and deliver complex projects involving multiple stakeholders



Benefits

Competitive Salary
Healthcare Benefits covered by the company
Stock Option Plan
401k Plan
Flexible vacation & flexible work schedule
Commuter Benefits
Autonomy and room to grow as a professional



About Us

Feedback Loop is the agile research platform for rapid consumer feedback. Farmers Insurance, Humana, Lending Tree, Uber and Fortune 500 companies trust Feedback Loop to bring the voice of the consumer into critical market decisions.

Founded as Alpha in 2014, Feedback Loop is headquartered in New York City and backed by Crosslink Capital, Spider Capital, and Calibrate Ventures.

Learn how agile research makes getting consumer input fast, easy and reliable for researchers and product managers alike at www.feedbackloop.com.

Mission: To help companies thrive by learning faster and innovating smarter.

Values:

We Embrace Agility
We Are Accountable
We Build Trust
We Work Together
We Keep Growing
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Feedback Loop (feedbackloop.com) is a growth-stage company whose agile research platform provides rapid consumer feedback to inform and accelerate innovation initiatives. At Feedback Loop, we change the way companies develop products for their customers by providing a platform that lets researchers and non-researchers alike learn faster and innovate smarter. We work with some of the largest B2C companies across industries including finance, insurance, healthcare, and media.<br><br>We're looking for ambitious professionals to join us as we reinvent the way companies collaborate and innovate. If you prioritize change over the status quo, progress over perfection, forgiveness over permission, and open-mindedness over ego, then we would like to hear from you.<br><br>The Feedback Loop data science team is empowered, cross-functional, and customer-driven. You'll work with talented colleagues across the product, marketing, sales, and engineering teams. Our team interfaces with customers, helping to create and refine Alpha's product vision with many of the world's largest and most respected brands. In your role as Analytics Engineer, you'll be responsible for ensuring product teams are held accountable to their outcomes and ensure the product organization is set up to scale consistently with minimal friction.<br><br><strong><u>Responsibilities<br></u></strong><ul> <li>Maintain and develop success metrics and quantitative dashboards for feature adoption, product engagement, sourcing, and data quality across customer segments, and report to internal stakeholders.</li> <li>Conduct comprehensive analyses using the above metrics.</li> <li>Build analytics pipelines for extracting data from various sources. (SQL, NoSQL, Redis, REST APIs)</li> <li>Leverage scripting languages (e.g. python) and SQL to create detailed reports that improve internal efficiency and solve customer needs.</li> <li>Support development of continuing education programs for product managers and internal stakeholders.</li> <br></ul><strong>What does success look like over the next three months?<br></strong><ul> <li>Different teams at Feedback Loop (Product, Data Science, CS) are making data-driven decisions influenced by your work.</li> <li>We are tracking, storing, and analyzing all our important metrics in an accessible way.</li> <li>The scripts you are generating to obtain metrics are robust and replicable.</li> <br><br></ul><strong><u>Requirements<br></u></strong><ul> <li>Experience with SQL, including schema design</li> <li>Experience with Python, Ruby or JS</li> <li>Experience working with REST APIs</li> <li>Experience with queue (job) based architectures</li> <li>Strong operational mindset and a track-record of making data-driven decisions</li> <li>Ability to work in a collaboration-driven work culture, providing back-up and support to team members</li> <li>Strong desire to bring clarity and definition to ambiguous requirements in a fast-paced environment</li> <li>An ability to execute on and deliver complex projects involving multiple stakeholders</li> <br><br></ul><strong><u>Benefits<br></u></strong><ul> <li>Competitive Salary</li> <li>Healthcare Benefits covered by the company</li> <li>Stock Option Plan</li> <li>401k Plan</li> <li>Flexible vacation &amp; flexible work schedule</li> <li>Commuter Benefits</li> <li>Autonomy and room to grow as a professional</li> <br><br></ul><strong><u>About Us<br><br></u></strong>Feedback Loop is the agile research platform for rapid consumer feedback. Farmers Insurance, Humana, Lending Tree, Uber and Fortune 500 companies trust Feedback Loop to bring the voice of the consumer into critical market decisions.<br><br>Founded as Alpha in 2014, Feedback Loop is headquartered in New York City and backed by Crosslink Capital, Spider Capital, and Calibrate Ventures.<br><br>Learn how agile research makes getting consumer input fast, easy and reliable for researchers and product managers alike at www.feedbackloop.com.<br><br>Mission: To help companies thrive by learning faster and innovating smarter.<br><br>Values:<br><ul> <li>We Embrace Agility</li> <li>We Are Accountable</li> <li>We Build Trust</li> <li>We Work Together</li> <li>We Keep Growing</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Internet"
"Software Engineer, Data Infrastructure","San Francisco, California, United States",Embark Trucks,2021-02-18,https://www.linkedin.com/jobs/view/software-engineer-data-infrastructure-at-embark-trucks-2429517348?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=An0wIUXSG%2Fb9xotqiWtOAA%3D%3D&position=19&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Do you believe that creators should have the ability to get paid for the value they give to their fans?
We do, which is why we're building Patreon, a platform that powers membership services for creators with established followings. Patreon strives to provide creators with insight, education, and tools that make it possible to retain creative control while running their creative business, so creators can focus on creating and energizing their fanbases.

Our user base has doubled in the last year alone, and we have paid over $1 billion directly to creators on our platform. In order to support this level of growth, Patreon is looking for Backend Engineer for Fraud.

What You Will Do

Design, build, deploy, and support engineering solutions to manage and fight fraud. You’ll contribute to projects from the initial design process all the way to deployment.
Write a lot of python and some javascript with robust unit and integration tests.
Collaborate with product, fraud operations, data science, payments and compliance to engineer ways to combat fraud.
Contribute at a global scale at a fast-moving, fast-growing company.
Skills and experience you possess:

You have 2+ years of experience working as a software engineer
You have an excitement for learning new things and for working with a variety of technologies in order to ship reliable code quickly
You have excellent communication skills to facilitate requirements gathering, decision-making, and knowledge sharing
You can collaborate cross-functionally. You will be working with product managers, data scientists, adjacent engineering teams, and operations teams.
You have experience working in Python and/or a similar general purpose language
You have a strong understanding of web servers and RESTful API design
You are proficient at writing well-optimized MySql database queries and can model data
You have experience shipping code quickly using CI/CD
You have a desire to write clean, easy-to-read code with a strong attention to detail
You are interested in learning or have experience with JavaScript, TypeScript, and/or React


Even if you don’t hit all these bullet points, we’d love to hear from you. Ultimately, we’re looking for someone who is excited to tackle new challenges and can learn quickly. If you’re someone who cares deeply about your work with a constant mind for improvement, you’re likely the candidate we’re looking for.

However, please note that in order to be set up for success during our initial technical screening process, you must know one of the following: Python, Ruby, Java, JS, TypeScript.

Projects You May Work On

Design, build and deploy scalable stream and graph processing systems to power model training and real-time automated decision making.
Migration of our fraud system to a separate standalone service, which will process thousands of transactions per minute, ensuring our creators and patrons are safe and secure.
Build risk checks to block in product features that require additional risk verifications.
What you will have the chance to learn about:

The design and shape of risk systems.
Fraud mitigation techniques that safeguard Patreon’s bottom line while maintaining a positive user experience.
How to build robust and reliable tools that are used extensively by an internal operations team.
Ways to empower a product that gets creators paid. You will help creators make a sustainable living and achieve higher levels of creativity.



Who You'll Work With

At Patreon, you'll join a high-performing and highly-empathetic team of people who proudly work on fulfilling our mission of funding the creative class. Our culture of creator-first, thoughtful teammates keeps work creative, stretching, and rewarding.

Our Core Behaviors

Put Creators First. Patreon is nothing without our creators.
Achieve Ambitious Outcomes. Set, measure, and accomplish goals that deliver massive value to our creators and patrons.
Cultivate Inclusion. We want an environment that retains and engages the diverse teams we build.
Bias Towards Action. When in doubt, we take the next best step, then course correct when needed. We go out of our way to fix problems when we see them. We take ownership seriously.
Be Candid and Kind. Be extremely caring and extremely direct in all you do at Patreon, especially when it comes to giving positive and constructive feedback.
Be Curious . You don’t know it all, and that’s the fun part. Everything gets better when you’re curious. Things get more interesting, more clear, and more approachable. When you bring curiosity into the workplace, you’re growing yourself, your teammates, and Patreon as a whole.


Want to learn more about Patreon?

Check out our reviews on Glassdoor
Check to see if you know a Patreon teammate on LinkedIn
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong>Do you believe that creators should have the ability to get paid for the value they give to their fans?<br></strong>We do, which is why we're building Patreon, a platform that powers membership services for creators with established followings. Patreon strives to provide creators with insight, education, and tools that make it possible to retain creative control while running their creative business, so creators can focus on creating and energizing their fanbases.<br><br>Our user base has doubled in the last year alone, and we have paid over $1 billion directly to creators on our platform. In order to support this level of growth, <strong>Patreon is looking for Backend Engineer for Fraud.<br><br></strong><strong><u>What You Will Do<br></u></strong><ul> <li> Design, build, deploy, and support engineering solutions to manage and fight fraud. You’ll contribute to projects from the initial design process all the way to deployment. </li> <li> Write a lot of python and some javascript with robust unit and integration tests. </li> <li> Collaborate with product, fraud operations, data science, payments and compliance to engineer ways to combat fraud. </li> <li> Contribute at a global scale at a fast-moving, fast-growing company. </li> </ul> <strong><strong>Skills and experience you possess:<br></strong></strong><ul> <li> You have 2+ years of experience working as a software engineer </li> <li> You have an excitement for learning new things and for working with a variety of technologies in order to ship reliable code quickly </li> <li> You have excellent communication skills to facilitate requirements gathering, decision-making, and knowledge sharing </li> <li> You can collaborate cross-functionally. You will be working with product managers, data scientists, adjacent engineering teams, and operations teams. </li> <li> You have experience working in Python and/or a similar general purpose language </li> <li> You have a strong understanding of web servers and RESTful API design </li> <li> You are proficient at writing well-optimized MySql database queries and can model data </li> <li> You have experience shipping code quickly using CI/CD </li> <li> You have a desire to write clean, easy-to-read code with a strong attention to detail </li> <li> You are interested in learning or have experience with JavaScript, TypeScript, and/or React </li> <br></ul>Even if you don’t hit all these bullet points, we’d love to hear from you. Ultimately, we’re looking for someone who is excited to tackle new challenges and can learn quickly. If you’re someone who cares deeply about your work with a constant mind for improvement, you’re likely the candidate we’re looking for.<br><br>However, please note that in order to be set up for success during our initial technical screening process, you must know one of the following: Python, Ruby, Java, JS, TypeScript.<br><br><strong><u>Projects You May Work On<br></u></strong><ul> <li> Design, build and deploy scalable stream and graph processing systems to power model training and real-time automated decision making. </li> <li> Migration of our fraud system to a separate standalone service, which will process thousands of transactions per minute, ensuring our creators and patrons are safe and secure. </li> <li> Build risk checks to block in product features that require additional risk verifications. </li> </ul> <strong><strong>What you will have the chance to learn about:<br></strong></strong><ul> <li> The design and shape of risk systems. </li> <li> Fraud mitigation techniques that safeguard Patreon’s bottom line while maintaining a positive user experience. </li> <li> How to build robust and reliable tools that are used extensively by an internal operations team. </li> <li> Ways to empower a product that gets creators paid. You will help creators make a sustainable living and achieve higher levels of creativity. </li> <br><br></ul><strong><u>Who You'll Work With<br><br></u></strong>At Patreon, you'll join a high-performing and highly-empathetic team of people who proudly work on fulfilling our mission of funding the creative class. Our culture of creator-first, thoughtful teammates keeps work creative, stretching, and rewarding.<br><br><strong><u>Our Core Behaviors<br></u></strong><ul> <li><strong>Put Creators First. </strong> Patreon is nothing without our creators. </li> <li><strong>Achieve Ambitious Outcomes. </strong> Set, measure, and accomplish goals that deliver massive value to our creators and patrons. </li> <li><strong>Cultivate Inclusion. </strong> We want an environment that retains and engages the diverse teams we build. </li> <li><strong>Bias Towards Action. </strong> When in doubt, we take the next best step, then course correct when needed. We go out of our way to fix problems when we see them. We take ownership seriously. </li> <li><strong>Be Candid and Kind. </strong> Be extremely caring and extremely direct in all you do at Patreon, especially when it comes to giving positive and constructive feedback. </li> <li><strong>Be Curious</strong> . You don’t know it all, and that’s the fun part. Everything gets better when you’re curious. Things get more interesting, more clear, and more approachable. When you bring curiosity into the workplace, you’re growing yourself, your teammates, and Patreon as a whole. </li> <br></ul><strong>Want to learn more about Patreon?<br></strong><ul> <li> Check out our reviews on Glassdoor </li> <li> Check to see if you know a Patreon teammate on LinkedIn</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Computer Software, Internet, Financial Services"
Data Scientist,"McLean, Virginia, United States",MITRE,2021-02-11,https://www.linkedin.com/jobs/view/data-scientist-at-mitre-2419744427?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=z3TdjFVkiOPgx%2B3I83q3RA%3D%3D&position=20&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Embark Trucks is a leading self-driving truck company bringing autonomous freight mainstream. We have raised $117m by partnering with Tiger Global ($70m Series C) and Sequoia Capital ($30m Series B) to help grow our team and introduce our technology to the public. Currently, we move freight daily between LA and Phoenix using our purpose-built transfer hubs. We have aligned ourselves with truck manufacturers, shippers, and carriers to integrate our technology into the freight ecosystem. This is an incredibly exciting time for autonomous vehicles and our team is looking to grow.

Data is core to everything that we do at Embark. Our fleet of self-driving trucks generate petabytes of valuable data from the road, and this data powers all of our engineering processes that enable us to deliver on our mission. From training machine learning algorithms, to generating and executing simulations in which we can measure the performance of our virtual driver across a wide variety of scenarios, to extracting insights from road data to drive our engineering decisions, data is fundamental to everything that we do, and the data engineering team builds the pipelines, architectures, APIs, and processes that power all of this.

As a data engineer, you’ll help make all of this possible.

Responsibilities

Maintain the on-vehicle code responsible for data collection, monitoring and real-time communication with our backend systems (supporting use cases such as real-time low-latency streaming of sensors such as camera and LiDAR over LTE) while also building the backend systems that power all of this.
Evaluate, architect, and deploy new database systems and data pipelines to enable our engineering team to gain richer insights into our data
Build scalable data pipelines which operate over petabytes of autonomous vehicle data to extract useful features, enable advanced queries, and power machine learning pipelines and simulation environments
Deploy, build and maintain infrastructure responsible for ingesting and processing data uploaded from our vehicles at centers across the country. This includes the software and hardware, as well as the operational processes that power the system that ingests terabytes of data daily


Preferred Experience

Significant experience with Python, C++, Go, or similar.
Experience managing large Kubernetes clusters powering microservice-oriented architectures.
Experience working with distributed data processing frameworks such as Spark and Hadoop.
Experience working with AWS and/or GCP.
Experience with relational and NoSQL databases.
Experience working with distributed message brokers like Kafka, Kinesis, or RabbitMQ.
Experience with configuration management tools such as Ansible, Puppet, or Chef.


Benefits

A full time, competitive salary with equity
Flexible paid vacation from the start
100% of the base insurance option covered for Medical, Dental, and Vision and a buy-up option for other plans
Life insurance covered by Embark
Access to a Flexible Spending Account & 401K Plan
Snacks & catered lunches
Work in a fast-growing startup revolutionizing transportation as we know it


At Embark we celebrate diversity and are committed to creating an inclusive environment for all employees.

When you apply, address the application to Jacqueline and let me know why you want to join our team.

A Few Company Highlights

Embark Blog - Series C and Transfer Hubs

Forbes - 70 Million Dollar Series C

Video - Day in the life of a self-driving truck

Embark Blog - Disengagement Report

30 Million Dollar Series B led by Sequoia

San Francisco, CA /

Engineering – Infrastructure /

Full-time
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Embark Trucks is a leading self-driving truck company bringing autonomous freight mainstream. We have raised $117m by partnering with Tiger Global ($70m Series C) and Sequoia Capital ($30m Series B) to help grow our team and introduce our technology to the public. Currently, we move freight daily between LA and Phoenix using our purpose-built transfer hubs. We have aligned ourselves with truck manufacturers, shippers, and carriers to integrate our technology into the freight ecosystem. This is an incredibly exciting time for autonomous vehicles and our team is looking to grow.<br><br>Data is core to everything that we do at Embark. Our fleet of self-driving trucks generate petabytes of valuable data from the road, and this data powers all of our engineering processes that enable us to deliver on our mission. From training machine learning algorithms, to generating and executing simulations in which we can measure the performance of our virtual driver across a wide variety of scenarios, to extracting insights from road data to drive our engineering decisions, data is fundamental to everything that we do, and the data engineering team builds the pipelines, architectures, APIs, and processes that power all of this.<br><br>As a data engineer, you’ll help make all of this possible.<br><br><strong><u>Responsibilities<br></u></strong><ul><ul><li>Maintain the on-vehicle code responsible for data collection, monitoring and real-time communication with our backend systems (supporting use cases such as real-time low-latency streaming of sensors such as camera and LiDAR over LTE) while also building the backend systems that power all of this.</li><li>Evaluate, architect, and deploy new database systems and data pipelines to enable our engineering team to gain richer insights into our data</li><li>Build scalable data pipelines which operate over petabytes of autonomous vehicle data to extract useful features, enable advanced queries, and power machine learning pipelines and simulation environments</li><li>Deploy, build and maintain infrastructure responsible for ingesting and processing data uploaded from our vehicles at centers across the country. This includes the software and hardware, as well as the operational processes that power the system that ingests terabytes of data daily<br><br></li></ul></ul><strong><u>Preferred Experience<br></u></strong><ul><ul><li>Significant experience with Python, C++, Go, or similar.</li><li>Experience managing large Kubernetes clusters powering microservice-oriented architectures.</li><li>Experience working with distributed data processing frameworks such as Spark and Hadoop.</li><li>Experience working with AWS and/or GCP.</li><li>Experience with relational and NoSQL databases.</li><li>Experience working with distributed message brokers like Kafka, Kinesis, or RabbitMQ.</li><li>Experience with configuration management tools such as Ansible, Puppet, or Chef.<br><br></li></ul></ul><strong><u>Benefits<br></u></strong><ul><ul><li>A full time, competitive salary with equity</li><li>Flexible paid vacation from the start</li><li>100% of the base insurance option covered for Medical, Dental, and Vision and a buy-up option for other plans</li><li>Life insurance covered by Embark</li><li>Access to a Flexible Spending Account &amp; 401K Plan</li><li>Snacks &amp; catered lunches</li><li>Work in a fast-growing startup revolutionizing transportation as we know it<br><br></li></ul></ul><em>At Embark we celebrate diversity and are committed to creating an inclusive environment for all employees.<br><br></em>When you apply, address the application to Jacqueline and let me know why you want to join our team.<br><br><strong><u>A Few Company Highlights<br><br></u></strong>Embark Blog - Series C and Transfer Hubs<br><br>Forbes - 70 Million Dollar Series C<br><br>Video - Day in the life of a self-driving truck<br><br>Embark Blog - Disengagement Report<br><br>30 Million Dollar Series B led by Sequoia<br><br>San Francisco, CA /<br><br>Engineering – Infrastructure /<br><br>Full-time</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Computer Software, Internet"
Data Engineer,"Ann Arbor, Michigan, United States",May Mobility,2021-01-23,https://www.linkedin.com/jobs/view/data-engineer-at-may-mobility-2392071954?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=ipu%2B%2B8CIZSWNPW0kq6XptQ%3D%3D&position=21&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"Why choose between doing meaningful work and having a fulfilling life? At MITRE, you can have both. That's because MITRE people are committed to tackling our nation's toughest challenges—and we're committed to the long-term well-being of our employees. MITRE is different from most technology companies. We are a not-for-profit corporation chartered to work for the public interest, with no commercial conflicts to influence what we do. The R&D centers we operate for the government create lasting impact in fields as diverse as cybersecurity, healthcare, aviation, defense, and enterprise transformation. We're making a difference every day—working for a safer, healthier, and more secure nation and world. Our workplace reflects our values. We offer competitive benefits, exceptional professional development opportunities, and a culture of innovation that embraces diversity, inclusion, flexibility, collaboration, and career growth. If this sounds like the choice you want to make, then choose MITRE—and make a difference with us.

The System Engineering Analytics Department is seeking a motivated, creative Data Scientist to apply cutting edge tools and techniques to challenging problems facing the US government. This position offers the opportunity to combine systems Engineering with Data Analytics to build end to end data analytic pipelines. You will have the opportunity to learn from seasoned data professionals in a fast paced and dynamic atmosphere. You will have the opportunity to make strategic differences and have real long-term impacts on some of the most challenging problems in the government space.

The Successful Candidate Will

Be passionate about applying data analytics to real world problems.
Have an innate curiosity and interest in developing research questions and testing hypotheses with open ended tasking.
Work with a spectrum of government sponsors to gain understanding of their challenges, evaluate possible solutions and conduct insightful, actionable analyses.
Support the development and application of a variety of analytical models to sponsor challenges, with a willingness to adapt and learn.
Present results in an intuitive, actionable manner that can be understood by all sponsor audiences, regardless of technical expertise.

Basic Qualifications

Bachelor's Degree in Computer Science, Computer Engineering, Mathematics, Statistics, Systems Engineering, Software Engineering, or related field
2 + years applicable work experience or equivalent academic / internships

Required Qualifications

Must be a U.S. citizen with ability to possess and maintain a DoD clearance
Proficiency in use of Microsoft Office including Outlook, Excel, and Word
Must have demonstrated proficiency and strength in verbal, written, PC, presentation, and communications skills
Demonstrated ability to manipulate large datasets
Experience with analytic tools such as Python, SAS, MATLAB, JavaScript, R, Java
Data Visualization tools such as Tableau, OBIEE, C#, JQuery
Ability to formulate complex algorithms and process to solve complex data problems

Preferred Qualifications

Advanced degree in technical field of study
Candidates that possess a current/active US Government clearance are preferred
Undergraduate research experience is a plus
Academic/ project experience working with databases (e.g., Oracle, MySQL, SQL Server, MongoDB)
Software Development experience in a shared environment leveraging tools such as GIT

This Requisition Requires The Following Clearance(s)

MITRE is proud to be an equal opportunity employer. MITRE recruits, employs, trains, compensates, and promotes regardless of race, religion, color, national origin, gender, gender expression, sexual identity, disability, age, veteran status, and other protected status.

MITRE intends to maintain a website that is fully accessible to all individuals. If you are unable to search or apply for jobs and would like to request a reasonable accommodation for any part of MITRE’s employment process, please contact MITRE’s Recruiting Help Line at 703-983-8226 or email at recruitinghelp@mitre.org.

Copyright © 1997-2021, The MITRE Corporation. All rights reserved. MITRE is a registered trademark of The MITRE Corporation. Material on this site may be copied and distributed with permission only.
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5"">Why choose between doing meaningful work and having a fulfilling life? At MITRE, you can have both. That's because MITRE people are committed to tackling our nation's toughest challenges—and we're committed to the long-term well-being of our employees. MITRE is different from most technology companies. We are a not-for-profit corporation chartered to work for the public interest, with no commercial conflicts to influence what we do. The R&amp;D centers we operate for the government create lasting impact in fields as diverse as cybersecurity, healthcare, aviation, defense, and enterprise transformation. We're making a difference every day—working for a safer, healthier, and more secure nation and world. Our workplace reflects our values. We offer competitive benefits, exceptional professional development opportunities, and a culture of innovation that embraces diversity, inclusion, flexibility, collaboration, and career growth. If this sounds like the choice you want to make, then choose MITRE—and make a difference with us.<br><br>The System Engineering Analytics Department is seeking a motivated, creative Data Scientist to apply cutting edge tools and techniques to challenging problems facing the US government. This position offers the opportunity to combine systems Engineering with Data Analytics to build end to end data analytic pipelines. You will have the opportunity to learn from seasoned data professionals in a fast paced and dynamic atmosphere. You will have the opportunity to make strategic differences and have real long-term impacts on some of the most challenging problems in the government space.<br><br><strong><u>The Successful Candidate Will<br></u></strong><ul><li> Be passionate about applying data analytics to real world problems.</li><li> Have an innate curiosity and interest in developing research questions and testing hypotheses with open ended tasking.</li><li> Work with a spectrum of government sponsors to gain understanding of their challenges, evaluate possible solutions and conduct insightful, actionable analyses.</li><li> Support the development and application of a variety of analytical models to sponsor challenges, with a willingness to adapt and learn.</li><li> Present results in an intuitive, actionable manner that can be understood by all sponsor audiences, regardless of technical expertise.<br></li></ul><strong><u>Basic Qualifications<br></u></strong><ul><li> Bachelor's Degree in Computer Science, Computer Engineering, Mathematics, Statistics, Systems Engineering, Software Engineering, or related field</li><li> 2 + years applicable work experience or equivalent academic / internships<br></li></ul><strong><u>Required Qualifications<br></u></strong><ul><li> Must be a U.S. citizen with ability to possess and maintain a DoD clearance</li><li> Proficiency in use of Microsoft Office including Outlook, Excel, and Word</li><li> Must have demonstrated proficiency and strength in verbal, written, PC, presentation, and communications skills</li><li> Demonstrated ability to manipulate large datasets</li><li> Experience with analytic tools such as Python, SAS, MATLAB, JavaScript, R, Java</li><li> Data Visualization tools such as Tableau, OBIEE, C#, JQuery</li><li> Ability to formulate complex algorithms and process to solve complex data problems<br></li></ul><strong><u>Preferred Qualifications<br></u></strong><ul><li> Advanced degree in technical field of study</li><li> Candidates that possess a current/active US Government clearance are preferred</li><li> Undergraduate research experience is a plus</li><li> Academic/ project experience working with databases (e.g., Oracle, MySQL, SQL Server, MongoDB)</li><li> Software Development experience in a shared environment leveraging tools such as GIT<br></li></ul><strong><u>This Requisition Requires The Following Clearance(s)<br><br></u></strong>MITRE is proud to be an equal opportunity employer. MITRE recruits, employs, trains, compensates, and promotes regardless of race, religion, color, national origin, gender, gender expression, sexual identity, disability, age, veteran status, and other protected status.<br><br>MITRE intends to maintain a website that is fully accessible to all individuals. If you are unable to search or apply for jobs and would like to request a reasonable accommodation for any part of MITRE’s employment process, please contact MITRE’s Recruiting Help Line at 703-983-8226 or email at recruitinghelp@mitre.org.<br><br>Copyright © 1997-2021, The MITRE Corporation. All rights reserved. MITRE is a registered trademark of The MITRE Corporation. Material on this site may be copied and distributed with permission only.</div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,"Engineering, Information Technology",Full-time,"Information Technology and Services, Defense & Space, Computer Software"
Data Scientist,"Charlotte, North Carolina, United States",NTT DATA Services,2021-02-17,https://www.linkedin.com/jobs/view/data-scientist-at-ntt-data-services-2416408140?refId=fe31c625-c857-45d1-a506-3fcba725ecd3&trackingId=GYg6YPVhdhVLGlRkpAveoA%3D%3D&position=22&pageNum=14&trk=public_jobs_job-result-card_result-card_full-click,"About May Mobility

May Mobility is a self-driving technology company working to transform today's mobility landscape, by starting with a niche market–low-speed shuttles for public roadways. Our vehicles are on the streets navigating complex downtown scenarios and transporting thousands of people on their daily commute every week. We are establishing a ground game that will propel us into even larger markets in the future.

Based in Ann Arbor, Michigan, our team develops driverless technology to give people more time to laugh with friends, to solve an interesting problem, or to enjoy the world around them. We're hiring people who share our passion for building the future, today.

Software @ May Mobility

May Software Engineers are changing how the world moves. Whether they're writing software to communicate with our vehicles, improving tooling for autonomy, automating cloud infrastructure for our data processing, or creating experiences for customers, our software engineers think with a systems level view towards making autonomous vehicles a reality today.

Our code base is largely built on Python and C, but we also develop in Javascript, Groovy, HTML, and more. We welcome engineers from a variety of backgrounds as long as they are comfortable working in one of our primary languages or are willing to learn. Because safety and reliability are our top priorities, we have a very high bar for software quality, testability, and maintainability.

Software and Data Infrastructure Team

The SDI Team is a key enabler of the May Mobility mission, operationalizing the experience of using autonomous technology for real people on real routes. We leverage automation and DevOps culture to build cloud infrastructure and developer productivity tools at scale. We provide the data backbone of the company, from raw log data on vehicles to consumers with varying needs. We build experiences for internal teams managing the fleet, external customers and passengers. Members of this tight-knit group act as a force multiplier for the company.

Your Opportunity to Drive Success

Build state-of-art data distribution, storage and analysis platforms powering experiences for internal and external customers
Manage and scale our real-time and historical data pipelines to enable our fleet to operate and facilitate continuous development of our system
Contribute to designing and implement data models for optimal storage and retrieval meeting requirements of stakeholders with different needs
Define, build, and expand libraries and APIs for managing, searching, and analyzing vehicle datasets with internal and external partners
Participate in new technology introduction initiatives for modern data tools and industry best practices


Required Qualifications:

B.S. Degree in Computer Science, Computer Engineering, or an equivalent degree and 2+ years of industry experience
Hands-on experience with distributed technology such as Kafka, Spark, Spark Streaming, Storm, Flink, Cassandra
Strong working knowledge of data structures and algorithms
Experience in an object oriented programming language, such as C++, Python, or Java
Attention to detail and rigorous testing methodology
Written and verbal communication skills
Experience with robotics, automotive engineering, or start-ups is not required
Ability to undergo a driving record check


Desirable Qualifications:

M.S. Degree in Computer Science, Computer Engineering and 2+ years of industry experience
Expertise in Python, C/C++ or Java
Experience building and managing large-scale data-processing pipelines in a cloud environment
Working knowledge of telemetry systems and real-time data processing



Benefits And Perks

Competitive salary and benefits (medical / dental / vision / 401k)
Meaningful stock incentives and equity refresh program
Unlimited vacation / company paid holidays
Daily catered lunches and snacks
Paid parental leave
Show moreShow less","<div class=""description__text description__text--rich""><section data-max-lines=""5"" class=""show-more-less-html show-more-less-html--hide-buttons""><div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5""><strong><u>About May Mobility<br><br></u></strong>May Mobility is a self-driving technology company working to transform today's mobility landscape, by starting with a niche market–low-speed shuttles for public roadways. Our vehicles are on the streets navigating complex downtown scenarios and transporting thousands of people on their daily commute every week. We are establishing a ground game that will propel us into even larger markets in the future.<br><br>Based in Ann Arbor, Michigan, our team develops driverless technology to give people more time to laugh with friends, to solve an interesting problem, or to enjoy the world around them. We're hiring people who share our passion for building the future, today.<br><br><strong>Software @ May Mobility<br><br></strong>May Software Engineers are changing how the world moves. Whether they're writing software to communicate with our vehicles, improving tooling for autonomy, automating cloud infrastructure for our data processing, or creating experiences for customers, our software engineers think with a systems level view towards making autonomous vehicles a reality today.<br><br>Our code base is largely built on Python and C, but we also develop in Javascript, Groovy, HTML, and more. We welcome engineers from a variety of backgrounds as long as they are comfortable working in one of our primary languages or are willing to learn. Because safety and reliability are our top priorities, we have a very high bar for software quality, testability, and maintainability.<br><br><strong>Software and Data Infrastructure Team<br><br></strong>The SDI Team is a key enabler of the May Mobility mission, operationalizing the experience of using autonomous technology for real people on real routes. We leverage automation and DevOps culture to build cloud infrastructure and developer productivity tools at scale. We provide the data backbone of the company, from raw log data on vehicles to consumers with varying needs. We build experiences for internal teams managing the fleet, external customers and passengers. Members of this tight-knit group act as a force multiplier for the company.<br><br><strong>Your Opportunity to Drive Success<br></strong><ul> <li>Build state-of-art data distribution, storage and analysis platforms powering experiences for internal and external customers</li> <li>Manage and scale our real-time and historical data pipelines to enable our fleet to operate and facilitate continuous development of our system</li> <li>Contribute to designing and implement data models for optimal storage and retrieval meeting requirements of stakeholders with different needs</li> <li>Define, build, and expand libraries and APIs for managing, searching, and analyzing vehicle datasets with internal and external partners</li> <li>Participate in new technology introduction initiatives for modern data tools and industry best practices</li> <br></ul><strong>Required Qualifications:<br></strong><ul> <li>B.S. Degree in Computer Science, Computer Engineering, or an equivalent degree and 2+ years of industry experience</li> <li>Hands-on experience with distributed technology such as Kafka, Spark, Spark Streaming, Storm, Flink, Cassandra</li> <li>Strong working knowledge of data structures and algorithms</li> <li>Experience in an object oriented programming language, such as C++, Python, or Java</li> <li>Attention to detail and rigorous testing methodology</li> <li>Written and verbal communication skills</li> <li>Experience with robotics, automotive engineering, or start-ups is not required</li> <li>Ability to undergo a driving record check</li> <br></ul><strong>Desirable Qualifications:<br></strong><ul> <li>M.S. Degree in Computer Science, Computer Engineering and 2+ years of industry experience</li> <li>Expertise in Python, C/C++ or Java</li> <li>Experience building and managing large-scale data-processing pipelines in a cloud environment</li> <li>Working knowledge of telemetry systems and real-time data processing</li> <br><br></ul><strong><u>Benefits And Perks<br></u></strong><ul> <li>Competitive salary and benefits (medical / dental / vision / 401k)</li> <li>Meaningful stock incentives and equity refresh program</li> <li>Unlimited vacation / company paid holidays</li> <li>Daily catered lunches and snacks</li> <li>Paid parental leave</li></ul></div><button aria-expanded=""false"" aria-label=""Show more"" data-tracking-control-name=""public_jobs_show-more-html-btn"" class=""show-more-less-html__button show-more-less-html__button--more"">Show more<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-down.svg"" class=""show-more-less-html__button-icon""></icon></button><button aria-expanded=""true"" aria-label=""Show less"" data-tracking-control-name=""public_jobs_show-less-html-btn"" class=""show-more-less-html__button show-more-less-html__button--less"">Show less<icon data-delayed-url=""https://static-exp1.licdn.com/sc/p/com.linkedin.jobs-guest-frontend%3Ajobs-guest-frontend-static-content%2B2.0.13/f/%2Fjobs-guest-frontend%2Fguest-ui-lib%2Fstatic%2Fimages%2Fsvg-for-lazyloading%2Ficon-chevron-up.svg"" class=""show-more-less-html__button-icon""></icon></button></section></div>",Entry level,Information Technology,Full-time,"Information Technology and Services, Computer Software, Automotive"
